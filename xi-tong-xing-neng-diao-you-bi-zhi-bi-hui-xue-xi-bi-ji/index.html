<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="keywords" content="《系统性能调优必知必会》学习笔记, kiba, zen, amor, kibazen, kibaamor, 木叶, 木叶禅">
    <meta name="description" content="一个普通游戏程序员的博客">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>《系统性能调优必知必会》学习笔记 | 木叶禅</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/css/my.css">

    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="木叶禅" type="application/atom+xml">
</head>



   <style>
    body{
       background-image: url(/medias/background.jpg);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>



<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">木叶禅</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/leetcode/" class="waves-effect waves-light">
      
      <i class="fas fa-code" style="zoom: 0.6;"></i>
      
      <span>LeetCode</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/learn/" class="waves-effect waves-light">
      
      <i class="fas fa-book" style="zoom: 0.6;"></i>
      
      <span>学习</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tool/" class="waves-effect waves-light">
      
      <i class="fas fa-toolbox" style="zoom: 0.6;"></i>
      
      <span>工具</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories/" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags/" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about/" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">木叶禅</div>
        <div class="logo-desc">
            
            一个普通游戏程序员的博客
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/leetcode/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-code"></i>
			
			LeetCode
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/learn/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-book"></i>
			
			学习
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tool/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-toolbox"></i>
			
			工具
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    
<script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = 'f65e070788a2647953051a7a1b70ada7fd2b3f70cd4d93c977207f5b762987d4';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/featureimages/5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">《系统性能调优必知必会》学习笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">
                                <span class="chip bg-color">极客时间</span>
                            </a>
                        
                            <a href="/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">
                                <span class="chip bg-color">性能优化</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-category">
                                学习笔记
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-01-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2022-01-11
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    19.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    69 分
                </div>
                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <blockquote>
<p>对应GitHub仓库：<a target="_blank" rel="noopener" href="https://github.com/russelltao/geektime_distrib_perf">https://github.com/russelltao/geektime_distrib_perf</a></p>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1645793">面试官：换人！他连 TCP 这几个参数都不懂</a></p>
</blockquote>
<h2 id="一、开篇词"><a href="#一、开篇词" class="headerlink" title="一、开篇词"></a>一、开篇词</h2><h3 id="0-开篇词-万变不离其宗，性能优化也有章可循"><a href="#0-开篇词-万变不离其宗，性能优化也有章可循" class="headerlink" title="0 开篇词 | 万变不离其宗，性能优化也有章可循"></a>0 开篇词 | 万变不离其宗，性能优化也有章可循</h3><p>一份系统性能优化核心关注点的知识脑图：</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/系统性能优化脑图.jpg" alt="系统性能优化脑图"></p>
<p>通过这份脑图，你会发现，我是从 4 个方面来梳理的，这其实就是我们在提升一个新系统的性能时，可以入手的 4 个层次。</p>
<p>首先，你可以从提升单机进程的性能入手，包括高效地使用主机的 CPU、内存、磁盘等硬件，通过并发编程提升吞吐量，根据业务特性选择合适的算法。</p>
<p>其次，分布式系统是由各个组件通过网络连接在一起，所以优化传输层网络可以让所有组件同时受益。具体优化时，你可以从降低请求的时延，提升总体吞吐量两个方向入手。</p>
<p>再次呢，你要对业务消息采用更高效的编码方式，这既包括协议头、包体的优化，也包括 TLS 安全层的性能提升。具体优化时，既要深入静态编码，也要从动态的增量编码上优化。同时，调整消息的交互方式也能提升性能。</p>
<p>最后，我们再从集群整体上进行架构层面的优化。基于 ACP、AKF、NWR 等分布式理论，我们的优化方向仍然是降低时延和提升吞吐量，但实现方式则要运用分而治之的思想，调度集群中的所有结点协作配合，完成性能优化目标。</p>
<h2 id="二、基础设施优化"><a href="#二、基础设施优化" class="headerlink" title="二、基础设施优化"></a>二、基础设施优化</h2><h3 id="01-CPU缓存：怎样写代码能够让CPU执行得更快？"><a href="#01-CPU缓存：怎样写代码能够让CPU执行得更快？" class="headerlink" title="01 | CPU缓存：怎样写代码能够让CPU执行得更快？"></a>01 | CPU缓存：怎样写代码能够让CPU执行得更快？</h3><h4 id="1-1-CPU-的多级缓存"><a href="#1-1-CPU-的多级缓存" class="headerlink" title="1.1 CPU 的多级缓存"></a>1.1 CPU 的多级缓存</h4><p>CPU 缓存通常分为大小不等的三级缓存。</p>
<p>CPU 缓存的材质 SRAM 比内存使用的 DRAM 贵许多，所以不同于内存动辄以 GB 计算，它的大小是以 MB 来计算的。比如，在我的 Linux 系统上，离 CPU 最近的一级缓存是 32KB，二级缓存是 256KB，最大的三级缓存则是 20MB（Windows 系统查看缓存大小可以用 wmic cpu 指令，或者用CPU-Z这个工具）。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/Linux下CPU缓存大小示例.png" alt="Linux下CPU缓存大小示例"></p>
<p>你可能注意到，三级缓存要比一、二级缓存大许多倍，这是因为当下的 CPU 都是多核心的，每个核心都有自己的一、二级缓存，但三级缓存却是一颗 CPU 上所有核心共享的。</p>
<p>程序执行时，会先将内存中的数据载入到共享的三级缓存中，再进入每颗核心独有的二级缓存，最后进入最快的一级缓存，之后才会被 CPU 使用，就像下面这张图。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/CPU的缓存架构.jpg" alt="CPU的缓存架构"></p>
<p>缓存要比内存快很多。CPU 访问一次内存通常需要 100 个时钟周期以上，而访问一级缓存只需要 4~5 个时钟周期，二级缓存大约 12 个时钟周期，三级缓存大约 30 个时钟周期（对于 2GHZ 主频的 CPU 来说，一个时钟周期是 0.5 纳秒。你可以在 LZMA 的Benchmark中找到几种典型 CPU 缓存的访问速度）。</p>
<p>如果 CPU 所要操作的数据在缓存中，则直接读取，这称为缓存命中。命中缓存会带来很大的性能提升，<strong>因此，我们的代码优化目标是提升 CPU 缓存的命中率。</strong></p>
<p>当然，缓存命中率是很笼统的，具体优化时还得一分为二。比如，你在查看 CPU 缓存时会发现有 2 个一级缓存（比如 Linux 上就是上图中的 index0 和 index1），这是因为，CPU 会区别对待指令与数据。比如，“1+1=2”这个运算，“+”就是指令，会放在一级指令缓存中，而“1”这个输入数字，则放在一级数据缓存中。虽然在冯诺依曼计算机体系结构中，代码指令与数据是放在一起的，但执行时却是分开进入指令缓存与数据缓存的，因此我们要分开来看二者的缓存命中率。</p>
<h4 id="1-2-提升数据缓存的命中率"><a href="#1-2-提升数据缓存的命中率" class="headerlink" title="1.2 提升数据缓存的命中率"></a>1.2 提升数据缓存的命中率</h4><p>我们先来看数据的访问顺序是如何影响缓存命中率的。</p>
<p>比如现在要遍历二维数组，其定义如下：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> array<span class="token punctuation">[</span>N<span class="token punctuation">]</span><span class="token punctuation">[</span>N<span class="token punctuation">]</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>你可以思考一下，用 array[j][i]和 array[i][j]访问数组元素，哪一种性能更快？</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">for</span><span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">+=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span>j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> j<span class="token operator">+=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        array<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在我给出的 GitHub 地址上的 C++ 代码实现中，前者 array[j][i]执行的时间是后者 array[i][j]的 8 倍之多（请参考 <a target="_blank" rel="noopener" href="https://github.com/russelltao/geektime_distrib_perf/blob/master/1-cpu_cache/traverse_2d_array/traverse_2d_array.cpp">traverse_2d_array.cpp</a> ，如果使用 Python 代码，traverse_2d_array.py 由于数组容器的差异，性能差距不会那么大）。</p>
<p>为什么会有这么大的差距呢？这是因为二维数组 array 所占用的内存是连续的，比如若长度 N 的值为 2，那么内存中从前至后各元素的顺序是：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">array[0][0]，array[0][1]，array[1][0]，array[1][1]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>如果用 array[i][j]访问数组元素，则完全与上述内存中元素顺序一致，因此访问 array[0][0]时，缓存已经把紧随其后的 3 个元素也载入了，CPU 通过快速的缓存来读取后续 3 个元素就可以。如果用 array[j][i]来访问，访问的顺序就是：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">array[0][0]，array[1][0]，array[0][1]，array[1][1]<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>此时内存是跳跃访问的，如果 N 的数值很大，那么操作 array[j][i]时，是没有办法把 array[j+1][i]也读入缓存的。</p>
<p>到这里我们还有 2 个问题没有搞明白：</p>
<ol>
<li>为什么两者的执行时间有约 7、8 倍的差距呢？</li>
<li>载入 array[0][0]元素时，缓存一次性会载入多少元素呢？</li>
</ol>
<p>其实这两个问题的答案都与 CPU Cache Line 相关，它定义了缓存一次载入数据的大小，Linux 上你可以通过 coherency_line_size 配置查看它，通常是 64 字节。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">cat</span> /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size
<span class="token number">64</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>因此，我测试的服务器一次会载入 64 字节至缓存中。当载入 array[0][0]时，若它们占用的内存不足 64 字节，CPU 就会顺序地补足后续元素。顺序访问的 array[i][j]因为利用了这一特点，所以就会比 array[j][i]要快。也正因为这样，当元素类型是 4 个字节的整数时，性能就会比 8 个字节的高精度浮点数时速度更快，因为缓存一次载入的元素会更多。</p>
<p><strong>因此，遇到这种遍历访问数组的情况时，按照内存布局顺序访问将会带来很大的性能提升。</strong></p>
<p>再来看为什么执行时间相差 8 倍。在二维数组中，其实第一维元素存放的是地址，第二维存放的才是目标元素。由于 64 位操作系统的地址占用 8 个字节（32 位操作系统是 4 个字节），因此，每批 Cache Line 最多也就能载入不到 8 个二维数组元素，所以性能差距大约接近 8 倍。（用不同的步长访问数组，也能验证 CPU Cache Line 对性能的影响，可参考我给你准备的Github上的测试代码）。</p>
<p>关于 CPU Cache Line 的应用其实非常广泛，如果你用过 Nginx，会发现它是用哈希表来存放域名、HTTP 头部等数据的，这样访问速度非常快，而哈希表里桶的大小如 server_names_hash_bucket_size，它默认就等于 CPU Cache Line 的值。由于所存放的字符串长度不能大于桶的大小，所以当需要存放更长的字符串时，就需要修改桶大小，但 Nginx 官网上明确建议它应该是 CPU Cache Line 的整数倍。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/server_names_hash_bucket_size.png" alt="server_names_hash_bucket_size"></p>
<p>为什么要做这样的要求呢？就是因为缓存是按照 64 字节的整数倍来访问内存的，哈希表的桶按此大小排列布局，就可以尽量减少访问内存的次数。比如，若桶大小为 64 字节，那么根据地址获取字符串时只需要访问一次内存，而桶大小为 50 字节，会导致最坏 2 次访问内存，而 70 字节最坏会有 3 次访问内存。</p>
<p>如果你在用 Linux 操作系统，可以通过一个名叫 Perf 的工具直观地验证缓存命中的情况。</p>
<p>执行 perf stat 可以统计出进程运行时的系统信息（通过 -e 选项指定要统计的事件，如果要查看三级缓存总的命中率，可以指定缓存未命中 cache-misses 事件，以及读取缓存次数 cache-references 事件，两者相除就是缓存的未命中率，用 1 相减就是命中率。类似的，通过 L1-dcache-load-misses 和 L1-dcache-loads 可以得到 L1 缓存的命中率），此时你会发现 array[i][j]的缓存命中率远高于 array[j][i]。</p>
<p>当然，perf stat 还可以通过指令执行速度反映出两种访问方式的优劣，如下图所示（instructions 事件指明了进程执行的总指令数，而 cycles 事件指明了运行的时钟周期，二者相除就可以得到每时钟周期所执行的指令数，缩写为 IPC。如果缓存未命中，则 CPU 要等待内存的慢速读取，因此 IPC 就会很低。array[i][j]的 IPC 值也比 array[j][i]要高得多）：</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/指令执行速度一.png" alt="指令执行速度一"></p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/指令执行速度二.png" alt="指令执行速度二"></p>
<h4 id="1-3-提升指令缓存的命中率"><a href="#1-3-提升指令缓存的命中率" class="headerlink" title="1.3 提升指令缓存的命中率"></a>1.3 提升指令缓存的命中率</h4><p>我们还是用一个例子来看一下。比如，有一个元素为 0 到 255 之间随机数字组成的数组：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> array<span class="token punctuation">[</span>N<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> TESTN<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> array<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">rand</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">256</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>接下来要对它做两个操作：一是循环遍历数组，判断每个数字是否小于 128，如果小于则把元素的值置为 0；二是将数组排序。那么，先排序再遍历速度快，还是先遍历再排序速度快呢？</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">for</span><span class="token punctuation">(</span>i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>array <span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token number">128</span><span class="token punctuation">)</span> array<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token function">sort</span><span class="token punctuation">(</span>array<span class="token punctuation">,</span> array <span class="token operator">+</span>N<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>我先给出答案：先排序的遍历时间只有后排序的三分之一（参考 GitHub 中的 <a target="_blank" rel="noopener" href="https://github.com/russelltao/geektime_distrib_perf/blob/master/1-cpu_cache/branch_predict/branch_predict.cpp">branch_predict.cpp</a> 代码）。为什么会这样呢？这是因为循环中有大量的 if 条件分支，而 CPU含有分支预测器。</p>
<p>当代码中出现 if、switch 等语句时，意味着此时至少可以选择跳转到两段不同的指令去执行。如果分支预测器可以预测接下来要在哪段代码执行（比如 if 还是 else 中的指令），就可以提前把这些指令放在缓存中，CPU 执行时就会很快。当数组中的元素完全随机时，分支预测器无法有效工作，而当 array 数组有序时，分支预测器会动态地根据历史命中数据对未来进行预测，命中率就会非常高。</p>
<p>究竟有多高呢？我们还是用 Linux 上的 perf 来做个验证。使用 -e 选项指明 branch-loads 事件和 branch-load-misses 事件，它们分别表示分支预测的次数，以及预测失败的次数。通过 L1-icache-load-misses 也能查看到一级缓存中指令的未命中情况。</p>
<p>下图是我在 GitHub 上为你准备的验证程序执行的 perf 分支预测统计数据（代码见这里），你可以看到，先排序的话分支预测的成功率非常高，而且一级指令缓存的未命中率也有大幅下降。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/分支预测统计数据一.png" alt="分支预测统计数据一"></p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/分支预测统计数据二.png" alt="分支预测统计数据二"></p>
<p>C/C++ 语言中编译器还给应用程序员提供了显式预测分支概率的工具，如果 if 中的条件表达式判断为“真”的概率非常高，我们可以用 likely 宏把它括在里面，反之则可以用 unlikely 宏。当然，CPU 自身的条件预测已经非常准了，仅当我们确信 CPU 条件预测不会准，且我们能够知晓实际概率时，才需要加入这两个宏。</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token expression"><span class="token function">likely</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token function">__builtin_expect</span><span class="token punctuation">(</span><span class="token operator">!</span><span class="token operator">!</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token expression"><span class="token function">unlikely</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token function">__builtin_expect</span><span class="token punctuation">(</span><span class="token operator">!</span><span class="token operator">!</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></span></span>
<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">likely</span><span class="token punctuation">(</span>a <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> …<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h4 id="1-4-提升多核-CPU-下的缓存命中率"><a href="#1-4-提升多核-CPU-下的缓存命中率" class="headerlink" title="1.4 提升多核 CPU 下的缓存命中率"></a>1.4 提升多核 CPU 下的缓存命中率</h4><p>前面我们都是面向一个 CPU 核心谈数据及指令缓存的，然而现代 CPU 几乎都是多核的。虽然三级缓存面向所有核心，但一、二级缓存是每颗核心独享的。我们知道，即使只有一个 CPU 核心，现代分时操作系统都支持许多进程同时运行。这是因为操作系统把时间切成了许多片，微观上各进程按时间片交替地占用 CPU，这造成宏观上看起来各程序同时在执行。</p>
<p>因此，若进程 A 在时间片 1 里使用 CPU 核心 1，自然也填满了核心 1 的一、二级缓存，当时间片 1 结束后，操作系统会让进程 A 让出 CPU，基于效率并兼顾公平的策略重新调度 CPU 核心 1，以防止某些进程饿死。如果此时 CPU 核心 1 繁忙，而 CPU 核心 2 空闲，则进程 A 很可能会被调度到 CPU 核心 2 上运行，这样，即使我们对代码优化得再好，也只能在一个时间片内高效地使用 CPU 一、二级缓存了，下一个时间片便面临着缓存效率的问题。</p>
<p>因此，操作系统提供了将进程或者线程绑定到某一颗 CPU 上运行的能力。如 Linux 上提供了 sched_setaffinity 方法实现这一功能，其他操作系统也有类似功能的 API 可用。我在 GitHub 上提供了一个示例程序（代码见 <a target="_blank" rel="noopener" href="https://github.com/russelltao/geektime_distrib_perf/blob/master/1-cpu_cache/cpu_migrate/cpu_migrate.cpp">这里</a> ），你可以看到，当多线程同时执行密集计算，且 CPU 缓存命中率很高时，如果将每个线程分别绑定在不同的 CPU 核心上，性能便会获得非常可观的提升。Perf 工具也提供了 cpu-migrations 事件，它可以显示进程从不同的 CPU 核心上迁移的次数。</p>
<h4 id="1-5-小结"><a href="#1-5-小结" class="headerlink" title="1.5 小结"></a>1.5 小结</h4><p>CPU 缓存分为数据缓存与指令缓存，对于数据缓存，我们应在循环体中尽量操作同一块内存上的数据，由于缓存是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时也有性能提升。</p>
<p>对于指令缓存，有规律的条件分支能够让 CPU 的分支预测发挥作用，进一步提升执行效率。对于多核系统，如果进程的缓存命中率非常高，则可以考虑绑定 CPU 来提升缓存命中率。</p>
<h3 id="02-内存池：如何提升内存分配的效率？"><a href="#02-内存池：如何提升内存分配的效率？" class="headerlink" title="02 | 内存池：如何提升内存分配的效率？"></a>02 | 内存池：如何提升内存分配的效率？</h3><p>在 Linux 系统中，用 Xmx 设置 JVM 的最大堆内存为 8GB，但在近百个并发线程下，观察到 Java 进程占用了 14GB 的内存。为什么会这样呢？</p>
<p>这是因为，绝大部分高级语言都是用 C 语言编写的，包括 Java，申请内存必须经过 C 库，而 C 库通过预分配更大的空间作为内存池，来加快后续申请内存的速度。这样，预分配的 6GB 的 C 库内存池就与 JVM 中预分配的 8G 内存池叠加在一起，造成了 Java 进程的内存占用超出了预期。</p>
<h4 id="2-1-隐藏的内存池"><a href="#2-1-隐藏的内存池" class="headerlink" title="2.1 隐藏的内存池"></a>2.1 隐藏的内存池</h4><p>当代码申请内存时，首先会到达应用层内存池，如果应用层内存池有足够的可用内存，就会直接返回给业务代码，否则，它会向更底层的 C 库内存池申请内存。比如，如果你在 Apache、Nginx 等服务之上做模块开发，这些服务中就有独立的内存池。当然，Java 中也有内存池，当通过启动参数 Xmx 指定 JVM 的堆内存为 8GB 时，就设定了 JVM 堆内存池的大小。</p>
<p>你可能听说过 Google 的 TCMalloc 和 FaceBook 的 JEMalloc，它们也是 C 库内存池。当 C 库内存池无法满足内存申请时，才会向操作系统内核申请分配内存。如下图所示：</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/隐藏的内存池.jpg" alt="隐藏的内存池"></p>
<p>回到文章开头的问题，Java 已经有了应用层内存池，为什么还会受到 C 库内存池的影响呢？这是因为，除了 JVM 负责管理的堆内存外，Java 还拥有一些堆外内存，由于它不使用 JVM 的垃圾回收机制，所以更稳定、持久，处理 IO 的速度也更快。这些堆外内存就会由 C 库内存池负责分配，这是 Java 受到 C 库内存池影响的原因。</p>
<p>以 Linux 系统的默认 C 库内存池 Ptmalloc2 来具体分析，看看它到底对性能发挥着怎样的作用。</p>
<p>C 库内存池工作时，会预分配比你申请的字节数更大的空间作为内存池。比如说，当主进程下申请 1 字节的内存时，Ptmalloc2 会预分配 132K 字节的内存（Ptmalloc2 中叫 Main Arena），应用代码再申请内存时，会从这已经申请到的 132KB 中继续分配。</p>
<p>如下所示（你可以在这里找到 <a target="_blank" rel="noopener" href="https://github.com/russelltao/geektime_distrib_perf/tree/master/2-memory/alloc_address">示例程序</a> ，注意地址的单位是 16 进制）：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">cat</span> /proc/2891/maps <span class="token operator">|</span> <span class="token function">grep</span> heap
01643000-01664000 rw-p 00000000 00:00 <span class="token number">0</span>     <span class="token punctuation">[</span>heap<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>当我们释放这 1 字节时，Ptmalloc2 也不会把内存归还给操作系统。Ptmalloc2 认为，与其把这 1 字节释放给操作系统，不如先缓存着放进内存池里，仍然当作用户态内存留下来，进程再次申请 1 字节的内存时就可以直接复用，这样速度快了很多。</p>
<p>你可能会想，132KB 不多呀？为什么这一讲开头提到的 Java 进程，会被分配了几个 GB 的内存池呢？这是因为多线程与单线程的预分配策略并不相同。</p>
<p>每个<strong>子线程预分配的内存是 64MB</strong>（Ptmalloc2 中被称为 Thread Arena，32 位系统下为 1MB，64 位系统下为 64MB）。如果有 100 个线程，就将有 6GB 的内存都会被内存池占用。当然，并不是设置了 1000 个线程，就会预分配 60GB 的内存，子线程内存池最多只能到 8 倍的 CPU 核数，比如在 32 核的服务器上，最多只会有 256 个子线程内存池，但这也非常夸张了，16GB（64MB * 256 = 16GB）的内存将一直被 Ptmalloc2 占用。</p>
<p>回到本文开头的问题，Linux 下的 JVM 编译时默认使用了 Ptmalloc2 内存池，因此每个线程都预分配了 64MB 的内存，这造成含有上百个 Java 线程的 JVM 多使用了 6GB 的内存。在多数情况下，这些预分配出来的内存池，可以提升后续内存分配的性能。</p>
<p>然而，Java 中的 JVM 内存池已经管理了绝大部分内存，确实不能接受莫名多出来 6GB 的内存，那该怎么办呢？既然我们知道了 Ptmalloc2 内存池的存在，就有两种解决办法。</p>
<ol>
<li><p>首先可以调整 Ptmalloc2 的工作方式。<strong>通过设置 MALLOC_ARENA_MAX 环境变量，可以限制线程内存池的最大数量</strong>，当然，线程内存池的数量减少后，会影响 Ptmalloc2 分配内存的速度。不过由于 Java 主要使用 JVM 内存池来管理对象，这点影响并不重要。</p>
</li>
<li><p>其次可以更换掉 Ptmalloc2 内存池，选择一个预分配内存更少的内存池，比如 Google 的 TCMalloc。</p>
</li>
</ol>
<p>这并不是说 Google 出品的 TCMalloc 性能更好，而是在特定的场景中的选择不同。而且，盲目地选择 TCMalloc 很可能会降低性能，否则 Linux 系统早把默认的内存池改为 TCMalloc 了。</p>
<h4 id="2-2-选择-Ptmalloc2-还是-TCMalloc？"><a href="#2-2-选择-Ptmalloc2-还是-TCMalloc？" class="headerlink" title="2.2 选择 Ptmalloc2 还是 TCMalloc？"></a>2.2 选择 Ptmalloc2 还是 TCMalloc？</h4><p>先来看 TCMalloc 适用的场景，<strong>它对多线程下小内存的分配特别友好。</strong></p>
<p>比如，在 2GHz 的 CPU 上分配、释放 256K 字节的内存，Ptmalloc2 耗时 32 纳秒，而 TCMalloc 仅耗时 10 纳秒（测试代码参见 <a target="_blank" rel="noopener" href="https://github.com/russelltao/geektime_distrib_perf/tree/master/2-memory/benchmark">这里</a> ）。<strong>差距超过了 3 倍，为什么呢？</strong> 这是因为，Ptmalloc2 假定，如果线程 A 申请并释放了的内存，线程 B 可能也会申请类似的内存，所以它允许内存池在线程间复用以提升性能。</p>
<p>因此，每次分配内存，Ptmalloc2 一定要加锁，才能解决共享资源的互斥问题。然而，加锁的消耗并不小。如果你监控分配速度的话，会发现单线程服务调整为 100 个线程，Ptmalloc2 申请内存的速度会变慢 10 倍。TCMalloc 针对小内存做了很多优化，每个线程独立分配内存，无须加锁，所以速度更快！</p>
<p>而且，<strong>线程数越多，Ptmalloc2 出现锁竞争的概率就越高。</strong>比如我们用 40 个线程做同样的测试，TCMalloc 只是从 10 纳秒上升到 25 纳秒，只增长了 1.5 倍，而 Ptmalloc2 则从 32 纳秒上升到 137 纳秒，增长了 3 倍以上。</p>
<p>下图是 TCMalloc 作者给出的性能测试数据，可以看到线程数越多，二者的速度差距越大。所以，<strong>当应用场景涉及大量的并发线程时，换成 TCMalloc 库也更有优势！</strong></p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/TCMallocThread-CachingMalloc.png" alt="TCMallocThread-CachingMalloc"></p>
<blockquote>
<p>图片来源：TCMalloc : Thread-Caching Malloc</p>
</blockquote>
<p>那么，为什么 GlibC 不把默认的 Ptmalloc2 内存池换成 TCMalloc 呢？<strong>因为 Ptmalloc2 更擅长大内存的分配。</strong></p>
<p>比如，单线程下分配 257K 字节的内存，Ptmalloc2 的耗时不变仍然是 32 纳秒，但 TCMalloc 就由 10 纳秒上升到 64 纳秒，增长了 5 倍以上！<strong>现在 TCMalloc 反过来比 Ptmalloc2 慢了 1 倍！</strong>这是因为 TCMalloc 特意针对小内存做了优化。</p>
<p>多少字节叫小内存呢？TCMalloc 把内存分为 3 个档次，小于等于 256KB 的称为小内存，从 256KB 到 1M 称为中等内存，大于 1MB 的叫做大内存。TCMalloc 对中等内存、大内存的分配速度很慢，比如我们用单线程分配 2M 的内存，Ptmalloc2 耗时仍然稳定在 32 纳秒，但 TCMalloc 已经上升到 86 纳秒，增长了 7 倍以上。</p>
<p>所以，<strong>如果主要分配 256KB 以下的内存，特别是在多线程环境下，应当选择 TCMalloc；否则应使用 Ptmalloc2，它的通用性更好。</strong></p>
<h4 id="2-3-从堆还是栈上分配内存？"><a href="#2-3-从堆还是栈上分配内存？" class="headerlink" title="2.3 从堆还是栈上分配内存？"></a>2.3 从堆还是栈上分配内存？</h4><p>不知道你发现没有，刚刚讨论的内存池中分配出的都是堆内存，如果你把在堆中分配的对象改为在栈上分配，速度还会再快上 1 倍（具体测试代码可以在<a target="_blank" rel="noopener" href="https://github.com/russelltao/geektime_distrib_perf/blob/master/2-memory/benchmark/heap_stack.java">这里</a>找到）！为什么？</p>
<p>如果你使用的是静态类型语言，那么，不使用 new 关键字分配的对象大都是在栈中的。比如：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">C/C++/Java语言： int a = 10;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>否则，通过 new 或者 malloc 关键字分配的对象则是在堆中的：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">C语言：int * a = (int*) malloc(sizeof(int));
C++语言：int * a = new int;
Java语言：int a = new Integer(10);<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>另外，对于动态类型语言，无论是否使用 new 关键字，内存都是从堆中分配的。</p>
<p>这是因为，由于每个线程都有独立的栈，所以分配内存时不需要加锁保护，而且栈上对象的尺寸在编译阶段就已经写入可执行文件了，执行效率更高！性能至上的 Golang 语言就是按照这个逻辑设计的，即使你用 new 关键字分配了堆内存，但编译器如果认为在栈中分配不影响功能语义时，会自动改为在栈中分配。</p>
<p>当然，在栈中分配内存也有缺点，它有功能上的限制。一是， 栈内存生命周期有限，它会随着函数调用结束后自动释放。在堆中分配的内存，并不随着分配时所在函数调用的结束而释放，它的生命周期足够使用；二是，栈的容量有限，如 CentOS 7 中是 8MB 字节，如果你申请的内存超过限制会造成栈溢出错误（比如，递归函数调用很容易造成这种问题），而堆则没有容量限制。</p>
<p><strong>所以，当我们分配内存时，如果在满足功能的情况下，可以在栈中分配的话，就选择栈。</strong></p>
<h4 id="2-3-小结"><a href="#2-3-小结" class="headerlink" title="2.3 小结"></a>2.3 小结</h4><p>进程申请内存的速度，以及总内存空间都受到内存池的影响。知道这些隐藏内存池的存在，是提升分配内存效率的前提。</p>
<p>隐藏着的 C 库内存池，对进程的内存开销有很大的影响。当进程的占用空间超出预期时，你需要清楚你正在使用的是什么内存池，它对每个线程预分配了多大的空间。</p>
<p>不同的 C 库内存池，都有它们最适合的应用场景，例如 TCMalloc 对多线程下的小内存分配特别友好，而 Ptmalloc2 则对各类尺寸的内存申请都有稳定的表现，更加通用。</p>
<p>内存池管理着堆内存，它的分配速度比不上在栈中分配内存。只是栈中分配的内存受到生命周期和容量大小的限制，应用场景更为有限。然而，如果有可能的话，尽量在栈中分配内存，它比内存池中的堆内存分配速度快很多！</p>
<h3 id="03-索引：如何用哈希表管理亿级对象？"><a href="#03-索引：如何用哈希表管理亿级对象？" class="headerlink" title="03 | 索引：如何用哈希表管理亿级对象？"></a>03 | 索引：如何用哈希表管理亿级对象？</h3><h3 id="04-零拷贝：如何高效地传输文件？"><a href="#04-零拷贝：如何高效地传输文件？" class="headerlink" title="04 | 零拷贝：如何高效地传输文件？"></a>04 | 零拷贝：如何高效地传输文件？</h3><p>这一讲，我们就通过解决“如何高效地传输文件”这个问题，来分析下磁盘是如何工作的，并且通过优化传输文件的性能，带你学习现在热门的零拷贝、异步 IO 与直接 IO 这些磁盘优化技术。</p>
<h4 id="4-1-你会如何实现文件传输？"><a href="#4-1-你会如何实现文件传输？" class="headerlink" title="4.1 你会如何实现文件传输？"></a>4.1 你会如何实现文件传输？</h4><p>服务器提供文件传输功能，需要将磁盘上的文件读取出来，通过网络协议发送到客户端。如果需要你自己编码实现这个文件传输功能，你会怎么实现呢？</p>
<p>通常，你会选择最直接的方法：从网络请求中找出文件在磁盘中的路径后，如果这个文件比较大，假设有 320MB，可以在内存中分配 32KB 的缓冲区，再把文件分成一万份，每份只有 32KB，这样，从文件的起始位置读入 32KB 到缓冲区，再通过网络 API 把这 32KB 发送到客户端。接着重复一万次，直到把完整的文件都发送完毕。如下图所示：</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/实现文件传输一.jpg" alt="实现文件传输一"></p>
<p>不过这个方案性能并不好，主要有两个原因。</p>
<p>首先，它至少<strong>经历了 4 万次用户态与内核态的上下文切换</strong>。因为每处理 32KB 的消息，就需要一次 read 调用和一次 write 调用，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。可见，每处理 32KB，就有 4 次上下文切换，重复 1 万次后就有 4 万次切换。</p>
<p>上下文切换的成本并不小，虽然一次切换仅消耗几十纳秒到几微秒，但高并发服务会放大这类时间的消耗。</p>
<p>其次，这个方案做了 <strong>4 万次内存拷贝，对 320MB 文件拷贝的字节数也翻了 4 倍，到了 1280MB。</strong> 很显然，过多的内存拷贝无谓地消耗了 CPU 资源，降低了系统的并发处理能力。</p>
<p>所以要想提升传输文件的性能，需要从<strong>降低上下文切换的频率和内存拷贝次数</strong>两个方向入手。</p>
<h4 id="4-2-零拷贝如何提升文件传输性能？"><a href="#4-2-零拷贝如何提升文件传输性能？" class="headerlink" title="4.2 零拷贝如何提升文件传输性能？"></a>4.2 零拷贝如何提升文件传输性能？</h4><p>首先，我们来看如何降低上下文切换的频率。</p>
<p>为什么读取磁盘文件时，一定要做上下文切换呢？这是因为，读取磁盘或者操作网卡都由操作系统内核完成。内核负责管理系统上的所有进程，它的权限最高，工作环境与用户进程完全不同。只要我们的代码执行 read 或者 write 这样的系统调用，一定会发生 2 次上下文切换：首先从用户态切换到内核态，当内核执行完任务后，再切换回用户态交由进程代码执行。</p>
<p>因此，如果想减少上下文切换次数，就一定要减少系统调用的次数。解决方案就是把 read、write 两次系统调用合并成一次，在内核中完成磁盘与网卡的数据交换。</p>
<p>其次，我们应该考虑如何减少内存拷贝次数。</p>
<p>每周期中的 4 次内存拷贝，其中与物理设备相关的 2 次拷贝是必不可少的，包括：把磁盘内容拷贝到内存，以及把内存拷贝到网卡。但另外 2 次与用户缓冲区相关的拷贝动作都不是必需的，因为在把磁盘文件发到网络的场景中，<strong>用户缓冲区没有必须存在的理由。</strong></p>
<p>如果内核在读取文件后，直接把 PageCache 中的内容拷贝到 Socket 缓冲区，待到网卡发送完毕后，再通知进程，这样就只有 2 次上下文切换，和 3 次内存拷贝。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/实现文件传输二.jpg" alt="实现文件传输二"></p>
<p>如果网卡支持 SG-DMA（The Scatter-Gather Direct Memory Access）技术，还可以再去除 Socket 缓冲区的拷贝，这样一共只有 2 次内存拷贝。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/实现文件传输三.jpg" alt="实现文件传输三"></p>
<p><strong>实际上，这就是零拷贝技术。</strong></p>
<p>它是操作系统提供的新函数，同时接收文件描述符和 TCP socket 作为输入参数，这样执行时就可以完全在内核态完成内存拷贝，既减少了内存拷贝次数，也降低了上下文切换次数。</p>
<p>而且，零拷贝取消了用户缓冲区后，不只降低了用户内存的消耗，还通过最大化利用 socket 缓冲区中的内存，间接地再一次减少了系统调用的次数，从而带来了大幅减少上下文切换次数的机会！</p>
<p>你可以回忆下，没用零拷贝时，为了传输 320MB 的文件，在用户缓冲区分配了 32KB 的内存，把文件分成 1 万份传送，然而，<strong>这 32KB 是怎么来的？</strong>为什么不是 32MB 或者 32 字节呢？这是因为，在没有零拷贝的情况下，我们希望内存的利用率最高。如果用户缓冲区过大，它就无法一次性把消息全拷贝给 socket 缓冲区；如果用户缓冲区过小，则会导致过多的 read/write 系统调用。</p>
<p>那用户缓冲区为什么不与 socket 缓冲区大小一致呢？这是因为，<strong>socket 缓冲区的可用空间是动态变化的</strong>，它既用于 TCP 滑动窗口，也用于应用缓冲区，还受到整个系统内存的影响（我在《Web 协议详解与抓包实战》第 5 部分课程对此有详细介绍，这里不再赘述）。尤其在长肥网络中，它的变化范围特别大。</p>
<p><strong>零拷贝使我们不必关心 socket 缓冲区的大小。</strong> 比如，调用零拷贝发送方法时，尽可以把发送字节数设为文件的所有未发送字节数，例如 320MB，也许此时 socket 缓冲区大小为 1.4MB，那么一次性就会发送 1.4MB 到客户端，而不是只有 32KB。这意味着对于 1.4MB 的 1 次零拷贝，仅带来 2 次上下文切换，而不使用零拷贝且用户缓冲区为 32KB 时，经历了 176 次（4 * 1.4MB/32KB）上下文切换。</p>
<p>综合上述各种优点，零拷贝可以把性能提升至少一倍以上！</p>
<p>此外，零拷贝还使用了 PageCache 技术，通过它，零拷贝可以进一步提升性能，我们接下来看看 PageCache 是如何做到这一点的。</p>
<h4 id="4-3-PageCache，磁盘高速缓存"><a href="#4-3-PageCache，磁盘高速缓存" class="headerlink" title="4.3 PageCache，磁盘高速缓存"></a>4.3 PageCache，磁盘高速缓存</h4><p>回顾上文中的几张图，你会发现，读取文件时，是先把磁盘文件拷贝到 PageCache 上，再拷贝到进程中。为什么这样做呢？有两个原因所致。</p>
<p>第一，由于磁盘比内存的速度慢许多，所以我们应该想办法把读写磁盘替换成读写内存，比如把磁盘中的数据复制到内存中，就可以用读内存替换读磁盘。但是，内存空间远比磁盘要小，内存中注定只能复制一小部分磁盘中的数据。</p>
<p>通常，刚被访问的数据在短时间内再次被访问的概率很高（这也叫“时间局部性”原理），用 PageCache 缓存最近访问的数据，当空间不足时淘汰最久未被访问的缓存（即 LRU 算法）。读磁盘时优先到 PageCache 中找一找，如果数据存在便直接返回，这便大大提升了读磁盘的性能。</p>
<p>第二，读取磁盘数据时，需要先找到数据所在的位置，对于机械磁盘来说，就是旋转磁头到数据所在的扇区，再开始顺序读取数据。其中，旋转磁头耗时很长，为了降低它的影响，PageCache 使用了<strong>预读功能。</strong></p>
<p>也就是说，虽然 read 方法只读取了 0-32KB 的字节，但内核会把其后的 32-64KB 也读取到 PageCache，这后 32KB 读取的成本很低。如果在 32-64KB 淘汰出 PageCache 前，进程读取到它了，收益就非常大。这一讲的传输文件场景中这是必然发生的。</p>
<p>从这两点可以看到 PageCache 的优点，它在 90% 以上场景下都会提升磁盘性能，<strong>但在某些情况下，PageCache 会不起作用，甚至由于多做了一次内存拷贝，造成性能的降低。</strong>在这些场景中，使用了 PageCache 的零拷贝也会损失性能。</p>
<p>具体是什么场景呢？就是在传输大文件的时候。比如，你有很多 GB 级的文件需要传输，每当用户访问这些大文件时，内核就会把它们载入到 PageCache 中，这些大文件很快会把有限的 PageCache 占满。</p>
<p>然而，由于文件太大，文件中某一部分内容被再次访问到的概率其实非常低。这带来了 2 个问题：首先，由于 PageCache 长期被大文件占据，热点小文件就无法充分使用 PageCache，它们读起来变慢了；其次，PageCache 中的大文件没有享受到缓存的好处，但却耗费 CPU 多拷贝到 PageCache 一次。</p>
<p>所以，高并发场景下，为了防止 PageCache 被大文件占满后不再对小文件产生作用，<strong>大文件不应使用 PageCache，进而也不应使用零拷贝技术处理。</strong></p>
<h4 id="4-4-异步-IO-直接-IO"><a href="#4-4-异步-IO-直接-IO" class="headerlink" title="4.4 异步 IO + 直接 IO"></a>4.4 异步 IO + 直接 IO</h4><p>高并发场景处理大文件时，应当使用异步 IO 和直接 IO 来替换零拷贝技术。</p>
<p>仍然回到本讲开头的例子，当调用 read 方法读取文件时，实际上 read 方法会在磁盘寻址过程中阻塞等待，导致进程无法并发地处理其他任务，如下图所示：</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/实现文件传输四.jpg" alt="实现文件传输四"></p>
<p>异步 IO（异步 IO 既可以处理网络 IO，也可以处理磁盘 IO，这里我们只关注磁盘 IO）可以解决阻塞问题。它把读操作分为两部分，前半部分向内核发起读请求，<strong>但不等待数据就位就立刻返回</strong>，此时进程可以并发地处理其他任务。当内核将磁盘中的数据拷贝到进程缓冲区后，进程将接收到内核的通知，再去处理数据，这是异步 IO 的后半部分。如下图所示：</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/实现文件传输五.jpg" alt="实现文件传输五"></p>
<p>从图中可以看到，异步 IO 并没有拷贝到 PageCache 中，这其实是异步 IO 实现上的缺陷。经过 PageCache 的 IO 我们称为缓存 IO，它与虚拟内存系统耦合太紧，导致异步 IO 从诞生起到现在都不支持缓存 IO。</p>
<p>绕过 PageCache 的 IO 是个新物种，我们把它称为直接 IO。对于磁盘，异步 IO 只支持直接 IO。</p>
<p>直接 IO 的应用场景并不多，主要有两种：第一，应用程序已经实现了磁盘文件的缓存，不需要 PageCache 再次缓存，引发额外的性能消耗。比如 MySQL 等数据库就使用直接 IO；第二，高并发下传输大文件，我们上文提到过，大文件难以命中 PageCache 缓存，又带来额外的内存拷贝，同时还挤占了小文件使用 PageCache 时需要的内存，因此，这时应该使用直接 IO。</p>
<p>当然，直接 IO 也有一定的缺点。除了缓存外，内核（IO 调度算法）会试图缓存尽量多的连续 IO 在 PageCache 中，最后合并成一个更大的 IO 再发给磁盘，这样可以减少磁盘的寻址操作；另外，内核也会预读后续的 IO 放在 PageCache 中，减少磁盘操作。直接 IO 绕过了 PageCache，所以无法享受这些性能提升。</p>
<p>有了直接 IO 后，异步 IO 就可以无阻塞地读取文件了。现在，大文件由异步 IO 和直接 IO 处理，小文件则交由零拷贝处理，至于判断文件大小的阈值可以灵活配置（参见 Nginx 的 directio 指令）。</p>
<h4 id="4-5-小结"><a href="#4-5-小结" class="headerlink" title="4.5 小结"></a>4.5 小结</h4><p>基于用户缓冲区传输文件时，过多的内存拷贝与上下文切换次数会降低性能。零拷贝技术在内核中完成内存拷贝，天然降低了内存拷贝次数。它通过一次系统调用合并了磁盘读取与网络发送两个操作，降低了上下文切换次数。尤其是，由于拷贝在内核中完成，它可以最大化使用 socket 缓冲区的可用空间，从而提高了一次系统调用中处理的数据量，进一步降低了上下文切换次数。</p>
<p>零拷贝技术基于 PageCache，而 PageCache 缓存了最近访问过的数据，提升了访问缓存数据的性能，同时，为了解决机械磁盘寻址慢的问题，它还协助 IO 调度算法实现了 IO 合并与预读（这也是顺序读比随机读性能好的原因），这进一步提升了零拷贝的性能。几乎所有操作系统都支持零拷贝，如果应用场景就是把文件发送到网络中，那么我们应当选择使用了零拷贝的解决方案。</p>
<p>不过，零拷贝有一个缺点，就是不允许进程对文件内容作一些加工再发送，比如数据压缩后再发送。另外，当 PageCache 引发负作用时，也不能使用零拷贝，此时可以用异步 IO+ 直接 IO 替换。我们通常会设定一个文件大小阈值，针对大文件使用异步 IO 和直接 IO，而对小文件使用零拷贝。</p>
<p>事实上 PageCache 对写操作也有很大的性能提升，因为 write 方法在写入内存中的 PageCache 后就会返回，速度非常快，由内核负责异步地把 PageCache 刷新到磁盘中，这里不再展开。</p>
<h3 id="05-协程：如何快速地实现高并发服务？"><a href="#05-协程：如何快速地实现高并发服务？" class="headerlink" title="05 | 协程：如何快速地实现高并发服务？"></a>05 | 协程：如何快速地实现高并发服务？</h3><h3 id="06-锁：如何根据业务场景选择合适的锁？"><a href="#06-锁：如何根据业务场景选择合适的锁？" class="headerlink" title="06 | 锁：如何根据业务场景选择合适的锁？"></a>06 | 锁：如何根据业务场景选择合适的锁？</h3><p><strong>自旋锁在用户态代码中完成加锁与解锁操作</strong>。</p>
<p>什么叫悲观锁呢？它认为同时修改资源的概率很高，很容易出现冲突，所以访问共享资源前，先加上锁，总体效率会更优。然而，如果并发产生冲突的概率很低，就不必使用悲观锁，而是使用乐观锁。</p>
<p>所谓“乐观”，就是假定冲突的概率很低，所以它采用的“加锁”方式是，先修改完共享资源，再验证这段时间内有没有发生冲突。如果没有其他线程在修改资源，那么操作完成。如果发现其他线程已经修改了这个资源，就放弃本次操作。</p>
<p>至于放弃后如何重试，则与业务场景相关，虽然重试的成本很高，但出现冲突的概率足够低的话，还是可以接受的。<strong>可见，乐观锁全程并没有加锁，所以它也叫无锁编程。</strong></p>
<p><strong>只有在冲突概率非常低，且加锁成本较高时，才考虑使用乐观锁。</strong></p>
<h2 id="三、系统层网络优化"><a href="#三、系统层网络优化" class="headerlink" title="三、系统层网络优化"></a>三、系统层网络优化</h2><h3 id="07-性能好，效率高的一对多通讯该如何实现？"><a href="#07-性能好，效率高的一对多通讯该如何实现？" class="headerlink" title="07 | 性能好，效率高的一对多通讯该如何实现？"></a>07 | 性能好，效率高的一对多通讯该如何实现？</h3><h4 id="7-1-广播是怎么实现的？"><a href="#7-1-广播是怎么实现的？" class="headerlink" title="7.1 广播是怎么实现的？"></a>7.1 广播是怎么实现的？</h4><p>一对多通讯分为两种：<strong>对局域网内所有主机发送消息的叫做广播</strong>，而<strong>对部分主机发送消息的，则叫做组播</strong>。</p>
<p><strong>当交换机收到目标 MAC 地址是 ff:ff:ff:ff:ff:ff 的报文时，便知道这是一个广播报文</strong>，才会将它转发给局域网中的所有主机，否则只会转发给 MAC 地址对应端口上的主机。</p>
<p>不过，我们写代码时无法控制底层的 MAC 地址，只能填写目标 IP 地址。什么样的目标 IP 地址，会生成广播 MAC 地址呢？<strong>如果只是对所在子网进行广播，那么使用受限广播地址 255.255.255.255 就可以了；如果局域网划分了多个子网，主机需要向其他子网广播，则需要正确地设置直接广播地址（路由器需要打开直接广播功能）。</strong></p>
<p><strong>主机 ID 的比特位全部设为 1 后就是广播地址。</strong> 比如，192.168.0.101 是 C 类地址，把主机 ID 从 101 改为 255 后，就可以用 192.168.0.255 发送广播了。</p>
<h3 id="08-事件驱动：C10M是如何实现的？"><a href="#08-事件驱动：C10M是如何实现的？" class="headerlink" title="08 | 事件驱动：C10M是如何实现的？"></a>08 | 事件驱动：C10M是如何实现的？</h3><h3 id="09-如何提升TCP三次握手的性能？"><a href="#09-如何提升TCP三次握手的性能？" class="headerlink" title="09 | 如何提升TCP三次握手的性能？"></a>09 | 如何提升TCP三次握手的性能？</h3><p>TCP 是面向连接的、可靠的、双向传输的传输层通信协议，所以在传输数据之前需要经过三次握手才能建立连接。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/三次握手与数据传输.png" alt="三次握手与数据传输.png"></p>
<p>那么，三次握手的过程在一个 HTTP 请求的平均时间占比 10% 以上，在网络状态不佳、高并发或者遭遇 SYN 攻击等场景中，如果不能有效正确的调节三次握手中的参数，就会对性能产生很多的影响。</p>
<p>如何正确有效的使用这些参数，来提高 TCP 三次握手的性能，这就需要理解「三次握手的状态变迁」，这样当出现问题时，先用 netstat 命令查看是哪个握手阶段出现了问题，再来对症下药，而不是病急乱投医。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/TCP 三次握手的状态变迁.png" alt="TCP 三次握手的状态变迁.png"></p>
<p>客户端和服务端都可以针对三次握手优化性能。主动发起连接的客户端优化相对简单些，而服务端需要监听端口，属于被动连接方，其间保持许多的中间状态，优化方法相对复杂一些。</p>
<p>所以，客户端（主动发起连接方）和服务端（被动连接方）优化的方式是不同的，接下来分别针对客户端和服务端优化。</p>
<h4 id="9-1-客户端的优化"><a href="#9-1-客户端的优化" class="headerlink" title="9.1 客户端的优化"></a>9.1 客户端的优化</h4><p>三次握手建立连接的首要目的是<strong>同步序列号</strong>。</p>
<p>只有同步了序列号才有可靠的传输，TCP 协议的许多特性都是依赖序列号实现的，比如流量控制、消息丢失后的重发等等，这也是三次握手中的报文被称为 SYN 的原因，因为 SYN 的全称就叫做 Synchronize Sequence Numbers。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/TCP头部格式.png" alt="TCP头部格式"></p>
<h5 id="9-1-1-SYN-SENT-状态的优化"><a href="#9-1-1-SYN-SENT-状态的优化" class="headerlink" title="9.1.1 SYN_SENT 状态的优化"></a>9.1.1 SYN_SENT 状态的优化</h5><p>客户端作为主动发起连接方，首先它将发送 SYN 包，于是客户端的连接就会处于 SYN_SENT 状态。</p>
<p>客户端在等待服务器回复的 ACK 报文。正常情况下，服务器会在几毫秒内返回 ACK，但如果客户端迟迟没有收到 ACK 会怎么样呢？客户端会重发 SYN，重试的次数由 tcp_syn_retries 参数控制，默认是 6 次：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_syn_retries = 6<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>第 1 次重试发生在 1 秒钟后，接着会<strong>以翻倍的方式</strong>在第 2、4、8、16、32 秒共做 6 次重试，最后一次重试会等待 64 秒，如果仍然没有返回 ACK，才会终止三次握手。所以，总耗时是 1+2+4+8+16+32+64=127 秒，超过 2 分钟。</p>
<p>你可以根据网络的稳定性和目标服务器的繁忙程度修改 SYN 的重传次数，调整客户端的三次握手时间上限。比如内网中通讯时，就可以适当调低重试次数，尽快把错误暴露给应用程序。</p>
<h4 id="9-2-服务器端的优化"><a href="#9-2-服务器端的优化" class="headerlink" title="9.2 服务器端的优化"></a>9.2 服务器端的优化</h4><p>当服务器收到 SYN 报文后，服务器会立刻回复 SYN+ACK 报文，既确认了客户端的序列号，也把自己的序列号发给了对方。此时，服务器端出现了新连接，状态是 SYN_RCV（RCV 是 received 的缩写）。这个状态下，服务器必须建立一个 SYN 半连接队列来维护未完成的握手信息，当这个队列溢出后，服务器将无法再建立新连接。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/半连接队列与全连接队列.png" alt="半连接队列与全连接队列"></p>
<p>SYN 攻击，攻击的是就是这个半连接队列。</p>
<ol>
<li><p>如何查看由于 SYN 半连接队列已满，而被丢弃连接的情况？</p>
<p> 可以通过该 netstat -s 命令给出的统计结果中，  可以得到由于半连接队列已满，引发的失败次数：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">netstat</span> -s <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">"SYNs to LISTEN"</span>
    <span class="token number">1192450</span> SYNs to LISTEN sockets dropped<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p> 这里给出的是队列溢出导致 SYN 被丢弃的个数。注意这是一个累计值，如果数值在持续增加，则应该调大 SYN 半连接队列。</p>
</li>
<li><p>如何调整 SYN 半连接队列大小？</p>
<p> <strong>修改队列大小的方法，是设置 Linux 的 tcp_max_syn_backlog 参数</strong>：</p>
 <pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_max_syn_backlog = 1024<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>如果 SYN 半连接队列已满，只能丢弃连接吗？</p>
<p> 并不是这样，<strong>开启 syncookies 功能就可以在不使用 SYN 队列的情况下成功建立连接。</strong></p>
<p> syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示。</p>
<p> <img src="/images/《系统性能调优必知必会》学习笔记/开启syncookies功能.png" alt="开启syncookies功能"></p>
</li>
<li><p>Linux 下怎样开启 syncookies 功能呢？</p>
<p> 修改 tcp_syncookies 参数即可：</p>
<ul>
<li>其中值为 0 时表示关闭该功能</li>
<li>2 表示无条件开启功能</li>
<li><p>而 1 则表示仅当 SYN 半连接队列放不下时，再启用它。</p>
<p>由于 syncookie 仅用于应对 SYN 泛洪攻击（攻击者恶意构造大量的 SYN 报文发送给服务器，造成 SYN 半连接队列溢出，导致正常客户端的连接无法建立），这种方式建立的连接，许多 TCP 特性都无法使用。所以，应当把 tcp_syncookies 设置为 1，仅在队列满时再启用。</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_syncookies = 1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="9-2-1-SYN-RCV-状态的优化"><a href="#9-2-1-SYN-RCV-状态的优化" class="headerlink" title="9.2.1 SYN_RCV 状态的优化"></a>9.2.1 SYN_RCV 状态的优化</h4></li>
</ul>
</li>
</ol>
<p>当客户端接收到服务器发来的 SYN+ACK 报文后，就会回复 ACK 去通知服务器，同时己方连接状态从 SYN_SENT 转换为 ESTABLISHED，表示连接建立成功。</p>
<p>服务器端连接成功建立的时间还要再往后，到它收到 ACK 后状态才变为 ESTABLISHED。</p>
<p>如果服务器没有收到 ACK，就会一直重发 SYN+ACK 报文，同时一直处于 SYN_RCV 状态。</p>
<p>当网络繁忙、不稳定时，报文丢失就会变严重，此时应该调大重发次数。反之则可以调小重发次数。<strong>修改重发次数的方法是，调整 tcp_synack_retries 参数</strong>：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_synack_retries = 5<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>tcp_synack_retries 的默认重试次数是 5 次，与客户端重发 SYN 类似，它的重试会经历 1、2、4、8、16 秒，最后一次重试后等待 32 秒，若仍然没有收到 ACK，才会关闭连接，故共需要等待 63 秒。</p>
<p>服务器收到 ACK 后连接建立成功，此时，内核会把连接从 SYN 半连接队列中移出，再移入 accept 队列，等待进程调用 accept 函数时把连接取出来。</p>
<p>如果进程不能及时地调用 accept 函数，就会造成 accept 队列溢出，最终导致建立好的 TCP 连接被丢弃。</p>
<ol>
<li><p>accept 队列已满，只能丢弃连接吗？</p>
<p> 实际上，丢弃连接只是 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建立失败。打开这一功能需要将 tcp_abort_on_overflow 参数设置为 1。</p>
 <pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_abort_on_overflow = 0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> tcp_abort_on_overflow 共有两个值分别是 0 和 1，其分别表示：</p>
<ul>
<li>0 ：如果 accept 队列满了，那么 server 扔掉 client  发过来的 ack ；</li>
<li><p>1 ：如果 accept 队列满了，server 发送一个 RST 包给 client，表示废掉这个握手过程和这个连接；</p>
<p>如果要想知道客户端连接不上服务端，是不是服务端 TCP 全连接队列满的原因，那么可以把 tcp_abort_on_overflow 设置为 1，这时如果在客户端异常中可以看到很多 connection reset by peer 的错误，那么就可以证明是由于服务端 TCP 全连接队列溢出的问题。</p>
<p><strong>通常情况下，应当把 tcp_abort_on_overflow 设置为 0，因为这样更有利于应对突发流量。</strong></p>
<p>举个例子，当 accept 队列满导致服务器丢掉了 ACK，与此同时，客户端的连接状态却是 ESTABLISHED，客户端进程就在建立好的连接上发送请求。只要服务器没有为请求回复 ACK，客户端的请求就会被多次「重发」。<strong>如果服务器上的进程只是短暂的繁忙造成 accept 队列满，那么当 accept 队列有空位时，再次接收到的请求报文由于含有 ACK，仍然会触发服务器端成功建立连接。</strong></p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/tcp_abort_on_overflow.png" alt="tcp_abort_on_overflow"></p>
<p><strong>tcp_abort_on_overflow 设为 0 可以提高连接建立的成功率，只有你非常肯定 accept 队列会长期溢出时，才能设置为 1 以尽快通知客户端。</strong></p>
</li>
</ul>
</li>
<li><p>如何调整 accept 队列的长度呢？</p>
<p> accept 队列的长度取决于 somaxconn 和 backlog 之间的最小值，也就是 min(somaxconn, backlog)，其中：</p>
<ul>
<li>somaxconn 是 Linux 内核的参数，默认值是 128，可以通过 net.core.somaxconn 来设置其值；</li>
<li><p>backlog 是 listen(int sockfd, int backlog) 函数中的 backlog 大小；</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">net.core.somaxconn = 128<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<blockquote>
<p>Tomcat、Nginx、Apache 常见的 Web 服务的 backlog 默认值都是 511。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>如何查看服务端进程 accept 队列的长度？</p>
<p> 可以通过 ss -ltn 命令查看：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ ss -ltn
State   Recv-Q      Send-Q      Local Address:Port  Peer Address:Port
LISTEN  <span class="token number">0</span>           <span class="token number">128</span>         *:8088              <span class="token number">0.0</span>.0.0:*<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<ul>
<li>Recv-Q：当前 accept 队列的大小，也就是当前已完成三次握手并等待服务端 accept() 的 TCP 连接；</li>
<li>Send-Q：accept 队列最大长度，上面的输出结果说明监听 8088 端口的 TCP 服务，accept 队列的最大长度为 128；</li>
</ul>
</li>
<li><p>如何查看由于 accept 连接队列已满，而被丢弃的连接？</p>
<p> 当超过了 accept 连接队列，服务端则会丢掉后续进来的 TCP 连接，丢掉的 TCP 连接的个数会被统计起来，我们可以使用 netstat -s 命令来查看：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">netstat</span> -s <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">"listen queue"</span>
    <span class="token number">14</span> <span class="token builtin class-name">times</span> the listen queue of a socket overflowed<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p> 注意这个是累计值。可以隔几秒钟执行下，如果这个数字一直在增加的话，说明 accept 连接队列偶尔满了。</p>
<p> 如果持续不断地有连接因为 accept 队列溢出被丢弃，就应该调大 backlog 以及 somaxconn 参数。</p>
</li>
</ol>
<h4 id="9-3-TFO-技术如何绕过三次握手？"><a href="#9-3-TFO-技术如何绕过三次握手？" class="headerlink" title="9.3 TFO 技术如何绕过三次握手？"></a>9.3 TFO 技术如何绕过三次握手？</h4><p>以上我们只是在对三次握手的过程进行优化，接下来我们看看如何绕过三次握手发送数据。</p>
<p>三次握手建立连接造成的后果就是，HTTP 请求必须在一次 RTT（Round Trip Time，从客户端到服务器一个往返的时间）后才能发送。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/常规HTTP请求.png" alt="常规HTTP请求"></p>
<p>因此，Google 提出了 TCP fast open 方案（简称TFO），客户端可以在首个 SYN 报文中就携带请求，这节省了 1 个 RTT 的时间。</p>
<h5 id="9-3-1-TCP-Fast-Open-功能的工作方式"><a href="#9-3-1-TCP-Fast-Open-功能的工作方式" class="headerlink" title="9.3.1 TCP Fast Open 功能的工作方式"></a>9.3.1 TCP Fast Open 功能的工作方式</h5><p><img src="/images/《系统性能调优必知必会》学习笔记/开启TCPFastOpen功能.png" alt="开启TCPFastOpen功能"></p>
<p><strong>为了让客户端在 SYN 报文中携带请求数据，必须解决服务器的信任问题。</strong>因为此时服务器的 SYN 报文还没有发给客户端，客户端是否能够正常建立连接还未可知，但此时服务器需要假定连接已经建立成功，并把请求交付给进程去处理，所以服务器必须能够信任这个客户端。</p>
<p>TFO把通讯分为两个阶段，第一阶段为首次建立连接，这时走正常的三次握手，但在客户端的 SYN 报文会明确地告诉服务器它想使用 TFO 功能，这样服务器会把客户端 IP 地址用只有自己知道的密钥加密（比如 AES 加密算法），作为 Cookie 携带在返回的 SYN+ACK 报文中，客户端收到后会将 Cookie 缓存在本地。</p>
<p>之后，如果客户端再次向服务器建立连接，就可以在第一个 SYN 报文中携带请求数据，同时还要附带缓存的 Cookie。很显然，这种通讯方式下不能再采用经典的“先 connect 再 write 请求”这种编程方法，而要改用 sendto 或者 sendmsg 函数才能实现。</p>
<p>服务器收到后，会用自己的密钥验证 Cookie 是否合法，验证通过后连接才算建立成功，再把请求交给进程处理，同时给客户端返回 SYN+ACK。虽然客户端收到后还会返回 ACK，但服务器不等收到 ACK 就可以发送 HTTP 响应了，这就减少了握手带来的 1 个 RTT 的时间消耗。</p>
<p>当然，为了防止 SYN 泛洪攻击，服务器的 TFO 实现必须能够自动化地定时更新密钥。</p>
<ol>
<li><p>Linux 下怎么打开 TCP Fast Open 功能呢</p>
<p> 在 Linux 系统中，可以通过<strong>设置 tcp_fastopn 内核参数，来打开 Fast Open 功能</strong>：</p>
 <pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_fastopen = 3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> tcp_fastopn 各个值的意义:</p>
<ul>
<li>0 关闭</li>
<li>1 作为客户端使用 Fast Open 功能</li>
<li>2 作为服务端使用 Fast Open 功能</li>
<li><p>3 无论作为客户端还是服务器，都可以使用 Fast Open 功能</p>
<p><strong>TCP Fast Open 功能需要客户端和服务端同时支持，才有效果。</strong></p>
</li>
</ul>
</li>
</ol>
<h4 id="9-4-小结"><a href="#9-4-小结" class="headerlink" title="9.4 小结"></a>9.4 小结</h4><p>本小结主要介绍了关于优化 TCP 三次握手的几个 TCP 参数。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/三次握手优化策略.png" alt="三次握手优化策略.png"></p>
<ol>
<li><p>客户端的优化</p>
<p> 当客户端发起 SYN 包时，可以通过 tcp_syn_retries 控制其重传的次数。</p>
</li>
<li><p>服务端的优化</p>
<p> 当服务端 SYN 半连接队列溢出后，会导致后续连接被丢弃，可以通过 netstat -s 观察半连接队列溢出的情况，如果 SYN 半连接队列溢出情况比较严重，可以通过 tcp_max_syn_backlog、somaxconn、backlog 参数来调整 SYN 半连接队列的大小。</p>
<p> 服务端回复 SYN+ACK 的重传次数由 tcp_synack_retries 参数控制。如果遭受 SYN 攻击，应把 tcp_syncookies 参数设置为 1，表示仅在 SYN 队列满后开启 syncookie 功能，可以保证正常的连接成功建立。</p>
<p> 服务端收到客户端返回的 ACK，会把连接移入 accpet 队列，等待进行调用 accpet() 函数取出连接。</p>
<p> 可以通过 ss -lnt 查看服务端进程的 accept 队列长度，如果 accept 队列溢出，系统默认丢弃 ACK，如果可以把 tcp_abort_on_overflow 设置为 1 ，表示用 RST 通知客户端连接建立失败。</p>
<p> 如果 accpet 队列溢出严重，可以通过 listen 函数的 backlog 参数和 somaxconn 系统参数提高队列大小，accept 队列长度取决于 min(backlog, somaxconn)。</p>
</li>
<li><p>绕过三次握手</p>
<p> TCP Fast Open 功能可以绕过三次握手，使得 HTTP 请求减少了 1 个 RTT 的时间，Linux 下可以通过 tcp_fastopen 开启该功能，同时必须保证服务端和客户端同时支持。</p>
</li>
</ol>
<h3 id="10-如何提升TCP四次挥手的性能？"><a href="#10-如何提升TCP四次挥手的性能？" class="headerlink" title="10 | 如何提升TCP四次挥手的性能？"></a>10 | 如何提升TCP四次挥手的性能？</h3><p>接下来，我们一起看看针对 TCP 四次挥手关不连接时，如何优化性能。</p>
<p>在开始之前，我们得先了解四次挥手状态变迁的过程。</p>
<p>客户端和服务端双方都可以主动断开连接，<strong>通常先关闭连接的一方称为主动方，后关闭连接的一方称为被动方。</strong></p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/客户端主动关闭.png" alt="客户端主动关闭"></p>
<p>可以看到，<strong>四次挥手过程只涉及了两种报文，分别是 FIN 和 ACK</strong>：</p>
<ul>
<li>FIN 就是结束连接的意思，谁发出 FIN 报文，就表示它将不会再发送任何数据，关闭这一方向上的传输通道；</li>
<li>ACK 就是确认的意思，用来通知对方：你方的发送通道已经关闭；</li>
</ul>
<h4 id="10-1-四次挥手的流程"><a href="#10-1-四次挥手的流程" class="headerlink" title="10.1 四次挥手的流程"></a>10.1 四次挥手的流程</h4><ul>
<li>当主动方关闭连接时，会发送 FIN 报文，此时发送方的 TCP 连接将从 ESTABLISHED 变成 FIN_WAIT1。</li>
<li>当被动方收到 FIN 报文后，内核会自动回复 ACK 报文，连接状态将从 ESTABLISHED 变成 CLOSE_WAIT，表示被动方在等待进程调用 close 函数关闭连接。</li>
<li>当主动方收到这个 ACK 后，连接状态由 FIN_WAIT1 变为 FIN_WAIT2，也就是表示<strong>主动方的发送通道就关闭了</strong>。</li>
<li>当被动方进入 CLOSE_WAIT 时，被动方还会继续处理数据，等到进程的 read 函数返回 0 后，应用程序就会调用 close 函数，进而触发内核发送 FIN 报文，此时被动方的连接状态变为 LAST_ACK。</li>
<li>当主动方收到这个 FIN 报文后，内核会回复 ACK 报文给被动方，同时主动方的连接状态由 FIN_WAIT2 变为 TIME_WAIT，<strong>在 Linux 系统下大约等待 1 分钟后，TIME_WAIT 状态的连接才会彻底关闭</strong>。</li>
<li>当被动方收到最后的 ACK 报文后，<strong>被动方的连接就会关闭</strong>。</li>
</ul>
<p>你可以看到，每个方向都需要<strong>一个 FIN 和一个 ACK</strong>，因此通常被称为<strong>四次挥手</strong>。</p>
<p>这里一点需要注意是：<strong>主动关闭连接的，才有 TIME_WAIT 状态</strong>。</p>
<ol>
<li><p>你想没想过，为什么建立连接是三次握手，而关闭连接需要四次挥手呢？</p>
<p> 这是因为 TCP 不允许连接处于半打开状态时就单向传输数据，所以在三次握手建立连接时，服务器会把 ACK 和 SYN 放在一起发给客户端，其中，ACK 用来打开客户端的发送通道，SYN 用来打开服务器的发送通道。这样，原本的四次握手就降为三次握手了。</p>
<p> 但是当连接处于半关闭状态时，TCP 是允许单向传输数据的。</p>
</li>
</ol>
<p><strong>互联网中往往服务器才是主动关闭连接的一方。</strong>这是因为，HTTP 消息是单向传输协议，服务器接收完请求才能生成响应，发送完响应后就会立刻关闭 TCP 连接，这样及时释放了资源，能够为更多的用户服务。</p>
<p>主动关闭方和被动关闭方优化的思路也不同，接下来分别说说如何优化他们。</p>
<h4 id="10-2-主动方的优化"><a href="#10-2-主动方的优化" class="headerlink" title="10.2 主动方的优化"></a>10.2 主动方的优化</h4><p>关闭的连接的方式通常有两种，分别是 RST 报文关闭和 FIN 报文关闭。</p>
<p>如果进程异常退出了，内核就会发送 RST 报文来关闭，它可以不走四次挥手流程，是一个暴力关闭连接的方式。</p>
<p>安全关闭连接的方式必须通过四次挥手，它由进程调用 close 或者 shutdown 函数发起，这二者都会向对方发送 FIN 报文（shutdown 参数须传入 SHUT_WR 或者 SHUT_RDWR 才会发送 FIN）。</p>
<ol>
<li><p>调用 close 函数 和 shutdown 函数有什么区别？</p>
<p> 调用了 close 函数意味着完全断开连接，<strong>完全断开不仅指无法传输数据，而且也不能发送数据。此时，调用了 close 函数的一方的连接叫做「孤儿连接」，如果你用 netstat -p 命令，会发现连接对应的进程名为空。</strong></p>
</li>
</ol>
<p>使用 close 函数关闭连接是不优雅的。于是，就出现了一种优雅关闭连接的 shutdown 函数，它可以控制只关闭一个方向的连接。</p>
<p>第二个参数决定断开连接的方式，主要有以下三种方式：</p>
<ul>
<li>SHUT_RD(0)：<strong>关闭连接的「读」这个方向</strong>，如果接收缓冲区有已接收的数据，则将会被丢弃，并且后续再收到新的数据，会对数据进行 ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本不知道数据已经被丢弃了。</li>
<li>SHUT_WR(1)：<strong>关闭连接的「写」这个方向</strong>，这就是常被称为「半关闭」的连接。如果发送缓冲区还有未发送的数据，将被立即发送出去，并发送一个 FIN 报文给对端。</li>
<li>SHUT_RDWR(2)：相当于 SHUT_RD 和 SHUT_WR 操作各一次，<strong>关闭套接字的读和写两个方向</strong>。</li>
</ul>
<p>close 和 shutdown 函数都可以关闭连接，但这两种方式关闭的连接，不只功能上有差异，控制它们的 Linux 参数也不相同。</p>
<h5 id="10-2-1-FIN-WAIT1-状态的优化？"><a href="#10-2-1-FIN-WAIT1-状态的优化？" class="headerlink" title="10.2.1 FIN_WAIT1 状态的优化？"></a>10.2.1 FIN_WAIT1 状态的优化？</h5><p>主动方发送 FIN 报文后，连接就处于 FIN_WAIT1 状态，正常情况下，如果能及时收到被动方的 ACK，则会很快变为 FIN_WAIT2 状态。</p>
<p>但是当迟迟收不到对方返回的 ACK 时，连接就会一直处于 FIN_WAIT1 状态。此时，<strong>内核会定时重发 FIN 报文，其中重发次数由 tcp_orphan_retries 参数控制</strong>（注意，orphan 虽然是孤儿的意思，该参数却不只对孤儿连接有效，事实上，它对所有 FIN_WAIT1 状态下的连接都有效），默认值是 0。</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_orphan_retries = 0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>你可能会好奇，这 0 表示几次？实际上当为 0 时，特指 8 次，从下面的内核源码可知：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token comment">/**
 *  tcp_orphan_retries() - Returns maximal number of retries on an orphaned socket
 *  @sk:    Pointer to the current socket.
 *  @alive: bool, socket alive state
 */</span>
<span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">tcp_orphan_retries</span><span class="token punctuation">(</span><span class="token keyword">struct</span> <span class="token class-name">sock</span> <span class="token operator">*</span>sk<span class="token punctuation">,</span> bool alive<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token keyword">int</span> retries <span class="token operator">=</span> <span class="token function">sock_net</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token operator">-&gt;</span>ipv4<span class="token punctuation">.</span>sysctl_tcp_orphan_retries<span class="token punctuation">;</span> <span class="token comment">/* May be zero. */</span>

    <span class="token comment">/* We know from an ICMP that something is wrong. */</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>sk<span class="token operator">-&gt;</span>sk_err_soft <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span>alive<span class="token punctuation">)</span>
        retries <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>

    <span class="token comment">/* However, if socket sent something recently, select some safe
     * number of retries. 8 corresponds to &gt;100 seconds with minimal
     * RTO of 200msec. */</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>retries <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> alive<span class="token punctuation">)</span>
        retries <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">;</span>
    <span class="token keyword">return</span> retries<span class="token punctuation">;</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>如果 FIN_WAIT1 状态连接很多，我们就需要考虑降低 tcp_orphan_retries 的值，当重传次数超过 tcp_orphan_retries 时，连接就会直接关闭掉。</p>
<p>对于普遍正常情况时，调低 tcp_orphan_retries 就已经可以了。如果遇到恶意攻击，FIN 报文根本无法发送出去，这由 TCP 两个特性导致的：</p>
<ul>
<li>首先，TCP 必须保证报文是有序发送的，FIN 报文也不例外，当发送缓冲区还有数据没有发送时，FIN 报文也不能提前发送。</li>
<li>其次，TCP 有流量控制功能，当接收方接收窗口为 0 时，发送方就不能再发送数据。所以，当攻击者下载大文件时，就可以通过接收窗口设为 0 ，这就会使得 FIN 报文都无法发送出去，那么连接会一直处于 FIN_WAIT1 状态。</li>
</ul>
<p>解决这种问题的方法，是<strong>调整 tcp_max_orphans 参数，它定义了「孤儿连接」的最大数量</strong>：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_max_orphans = 16384<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>当进程调用了 close 函数关闭连接，此时连接就会是「孤儿连接」，因为它无法在发送和接收数据。Linux 系统为了防止孤儿连接过多，导致系统资源长时间被占用，就提供了 tcp_max_orphans 参数。如果孤儿连接数量大于它，新增的孤儿连接将不再走四次挥手，而是直接发送 RST 复位报文强制关闭。</p>
<h5 id="10-2-2-FIN-WAIT2-状态的优化"><a href="#10-2-2-FIN-WAIT2-状态的优化" class="headerlink" title="10.2.2 FIN_WAIT2 状态的优化"></a>10.2.2 FIN_WAIT2 状态的优化</h5><p>当主动方收到 ACK 报文后，会处于 FIN_WAIT2 状态，就表示主动方的发送通道已经关闭，接下来将等待对方发送 FIN 报文，关闭对方的发送通道。</p>
<p>这时，<strong>如果连接是用 shutdown 函数关闭的，连接可以一直处于 FIN_WAIT2 状态，因为它可能还可以发送或接收数据。但对于 close 函数关闭的孤儿连接，由于无法在发送和接收数据，所以这个状态不可以持续太久，而 tcp_fin_timeout 控制了这个状态下连接的持续时长</strong>，默认值是 60 秒：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_fin_timeout = 60<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>它意味着对于孤儿连接（调用 close 关闭的连接），如果在 60 秒后还没有收到 FIN 报文，连接就会直接关闭。</p>
<p>这个 60 秒不是随便决定的，它与 TIME_WAIT 状态持续的时间是相同的，后面我们在来说说为什么是 60 秒。</p>
<h5 id="10-2-3-TIME-WAIT-状态的优化"><a href="#10-2-3-TIME-WAIT-状态的优化" class="headerlink" title="10.2.3 TIME_WAIT 状态的优化"></a>10.2.3 TIME_WAIT 状态的优化</h5><p>TIME_WAIT 是主动方四次挥手的最后一个状态，也是最常遇见的状态。</p>
<p>当收到被动方发来的 FIN 报文后，主动方会立刻回复 ACK，表示确认对方的发送通道已经关闭，接着就处于 TIME_WAIT 状态。在 Linux 系统，TIME_WAIT 状态会持续 60 秒后才会进入关闭状态。</p>
<p>TIME_WAIT 状态的连接，在主动方看来确实快已经关闭了。然后，被动方没有收到 ACK 报文前，还是处于 LAST_ACK 状态。如果这个 ACK 报文没有到达被动方，被动方就会重发 FIN 报文。重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制。</p>
<p>TIME-WAIT 的状态尤其重要，主要是两个原因：</p>
<ul>
<li>防止具有相同「四元组」的「旧」数据包被收到；</li>
<li>保证「被动关闭连接」的一方能被正确的关闭，即保证最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭；</li>
</ul>
<ol>
<li><p>原因一：防止旧连接的数据包</p>
<p> TIME-WAIT 的一个作用是<strong>防止收到历史数据，从而导致数据错乱的问题。</strong></p>
<p> <img src="/images/《系统性能调优必知必会》学习笔记/接收到历史数据的异常.png" alt="接收到历史数据的异常"></p>
<ul>
<li>如上图黄色框框服务端在关闭连接之前发送的 SEQ = 301 报文，被网络延迟了。</li>
<li><p>这时有相同端口的 TCP 连接被复用后，被延迟的 SEQ = 301 抵达了客户端，那么客户端是有可能正常接收这个过期的报文，这就会产生数据错乱等严重的问题。</p>
<p>所以，TCP 就设计出了这么一个机制，经过 2MSL 这个时间，<strong>足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。</strong></p>
</li>
</ul>
</li>
<li><p>原因二：保证连接正确关闭</p>
<p> TIME-WAIT 的另外一个作用是<strong>等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。</strong></p>
<p> 假设 TIME-WAIT 没有等待时间或时间过短，断开连接会造成什么问题呢？</p>
<p> <img src="/images/《系统性能调优必知必会》学习笔记/没有确保正常断开的异常.png" alt="没有确保正常断开的异常"></p>
<ul>
<li>如上图红色框框客户端四次挥手的最后一个 ACK 报文如果在网络中被丢失了，此时如果客户端 TIME-WAIT 过短或没有，则就直接进入了 CLOSE 状态了，那么服务端则会一直处在 LASE-ACK 状态。</li>
<li>当客户端发起建立连接的 SYN 请求报文后，服务端会发送 RST 报文给客户端，连接建立的过程就会被终止。</li>
</ul>
</li>
</ol>
<p>我们再回过头来看看，为什么 TIME_WAIT 状态要保持 60 秒呢？这与孤儿连接 FIN_WAIT2 状态默认保留 60 秒的原理是一样的，<strong>因为这两个状态都需要保持 2MSL 时长。MSL 全称是 Maximum Segment Lifetime，它定义了一个报文在网络中的最长生存时间</strong>（报文每经过一次路由器的转发，IP 头部的 TTL 字段就会减 1，减到 0 时报文就被丢弃，这就限制了报文的最长存活时间）。</p>
<p>为什么是 2 MSL 的时长呢？这其实是相当于至少允许报文丢失一次。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。</p>
<p>为什么不是 4 或者 8 MSL 的时长呢？你可以想象一个丢包率达到百分之一的糟糕网络，连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比。</p>
<p><strong>因此，TIME_WAIT 和 FIN_WAIT2 状态的最大时长都是 2 MSL，由于在 Linux 系统中，MSL 的值固定为 30 秒，所以它们都是 60 秒。</strong></p>
<p>虽然 TIME_WAIT 状态有存在的必要，但它毕竟会消耗系统资源。<strong>如果发起连接一方的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。</strong></p>
<ul>
<li><strong>客户端受端口资源限制</strong>：如果客户端 TIME_WAIT 过多，就会导致端口资源被占用，因为端口就65536个，被占满就会导致无法创建新的连接；</li>
<li><strong>服务端受系统资源限制</strong>：由于一个 四元组表示TCP连接，理论上服务端可以建立很多连接，服务端确实只监听一个端口 但是会把连接扔给处理线程，所以理论上监听的端口可以继续监听。但是线程池处理不了那么多一直不断的连接了。所以当服务端出现大量 TIME_WAIT 时，系统资源被占满时，会导致处理不过来新的连接；</li>
</ul>
<p>另外，<strong>Linux 提供了 tcp_max_tw_buckets 参数，当 TIME_WAIT 的连接数量超过该参数时，新关闭的连接就不再经历 TIME_WAIT 而直接关闭</strong>：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_max_tw_buckets = 5000<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>当服务器的并发连接增多时，相应地，同时处于 TIME_WAIT 状态的连接数量也会变多，此时就应当调大 tcp_max_tw_buckets 参数，减少不同连接间数据错乱的概率。</p>
<p>tcp_max_tw_buckets 也不是越大越好，毕竟内存和端口都是有限的。</p>
<p><strong>有一种方式可以在建立新连接时，复用处于 TIME_WAIT 状态的连接，那就是打开 tcp_tw_reuse 参数。但是需要注意，该参数是只用于客户端（建立连接的发起方），因为是在调用 connect() 时起作用的，而对于服务端（被动连接方）是没有用的。</strong></p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_tw_reuse = 1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>tcp_tw_reuse 从协议角度理解是安全可控的，可以复用处于 TIME_WAIT 的端口为新的连接所用。</p>
<p>什么是协议角度理解的安全可控呢？主要有两点：</p>
<ul>
<li>只适用于连接发起方，也就是 C/S 模型中的客户端；</li>
<li>对应的 TIME_WAIT 状态的连接创建时间超过 1 秒才可以被复用。</li>
</ul>
<p>使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持（对方也要打开 ）：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_timestamps = 1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>由于引入了时间戳，它能带来了些好处：</p>
<ul>
<li>我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃；</li>
<li>同时，它还可以防止序列号绕回，也是因为重复的数据包会由于时间戳过期被自然丢弃；</li>
</ul>
<p>老版本的 Linux 还提供了 tcp_tw_recycle 参数，但是当开启了它，就有两个坑：</p>
<ul>
<li><strong>Linux 会加快客户端和服务端 TIME_WAIT 状态的时间</strong>，也就是它会使得 TIME_WAIT 状态会小于 60 秒，很容易导致数据错乱；</li>
<li>另外，<strong>Linux 会丢弃所有来自远端时间戳小于上次记录的时间戳（由同一个远端发送的）的任何数据包</strong>。就是说要使用该选项，则必须保证数据包的时间戳是单调递增的。那么，问题在于，此处的时间戳并不是我们通常意义上面的绝对时间，而是一个相对时间。很多情况下，我们是没法保证时间戳单调递增的，比如使用了 NAT，LVS 等情况；</li>
</ul>
<p>所以，不建议设置为 1 ，建议关闭它：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">net.ipv4.tcp_tw_recycle = 0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>在 Linux 4.12 版本后，Linux 内核直接取消了这一参数。</p>
<p>另外，我们可以在程序中设置 socket 选项，来设置调用 close 关闭连接行为。</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">struct</span> <span class="token class-name">lingger</span> so_linger<span class="token punctuation">;</span>
so_linger<span class="token punctuation">.</span>l_onoff <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
so_linger<span class="token punctuation">.</span>l_linger <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token function">setsocketopt</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> SOL_SOCKET<span class="token punctuation">,</span> SO_LINGER<span class="token punctuation">,</span> <span class="token operator">&amp;</span>so_linger<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>so_linger<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>如果l_onoff为非 0， 且l_linger值为 0，那么调用close后，会立该发送一个 RST 标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了 TIME_WAIT 状态，直接关闭。</p>
<p>但这为跨越 TIME_WAIT 状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。</p>
<h4 id="10-3-被动方的优化"><a href="#10-3-被动方的优化" class="headerlink" title="10.3 被动方的优化"></a>10.3 被动方的优化</h4><p>当被动方收到 FIN 报文时，内核会自动回复 ACK，同时连接处于 CLOSE_WAIT 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。</p>
<p>内核没有权利替代进程去关闭连接，因为如果主动方是通过 shutdown 关闭连接，那么它就是想在半关闭连接上接收数据或发送数据。因此，Linux 并没有限制 CLOSE_WAIT 状态的持续时间。</p>
<p>当然，大多数应用程序并不使用 shutdown 函数关闭连接。所以，<strong>当你用 netstat 命令发现大量 CLOSE_WAIT 状态。就需要排查你的应用程序，因为可能因为应用程序出现了 Bug，read 函数返回 0 时，没有调用 close 函数。</strong></p>
<p>处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文关闭发送通道，同时连接进入 LAST_ACK 状态，等待主动方返回 ACK 来确认连接关闭。</p>
<p>如果迟迟收不到这个 ACK，内核就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与主动方重发 FIN 报文的优化策略一致。</p>
<p>还有一点我们需要注意的，<strong>如果被动方迅速调用 close 函数，那么被动方的 ACK 和 FIN 有可能在一个报文中发送，这样看起来，四次挥手会变成三次挥手，这只是一种特殊情况，不用在意。</strong></p>
<ol>
<li><p>如果连接双方同时关闭连接，会怎么样？</p>
<p> 由于 TCP 是双全工的协议，所以是会出现两方同时关闭连接的现象，也就是同时发送了 FIN 报文。</p>
<p> 此时，上面介绍的优化策略仍然适用。两方发送 FIN 报文时，都认为自己是主动方，所以都进入了 FIN_WAIT1 状态，FIN 报文的重发次数仍由 tcp_orphan_retries 参数控制。</p>
<p> <img src="/images/《系统性能调优必知必会》学习笔记/同时关闭.png" alt="同时关闭"></p>
<p> 接下来，<strong>双方在等待 ACK 报文的过程中，都等来了 FIN 报文。这是一种新情况，所以连接会进入一种叫做 CLOSING 的新状态，它替代了 FIN_WAIT2 状态。</strong>接着，双方内核回复 ACK 确认对方发送通道的关闭后，进入 TIME_WAIT 状态，等待 2MSL 的时间后，连接自动关闭。</p>
</li>
</ol>
<h4 id="10-4-小结"><a href="#10-4-小结" class="headerlink" title="10.4 小结"></a>10.4 小结</h4><p>针对 TCP 四次挥手的优化，我们需要根据主动方和被动方四次挥手状态变化来调整系统 TCP 内核参数。</p>
<p><img src="/images/《系统性能调优必知必会》学习笔记/四次挥手的优化策略.png" alt="四次挥手的优化策略"></p>
<h5 id="10-4-1-主动方的优化"><a href="#10-4-1-主动方的优化" class="headerlink" title="10.4.1 主动方的优化"></a>10.4.1 主动方的优化</h5><p>主动发起 FIN 报文断开连接的一方，如果迟迟没收到对方的 ACK 回复，则会重传 FIN 报文，重传的次数由 tcp_orphan_retries 参数决定。</p>
<p>当主动方收到 ACK 报文后，连接就进入 FIN_WAIT2 状态，根据关闭的方式不同，优化的方式也不同：</p>
<ul>
<li>如果这是 close 函数关闭的连接，那么它就是孤儿连接。如果 tcp_fin_timeout 秒内没有收到对方的 FIN 报文，连接就直接关闭。同时，为了应对孤儿连接占用太多的资源，tcp_max_orphans 定义了最大孤儿连接的数量，超过时连接就会直接释放。</li>
<li>反之是 shutdown 函数关闭的连接，则不受此参数限制；</li>
</ul>
<p>当主动方接收到 FIN 报文，并返回 ACK 后，主动方的连接进入 TIME_WAIT 状态。这一状态会持续 1 分钟，为了防止 TIME_WAIT 状态占用太多的资源，tcp_max_tw_buckets 定义了最大数量，超过时连接也会直接释放。</p>
<p>当 TIME_WAIT 状态过多时，还可以通过设置 tcp_tw_reuse 和 tcp_timestamps 为 1 ，将 TIME_WAIT 状态的端口复用于作为客户端的新连接，注意该参数只适用于客户端。</p>
<h5 id="10-4-2-被动方的优化"><a href="#10-4-2-被动方的优化" class="headerlink" title="10.4.2 被动方的优化"></a>10.4.2 被动方的优化</h5><p>被动关闭的连接方应对非常简单，它在回复 ACK 后就进入了 CLOSE_WAIT 状态，等待进程调用 close 函数关闭连接。因此，出现大量 CLOSE_WAIT 状态的连接时，应当从应用程序中找问题。</p>
<p>当被动方发送 FIN 报文后，连接就进入 LAST_ACK 状态，在未等到 ACK 时，会在 tcp_orphan_retries 参数的控制下重发 FIN 报文。</p>
<h2 id="四、应用层编解码优化"><a href="#四、应用层编解码优化" class="headerlink" title="四、应用层编解码优化"></a>四、应用层编解码优化</h2><h2 id="五、期中考试周"><a href="#五、期中考试周" class="headerlink" title="五、期中考试周"></a>五、期中考试周</h2><h2 id="六、分布式系统优化"><a href="#六、分布式系统优化" class="headerlink" title="六、分布式系统优化"></a>六、分布式系统优化</h2><h2 id="七、加餐与分享"><a href="#七、加餐与分享" class="headerlink" title="七、加餐与分享"></a>七、加餐与分享</h2><h2 id="八、结束语"><a href="#八、结束语" class="headerlink" title="八、结束语"></a>八、结束语</h2>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kibazen.cn" rel="external nofollow noreferrer">Kiba Amor</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                    </span>
                <span class="reprint-info">
                    <a href="https://kibazen.cn/xi-tong-xing-neng-diao-you-bi-zhi-bi-hui-xue-xi-bi-ji/">https://kibazen.cn/xi-tong-xing-neng-diao-you-bi-zhi-bi-hui-xue-xi-bi-ji/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY-NC-ND 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://kibazen.cn" target="_blank">Kiba Amor</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">
                                    <span class="chip bg-color">极客时间</span>
                                </a>
                            
                                <a href="/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">
                                    <span class="chip bg-color">性能优化</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="qq,wechat,weibo,douban" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/xi-tong-xing-neng-diao-you-bi-zhi-bi-hui-xue-xi-bi-ji/">
                    <div class="card-image">
                        
                        
                        <img src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/featureimages/5.jpg" class="responsive-img" alt="《系统性能调优必知必会》学习笔记">
                        
                        <span class="card-title">《系统性能调优必知必会》学习笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-01-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-category">
                                    学习笔记
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">
                        <span class="chip bg-color">极客时间</span>
                    </a>
                    
                    <a href="/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">
                        <span class="chip bg-color">性能优化</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/linux-nei-he-ji-zhu-shi-zhan-ke-xue-xi-bi-ji/">
                    <div class="card-image">
                        
                        
                        <img src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/featureimages/23.jpg" class="responsive-img" alt="《Linux内核技术实战课》学习笔记">
                        
                        <span class="card-title">《Linux内核技术实战课》学习笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-01-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-category">
                                    学习笔记
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">
                        <span class="chip bg-color">极客时间</span>
                    </a>
                    
                    <a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">
                        <span class="chip bg-color">操作系统</span>
                    </a>
                    
                    <a href="/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">
                        <span class="chip bg-color">性能优化</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (true) {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: 木叶禅<br />'
            + '文章作者: Kiba Amor<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者木叶禅所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('2'),
            headingSelector: 'h2, h3, h4, h5'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4, h5').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2022</span>
            
            <span id="year">2019</span>
            <a href="/about" target="_blank">Kiba Amor</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">687.3k</span>&nbsp;字
            
            
            
            
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link ">
    <a href="https://github.com/kibaamor" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>









    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=562236616" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 562236616" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/kibaamor" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kibaamor" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    

    

    

	
    

    

    

    
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
