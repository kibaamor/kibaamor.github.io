<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="keywords" content="《周志明的软件架构课》学习笔记（上）, kiba, zen, amor, kibazen, kibaamor, 木叶, 木叶禅">
    <meta name="description" content="You are too concerned with what was and what will be">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>《周志明的软件架构课》学习笔记（上） | 木叶禅</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/css/my.css">

    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="木叶禅" type="application/atom+xml">
</head>



   <style>
    body{
       background-image: url(/medias/background.jpg);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>



<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">木叶禅</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/learn/" class="waves-effect waves-light">
      
      <i class="fas fa-book" style="zoom: 0.6;"></i>
      
      <span>Learn</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/memo/" class="waves-effect waves-light">
      
      <i class="fas fa-sticky-note" style="zoom: 0.6;"></i>
      
      <span>Memo</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories/" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags/" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about/" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">木叶禅</div>
        <div class="logo-desc">
            
            You are too concerned with what was and what will be
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/learn/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-book"></i>
			
			Learn
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/memo/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-sticky-note"></i>
			
			Memo
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    
<script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = 'f65e070788a2647953051a7a1b70ada7fd2b3f70cd4d93c977207f5b762987d4';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/featureimages/16.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">《周志明的软件架构课》学习笔记（上）</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">
                                <span class="chip bg-color">极客时间</span>
                            </a>
                        
                            <a href="/tags/%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84/">
                                <span class="chip bg-color">软件架构</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-category">
                                学习笔记
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-03-06
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2023-04-13
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    85.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    300 分
                </div>
                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="开篇词"><a href="#开篇词" class="headerlink" title="开篇词"></a>开篇词</h2><h3 id="如何构建一个可靠的分布式系统？"><a href="#如何构建一个可靠的分布式系统？" class="headerlink" title="如何构建一个可靠的分布式系统？"></a>如何构建一个可靠的分布式系统？</h3><p>作为一名架构师，在软件研发的过程中，最难的事儿，其实并不是如何解决具体某个缺陷、如何提升某段代码的性能，而是 <strong>如何才能让一系列来自不同开发者、不同厂商、不同版本、不同语言、质量也良莠不齐的软件模块，在不同的物理硬件和拓扑结构随时变动的网络环境中，依然能保证可靠的运行质量。</strong></p>
<p>显然，这并不是一个研发过程的管理问题。一套”靠谱”的软件系统，尤其是大型的、分布式的软件系统，很难指望只依靠团队成员的个人能力水平，或者依靠质量管理流程来达成。</p>
<p>在我看来，这是一个系统性的、架构层面的问题，最终还是要在技术和架构中去解决。而这也正是我要在这门课中跟你一起探讨的主题： <strong>如何构建一个可靠的分布式系统。</strong></p>
<h4 id="我是怎么规划课程的？"><a href="#我是怎么规划课程的？" class="headerlink" title="我是怎么规划课程的？"></a>我是怎么规划课程的？</h4><p>那么，为了能够讨论清楚这个话题，我把课程划分成了以下 5 个模块。</p>
<ol>
<li><p><strong>演进中的架构</strong>: 我会借着讨论历史之名，从全局性的视角，帮你梳理微服务发展历程中出现的大量技术名词、概念，让你了解这些技术的时代背景和探索过程，帮你在后续的课程讲解中，更容易去深入理解软件架构设计的本质。</p>
</li>
<li><p><strong>分布式的基石</strong>：我会聚焦在分布式架构，和你探讨分布式带来的问题与应对策略。我会带你剖析分布式架构中出现的一系列问题，比如服务的注册发现、跟踪治理、负载均衡、故障隔离、认证授权、伸缩扩展、传输通讯、事务处理等，有哪些解决思路、方法和常见工具。</p>
</li>
<li><p><strong>不可变基础设施</strong>：我会按照云原生时代”基础设施即代码”的新思路，带你深入理解基础设施不变性的目的、原理与实现途径，和你一起去体会用代码和用基础设施，来解决分布式问题的差异，让你能够理解不可变基础设施的内涵，便于在实际工作中做运维、程序升级和部署等工作。</p>
</li>
<li><p><strong>探索与实践</strong>：我会带你一起开发不同架构的 Fenix”s Bookstore（”<a target="_blank" rel="noopener" href="http://time.geekbang.org/column/article/309747">导读</a>“这一讲会具体介绍这个项目），并看看在不同环境下都应该怎么部署。这个模块的定位是”实战”，为了保证学习效果，我特意没有安排音频，所以建议你一定要自己动手去实操。</p>
</li>
</ol>
<p>因为我相信，如果你是一名驾驶初学者，最合理的学习路径应该是先把汽车发动，然后慢慢行驶起来，而不是马上从”引擎动力原理””变速箱构造”入手，去设法深刻地了解一台汽车。学习计算机技术也是同样的道理。所以在”探索与实践”模块，我会先带你从运行程序开始，看看效果，然后再搭建好开发、调试环境。</p>
<p>说到这里，我一定要和你说说怎么学习这门课，才能保证最好的效果。</p>
<h4 id="你要怎么学习这门课？"><a href="#你要怎么学习这门课？" class="headerlink" title="你要怎么学习这门课？"></a>你要怎么学习这门课？</h4><p>如果你已经是一名系统架构师或者高级开发工程师了，那这门课程就非常适合你。通过跟随学习，你会知道，在软件设计、架构工作中，都需要考虑哪些因素、需要解决哪些问题、有哪些行业标准的解决方案。而如果你是个刚入行不久的程序员，那你可以把这门课程作为一个概念名词的速查手册。</p>
<p>很多内容对你来说可能是全新的，甚至会颠覆你过去的一些认知。而这门课程的好处就是，在不同的技术水平阶段，你都会找到不同的使用方法。具体怎么做呢？</p>
<ul>
<li>第一步，先完整地跟着课程的节奏学习一遍。你可以先去串一下各种技术名词和架构理论概念，拓展一下视野，去看看大型的架构项目是怎么搭建的，涨涨见识，不一定要求自己深入地理解和记住每一讲的内容。</li>
<li>第二步，根据自己当前的情况，按图索骥寻找对应的章节深入学习并实践。</li>
<li>第三步，当你有了一定的实践经验之后，再来重新学习对应的章节，看看自己曾经的理解是否有遗漏或者有偏差，或者看看我的内容是否还有不完善的地方，真正将知识变成自己的认知。</li>
</ul>
<h4 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h4><p>最后，我想说的是，我在极客时间上开设这门课程，既是为了分享与技术布道，也是为了借这个机会，系统性地整理自己的知识，查缺补漏，将它们都融入既有的知识框架之中。</p>
<p><strong>我一直认为，技术人员的成长是有”捷径”的，做技术不仅要去看、去读、去想、去用，更要去写、去说。</strong></p>
<p>把自己”认为掌握了的”知识给叙述出来，能够写得条理清晰，讲得理直气壮；能够让别人听得明白，释去心中疑惑；能够把自己的观点交给别人审视，乃至质疑。在这个过程之中，就会挖掘出很多潜藏在”已知”背后的”未知”。</p>
<h3 id="什么是”The-Fenix-Project”？"><a href="#什么是”The-Fenix-Project”？" class="headerlink" title="什么是”The Fenix Project”？"></a>什么是”The Fenix Project”？</h3><h4 id="软件架构探索"><a href="#软件架构探索" class="headerlink" title="软件架构探索"></a>软件架构探索</h4><p>“Phoenix”的字面意思，就是”凤凰”，或者是”不死鸟”，这个词我们东方人不太常用，但它在西方的软件工程读物，尤其是关于 Agile、DevOps 话题的作品中经常会出现。</p>
<p>比如说，软件工程小说《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/20644908/">The Phoenix Project</a>》，就讲述了徘徊在死亡边缘的 Phoenix 项目，在精益方法下浴火重生的故事；马丁 · 福勒（Martin Fowler）对《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/4327796/">Continuous Delivery</a>》（持续交付）的诠释里，也多次提到过”<a target="_blank" rel="noopener" href="https://martinfowler.com/bliki/PhoenixServer.html">Phoenix Server</a>“（取其能够”涅槃重生”之意）与”<a target="_blank" rel="noopener" href="https://martinfowler.com/bliki/SnowflakeServer.html">Snowflake Server</a>“（取其”世界上没有相同的两片雪花”之意）的优劣比对。</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/ThePhoenixProject.webp" alt="ThePhoenixProject"></p>
<p>也许是东西方文化差异的原因，尽管我们东方人会说”失败是成功之母”，但骨子里还是更注重一次就能把事做对、做好，尽量别出乱子；而西方人则要”更看得开”一些，把出错看作是正常、甚至是必须的发展过程，只要出了问题能够兜底，能重回正轨就好。</p>
<p>其实在软件工程的世界里，任何产品的研发，只要时间尺度足够长，人就总会疏忽犯错，代码就总会带有缺陷，电脑就总会宕机崩溃，网络就总会堵塞中断……</p>
<p>所以如果一项工程需要大量的人员共同去研发，并保证它们分布在网络中的大量服务器节点能够同时运行，那么随着项目规模的增大、运作时间变长，它必然会受到墨菲定律的无情打击。</p>
<blockquote>
<p>Murphy”s Law: Anything that can go wrong will go wrong.</p>
<p>墨菲定律：凡事只要有可能出错，那就一定会出错。</p>
</blockquote>
<p><strong>这样问题就来了：为了得到高质量的软件产品，我们是应该把精力更多地集中在提升每一个人员、过程、产出物的能力和质量上，还是放在整体流程和架构上？</strong></p>
<p>这里我先给一个”和稀泥”式的回答：这两者都重要。前者重术，后者重道；前者更多与编码能力相关，后者更多与软件架构相关；前者主要由开发者个体水平决定，后者主要由技术决策者水平决定。</p>
<p>但是，我也必须要强调这个问题的另外一面：这两者的理解路径和抽象程度是不一样的。</p>
<p>如何学习一项具体的语言、框架、工具，比如 Java、Spring、Vue.js，等等，都是相对具象的，不论其蕴含的内容多少、复杂程度的高低，它们至少是能看得见、摸得着的。</p>
<p>而如何学习某一种风格的架构方法，比如单体、微服务、服务网格、无服务、云原生，等等，则是相对抽象的，谈论它们可能要面临着”一百个人眼中有一百个哈姆雷特”的困境。</p>
<p>所以，探讨这方面的话题，要想言之有物，就不能只是单纯的经验陈述了。</p>
<p>那么我就想，回到这些架构根本的出发点和问题上，带你一起真正去使用这些不同风格的架构方法，来实现某些需求、解决某些问题，然后在实践中观察它们的异同优劣，这会是一种很好的，也许是最好的学习方式。</p>
<h4 id="可靠的系统"><a href="#可靠的系统" class="headerlink" title="可靠的系统"></a>可靠的系统</h4><p>我们接着前面提出的”人与系统”的探讨，再来思考一个问题： <strong>构建一个大规模但依然可靠的软件系统，是否可行？</strong></p>
<p>看到这个问题，你的第一感觉可能会认为有点荒谬：废话。如果这个事情从理论上来说就根本不可能的话，那我们这些做软件开发的还在瞎忙活些什么呢？</p>
<p>但你再仔细想想，根据”墨菲定律”和在”大规模”这个前提下，在做软件开发时，你一定会遇到各种不靠谱的人员、代码、硬件、网络等因素。那你从中就能得出一个听起来很符合逻辑直觉的推论： <strong>如果一项工作，要经过多个”不靠谱”的过程相互协作来完成，其中的误差应该会不断地累积叠加，导致最终结果必然不能收敛稳定才对。</strong></p>
<p>这个问题，也并不是杞人忧天、庸人自扰式的瞎操心，计算机之父冯 · 诺依曼（John von Neumann）在 1940 年代末期，就曾经花了大约两年的时间，来研究这个问题，并且得出了一门理论《自复制自动机》（Theory of Self-Reproducing Automata），这个理论以机器应该如何从基本的部件中，构造出与自身相同的另一台机器引出。</p>
<p>他的目的并不是想单纯地模拟或者理解生物体的自我复制，也并不是简单地想制造自我复制的计算机，而就是想回答一个理论问题： <strong>如何用一些不可靠的部件来构造出一个可靠的系统。</strong></p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/当时自复制机的艺术表示.webp" alt="当时自复制机的艺术表示"></p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Self-replicating_machine">当时自复制机的艺术表示</a></p>
<p>所以说，自复制机恰好就是一个最好的、用不可靠部件构造的可靠系统的例子。这里的”不可靠部件”，你可以理解为构成生命的大量细胞、甚至是分子。由于热力学扰动、生物复制差错等因素的干扰，这些分子本身并不可靠。</p>
<p>但是，生命系统之所以可靠的本质，恰恰是因为它可以使用不可靠的部件来完成遗传迭代。这其中的关键点，便是承认细胞、分子等这些零部件可能会出错，某个具体的零部件可能会崩溃消亡，但在存续生命的微生态系统中，一定会有其后代的出现，重新代替该零部件的作用，以维持系统的整体稳定。</p>
<p>因而，在这个微生态里，每一个部件都可以看作是一只不死鸟（Phoenix），它会老迈，而之后又能涅槃重生。</p>
<p>虽然几乎是在计算机诞生的同时，计算机科学家就开始研究如何构造可靠的软件系统，并且得到了”像 Phoenix 一样迭代的生态才是可靠的”明确的结论，但是软件架构却不是一蹴而就地直接照这个结论去设计。原因也很简单，因为软件架构有一个逐渐演进的过程。</p>
<h4 id="架构的演进"><a href="#架构的演进" class="headerlink" title="架构的演进"></a>架构的演进</h4><p>软件架构风格从大型机（Mainframe），发展到了多层单体架构（Monolithic），到分布式（Distributed），到微服务（Microservices），到服务网格（Service Mesh），到无服务（Serverless）……你能发现，在技术架构上确实呈现出”从大到小”的发展趋势。</p>
<p>这几年微服务兴起后，出现了各类文章去总结、去赞美它的各种好处，比如简化了部署、逻辑拆分更清晰、便于技术异构、易于伸缩拓展应对更高的性能，等等。没错，这些都是微服务架构非常重要的优点，也是企业去搭建微服务的动力。</p>
<p>可是，如果不拘泥于特定系统或特定的某个问题，我们从更宏观的角度来看，前面所列举的这些好处，都只能算是”锦上添花”、是让系统”活得更好”的动因，肯定比不上系统如何”确保生存”的需求来得更关键、本质。</p>
<p>在我看来，架构演变最重要的驱动力，或者说产生这种”从大到小”趋势的最根本的驱动力，始终都是 <strong>为了方便某个服务能够顺利地”死去”与”重生”而设计</strong> 的。个体服务的生死更迭，是关系到整个系统能否可靠续存的关键因素。</p>
<p>我举个例子。假设某个企业中应用的是单体架构的 Java 系统，它的更新、升级都必须要有固定的停机计划，必须在特定的时间窗口内才能按时开始，而且必须按时结束。如果出现了非计划之中的宕机，那就是生产事故。</p>
<p>但是，软件的缺陷不会遵循领导定下的停机计划来”安排时间出错”，所以为了应对缺陷与变化，做到不停机地检修，Java 曾经搞出了 OSGi 和 JVMTI Instrumentation 等这样复杂的 HotSwap 方案，以实现给奔跑中的汽车更换轮胎这种匪夷所思却又无可奈何的需求。</p>
<p>而在微服务架构的视角下，所谓的系统检修，只不过是一次在线服务更新而已，先停掉 1/3 的机器，升级新的软件版本，再有条不紊地导流、测试、做金丝雀发布，一切都是显得如此理所当然；而在无服务架构的视角下，我们甚至都不可能去关心服务所运行的基础设施，甚至连机器是哪台都不用知道，停机升级什么的就根本无从谈起了。</p>
<p><strong>流水不腐，有老朽、有消亡、有重生、有更迭，才是正常生态的运作合理规律。</strong></p>
<p>那么你来设想一下，如果你的系统中，每个部件都符合”Phoenix”的特性，哪怕其中的某些部件采用了极不靠谱的程序代码，哪怕存在严重的内存泄漏问题，最多只能服务三分钟就一定会崩溃。而即便这样，只要在整体架构设计中，有恰当的、自动化的错误熔断、服务淘汰和重建的机制，那在系统外部来观察，它在整体上仍然有可能表现出稳定和健壮的服务能力。</p>
<p>铺垫到这里，我就可以给你解释清楚，到底什么是”The Fenix Project”了。</p>
<h4 id="为什么叫做”The-Fenix-Project”？"><a href="#为什么叫做”The-Fenix-Project”？" class="headerlink" title="为什么叫做”The Fenix Project”？"></a>为什么叫做”The Fenix Project”？</h4><p>你应该也知道，在企业软件开发的历史中，当发布一项新技术的时候，常常会有伴以该技术开发的”宠物店（PetStore）”作为演示的传统（如J2EE PetStore、.NET PetShop、Spring PetClinic等）。</p>
<p>所以，在课程里，我在带你做不同架构风格的演示时，也希望能遵循这个传统。不过无奈的是，我从来没养过宠物，于是就改行开了书店（Fenix”s Bookstore），里面出售了几本我写过的书，算是夹带了一点私货，这样也避免了在使用素材时可能产生的版权问题。</p>
<p>另外，尽管我相信没有人会误解，但我还是想多强调一句，Oracle、Microsoft、Pivotal 等公司设计宠物店的目的，绝不是为了日后能在网上贩卖小猫小狗，他们只是在纯粹地演示技术。</p>
<p>所以说，你也不要以”实现这种学生毕业设计复杂度的需求，却引入如此规模的架构或框架，纯属大炮打苍蝇，肯定是过度设计”的眼光，来看待这个”Fenix”s Bookstore”项目。</p>
<p>相反，如果可能的话，我会在有新的技术、框架发布出来的时候，持续更新，以恰当的形式添加到项目的不同版本中，让它的技术栈越来越复杂。我希望把这些新的、不断发展的知识，融合进已有的知识框架之中，让自己学习、理解、思考，然后将这些技术连同自己的观点看法，分享给你。</p>
<p>说到这儿，我和”Fenix”这个名字还有一段奇妙的缘分。在二十多年前，我就开始用”IcyFenix”这个网名了。这个名字来源于暴雪公司的即时战略游戏《星际争霸》，里面有一个 Protoss（普罗托斯）英雄叫Fenix（菲尼克斯）。就像这个名字所预示的那样，Fenix 曾经是 Zealot（狂热者），牺牲后以 Dragoon（龙骑兵）的形式重生，带领 Protoss 与刀锋女王 Kerrigan（凯瑞甘）继续抗争。</p>
<p>所以，既然我们要开始一段关于”Phoenix”的代码与故事，那便叫它”The Fenix Project”，如何？</p>
<h2 id="演进中的架构"><a href="#演进中的架构" class="headerlink" title="演进中的架构"></a>演进中的架构</h2><h3 id="01-原始分布式时代：Unix设计哲学下的服务探索"><a href="#01-原始分布式时代：Unix设计哲学下的服务探索" class="headerlink" title="01 | 原始分布式时代：Unix设计哲学下的服务探索"></a>01 | 原始分布式时代：Unix设计哲学下的服务探索</h3><p>架构并不是被”发明”出来的，而是持续进化的结果。所以在这一模块中，我会借着讨论历史之名，从全局性的视角，来带你一起梳理下微服务的发展历程中，出现的大量技术名词、概念。</p>
<p>我会和你一起去分析，它们都是什么、取代了什么，以及为什么能够在技术发展的斗争中取得成功，为什么会成为软件架构不可或缺的支撑；又或者它们为什么会失败，为什么会逐渐被我们遗忘。</p>
<p>了解了这些技术的时代背景和探索过程，在后续的课程中，我再去讲解它们的原理、它们是如何解决问题的时候，你就能与它们当初的设计思想产生共鸣，能更容易深入理解其本质了。</p>
<p>今天这一讲，让我们先把时间拨回到半个世纪之前，一起来探讨下计算机最开始进入公众视野的时候，在 Unix 设计哲学的指导下，分布式架构的第一次服务化探索的得与失。</p>
<blockquote>
<p><strong>Unix 的分布式设计哲学</strong></p>
<p>Simplicity of both the interface and the implementation are more important than any other attributes of the system — including correctness, consistency, and completeness.</p>
<p>保持接口与实现的简单性，比系统的任何其他属性，包括准确性、一致性和完整性，都来得更加重要。</p>
<p>—— <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Richard_P._Gabriel">Richard P. Gabriel</a>，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Worse_is_better">The Rise of ‘Worse is Better</a>，1991</p>
</blockquote>
<p>分布式架构的目标是使用多个独立的分布式服务，来共同构建一个更大型的系统。不过，可能跟绝大多数人心中的认知有点儿差异，分布式系统的设想和它实际的尝试，反而要比你今天所了解的大型单体系统出现的时间更早。</p>
<p>在 20 世纪 70 年代末到 80 年代初，计算机科学刚经历了从以大型机为主，到向以微型机为主的蜕变，计算机也逐渐从一种存在于研究机构、实验室当中的科研设备，转变为了存在于商业企业中的生产设备，甚至是面向家庭、个人用户的娱乐设备。</p>
<p>这个时候的微型计算机系统，通常具有 16 位寻址能力、不足 5MHz（兆赫）时钟频率的处理器和 128KB 左右的内存地址空间。比如说，著名的英特尔处理器的鼻祖，<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/zh-tw/Intel_8086">Intel 8086 处理器</a> 就是在 1978 年研制成功，流行于 80 年代中期的，甚至一直到 90 年代初期还在生产销售。</p>
<p>不过，因为当时的计算机硬件的运算处理能力还相当薄弱，已经直接妨碍了单台计算机上信息系统软件能够达到的最大规模。所以，为了突破硬件算力的限制，各个高校、研究机构、软硬件厂商，都开始分头探索，想看看到底能不能使用多台计算机共同协作，来支撑同一套软件系统的运行。</p>
<p>这个阶段其实是对分布式架构最原始的探索与研究。你可能会觉得奇怪， <strong>计算机科学这个技术发展一日千里的领域，半个世纪之前的研究对今天还能有什么指导意义？</strong> 那个时候探索的分布式如果是可行的，又怎么会拖到今时今日，软件系统才逐步进入微服务时代？</p>
<p>然而并非如此，从结果来看，历史局限决定了它不可能一蹴而就地解决分布式的难题，但仅从过程来看，这个阶段的探索可以称得上是硕果累累、成绩斐然。因为在这个时期提出的很多技术、概念，对 Unix 系统后续的发展，甚至是对今天计算机科学的很多领域，都产生了巨大而深远的影响，直接带动了后续的软件架构演化进程。</p>
<p>我们看一些比较熟悉的例子吧。</p>
<p>比如，惠普公司（及后来被惠普收购的 Apollo），在 80 年代初期提出的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Network_Computing_System">网络运算架构（Network Computing Architecture，NCA）</a> ，就可以说是未来远程服务调用的雏形。</p>
<p>再比如，卡内基 · 梅隆大学提出的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Andrew_File_System">AFS 文件系统（Andrew File System）</a> ，可以看作是分布式文件系统的最早实现（顺便一提，Andrew 的意思是纪念 Andrew Carnegie 和 Andrew Mellon）。</p>
<p>再比如，麻省理工学院提出的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Kerberos_(protocol">Kerberos 协议</a>) ，是服务认证和访问控制（ACL）的基础性协议，是分布式服务安全性的重要支撑，目前包括 Windows 和 macOS 在内的众多操作系统的登录、认证功能，等等，都会利用到这个协议。</p>
<p>而为了避免 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Unix_wars">Unix 系统的版本战争</a> 在分布式领域中重演，负责制定 Unix 系统技术标准的 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%96%8B%E6%94%BE%E8%BB%9F%E9%AB%94%E5%9F%BA%E9%87%91%E6%9C%83">开放软件基金会（Open Software Foundation，OSF，也就是后来的”国际开放标准组织”）</a> 就邀请了各个主要的研究厂商一起参与，共同制订了 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%88%86%E6%95%A3%E5%BC%8F%E9%81%8B%E7%AE%97%E7%92%B0%E5%A2%83">“分布式运算环境”（Distributed Computing Environment，DCE）</a> 的分布式技术体系。</p>
<p><strong>DCE 包括了一整套完整的分布式服务组件的规范与实现。</strong></p>
<p>比如，源自 NCA 的远程服务调用规范（Remote Procedure Call，RPC，在当时被称为是 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/DCE/RPC">DCE/RPC</a> ），跟后来不局限于 Unix 系统的、基于通用 TCP/IP 协议的远程服务标准 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%96%8B%E6%94%BE%E7%B6%B2%E8%B7%AF%E9%81%8B%E7%AE%97%E9%81%A0%E7%AB%AF%E7%A8%8B%E5%BA%8F%E5%91%BC%E5%8F%AB">ONC RPC</a> ，一起被认为是现代 RPC 的共同鼻祖（这是 Sun 公司向互联网工程任务组提交的）；源自 AFS 的分布式文件系统（Distributed File System，DFS）规范，在当时被称为 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/DCE_Distributed_File_System">DCE/DFS</a> ；源自 Kerberos 的服务认证规范；还有时间服务、命名与目录服务，就连现在程序中很常用的通用唯一识别符 UUID，也是在 DCE 中发明出来的。</p>
<p>因为 OSF 本身的背景（它是一个由 Unix 开发者组成的 Unix 标准化组织），所以在当时研究这些分布式技术，通常都会有一个预设的重要原则，也就是在实现分布式环境中的服务调用、资源访问、数据存储等操作的时候，要尽可能地透明化、简单化，让开发人员不用去过于关注他们访问的方法，或者是要知道其他资源是位于本地还是远程。</p>
<p>这样的主旨呢，确实非常符合 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Unix_philosophy#cite_note-0">Unix 设计哲学</a> （有过几个版本的不同说法，这里我指的是 Common Lisp 作者 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Richard_P._Gabriel">Richard P. Gabriel</a> 提出的简单优先” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/KISS_principle">Worse is Better</a> “原则），但这个目标其实是过于理想化了，它存在一些在当时根本不可能完美解决的技术困难。</p>
<p>“调用远程方法”与”调用本地方法”尽管只是两字之差，但要是想能同时兼顾到简单、透明、性能、正确、鲁棒（Robust）、一致的目标的话，两者的复杂度就完全不能相提并论了。</p>
<p>我们先不说，远程方法是不可能做到像本地方法一样，能用内联等传统编译原理中的优化算法，来提升程序运行速度的，光是”远程”二字带来的网络环境下的新问题。</p>
<p>比如说，远程的服务在哪里（服务发现）、有多少个（负载均衡）、网络出现分区、超时或者服务出错了怎么办（熔断、隔离、降级）、方法的参数与返回结果如何表示（序列化协议）、如何传输（传输协议）、服务权限如何管理（认证、授权）、如何保证通信安全（网络安全层）、如何令调用不同机器的服务能返回相同的结果（分布式数据一致性）等一系列问题，就需要设计者耗费大量的心思。</p>
<p>那么，面对重重的困难与压力， <strong>DCE 不仅从零开始、从无到有地回答了其中大部分问题，构建出了大量的分布式基础组件与协议，而且它还真的尽力去做到了相对意义的”透明”。</strong></p>
<p>比如说，你在 DFS 上访问文件，如果不考虑性能上的差异的话，就很难感受到，它与本地磁盘文件系统有什么不同。可是，一旦考虑性能上的差异，分布式和本地的鸿沟是无比深刻的，这是数量级上的差距，是不可调和的。</p>
<p>尤其是在那个年代，在机器硬件的限制下，开发者为了让程序在运行效率上可以接受，就只有在方法本身的运行时间很长，可以相对忽略远程调用成本时的情况下，才去考虑使用分布式。如果方法本身的运行时长不够，就要人为地用各种奇技淫巧来刻意构造出这样的场景，比如可能会将几个原本毫无关系的方法打包到一个方法内，一块进行远程调用。</p>
<p>一方面，刻意构造长时间运行的方法这本身就与使用分布式来突破硬件算力、提升性能的初衷相互矛盾，需要我们小心平衡；另一方面，此时的开发人员，实际上仍然必须无时无刻地都要意识到，自己是在编写分布式的程序，不能随随便便地踏过本地与远程的界限，让软件系统的设计向性能做出妥协，让 DCE”尽量简单透明”的努力几乎全部付诸东流。</p>
<p>因为本地与远程，无论是从编码、部署，还是从运行效率的角度上看，都有着天壤之别，所以在设计一个能运作良好的分布式应用的时候，就变得需要极高的编程技巧和各方面的知识来作为支撑，这个时候，反而是人员本身对软件规模的约束，超过机器算力上的约束了。</p>
<p>对 DCE 的研究呢，算得上是计算机科学中第一次有组织领导、有标准可循、有巨大投入的分布式计算的尝试。但无论是 DCE，还是稍后出现的 CORBA（Common ObjectRequest Broker Architecture，公共对象请求代理体系结构），我们从结果来看，都不能说它们取得了成功。</p>
<p>因为把一个系统直接拆分到不同的机器之中，这样做带来的服务的发现、跟踪、通讯、容错、隔离、配置、传输、数据一致性和编码复杂度等方面的问题，所付出的代价远远超过了分布式所取得的收益。</p>
<p>而亲身经历过那个年代的计算机科学家、IBM 院士凯尔 · 布朗（Kyle Brown），在事后曾经评价道，”这次尝试最大的收获就是对 RPC、DFS 等概念的开创，以及得到了一个价值千金的教训：某个功能能够进行分布式，并不意味着它就应该进行分布式，强行追求透明的分布式操作，只会自寻苦果”。</p>
<blockquote>
<p><strong>原始分布式时代的教训</strong></p>
<p>Just because something can be distributed doesn”t mean it should be distributed. Trying to make a distributed call act like a local call always ends in tears.</p>
<p>某个功能能够进行分布式，并不意味着它就应该进行分布式，强行追求透明的分布式操作，只会自寻苦果。</p>
<p>—— Kyle Brown，IBM Fellow，Beyond buzzwords: A brief history of microservices patterns，2016</p>
</blockquote>
<p>其实，从设计角度来看，以上的结论是有违 Unix 哲学的，但这也是在当时的现实情况下，不得不做出的让步。在当时计算机科学面前，有两条通往更大规模软件系统的道路， <strong>一条路是尽快提升单机的处理能力，以避免分布式的种种问题；另一条路是找到更完美的解决方案，来应对如何构筑分布式系统的问题。</strong></p>
<p>在 20 世纪 80 年代，正是 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B">摩尔定律</a> 开始稳定发挥作用的黄金时期，微型计算机的性能以每两年就增长一倍的惊人速度在提升，硬件算力束缚软件规模的链条，很快就松动了，我们用单台或者几台计算机，就可以作为服务器来支撑大型信息系统的运作了，信息系统进入了单体时代，而且在未来很长的一段时间内，单体系统都将是软件架构的主流。</p>
<p>不过尽管如此，对于另外一条路径，也就是对分布式计算、远程服务调用的探索，开发者们也从没有中断过。关于远程服务调用这个关键问题的历史、发展与现状，我还会在服务设计风格的”远程服务调用”部分（第 7~10 讲），以现代 RPC 和 RESTful 为主角，来进行更详细的讲述。而对于在原始分布式时代中遭遇到的其他问题，我也还会在软件架构演进的后面几个时代里，反复提起它们。</p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><p>今天，我给你介绍了计算机科学对分布式和服务化的第一次探索，着重分析了这次探索的主旨思想，也就是追求简单、符合 Unix 哲学的分布式系统，以及它当时所面临的困难，比如在捉襟见肘的运算能力、网络带宽下，设计不得不做出的妥协。</p>
<p>在这个过程中，我们接触到了 DCE、CORBA 等早期的分布式基础架构。其中许多的技术，比如远程服务调用、分布式文件系统、Kerberos 认证协议等。如果你对这些技术觉得还有点陌生、或者还有很多疑惑，没有关系，我还会在后面的课程中为你着重介绍。</p>
<p>原始分布式时代提出的构建”符合 Unix 的设计哲学的”，以及”如同本地调用一般简单透明的”分布式系统的这个目标，是软件开发者对分布式系统最初的美好愿景。不过迫于现实，它会在一定时期内被妥协、被舍弃，分布式将会经过一段越来越复杂的发展进程。</p>
<p>但是，到了三十多年以后的今天，随着微服务的逐渐成熟完善，成为大型软件的主流架构风格以后，这个美好的愿景终将还是会重新被开发者拾起。</p>
<h4 id="一课一思"><a href="#一课一思" class="headerlink" title="一课一思"></a>一课一思</h4><p>Richard P. Gabriel 提出的 Unix 设计哲学中写到：”保持接口与实现的简单性，比系统的任何其他属性，包括准确性、一致性和完整性，都来得更加重要。”</p>
<p>现在你来思考一下： <strong>今天以微服务为代表的分布式系统，是如何看待”简单”的？</strong> 欢迎在留言区分享你的见解，我也将会在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/312589">第 5 讲”后微服务时代”</a> 中，带你一起重新审视这个问题。</p>
<h4 id="精选留言"><a href="#精选留言" class="headerlink" title="精选留言"></a>精选留言</h4><ol>
<li><p>Jxin</p>
<p> 1.这个简单需要从两方面来看待，分别是业务和技术。</p>
<p> 2.先说业务。现代的软件系统的业务复杂性越来越高。而分离关注点无疑是应对日益增长的业务复杂性的有效手段。但如果依旧是是一个大单体系统（所有业务单元都在一个容器下），那么跨业务单元的知识诉求便很难避免，并且开发迭代以及版本发布中彼此还会相互影响。而微服务的出现为其提供了设定物理边界的技术基础。使得多个特性团队对业务知识的诉求可以收敛在自身领域，降低单个特性团队所需了解的业务知识。</p>
<p> 3.再说下技术。这里我认为主要提现在技术隔离上。就像rpc让你像调用本地方法一样调用远程方法，微服务技术组件的出现，大多是为了让开发人员可以基于意图去使用各种协调分布式系统的工具，而不用深入具体工具的实现细节去研究怎么解决的分布式难题。</p>
<p> 4.同时就像 springboot 提到的生产就绪，微服务的生态已经不局限于开发的阶段。在部署和运行阶段都有健全组件支持。它可以让开发人员基于意图就可以简便的实现金丝雀发布，基于意图就能拿到所有系统运行期的数据。所有的这些便利都算是技术隔离带来的好处。</p>
<blockquote>
<p>作者回复: 上述观点是比较深刻的。整个”演进中的架构”这部分，一条重要的逻辑线索就是软件工业对如何拆分业务、隔离技术复杂性的探索。从最初的不拆分，到通过越来越复杂的技术手段逐渐满足了业务的拆分与协作，再到追求隔离掉这些复杂技术手段，将它们掩埋于基础设施之中，到未来（有可能的）重新回到无需考虑算力、无需拆分的云端系统。</p>
</blockquote>
</li>
<li><p>LYy</p>
<p> 计算机技术一个关键命题是使用有限的”成本”尽可能”高效(性能)”的解决”复杂(度)”问题。</p>
<p> 分布式的初期探索，其实就是在单机性能有限的情况下，期望通过”集群化”、”分离变化点”的架构手段来提升性能，但由于时代限制，这条路线的成本过高，同时随着摩尔定律+时间，性能问题在单机上得到了阶段性解决，所以才有了后面的单体时代。</p>
<p> 但要解决的复杂度随着时代发展爆炸性增长，摩尔定律+时间这一法宝也日渐失灵，人们其实也不得不回到分布式这条路线上，于是有了后面微服务，云原生的故事。</p>
</li>
</ol>
<h3 id="02-单体系统时代：应用最广泛的架构风格"><a href="#02-单体系统时代：应用最广泛的架构风格" class="headerlink" title="02 | 单体系统时代：应用最广泛的架构风格"></a>02 | 单体系统时代：应用最广泛的架构风格</h3><p>这一讲，我会带你去了解以单体架构构建的软件系统，都有哪些优势和缺点，还有哪些容易让人产生错误理解的误区。在探索的过程中，你可以同时思考一下，为什么单体架构能够在相当长的时间里成为软件架构的主流风格，然后再对比下我在这一讲最后给出答案。</p>
<h4 id="大型单体系统"><a href="#大型单体系统" class="headerlink" title="大型单体系统"></a>大型单体系统</h4><p>单体架构是绝大部分软件开发者都学习和实践过的一种软件架构，很多介绍微服务的图书和技术资料中，也常常会把这种架构形式的应用称作 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Monolithic_application">“巨石系统”（Monolithic Application）</a> 。</p>
<p>在整个软件架构演进的历史进程里，单体架构是出现时间最早、应用范围最广、使用人数最多、统治历史最长的一种架构风格。但”单体”这个名称，却是从微服务开始流行之后，才”事后追认”所形成的概念。在这之前，并没有多少人会把”单体”看成一种架构。</p>
<p>如果你去查找软件架构的开发资料，可以轻轻松松找到很多以微服务为主题的图书和文章，但却很难能找到专门教我们怎么开发单体系统的任何形式的材料。</p>
<p>这一方面体现了单体架构本身的简单性；另一方面也体现出，在相当长的时间里，我们都已经习惯了，软件架构就应该是单体这种样子的。</p>
<p>那在剖析单体架构之前呢，我们有必要 <strong>先搞清楚一个思维误区</strong> ，那就是单体架构是落后的系统架构风格，最终会被微服务所取代。</p>
<p>因为在许多微服务的研究资料里，单体系统往往是以”反派角色”的身份登场的，比如著名的微服务入门书《 <a target="_blank" rel="noopener" href="https://book.douban.com/subject/33425123/">微服务架构设计模式</a> 》，第一章的名字就是”逃离单体的地狱”。而这些材料所讲的单体系统，其实都有一个没有明说的隐含定语：”大型的单体系统”。</p>
<p>对于小型系统，也就是用单台机器就足以支撑其良好运行的系统来说，这样的单体不仅易于开发、易于测试、易于部署，而且因为各个功能、模块、方法的调用过程，都是在进程内调用的，不会发生 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E8%A1%8C%E7%A8%8B%E9%96%93%E9%80%9A%E8%A8%8A">进程间通讯</a> ，所以程序的运行效率也要比分布式系统更高，完全不应该被贴上”反派角色”的标签。要我说的话，反倒是那些爱赶技术潮流，却不顾需求现状的微服务吹捧者更像是个反派。</p>
<blockquote>
<p>进程间通讯：Inter-Process Communication，IPC。RPC 属于 IPC 的一种特例，但请注意，这里两个”PC”不是同个单词的缩写，关于 IPC 与 RPC 的知识，在”远程服务调用”这个小章节中我会详细讲解。</p>
</blockquote>
<p>所以，当我们在讨论单体系统的缺陷的时候，必须基于软件的性能需求超过了单机，软件的开发人员规模明显超过了” <a target="_blank" rel="noopener" href="https://wiki.mbalib.com/wiki/%E4%B8%A4%E4%B8%AA%E6%8A%AB%E8%90%A8%E5%8E%9F%E5%88%99">2 Pizza Teams</a> “范畴的前提下，这样才有讨论的价值。那么，在咱们课程后续讨论中，我所说的单体，都应该是特指的”大型的单体系统”。</p>
<p>也正因如此，在这一讲的开篇中”单体是出现最早的架构风格”，跟我在上一讲介绍”原始分布式时代”时，在开篇中提到的”使用多个独立的分布式服务共同构建一个更大型系统的设想与实际尝试，反而要比今天你所了解的大型单体系统出现的时间更早”，这两句话实际上并没有矛盾的地方。</p>
<h4 id="可拆分的单体系统"><a href="#可拆分的单体系统" class="headerlink" title="可拆分的单体系统"></a>可拆分的单体系统</h4><p>好了，回到主题，接下来我就带你来详细、深入地了解一下单体系统，看看”巨石系统”为何仍然是可以拆分的。</p>
<p>尽管”Monolithic”这个词语本身的意思”巨石”，确实是带有一些”不可拆分”的隐含意味，但我们也不能简单粗暴地把单体系统在维基百科上的定义”All in One Piece”，翻译成”铁板一块”，它其实更接近于自给自足（Self-Contained）的含义。</p>
<blockquote>
<p><strong>单体系统</strong></p>
<p>Monolith means composed all in one piece. The Monolithic application describes a single-tiered software application in which different components combined into a single program from a single platform.</p>
<p>—— Monolithic Application，Wikipedia</p>
</blockquote>
<p>当然了，这种”铁板一块”的译法也不全是段子。我相信肯定有一部分人说起单体架构、巨石系统的缺点，脑海中闪过的第一印象就是”不可拆分”，难以扩展，所以它才不能支撑起越来越大的软件规模。这种想法我觉得其实是有失偏颇的，至少不完整。</p>
<p>我为什么会这么判断呢？</p>
<p>因为从 <strong>纵向角度</strong> 来看，在现代信息系统中，我从来没有见到过实际的生产环境里，有哪个大型的系统是完全不分层的。</p>
<p>分层架构（Layered Architecture）已经是现在几乎所有的信息系统建设中，都普遍认可、普遍采用的软件设计方法了。无论是单体还是微服务，或者是其他架构风格，都会对代码进行纵向拆分，收到的外部请求会在各层之间，以不同形式的数据结构进行流转传递，在触及到最末端的数据库后依次返回响应。</p>
<p>那么，对于单体架构来说，在这个意义上的”可拆分”，单体其实完全不会展露出丝毫的弱势，反而还可能因为更容易开发、部署、测试而更加便捷。比如说，当前市面上所有主流的 IDE，如 Intellij IDEA、Eclipse 等，都对单体架构最为友好。IDE 提供的代码分析、重构能力，以及对编译结果的自动化部署和调试能力，都是主要面向单体架构而设计的。</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/分层架构（LayeredArchitecture）.webp" alt="分层架构（LayeredArchitecture）"></p>
<p>（上图来自 O’Reilly 的开放文档《 <a target="_blank" rel="noopener" href="https://www.oreilly.com/programming/free/files/software-architecture-patterns.pdf">Software Architecture Patterns</a> 》）</p>
<p>而在 <strong>横向角度</strong> 的”可拆分”上，单体架构也可以支持按照技术、功能、职责等角度，把软件拆分为各种模块，以便重用和团队管理。</p>
<p>实际上，单体系统并不意味着就只能有一个整体的程序封装形式，如果有需要，它完全可以由多个 JAR、WAR、DLL、Assembly 或者其他模块格式来构成。</p>
<p>即使是从 <strong>横向扩展（Scale Horizontally）</strong> 的角度来衡量，如果我们要在负载均衡器之后，同时部署若干个单体系统的副本，以达到分摊流量压力的效果，那么基于单体架构，也是轻而易举就可以实现的。</p>
<h4 id="非独立的单体"><a href="#非独立的单体" class="headerlink" title="非独立的单体"></a>非独立的单体</h4><p>不过，在”拆分”这方面， <strong>单体系统的真正缺陷实际上并不在于要如何拆分，而在于拆分之后，它会存在隔离与自治能力上的欠缺。</strong></p>
<p>在单体架构中，所有的代码都运行在同一个进程空间之内，所有模块、方法的调用也都不需要考虑网络分区、对象复制这些麻烦事儿，也不担心因为数据交换而造成性能的损失。</p>
<p>可是，在获得了进程内调用的简单、高效这些好处的同时，也就意味着，如果在单体架构中，有任何一部分的代码出现了缺陷，过度消耗进程空间内的公共资源，那所造成的影响就是全局性的、难以隔离的。</p>
<p><strong>我们要怎么理解这个问题呢？</strong></p>
<p>首先，一旦架构中出现了内存泄漏、线程爆炸、阻塞、死循环等问题，就都将会影响到整个程序的运行，而不仅仅是某一个功能、模块本身的正常运作；而如果消耗的是某些更高层次的公共资源，比如端口占用过多或者数据库连接池泄漏，还将会波及到整台机器，甚至是集群中其他单体副本的正常工作。</p>
<p>此外，同样是因为所有代码都共享着同一个进程空间，如果代码无法隔离，那也就意味着，我们无法做到单独停止、更新、升级某一部分代码，因为不可能有”停掉半个进程，重启 1/4 个进程”这样不合逻辑的操作。所以， <strong>从动态可维护性的角度来说</strong> ，单体系统也是有所不足的，对于程序升级、修改缺陷这样的工作，我们往往需要制定专门的停机更新计划，而且做灰度发布也相对会更加复杂。</p>
<blockquote>
<p>补充：这里我说的”代码无法隔离，无法做到单独停止、更新……”，其实严谨来说还是有办法的，比如可以使用 OSGi 这种运行时模块化框架，只是会很别扭、很复杂。</p>
</blockquote>
<p>这里就涉及到一个需要权衡的问题：如果说共享同一进程获得简单、高效这些优势的代价，是损失了各个功能模块的自治、隔离能力，那这两者孰轻孰重呢？这个问题很有代表性，我们还可以换个角度思考一下，它的潜台词其实是在比较微服务、单体架构哪种更好用、优秀？</p>
<p>在我看来，”好用和优秀”不一定是绝对的。我们看一个例子吧。</p>
<p>比如说，沃尔玛将超市分为仓储部、采购部、安保部、库存管理部、巡检部、质量管理部、市场营销部，等等，来划清职责，明确边界，让管理能力可以支持企业的成长规模；但如果你家楼下开的小卖部，爸、妈加儿子，再算上看家的中华田园犬小黄，一共也就只有四名员工，也去追求”先进管理”，来划分仓储部、采购部、库存管理部……的话，那纯粹是给自己找麻烦。</p>
<p>在单体架构下，哪怕是信息系统中两个毫无关联的子系统，我们也都必须部署到一起。当系统规模小的时候，这是个优势；但当系统规模扩大、程序需要修改的时候，相应的部署成本、技术升级时的迁移成本，都会变得非常高。</p>
<p>就拿沃尔玛例子来说，也就是当公司规模比较小的时候，让安保部和质检部两个不相干的部门在同一栋大楼中办公，算是节约资源。但当公司的人数增加了，办公室已经变得拥挤不堪的时候，我们也最多只能在楼顶加盖新楼层（相当于增强硬件性能），而不能让安保、质检分开地方办公，这才是缺陷所在。</p>
<p>另外，由于隔离能力的缺失，除了会带来难以阻断错误传播、不便于动态更新程序的问题，还会给带来难以 <strong>技术异构</strong> 等困难。</p>
<blockquote>
<p><strong>技术异构</strong> ：后面在介绍微服务时，我会提到马丁 · 福勒（Martin Fowler）提出的 9 个特征，技术异构就是其中之一。它的意思是说允许系统的每个模块，自由选择不一样的程序语言、不一样的编程框架等技术栈去实现。单体系统的技术栈异构不是一定做不到，比如 JNI 就可以让 Java 混用 C/C++，但是这也是很麻烦的事，是迫不得已下的选择。</p>
</blockquote>
<p>不过，在我看来，我们提到的这些问题，还不是我们今天以微服务去代替单体系统的根本原因。我认为最根本的原因是：单体系统并不兼容” <a target="_blank" rel="noopener" href="http://icyfenix.cn/introduction/about-the-fenix-project.html#%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E8%BF%9B">Phoenix</a> “的特性。</p>
<p>单体这种架构风格，潜在的观念是希望系统的每一个部件，甚至每一处代码都尽量可靠，不出、少出错误，致力于构筑一个 7×24 小时不间断的可靠系统。</p>
<p>这种观念在小规模软件上能运作良好，但当系统越来越大的时候，交付一个可靠的单体系统就会变得越来越有挑战性。就像我在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/309747">导读《什么是”The Fenix Project”？》</a> 中所说的，正是随着软件架构的不断演进，我们构﻿建可靠系统的观念，开始从”追求尽量不出错”，转变为了正视”出错是必然”。实际上，这才是微服务架构能够挑战，并且能逐步开始代替运作了几十年的单体架构的根本驱动力。</p>
<p>不过，即使是为了允许程序出错，为了获得隔离、自治的能力，为了可以技术异构等目标，也并不意味着一定要依靠微服务架构。在新旧世纪之交，人们曾经探索过几种服务的拆分方法，把一个大的单体系统拆分为若干个更小的、不运行在同一个进程的独立服务，这些服务拆分的方法，后来导致了面向服务架构（Service-Oriented Architecture）的一段兴盛期，我们把它称作是” <a target="_blank" rel="noopener" href="http://icyfenix.cn/architecture/architect-history/soa.html">SOA 时代</a> “。</p>
<h3 id="03-SOA时代：成功理论与失败实践"><a href="#03-SOA时代：成功理论与失败实践" class="headerlink" title="03 | SOA时代：成功理论与失败实践"></a>03 | SOA时代：成功理论与失败实践</h3><p>SOA 架构是第一次被广泛使用过的、通过分布式服务来构建信息系统的工程实践。它有完善的理论和工具，可以说，它解决了分布式系统中，几乎所有主要的技术问题。</p>
<p>但遗憾的是，虽然 SOA 架构曾经被视为更大规模的软件发展的方向，但它最终还是没能成为一种普适的软件架构。</p>
<p>所以今天，我们就来探索一下 SOA 架构，一起来找找，它没能成为普适的软件架构的原因。通过这一讲，你能从中体会到 SOA 的设计思想与原则，理解它为什么不能成功。</p>
<h4 id="三种代表性的服务拆分架构模式"><a href="#三种代表性的服务拆分架构模式" class="headerlink" title="三种代表性的服务拆分架构模式"></a>三种代表性的服务拆分架构模式</h4><p>在上一讲，我曾经提到过，为了对大型的单体系统进行拆分，让每一个子系统都能独立地部署、运行、更新，开发者们尝试了很多种方案。</p>
<p>所以，在介绍 SOA 架构模式之前，我还要先带你学习三种比较有代表性的服务拆分的架构模式。这些架构是 SOA 演化过程的中间产物，你也可以理解为，它们是 SOA 架构出现的必要前提。</p>
<h5 id="烟囱式架构（Information-Silo-Architecture）"><a href="#烟囱式架构（Information-Silo-Architecture）" class="headerlink" title="烟囱式架构（Information Silo Architecture）"></a>烟囱式架构（Information Silo Architecture）</h5><p>第一种架构模式是 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Information_silo">烟囱式架构</a> 。</p>
<p>信息烟囱也被叫做信息孤岛（Information Island），使用这种架构的系统呢，也被称为孤岛式信息系统或者烟囱式信息系统。这种信息系统，完全不会跟其他相关的信息系统之间进行互操作，或者是进行协调工作。</p>
<p>那你就会发现，这样的系统其实并没有什么”架构设计”可言。你还记不记得，我在上一讲中举的那个”企业与部门”的例子？如果两个部门真的完全不会发生任何交互，那我们就并没有什么理由，一定要强迫他们必须在一栋楼里办公。</p>
<p>所以，两个不发生交互的信息系统，让它们使用独立的数据库、服务器，就可以完成拆分了。</p>
<p>而唯一的问题，也是这个架构模式的致命问题，那就是： <strong>企业中真的存在完全不发生交互的部门吗？</strong></p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/烟囱式架构模式示意图.webp" alt="烟囱式架构模式示意图"></p>
<p>对于两个信息系统来说，哪怕真的毫无业务往来关系，但系统的人员、组织、权限等主数据，会是完全独立、没有任何重叠的吗？这样”独立拆分””老死不相往来”的系统，显然不可能是企业所希望见到的。</p>
<h5 id="微内核架构（Microkernel-Architecture）"><a href="#微内核架构（Microkernel-Architecture）" class="headerlink" title="微内核架构（Microkernel Architecture）"></a>微内核架构（Microkernel Architecture）</h5><p>第二种是 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Microkernel">微内核架构</a> ，它也被称为插件式架构（Plug-in Architecture）。</p>
<p>既然在烟囱式架构中，我们说两个没有业务往来关系的系统，也可能需要共享人员、组织、权限等一些公共的主数据，那就不妨把这些主数据，连同其他可能被各个子系统使用到的公共服务、数据、资源，都集中到一块，成为一个被所有业务系统共同依赖的核心系统（Kernel，也称为 Core System）。</p>
<p>这样的话，具体的业务系统就能以 <strong>插件模块（Plug-in Modules）</strong> 的形式存在了，就可以为整个系统提供可扩展的、灵活的、天然隔离的功能特性。</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/微内核架构模式示意图.webp" alt="微内核架构模式示意图"></p>
<p>（上图来自 O’Reilly 的开放文档《 <a target="_blank" rel="noopener" href="https://www.oreilly.com/programming/free/files/software-architecture-patterns.pdf">Software Architecture Patterns</a> 》）</p>
<p>以更高层次的抽象程度来看，任何计算机系统都是由各种架构的软件互相配合来实现各种功能的，这一讲我介绍的各种架构模式，一般都可以看作是整个系统的一种插件。对于产品型应用程序来说，如果我们想将新特性或者功能及时加入系统，微内核架构会是一个不错的选择。</p>
<p>微内核架构也可以嵌入到其它架构模式之中，通过插件的方式，来提供逐步演化的功能和增量开发。所以，如果你准备实现一个能够支持二次开发的软件系统，微内核就是一种良好的架构模式。</p>
<p>不过，微内核架构也有它的局限和使用前提，它会假设系统中各个插件模块之间是互不认识的（不可预知系统会安装哪些模块），这些插件会访问内核中一些公共的资源，但不会发生直接交互。</p>
<p>可是，无论是在企业信息系统还是在互联网，在许多场景中这一假设都不成立。比如说，你要建设一个购物网站，支付子系统和用户子系统是独立的，但当交易发生时，支付子系统可能需要从用户子系统中得到是否是 VIP、银行账号等信息，而用户子系统也可能要从支付子系统中获取交易金额等数据，来维护用户积分。</p>
<p>所以，我们必须找到一个办法，它既能拆分出独立的系统，也能让拆分后的子系统之间可以顺畅地互相调用通讯。</p>
<h5 id="事件驱动架构（Event-Driven-Architecture）"><a href="#事件驱动架构（Event-Driven-Architecture）" class="headerlink" title="事件驱动架构（Event-Driven Architecture）"></a>事件驱动架构（Event-Driven Architecture）</h5><p>那么，为了能让子系统之间互相通讯， <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Event-driven_architecture">事件驱动架构</a> 就应运而生了。</p>
<p>这种架构模式的运作方案是，在子系统之间建立一套事件队列管道（Event Queues），来自系统外部的消息将以事件的形式发送到管道中，各个子系统可以从管道里获取自己感兴趣、可以处理的事件消息，也可以为事件新增或者是修改其中的附加信息，甚至还可以自己发布一些新的事件到管道队列中去。</p>
<p>这样一来，每一个消息的处理者都是独立的、高度解耦的，但它又能与其他处理者（如果存在该消息处理者的话）通过事件管道来进行互动。</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/事件驱动架构模式示意图.webp" alt="事件驱动架构模式示意图"></p>
<p>（上图来自 O’Reilly 的开放文档《 <a target="_blank" rel="noopener" href="https://www.oreilly.com/programming/free/files/software-architecture-patterns.pdf">Software Architecture Patterns</a> 》）</p>
<p>那么，当系统演化至事件驱动架构的时候，我在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/309761">原始分布式时代</a> 这一讲的结尾中，提到的第二条通往大规模软件的路径，也就是仍然在并行发展的远程服务调用，就迎来了 SOAP 协议的诞生（我在后面第 7~10 讲分享远程服务调用的时候，还会给你详细介绍它，你到时可以再次印证一下这一讲的内容）。</p>
<p>此时”面向服务的架构”（Service Oriented Architecture，SOA），就已经有了登上软件架构舞台所需要的全部前置条件了。</p>
<h5 id="SOA-架构时代的探索"><a href="#SOA-架构时代的探索" class="headerlink" title="SOA 架构时代的探索"></a>SOA 架构时代的探索</h5><p>SOA 的概念最早是由 Gartner 公司在 1994 年提出的。当时的 SOA 还不具备发展的条件，直到 2006 年情况才有所变化，IBM、Oracle、SAP 等公司，共同成立了 OSOA 联盟（Open Service Oriented Architecture），来联合制定和推进 SOA 相关行业标准。</p>
<p>到 2007 年，在 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/OASIS_(organization">结构化资讯标准促进组织（Organization for the Advancement of Structured Information Standards，OASIS）</a>) 的倡议与支持下，OSOA 就由一个软件厂商组成的松散联盟，转变为了一个制定行业标准的国际组织。它联合 OASIS 共同新成立了 <a target="_blank" rel="noopener" href="http://www.oasis-opencsa.org/">Open CSA组织（Open Composite Services Architecture）</a> ，也就是 SOA 的”官方管理机构”。</p>
<p>当软件架构发展至 SOA 时代的时候，其中的许多概念、思想都已经能在今天的微服务中，找到对应的身影了。比如说，服务之间的松散耦合、注册、发现、治理、隔离、编排等等，都是微服务架构中耳熟能详的概念了，也大多是在分布式服务刚被提出的时候，就已经可以预见到的困难。</p>
<p>所以，SOA 就针对这些问题，乃至于针对”软件开发”这件事儿本身，进行了更具体、更系统的探索。</p>
<h6 id="更具体"><a href="#更具体" class="headerlink" title="更具体"></a>更具体</h6><p>“更具体”体现在，尽管 SOA 本身还是属于一种抽象概念，而不是特指某一种具体的技术，但它比单体架构和烟囱式架构、微内核架构、事件驱动架构，都要更具可操作性，细节也充实了很多。所以，我们已经不能简单地把 SOA 看作是一种架构风格了，而是可以称之为一套软件架构的基础平台了。</p>
<p>那，我们怎么理解”基础平台”这个概念呢？在我看来，主要是下面几个方面：</p>
<ul>
<li>SOA 拥有领导制定技术标准的组织 Open CSA；</li>
<li>SOA 具有清晰的软件设计的指导原则，比如服务的封装性、自治、松耦合、可重用、可组合、无状态，等等；</li>
<li>SOA 架构明确了采用 SOAP 作为远程调用的协议，依靠 SOAP 协议族（WSDL、UDDI 和一大票 WS-* 协议）来完成服务的发布、发现和治理；</li>
<li>SOA 架构会利用一个被称为是 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/zh-hans/%E4%BC%81%E4%B8%9A%E6%9C%8D%E5%8A%A1%E6%80%BB%E7%BA%BF">企业服务总线（Enterprise Service Bus，ESB）</a> 的消息管道，来实现各个子系统之间的通讯交互，这就让各个服务间在 ESB 的调度下，不需要相互依赖就可以实- 现相互通讯，既带来了服务松耦合的好处，也为以后可以进一步实现 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%B8%9A%E5%8A%A1%E6%B5%81%E7%A8%8B%E7%AE%A1%E7%90%86">业务流程编排（Business Process Management，BPM）</a> 提供了基础；</li>
<li>SOA 架构使用了 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%9C%8D%E5%8A%A1%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1">服务数据对象（Service Data Object，SDO）</a> 来访问和表示数据，使用 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%9C%8D%E5%8A%A1%E7%BB%84%E4%BB%B6%E6%9E%B6%E6%9E%84">服务组件架构（Service Component Architecture，SCA）</a> 来定义服务封装的形式和服务运行的容器；</li>
<li>……</li>
</ul>
<p>在这一整套成体系、可以互相精密协作的技术组件的支持下，我们从技术可行性的角度来评判的话，SOA 实际上就可以算是成功地解决了分布式环境下，出现的诸如服务注册、发现、隔离、治理等主要技术问题了。</p>
<h6 id="更系统"><a href="#更系统" class="headerlink" title="更系统"></a>更系统</h6><p>这里我说的”更系统”，指的是 SOA 的宏大理想。因为 SOA 最根本的目标，就是希望能够总结出一套自上而下的软件研发方法论，让企业只需要跟着它的思路，就能够一揽子解决掉软件开发过程中的全套问题。比如，如何挖掘需求、如何将需求分解为业务能力、如何编排已有服务、如何开发测试部署新的功能，等等。</p>
<p>如果这个目标真的能够达成，那么软件开发就有可能从此迈进工业化大生产的阶段。你可以试想一下，如果有一天，你在写符合客户需求的软件时，就像写八股文一样有迹可循、有法可依，那对你来说或许很无趣，但这肯定可以大幅提升整个社会实施信息化的效率。</p>
<p>SOA 在 21 世纪最初的十年里，曾经盛行一时，有 IBM 等一众巨头为其摇旗呐喊，吸引了不少软件开发商，尤其是企业级软件开发商的跟随，但最终却还是偃旗息鼓，沉寂了下去。</p>
<p>原因也很简单，开发信息系统毕竟不是写八股文，SOA 架构过于严谨精密的流程与理论，导致了软件开发的全过程，都需要有懂得复杂概念的专业人员才能够驾驭。从 SOA 诞生的那一天起，就已经注定了它只能是少数系统的阳春白雪式的精致奢侈品：它可以实现多个异构大型系统之间的复杂集成交互，却很难作为一种具有广泛普适性的软件架构风格来推广。</p>
<p>我在后面第 7~10 讲介绍远程服务调用时，我还会为你介绍 Web  Service 的兴起与衰落。Web  Service 之所以被逐渐边缘化，最本质的原因就是过于严格的规范定义，给架构带来了过度的复杂性。</p>
<p>而构建在 Web Service 基础之上的 ESB、BPM、SCA、SDO 等诸多的上层建筑，就进一步加剧了这种复杂性。</p>
<p><strong>SOA 最终没有获得成功的致命伤，其实跟当年的 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/EJB">EJB（Enterprise JavaBean，企业级 JavaBean）</a> 的失败如出一辙。</strong></p>
<p>尽管在当时，EJB 有 Sun Microsystems（被甲骨文收购）和 IBM 等一众巨头在背后力挺，希望能把它发展成一套面向信息系统的编程范式，但它仍然被以 Spring、Hibernate 为代表的”草根框架”给打败了。可见，任何事物一旦脱离了人民群众，最终都会淹没在群众的海洋之中，就连信息技术也不曾例外过。</p>
<p>最后，当你读到这一段的时候，你不妨再重新思考下我们这一讲的开头提到的，”如何使用多个独立的分布式服务共同构建一个更大型系统”这个问题，再回顾下”原始分布式时代”这一讲中，Unix DCE 提出的分布式服务的主旨：”让开发人员不必关心服务是远程还是本地，都能够透明地调用服务或者访问资源”。</p>
<p>经过了三十年的技术发展，信息系统经历了巨石、烟囱、微内核、事件驱动、SOA 等架构模式，应用受架构复杂度的牵绊却是越来越大，距离”透明”二字已经越来越远了。这是否算不自觉间忘记了当年的初心呢？</p>
<p>接下来我们要探索的微服务时代，似乎正是带着这样自省式的问句而开启的。</p>
<h4 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h4><p>这一讲，我带你学习了解了 SOA 架构，重点了解了从原始分布式架构、单体架构演进到 SOA 架构这段过程中的一些中间产物，如烟囱式架构、微内核架构、事件驱动架构等。</p>
<p>另外，我之所以带你解构 SOA 架构，就是要帮助你弄清楚它成功的部分，比如它是如何提出了哪些技术、解决问题的方法论是什么，它是如何看待分布式、乃至是如何看待软件开发的；你也要弄清楚它失败的部分，要清楚为什么 SOA 在众多软件业巨头的推动下，仍然没能成为软件开发者所普遍接受的普适的软件开发方法。这是你了解和掌握推动架构时代演进原因的重要方式。</p>
<h3 id="04-微服务时代：SOA的革命者"><a href="#04-微服务时代：SOA的革命者" class="headerlink" title="04 | 微服务时代：SOA的革命者"></a>04 | 微服务时代：SOA的革命者</h3><p>其实”微服务”这个词儿，Peter Rodgers 博士在 2005 年的云计算博览会（Web Services Edge 2005）上，就已经提出和使用了。当时的说法是”Micro-Web-Service”，指的是一种专注于单一职责的、与语言无关的、细粒度的 Web 服务（Granular Web Services）。</p>
<p>“微服务”这个词，并不是 Peter Rodgers 直接凭空创造出来的概念。最开始的微服务，可以说是在 SOA 发展的同时被催生出来的产物，就像是 EJB 在推广的过程中，催生出了 Spring 和 Hibernate 框架那样。这一阶段的微服务，是作为 SOA 的一种轻量化的补救方案而被提出来的。</p>
<p>到今天为止，在英文版的维基百科上，人们仍然是把微服务定义成了 SOA 的一个变种。所以，微服务在诞生和最初的发展阶段，跟 SOA、Web Service 这些概念有所牵扯，也是完全可以理解的。</p>
<blockquote>
<p><strong>What is microservices</strong></p>
<p>Microservices is a software development technique — a variant of the service-oriented architecture （SOA） structural style.</p>
<p>—— Wikipedia，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Microservices">Microservices</a></p>
</blockquote>
<p>但我们现在再来看，维基百科对微服务的定义，其实已经有些过时了。至于为什么这样说，就是我在这一讲中要和你解释的了。</p>
<p>在微服务的概念被提出后将近 10 年的时间里面，它都没有受到太多人的追捧。毕竟，如果只是对现有的 SOA 架构的修修补补，确实难以唤起广大技术人员的更多激情。</p>
<p>不过，也是在这 10 年的时间里，微服务本身其实一直在思考、蜕变。</p>
<p>2012 年，在波兰克拉科夫举行的”33rd Degree Conference”大会上，Thoughtworks 首席咨询师 James Lewis 做了题为《 <a target="_blank" rel="noopener" href="http://2012.33degree.org/talk/show/67">Microservices - Java, the Unix Way</a> 》的主题演讲。其中，他提到了单一服务职责、 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Conway%27s_law">康威定律</a> 、自动扩展、领域驱动设计等原则，却只字未提 SOA，反而号召大家，应该重拾 Unix 的设计哲学（As Well Behaved Unix Services）。这一点跟我在上一讲中所说的”初心与自省”，可以说是一个意思。</p>
<p>微服务已经迫不及待地要脱离 SOA 的附庸，想要成为一种独立的架构风格，也许，它还将会是 SOA 的革命者，找到一条能被广大开发者普遍接受且愿意接受的、实现服务化系统的目标。</p>
<p>微服务真正崛起是在 2014 年。相信我们大多数程序员，也是从 Martin Fowler 和 James Lewis 合写的文章” <a target="_blank" rel="noopener" href="https://martinfowler.com/articles/microservices.html">Microservices: a definition of this new architectural term</a> “里面，第一次了解到微服务的。这篇文章虽然不是最早提出”微服务”这个概念的，但却是真正丰富的、广为人知的和可操作的微服务指南。也就是说，这篇文章才是微服务的真正起源。</p>
<p>这篇文章定义了现代微服务的概念：微服务是一种通过多个小型服务的组合，来构建单个应用的架构风格，这些服务会围绕业务能力而非特定的技术标准来构建。各个服务可以采用不同的编程语言、不同的数据存储技术、运行在不同的进程之中。服务会采取轻量级的通讯机制和自动化的部署机制，来实现通讯与运维。</p>
<p>此外，在这篇论文中，作者还列举出了微服务的九个核心的业务与技术特征。接下来，我就一一解读为你解读下，希望你可以从中领悟到，微服务在团队、开发、运维等一系列研发过程中的核心思想。</p>
<ol>
<li><p><strong>第一，围绕业务能力构建（Organized around Business Capabilities）</strong></p>
<p> 这个核心技术特征，实际上再次强调了 <strong>康威定律</strong> 的重要性。它的意思是， <strong>有怎样的结构、规模和能力的团队，就会产生出对应结构、规模、能力的产品。</strong> 这个结论不是某个团队、某个公司遇到的巧合，而是必然的演化结果。</p>
<p> 如果本应该归属同一个产品内的功能，被划分在了不同的团队当中，那就必然会产生大量的跨团队沟通协作，而跨越团队边界，无论是在管理、沟通，还是在工作安排上，都会产生更高的成本。高效的团队，自然会针对这个情况进行改进，而当团队和产品磨合调节稳定了之后，就会拥有一致的结构。</p>
</li>
<li><p><strong>第二，分散治理（Decentralized Governance）</strong></p>
<p> 这个技术特征，表达的是”谁家孩子谁来管”。微服务对应的开发团队，有着直接对服务运行质量负责的责任，也应该有着不受外界干预，掌控服务各个方面的权力，可以选择与其他服务异构的技术来实现自己的服务。</p>
<p> 这一点在真正实践的时候，其实多少都会留点儿宽松的处理余地。因为大多数的公司都不会在某一个服务用 Java，另一个用 Python，下一个用 Golang，而是通常都会统一主流语言，甚至会有统一的技术栈或专有的技术平台。</p>
<p> 微服务不提倡也并不反对这种”统一”，它只负责提供和维护基础技术栈的团队，有被各方依赖的觉悟，要有”经常被凌晨 3 点的闹钟吵醒”的心理准备就好。</p>
<p> 微服务更加强调的是， <strong>在确实有必要进行技术异构的时候，一个开发团队应该能有选择”不统一”的权利。</strong> 比如说，我们不应该强迫用 Node.js 去开发报表页面；要做人工智能计算的时候，也可以选择用 Python，等等。</p>
</li>
<li><p><strong>第三，通过服务来实现独立自治的组件（Componentization via Services）</strong></p>
<p> 这里，Martin Fowler 与 James Lewis 之所以强调要通过”服务”（Service）而不是”类库”（Library）来构建组件，是因为类库是在编译期静态链接到程序中的，会通过本地调用来提供功能，而服务是进程外组件，它是通过远程调用来提供功能的。在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/309772">第 2 讲</a> 中，我们已经分析过，尽管远程服务有更高昂的调用成本，但这是为组件带来隔离与自治能力的必要代价。</p>
</li>
<li><p><strong>第四，产品化思维（Products not Projects）</strong></p>
<p> 产品化思维的意思就是，我们要 <strong>避免把软件研发看作是要去完成某种功能，而要把它当做是一种持续改进、提升的过程。</strong> 比如，我们不应该把运维看作就是运维团队的事，把开发看作就是开发团队的事。</p>
<p> 开发团队应该为软件产品的整个生命周期负责。开发者不仅应该知道软件是如何开发的，还应该知道它会如何运作、用户如何反馈，乃至售后支持工作是怎样进行的。这里服务的用户，不一定是最终用户，也可能是消费这个服务的另外一个服务。</p>
<p> 以前在单体的架构模式下，程序的规模决定了我们无法让全部的开发人员，都关注到一个完整的产品，在组织中会有开发、运维、支持等细致分工的成员，他们只关注于自己的一块工作。但在微服务下，我们可以让团队中的每一位成员，都具有产品化思维。因为在”2 Pizza Teams”的团队规模下，每一个人都了解全过程是完全有可能实现的。</p>
</li>
<li><p><strong>第五，数据去中心化（Decentralized Data Management）</strong></p>
<p> 微服务这种架构模式也明确地提倡，数据应该按领域来分散管理、更新、维护和存储。</p>
<p> 在单体服务中，通常一个系统的各个功能模块会使用同一个数据库，虽然这种中心化的存储确实天生就更容易避免一致性的问题，但是，同一个数据实体在不同服务的视角里，它的抽象形态往往也是不同的。</p>
<p> 比如，Bookstore 应用中的书本，在销售领域中关注的是价格，在仓储领域中关注的是库存数量，在商品展示领域中关注的是书籍的介绍信息。如果是作为中心化的存储，那么这里所有的领域，都必须修改和映射到同一个实体之中，就会导致不同的服务之间，可能会互相产生影响，从而丧失了各自的独立性。</p>
<p> 另外，尽管在分布式中，我们要想处理好一致性的问题也很困难，很多时候都没法使用传统的事务处理来保证不出现一致性问题。但是两害相权取其轻，一致性问题这些必要的代价是值得付出的。</p>
</li>
<li><p><strong>第六，轻量级通讯机制（Smart Endpoints and Dumb Pipes）</strong></p>
<p> 这个弱管道（Dumb Pipes）机制，可以说几乎算是在直接指名道姓地反对 ESB、BPM 和 SOAP 等复杂的通讯机制。</p>
<p> ESB 可以处理消息的编码加工、业务规则转换等；BPM 可以集中编排企业的业务服务；SOAP 有几十个 WS-* 协议族在处理事务、一致性、认证授权等一系列工作。这些构筑在通讯管道上的功能，也许在某个系统中的确有一部分服务是需要的，但对于另外更多的服务来说是强加进来的负担。</p>
<p> <strong>如果服务需要上面的某一种功能或能力，那就应该在服务自己的 Endpoint（端点）上解决，而不是在通讯管道上一揽子处理。</strong></p>
<p> 微服务提倡的是类似于经典 Unix 过滤器那样，简单直接的通讯方式。比如说，RESTful 风格的通讯，在微服务中就是比较适合的。</p>
</li>
<li><p><strong>第七，容错性设计（Design for Failure）</strong></p>
<p> 容错性设计，是指软件架构不再虚幻地追求服务永远稳定，而是接受服务总会出错的现实。</p>
<p> 这个技术特征要求，在微服务的设计中，有自动的机制能够对其依赖的服务进行快速故障检测，在持续出错的时候进行隔离，在服务恢复的时候重新联通。所以 <strong>“断路器”这类设施，对实际生产环境的微服务来说，并不是可选的外围组件，而是一个必须的支撑点。</strong> 如果没有容错性的设计，系统很容易就会因为一两个服务的崩溃带来的雪崩效应而被淹没。</p>
<p> 我想说的是，可靠系统完全可以由会出错的服务来组成，这是微服务最大的价值所在，也是咱们这门课的开篇导读标题中”The Fenix Project”的含义。</p>
</li>
<li><p><strong>第八，演进式设计（Evolutionary Design）</strong></p>
<p> 容错性设计承认服务会出错，而演进式设计则是 <strong>承认服务会被报废淘汰。</strong></p>
<p> 一个良好设计的服务，应该是能够报废的，而不是期望得到长久的发展。如果一个系统中出现不可更改、无可替代的服务，这并不能说明这个服务有多么重要，反而是系统设计上脆弱的表现。微服务带来的独立、自治，也是在反对这种脆弱性。</p>
</li>
<li><p><strong>第九，基础设施自动化（Infrastructure Automation）</strong></p>
<p> 基础设施自动化，如 CI/CD 的长足发展，大大降低了构建、发布、运维工作的复杂性。</p>
<p> 由于微服务架构下，运维的服务数量比起单体架构来说，要有数量级的增长，所以使用微服务的团队，会更加依赖于基础设施的自动化。毕竟，人工是无法运维成百上千，乃至成千上万级别的服务的。</p>
<p> 好，到这里，通过我的解读，你是不是已经大概理解了微服务核心的业务和技术特征了？</p>
</li>
</ol>
<p><strong>以上 9 个特征，是一个合理的微服务系统展示出来的内、外在表现，它能够指导你该如何应用微服务架构，却不必作为一种强加于系统中的束缚来看待。</strong></p>
<p><a target="_blank" rel="noopener" href="https://martinfowler.com/articles/microservices.html">“Microservices: a definition of this new architectural term”</a> 一文中，对微服务特征的描写已经非常具体了，除定义了微服务是什么，还专门申明了微服务不是什么：微服务不是 SOA 的衍生品，应该明确地与 SOA 划清界线，不再贴上任何 SOA 的标签。</p>
<p>这样一来，微服务才算是一种真正丰满、独立、具体的架构风格，为它在未来的几年时间里，如同明星一般闪耀崛起于技术舞台奠定了坚实的基础。</p>
<blockquote>
<p><strong>Microservices and SOA</strong></p>
<p>This common manifestation of SOA has led some microservice advocates to reject the SOA label entirely, although others consider microservices to be one form of SOA , perhaps service orientation done right. Either way, the fact that SOA means such different things means it”s valuable to have a term that more crisply defines this architectural style.</p>
<p>由于与 SOA 具有一致的表现形式，这让微服务的支持者更加迫切地拒绝再被打上 SOA 的标签。一些人坚持认为微服务就是 SOA 的一种变体，尽管仅从面向服务这个角度来考虑，这个观点可以说也是正确的。但无论如何，从整体上看 SOA 与微服务都是两种不同的东西。也因此，使用一个别的名称，来简明地定义这种架构风格就显得非常有必要了。</p>
<p>—— Martin Fowler / James Lewis，Microservices</p>
</blockquote>
<p>从上面我对微服务的定义和特征的解读当中，你还可以明显地感觉到，微服务追求的是更加自由的架构风格，它摒弃了 SOA 中几乎所有可以抛弃的约束和规定，提倡以”实践标准”代替”规范标准”。</p>
<p><strong>可是，如果没有了统一的规范和约束，以前 SOA 解决的那些分布式服务的问题，不又都重新出现了吗？</strong></p>
<p>没错，的确如此。服务的注册发现、跟踪治理、负载均衡、故障隔离、认证授权、伸缩扩展、传输通讯、事务处理等问题，在微服务中，都不再会有统一的解决方案。</p>
<p>即使我们只讨论 Java 范围内会使用到的微服务，那么光一个服务间通讯的问题，可以列入候选清单的解决方案就有很多很多。比如，RMI（Sun/Oracle）、Thrift（Facebook）、Dubbo（阿里巴巴）、gRPC（Google）、Motan2（新浪）、Finagle（Twitter）、brpc（百度）、Arvo（Hadoop）、JSON-RPC、REST，等等。</p>
<p>再来举个例子，光一个服务发现问题，我们可以选择的解决方案就有：Eureka（Netflix）、Consul（HashiCorp）、Nacos（阿里巴巴）、ZooKeeper（Apache）、etcd（CoreOS）、CoreDNS（CNCF），等等。</p>
<p>其他领域的情况也很类似。总之，完全就是”八仙过海，各显神通”的局面。</p>
<p>所以说，微服务所带来的自由是一把双刃开锋的宝剑。当软件架构者拿起这把宝剑的时候，它的一刃指向的是 SOA 定下的复杂技术标准，而在将选择的权力夺回的同一时刻，另外一刃也正朝向着自己映出冷冷的寒光。</p>
<h4 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h4><p>在微服务时代中，软件研发本身的复杂度应该说是有所降低，一个简单服务，并不见得就会同时面临分布式中所有的问题，也就没有必要背上 SOA 那百宝袋般沉重的技术包袱。 <strong>微服务架构下，我们需要解决什么问题，就引入什么工具；团队熟悉什么技术，就使用什么框架。</strong></p>
<p>此外，像 Spring Cloud 这样的胶水式的全家桶工具集，通过一致的接口、声明和配置，进一步屏蔽了源自于具体工具、框架的复杂性，降低了在不同工具、框架之间切换的成本。所以，作为一个普通的服务开发者，作为一个”螺丝钉”式的程序员，微服务架构对我们来说是很友善的。</p>
<p>可是，微服务对架构者来说却是满满的恶意，因为它对架构能力的要求可以说是史无前例。要知道， <strong>技术架构者的第一职责就是做决策权衡</strong> ，有利有弊才需要决策，有取有舍才需要权衡。如果架构者本身的知识面不足以覆盖所需要决策的内容，不清楚其中的利弊，也就不可避免地会陷入选择困难症的困境之中。</p>
<p>总而言之，微服务时代充满着自由的气息，也充斥着迷茫的选择。软件架构不会止步于自由，微服务仍然不可能是架构探索的终点。如果有下一个时代，我希望信息系统能同时拥有微服务的自由权利，围绕业务能力构建自己的服务而不受技术规范管束，但同时又不必承担自行解决分布式问题的代价。管他什么利弊权衡！小孩子才做选择题，成年人全部都要！</p>
<h3 id="05-后微服务时代：跨越软件与硬件之间的界限"><a href="#05-后微服务时代：跨越软件与硬件之间的界限" class="headerlink" title="05 | 后微服务时代：跨越软件与硬件之间的界限"></a>05 | 后微服务时代：跨越软件与硬件之间的界限</h3><p>在开始探讨这一讲的主题之前呢，我想先跟你讨论一个问题。我们都知道，在微服务架构中，会面临一些必须解决的问题，比如注册发现、跟踪治理、负载均衡、传输通讯等。但这些问题，其实在 SOA 时代甚至可以说自原始分布式时代，就一直存在了。既然只要是分布式系统，就没办法完全避免这些问题，那我们就回过头来想一下：这些问题一定要由分布式系统自己来解决吗？</p>
<p>既然这样，那我们就先不去纠结到底是用微服务还是什么别的架构，直接看看面对这些问题，现在最常见的解决方法是怎样的：</p>
<ul>
<li>如果某个系统需要 <strong>伸缩扩容</strong> ，我们通常会购买新的服务器，多部署几套副本实例来分担压力；</li>
<li>如果某个系统需要解决 <strong>负载均衡</strong> 的问题，我们通常会布置负载均衡器，并选择恰当的均衡算法来分流；</li>
<li>如果需要解决 <strong>安全传输</strong> 的问题，我们通常会布置 TLS 传输链路，配置好 CA 证书，以保证通讯不被窃听篡改；</li>
<li>如果需要解决 <strong>服务发现</strong> 的问题，我们通常会设置 DNS 服务器，让服务访问依赖稳定的记录名而不是易变的 IP 地址，等等。</li>
</ul>
<p>所以你会发现，计算机科学经过了这么多年的发展，这些问题已经大多都有了专职化的基础设施来帮助解决了。</p>
<p>那么，在微服务时代，我们之所以不得不在应用服务层面，而不是基础设施层面去解决这些分布式问题， <strong>完全是因为由硬件构成的基础设施，跟不上由软件构成的应用服务的灵活性。</strong> 这其实是一种无奈之举。</p>
<p>软件可以做到只使用键盘就能拆分出不同的服务，只通过拷贝、启动就能够伸缩扩容服务。那么，硬件难道也可以通过敲键盘就变出相应的应用服务器、负载均衡器、DNS 服务器、网络链路等等的这些设施吗？嗯？好像也可以啊！</p>
<p>到这里，你是不是已经知道了，注册发现、跟踪治理等等问题的解决，依靠的就是 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Virtualization">虚拟化</a> 技术和 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/OS-level_virtualization">容器化</a> 技术。我们也就明白了， <strong>微服务时代所取得的成就，本身就离不开以 Docker 为代表的早期容器化技术的巨大贡献。</strong></p>
<p>不知道你注意到没有，在这之前，我从来没有提起过”容器”二字。其实，这并不是我想刻意冷落它，而是因为早期的容器只是被简单地视为一种可快速启动的服务运行环境，使用它的目的是方便程序的分发部署。所以，早期阶段针对单个服务的容器，并没有真正参与到分布式问题的解决之中。</p>
<p>尽管 2014 年，微服务真正崛起的时候，Docker Swarm（2013 年）和 Apache Mesos（2012 年）就已经存在了，更早之前也出现过 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Software-defined_networking">软件定义网络（Software-Defined Networking，SDN）</a> 、 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Software-defined_storage">软件定义存储（Software-Defined Storage，SDS）</a> 等技术，但是，被业界广泛认可、普遍采用的通过虚拟化的基础设施，去解决分布式架构问题的方案，应该要从 2017 年 Kubernetes 赢得容器战争的胜利开始算起。</p>
<p><strong>2017 年，可以说是容器生态发展历史中具有里程碑意义的一年。</strong></p>
<p>在这一年，长期作为 Docker 竞争对手的 <a target="_blank" rel="noopener" href="https://coreos.com/rkt/docs/latest/">RKT</a> 容器一派的领导者 CoreOS，宣布放弃了自己的容器管理系统 Fleet，未来将会把所有容器管理功能，转移到 Kubernetes 之上去实现。</p>
<p>在这一年，容器管理领域的独角兽 Rancher Labs，宣布放弃其内置了数年的容器管理系统 Cattle，提出了”All-in-Kubernetes”战略，从 2.0 版本开始，把 1.x 版本能够支持多种容器管理工具的 Rancher，”升级”为只支持 Kubernetes 一种的容器管理系统。</p>
<p>在这一年，Kubernetes 的主要竞争者 Apache Mesos，在 9 月正式宣布了” <a target="_blank" rel="noopener" href="https://k8smeetup.github.io/docs/getting-started-guides/mesos/">Kubernetes on Mesos</a> “集成计划，开始由竞争关系，转为了对 Kubernetes 提供支持，使其能够与 Mesos 的其他一级框架（如 <a target="_blank" rel="noopener" href="https://docs.mesosphere.com/latest/usage/service-guides/hdfs/">HDFS</a>、<a target="_blank" rel="noopener" href="https://docs.mesosphere.com/latest/usage/service-guides/spark/">Spark</a> 和 <a target="_blank" rel="noopener" href="https://mesos.github.io/chronos/docs/getting-started.html">Chros</a> 等）进行集群资源动态共享、分配与隔离。</p>
<p>在这一年，Kubernetes 的最大竞争者，Docker Swarm 的母公司 Docker，终于在 10 月被迫宣布 Docker 要同时支持 Swarm 与 Kubernetes 两套容器管理系统，也就是承认了 Kubernetes 的统治地位。</p>
<p>至此，这场已经持续了三、四年时间，以 Docker Swarm、Apache Mesos 与 Kubernetes 为主要竞争者的”容器战争”，终于有了明确结果。可以说，Kubernetes 最后从众多的容器管理系统中脱颖而出、”登基加冕”，就代表了容器发展中一个时代的结束。而且我可以说，它带来的容器间网络、服务、负载均衡、配置等虚拟化基础设施，也将会是开启下一个软件架构发展新纪元的钥匙。</p>
<p>我为什么会这么肯定呢？</p>
<p>针对同一个分布式服务的问题，对比下 Spring Cloud 中提供的应用层面的解决方案，以及 Kubernetes 中提供的基础设施层面的解决方案，你就可以明白其中缘由了。</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/Kubernetes对比SprintCloud.webp" alt="Kubernetes对比SprintCloud"></p>
<p>虽然 Spring Cloud 和 Kubernetes 的出发点不同，解决问题的方法和效果也不一样，但不容忽视的是，Kubernetes 的确提供了一条全新的、前途更加广阔的解题思路。</p>
<p>我说的”前途广阔”，不仅仅是一句恭维赞赏的客气话。当虚拟化的基础设施，开始从单个服务的容器发展到由多个容器构成的服务集群，以及集群所需的所有通讯、存储设施的时候，软件与硬件的界限就开始模糊了。</p>
<p>一旦硬件能够跟得上软件的灵活性，那么这些与业务无关的技术问题，便很可能从软件的层面剥离出来，在硬件的基础设施之内就被悄悄解决掉，让软件可以只专注于业务，真正”围绕业务能力构建”团队与产品。那么原来只能从软件层面解决的分布式架构问题，于是有了另外一种解法：应用代码与基础设施软硬一体，合力应对。</p>
<p>这样一来，在 DCE 中未能实现的”透明的分布式应用”就成为了可能，Martin Fowler 设想的” <a target="_blank" rel="noopener" href="https://martinfowler.com/bliki/PhoenixServer.html">凤凰服务器</a> “就成为了可能，Chad Fowler 提出的” <a target="_blank" rel="noopener" href="http://chadfowler.com/2013/06/23/immutable-deployments.html">不可变基础设施</a> “也会成为可能。</p>
<p>没错，我们借此就来到了现在媒体文章中常说的”云原生”时代。这样理解下来，”云原生”这个概念，是不是没那么抽象了。</p>
<p>云原生时代追求的目标，跟此前微服务时代中追求的目标相比，并没有什么本质的改变，它们都是通过一系列小型服务去构建大型系统。在服务架构演进的历史进程中，我更愿意把”云原生时代”称为 <strong>“后微服务时代”</strong> 。</p>
<p><strong>不过还有一点值得注意的是</strong> ，前面我说，Kubernetes 成为了容器战争的胜利者，标志着后微服务时代的开端， <strong>但 Kubernetes 其实并没有完美地解决全部的分布式问题。</strong></p>
<p>这里所说的”不完美”的意思是，仅从功能灵活强大这点来看，Kubernetes 反而还不如之前的 Spring Cloud 方案。这是因为有一些问题处于应用系统与基础设施的边缘，我们很难能完全在基础设施的层面中，去精细化地解决掉它们。</p>
<p>给你举个例子，微服务 A 调用了微服务 B 中发布的两个服务，我们称之为 B1 和 B2，假设 B1 表现正常，但 B2 出现了持续的 500 错，那在达到一定的阈值之后，我们就应该对 B2 进行熔断，以避免产生 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Snowball_effect">雪崩效应</a> 。如果我们仅在基础设施的层面来做处理，这就会遇到一个两难问题，也就是切断 A 到 B 的网络通路，会影响到 B1 的正常调用，而不切断的话则会持续受到 B2 的错误影响。</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/是否要熔断对服务B的访问.webp" alt="是否要熔断对服务B的访问"></p>
<p>这种问题在通过 Spring Cloud 这类应用代码实现的微服务中，其实并不难处理，反正是使用代码（或者配置）来解决问题，只要合乎逻辑，我们想做什么功能都是可以的，只是会受限于开发人员的想象力与技术能力。但基础设施是针对整个容器来做整体管理的，它的粒度就相对粗犷。</p>
<p>实际上，类似的情况不仅仅会在断路器上出现，服务的监控、认证、授权、安全、负载均衡等功能，都有细化管理的需求。比如，服务调用时的负载均衡，往往需要根据流量特征，调整负载均衡的层次、算法等，而 DNS 尽管能实现一定程度的负载均衡，但它通常并不能满足这些额外的需求。</p>
<p>所以，为了解决这一类问题，微服务基础设施很快就进行了第二次进化，引入在今天被我们叫做是 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Service_mesh">“服务网格”（Service Mesh）</a> 的 <strong>“边车代理模式”（Sidecar Proxy）</strong> 。</p>
<p>所谓的”边车”，是指一种带挎斗的三轮摩托，我小时候还算常见，现在基本就只在抗日神剧中才会看到了。</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/边车（Sidecar）.webp" alt="边车（Sidecar）"></p>
<p>具体到咱们现在的语境里，”边车”的意思是，微服务基础设施会由系统自动地在服务的资源容器（指 Kubernetes 的 Pod）中注入一个通讯代理服务器（相当于那个挎斗），用类似网络安全里中间人攻击的方式进行流量劫持，在应用毫无感知的情况下，悄悄接管掉应用的所有对外通讯。</p>
<p>这个代理除了会实现正常的服务调用以外（称为数据平面通讯），同时还接受来自控制器的指令（称为控制平面通讯），根据控制平面中的配置，分析数据平面通讯的内容，以实现熔断、认证、度量、监控、负载均衡等各种附加功能。</p>
<p>这样，就实现了既不需要在应用层面附带额外的代码，也提供了几乎不亚于应用代码的精细管理能力的目的。</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/边车代理流量.webp" alt="边车代理流量"></p>
<p>（来自 Istio 的 <a target="_blank" rel="noopener" href="https://istio.io/docs/reference/config/policy-and-telemetry/mixer-overview/">配置文档</a> ，图中的 Mixer 在 Istio 1.5 之后已经取消，这里仅作示意）</p>
<h4 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h4><p>今天，我带着你一起游览了后微服务时代，一起了解了容器化技术兴起对软件架构、软件开发的改变，并一起探讨了微服务如何通过虚拟化基础设施，来解决分布式问题的办法，即今天服务网格中的”边车代理模式”。</p>
<p>服务网格在 2018 年才火了起来，到今天它仍然是一个新潮的概念，Istio 和 Envoy 的发展时间还很短，仍然没有完全成熟，甚至连 Kubernetes 也还算是个新生事物（以它开源的日期来计算）。</p>
<p>但我相信，未来几年，Kubernetes 将会成为服务器端标准的运行环境，如同在此之前的 Linux 一样；服务网格将会成为微服务之间通讯交互的主流模式，它会把”选择什么通讯协议””如何做认证授权”之类的技术问题隔离于应用软件之外，取代今天的 Spring Cloud 全家桶中的大部分组件的功能。这是最理想的 <a target="_blank" rel="noopener" href="https://martinfowler.com/articles/microservices.html#SmartEndpointsAndDumbPipes">Smart Endpoints</a> 解决方案，微服务只需要考虑业务本身的逻辑就行了。</p>
<p>上帝的归上帝，凯撒的归凯撒，业务与技术完全分离，远程与本地完全透明，我想也许这就是分布式架构最好的时代吧。</p>
<h3 id="06-无服务时代：”不分布式”云端系统的起点"><a href="#06-无服务时代：”不分布式”云端系统的起点" class="headerlink" title="06 | 无服务时代：”不分布式”云端系统的起点"></a>06 | 无服务时代：”不分布式”云端系统的起点</h3><p>今天是探索”演进中的架构”的最后一讲，我们来聊聊最近一两年才开始兴起的 <strong>“无服务架构”</strong> 。</p>
<p>我们都知道，分布式架构出现的最初目的，是要解决单台机器的性能成为整个软件系统的瓶颈的问题。后来随着技术的演进，容错能力、技术异构、职责划分等其他因素，也都成了分布式架构要考虑的问题。但不可否认的是，获得更好的性能，仍然在架构设计中占有非常大的比重。</p>
<p>在前面几讲我们也说，分布式架构也会引入一些新问题（比如服务的安全、容错，分布式事务的一致性），因此对软件开发这件事儿来说，不去做分布式无疑是最简单的。如果单台服务器的性能可以是无限的，那架构演进的结果，肯定会跟今天不一样。不管是分布式和容器化，还是微服务，恐怕都未必会出现了，最起码不会是今天的模样。</p>
<p>当然了，绝对意义上的无限性能肯定是不存在的，但相对意义上的无限性能其实已经实现了，云计算的成功落地就可以说明这一点。对基于云计算的软件系统来说，无论用户有多少、逻辑如何复杂，AWS、阿里云等云服务提供商都能在算力上满足系统对性能的需求，只要你能为这种无限的性能支付得起对应的代价。</p>
<p>在工业界，2012 年，<a target="_blank" rel="noopener" href="https://www.iron.io/">iron.io 公司</a> 率先提出了”无服务”（Serverless，应该翻译为”无服务器”才合适，但现在用”无服务”已形成习惯了）的概念；2014 年开始，AWS 发布了命名为 Lambda 的商业化无服务应用，并在后续的几年里逐步得到了开发者的认可，发展成目前世界上最大的无服务的运行平台；到了 2019 年，中国的阿里云、腾讯云等厂商，也发布了无服务的产品。”无服务”成了近期技术圈里的”新网红”之一。</p>
<p>我们再看看学术界对无服务的态度。在 2009 年云计算刚提出的时候，UC Berkeley 大学就发表了一篇论文 <a target="_blank" rel="noopener" href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-28.pdf">“Above the Clouds: A Berkeley View of Cloud Computing”</a> ，文中预言的云计算的价值、演进和普及，在过去的十年（2009~2019 年）里一一得到了验证。十年之后的 2019 年，UC Berkeley 的第二篇命名风格相同的论文 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1902.03383">“Cloud Programming Simplified: A Berkeley View on Serverless Computing”</a> ，再次预言”无服务将会成为日后云计算的主流方式”。</p>
<p>由此可见，主流学术界也同样认可无服务是未来的一个发展方向。</p>
<p>虽然工业界和学术界在”无服务”这件事儿上都取得了些成果，但是到今天”无服务”也还没有一个特别权威的定义。不过这也不是什么问题，毕竟它没有我们前面讲到的微服务、SOA 等各种架构那么复杂， <strong>它最大的卖点就是简单</strong> ，只涉及了后端设施（Backend）和函数（Function）两块内容。</p>
<ul>
<li><strong>后端设施</strong> 是指数据库、消息队列、日志、存储等这一类用于支撑业务逻辑运行，但本身无业务含义的技术组件。这些后端设施都运行在云中，也就是无服务中的 <strong>“后端即服务”（Backend as a Service，BaaS）</strong> 。</li>
<li><strong>函数</strong> 指的就是业务逻辑代码。这里函数的概念与粒度，都已经和程序编码角度的函数非常接近了，区别就在于，无服务中的函数运行在云端，不必考虑算力问题和容量规划（从技术角度可以不考虑，但从计费的角度来看，你还是要掂量一下自己的钱包够不够用），也就是无服务中的 <strong>“函数即服务”（Function as a Service，FaaS）</strong> 。</li>
</ul>
<p><strong>无服务的愿景是让开发者只需要纯粹地关注业务：</strong> 一是，不用考虑技术组件，因为后端的技术组件是现成的，可以直接取用，没有采购、版权和选型的烦恼；二是，不需要考虑如何部署，因为部署过程完全是托管到云端的，由云端自动完成；三是，不需要考虑算力，因为有整个数据中心的支撑，算力可以认为是无限的；四是，也不需要操心运维，维护系统持续地平稳运行是云服务商的责任，而不再是开发者的责任。</p>
<p>你看，这是不是就像从汇编语言发展到高级语言后，开发者不用再去关注寄存器、信号、中断等与机器底层相关的细节？没错儿，UC Berkeley 的论文 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1902.03383">“Cloud Programming Simplified: A Berkeley View on Serverless Computing”</a> 中，就是这样描述无服务给生产力带来的极大解放的。</p>
<p>不过，无服务架构的远期前景也许很美好，但我自己对无服务中短期内的发展，并没有那么乐观。为什么这么说呢？</p>
<p><strong>与单体架构、微服务架构不同，无服务架构天生的一些特点，比如冷启动、 无状态、运行时间有限制等等，决定了它不是一种具有普适性的架构模式。</strong> 除非是有重大变革，否则它也很难具备普适性。</p>
<p>一方面，对一些适合的应用来说，使用无服务架构确实能够降低开发和运维环节的成本，比如不需要交互的离线大规模计算，又比如多数 Web 资讯类网站、小程序、公共 API 服务、移动应用服务端等，都跟无服务架构擅长的短链接、无状态、适合事件驱动的交互形式很契合。</p>
<p>但另一方面，对于那些信息管理系统、网络游戏等应用来说，又或者说对所有具有业务逻辑复杂、依赖服务端状态、响应速度要求较高、需要长连接等特征的应用来说，无服务架构至少在目前来看并不是最合适的。</p>
<p>这是因为，无服务天生”无限算力”的假设，就决定了它必须要按使用量（函数运算的时间和内存）来计费，以控制消耗算力的规模，所以函数不会一直以活动状态常驻服务器，只有请求到了才会开始运行。这导致了函数不便于依赖服务端状态，也导致了函数会有冷启动时间，响应的性能不可能会太好（目前，无服务的云函数冷启动过程大概是在百毫秒级别，对于 Java 这类启动性能差的应用，甚至能到秒级）。</p>
<p>但无论如何，云计算毕竟是大势所趋，今天信息系统建设的概念和观念，在较长尺度的”明天”都是会转变成适应云端的。我并不怀疑 Serverless+API 的这种设计方式，随着云计算的持续发展，将会成为一种主流的软件架构形式，无服务到时候也应该会有更广阔的应用空间。</p>
<p><strong>如果说微服务架构是分布式系统这条路当前所能做到的极致，那无服务架构，也许就是”不分布式”的云端系统这条路的起点。</strong></p>
<p>虽然在顺序上，我把”无服务”安排到了”微服务”和”云原生”时代之后，但它们并没有继承替代关系。我之所以要强调这一点，是为了避免你可能会从两者的名称和安排顺序的角度，产生”无服务比微服务更加先进”的错误想法。我相信，软件开发的未来，不会只存在某一种”最先进的”架构风格，而是会有多种具有针对性的架构风格并存。这才是软件产业更有生命力的形态。</p>
<p>我同样也相信，软件开发的未来，多种架构风格将会融合互补，”分布式”与”不分布式”的边界将会逐渐模糊，两条路线将会在云端的数据中心交汇。</p>
<p>今天，我们已经能初步看见一些使用无服务的云函数去实现微服务架构的苗头了，所以把无服务作为技术层面的架构，把微服务视为应用层面的架构，这样的组合使用也是完全合理可行的。比如，根据腾讯公开的资料，企业微信、QQ 小程序、腾讯新闻等产品，就是使用自己的无服务框架构成的微服务系统。以后，无论是通过物理机、虚拟机、容器，或者是无服务云函数，都会是微服务实现方案的一个候选项。</p>
<h4 id="小结-4"><a href="#小结-4" class="headerlink" title="小结"></a>小结</h4><p>今天是架构演进历史的最后一讲，如 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/309761">第 1 讲</a> 的开篇所说，我们谈历史重点不在考古，而是要借历史之名，来理解每种架构出现的意义以及被淘汰的原因。这样，我们才能更好地解决今天遇到的各种实际的问题，看清楚未来架构演进的发展道路。</p>
<p>对于架构演进的未来，2014 年的时候，Martin Fowler 和 James Lewis 在 <a target="_blank" rel="noopener" href="https://martinfowler.com/articles/microservices.html">《Microservices》</a> 的结束语中分享的观点是，他们对于微服务日后能否被大范围地推广，最多只能持谨慎的乐观态度。无服务方兴未艾的今天，与那时微服务的情况十分相近，我对无服务日后的推广也是持有谨慎的乐观态度。软件开发的最大挑战就在于，只能在不完备的信息下决定当前要处理的问题。</p>
<p>时至今日，我们依然很难预想在架构演进之路的前方，微服务和无服务之后，还会出现什么形式的架构风格，这也正契合了图灵的那句名言：尽管目光所及之处，只是不远的前方，即使如此，依然可以看到那里有许多值得去完成的工作在等待我们。</p>
<blockquote>
<p>We can only see a short distance ahead, but we can see plenty there that needs to be done.</p>
<p>尽管目光所及之处，只是不远的前方，即使如此，依然可以看到那里有许多值得去完成的工作在等待我们。</p>
<p>—— Alan Turing, <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence">Computing Machinery and Intelligence</a>, 1950</p>
</blockquote>
<h2 id="架构师的视角"><a href="#架构师的视角" class="headerlink" title="架构师的视角"></a>架构师的视角</h2><h3 id="07-远程服务调用（上）：从本地方法到远程方法的桥梁"><a href="#07-远程服务调用（上）：从本地方法到远程方法的桥梁" class="headerlink" title="07 | 远程服务调用（上）：从本地方法到远程方法的桥梁"></a>07 | 远程服务调用（上）：从本地方法到远程方法的桥梁</h3><p>“架构师”这个词，其实指向非常宽泛，你可以说做企业战略设计的是架构师，也可以说做业务流程分析的是架构师。而在这门课程中，我所针对的架构师视角，特指软件系统中技术模型的系统设计者。在这个模块当中，我会带你系统性地了解，在做架构设计的时候，架构师都应该思考哪些问题、可以选择哪些主流的解决方案和行业标准做法，以及这些主流方案都有什么优缺点、会给架构设计带来什么影响，等等。</p>
<p>理解了架构师的这些职责，你对”架构设计”这种听起来就很抽象的工作，是不是有个更具体的认识了？</p>
<p>从今天开始，我会花两讲的时间，和你一起学习 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Remote_procedure_call">“远程服务调用（Remote Procedure Call，RPC）”</a> 这个话题。我会尽可能地从根源到现状、从表现到本质，为你解释清楚 RPC 的一些常见的问题。</p>
<p>那今天，我们就先从”什么是 RPC”开始，一起去学习”远程服务”这个构建分布式系统的最基本的前置条件，看看它是如何出现、如何发展的，以及当前业界的主流实现手段。</p>
<p>其实，RPC 这个词儿在计算机科学中已经有超过 40 年的历史了，肯定不是一个新概念。但是直到今天，我们还是会在知乎等网站上，看到很多人提问”什么是 RPC？””如何评价某某 RPC 技术？””RPC 好还是 REST 好？”，仍然”每天”都有新的不同形状的 RPC 轮子被发明出来，仍然有层出不穷的文章，去比对 Google gRPC、Facebook Thrift 等各个厂家的 RPC 技术的优劣。</p>
<p>像计算机科学这种知识快速更迭的领域，一项 40 岁高龄的技术能有如此的关注度，可以说是相当稀罕的现象了。那为什么会出现这种现象呢？</p>
<p>我分析了其中的原因：一方面，可能是微服务风潮带来的热度；另一方面，也不得不承认，作为开发者，我们很多人对 RPC 本身可以解决什么问题、如何解决这些问题、为什么要这样解决，都或多或少存在些认知模糊的情况。</p>
<p>那接下来，我就给你详细解读一下，关于 RPC 的各种分歧和普遍的错误认知。</p>
<h4 id="进程间通讯"><a href="#进程间通讯" class="headerlink" title="进程间通讯"></a>进程间通讯</h4><p>尽管今天的大多数 RPC 技术已经不再追求”与本地方法调用一致”这个目标了，但不可否认的是，RPC 出现的最初目的，就是为了让计算机能够跟调用本地方法一样，去调用远程方法。所以，我们先来看一下在本地方法调用的时候，都会发生些什么。</p>
<p>我们先通过下面这段 Java 风格的伪代码，来定义几个概念：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">
<span class="token comment">// 调用者（Caller）      ： main()</span>
<span class="token comment">// 被调用者（Callee）    ： println()</span>
<span class="token comment">// 调用点（Call Site）   ： 发生方法调用的指令流位置</span>
<span class="token comment">// 调用参数（Parameter） ： 由Caller传递给Callee的数据，即"hello world"</span>
<span class="token comment">// 返回值（Retval）      ： 由Callee传递给Caller的数据，如果方法正常完成，返回值是void，否则是对应的异常</span>
<span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"hello world"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>通过这段伪代码，你可以发现，在完全不考虑编译器优化的前提下，程序运行至调用 println() 这一行的时候，计算机（物理机或者虚拟机）会做以下这些事情：</p>
<ol>
<li><strong>传递方法参数</strong> ：将字符串 hello world 的引用压栈。</li>
<li><strong>确定方法版本</strong> ：根据 println() 方法的签名，确定它的执行版本其实并不是一个简单的过程，不管是编译时的静态解析也好，还是运行时的动态分派也好，程序都必须根据某些语言规范中明确定义的原则，找到明确的被调用者 Callee。这里的”明确”是指唯一的一个 Callee，或者有严格优先级的多个 Callee，比如不同的重载版本。我曾在 <a target="_blank" rel="noopener" href="https://book.douban.com/subject/34907497/">《深入理解 Java 虚拟机》</a> 中用一整章介绍过这个过程。如果你感兴趣的话，可以去深入了解一下。</li>
<li><strong>执行被调方法</strong> ：从栈中获得 Parameter，以此为输入，执行 Callee 内部的逻辑。</li>
<li><strong>返回执行结果</strong> ：将 Callee 的执行结果压栈，并将指令流恢复到 Call Site 处，继续向下执行。</li>
</ol>
<p>接下来，我们就需要考虑一下，当 println() 方法不在当前进程的内存地址空间中，会出现什么问题。不难想到，此时至少面临 <strong>两个直接的障碍</strong> ：</p>
<ul>
<li>第一个障碍，前面的第一步和第四步所做的传递参数、传回结果都依赖于栈内存的帮助，如果 Caller 与 Callee 分属不同的进程，就不会拥有相同的栈内存，那么在 Caller 进程的内存中将参数压栈，对于 Callee 进程的执行毫无意义。</li>
<li>第二个障碍，第二步的方法版本选择依赖于语言规则的定义，而如果 Caller 与 Callee 不是同一种语言实现的程序，方法版本选择就将是一项模糊的不可知行为。</li>
</ul>
<p>所以为了简化，我们暂时忽略第二个障碍，假设 Caller 与 Callee 是使用同一种语言实现的，先来解决两个进程之间如何交换数据的问题，这件事情在计算机科学中被称为”进程间通讯”（Inter-Process Communication，IPC）。那么我们可以考虑的解决办法就有以下几种：</p>
<ol>
<li><p><strong>第一，管道（Pipe）或具名管道（Named Pipe）</strong></p>
<p> 管道其实类似于两个进程间的桥梁，用于进程间传递少量的字符流或字节流。 <strong>普通管道</strong> 可用于 <strong>有亲缘关系进程间的通信（由一个进程启动的另外一个进程）</strong> ；而 <strong>具名管道</strong> 摆脱了普通管道没有名字的限制，除了具有普通管道所具有的功能以外，它还允许 <strong>无亲缘关系进程间的通信</strong> 。</p>
<p> 管道典型的应用就是命令行中的” | “操作符，比如说，命令”ps -ef | grep java”  ，就是管道操作符” | “将 ps 命令的标准输出通过管道，连接到 grep 命令的标准输入上。</p>
</li>
<li><p><strong>第二，信号（Signal）</strong></p>
<p> 信号是用来通知目标进程有某种事件发生的。除了用于进程间通信外，信号还可以被进程发送给进程自身。信号的典型应用是 kill 命令，比如”kill -9 pid”，意思就是由 Shell 进程向指定 PID 的进程发送 SIGKILL 信号。</p>
</li>
<li><p><strong>第三，信号量（Semaphore）</strong></p>
<p> 信号量是用于两个进程之间同步协作的手段，相当于操作系统提供的一个特殊变量。我们可以在信号量上，进行 wait() 和 notify() 操作。</p>
</li>
<li><p><strong>第四，消息队列（Message Queue）</strong></p>
<p> 前面所说的这三种方式，只适合传递少量信息，而 POSIX 标准中，有定义”消息队列”用于进程间通讯的方法。也就是说，进程可以向队列中添加消息，而被赋予读权限的进程则可以从队列中消费消息。消息队列就克服了信号承载信息量少、管道只能用于无格式字节流，以及缓冲区大小受限等缺点  ，但实时性相对受限。</p>
</li>
<li><p><strong>第五，共享内存（Shared Memory）</strong></p>
<p> 允许多个进程可以访问同一块内存空间，这是效率最高的进程间通讯形式。进程的内存地址空间是独立隔离的，但操作系统提供了让进程主动创建、映射、分离、控制某一块内存的接口。由于内存是多进程共享的，所以往往会与其它通信机制，如信号量等结合使用，来达到进程间的同步及互斥。</p>
</li>
<li><p><strong>第六，本地套接字接口（IPC Socket）</strong></p>
<p> 消息队列和共享内存这两种方式，只适合单机多进程间的通讯。而 <strong>套接字接口，是更为普适的进程间通信机制，可用于不同机器之间的进程通信。</strong></p>
<p> 套接字（Socket）起初是由 Unix 系统的 BSD 分支开发出来的，但现在已经移植到所有的 Unix 和 Linux 系统上了。基于效率考虑，当仅限于本机进程间通讯的时候，套接字接口是被优化过的，不会经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等操作，只是简单地将应用层数据从一个进程拷贝到另一个进程，这种进程间通讯方式有个专有的名称：Unix Domain Socket，又叫做 IPC  Socket。</p>
</li>
</ol>
<h4 id="通信的成本"><a href="#通信的成本" class="headerlink" title="通信的成本"></a>通信的成本</h4><p>我之所以花这么多篇幅来介绍 IPC 的手段，是因为计算机科学家们最初的想法，就是将 RPC 作为 IPC 的一种特例来看待（其实现在分类上这么说也仍然合适，只是在具体操作手段上不会这么做了）。</p>
<p>这里，我们需要特别关注的是最后一种 <strong>基于套接字接口的通讯方式（IPC Socket）</strong> 。因为它不仅适用于本地相同机器的不同进程间通讯，而且因为 Socket 是网络栈的统一接口，它也理所当然地能支持基于网络的跨机器、跨进程的通讯。比如 Linux 系统的图形化界面中，X Window 服务器和 GUI 程序之间的交互，就是由这套机制来实现的。</p>
<p>此外，这样做还有一个看起来无比诱人的好处。因为 IPC Socket 是操作系统提供的标准接口，所以它完全有可能把远程方法调用的通讯细节，隐藏在操作系统底层，从应用层面上来看，可以做到远程调用与本地方法调用几乎完全一致。</p>
<p>事实上，在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/309761">原始分布式时代</a> 的初期确实是奔着这个目标去做的， <strong>但这种透明的调用形式反而让程序员们误以为通信是无成本的，从而被滥用，以至于显著降低了分布式系统的性能。</strong></p>
<p>1987 年，当”透明的 RPC 调用”一度成为主流范式的时候，安德鲁 · 塔能鲍姆（Andrew Tanenbaum）教授曾发表了一篇论文 <a target="_blank" rel="noopener" href="https://www.cs.vu.nl/~ast/Publications/Papers/euteco-1988.pdf">“A Critique of the Remote Procedure Call Paradigm”</a> ，对这种透明的 RPC 范式提出了一系列质问：</p>
<ul>
<li>两个进程通讯，谁作为服务端，谁作为客户端？</li>
<li>怎样进行异常处理？异常该如何让调用者获知？</li>
<li>服务端出现多线程竞争之后怎么办？</li>
<li>如何提高网络利用的效率，比如连接是否可被多个请求复用以减少开销？是否支持多播？</li>
<li>参数、返回值如何表示？应该有怎样的字节序？</li>
<li>如何保证网络的可靠性，比如调用期间某个链接忽然断开了怎么办？</li>
<li>服务端发送请求后，收不到回复该怎么办？</li>
<li>……</li>
</ul>
<p><strong>论文的中心观点</strong> 是：把本地调用与远程调用当作一样的来处理，是犯了方向性的错误，把系统间的调用做成透明的，反而会增加程序员工作的复杂度。</p>
<p>此后几年，关于 RPC 应该如何发展、如何实现的论文层出不穷，有支持的也有反对，有冷静分析的也有狂热唾骂的，但历史逐渐证明了 Andrew Tanenbaum 的预言是正确的。</p>
<p>最终，1994 年至 1997 年间，由 ACM 和 Sun 的院士 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/L._Peter_Deutsch">Peter Deutsch</a>、套接字接口发明者 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Bill_Joy">Bill Joy</a> 、Java 之父 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/James_Gosling">James Gosling</a> 等众多在 Sun Microsystems 工作的大佬们，共同总结了 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing">通过网络进行分布式运算的八宗罪（8 Fallacies of Distributed Computing）</a> ：</p>
<ul>
<li>网络是可靠的（The network is reliable）</li>
<li>延迟是不存在的（Latency is zero ）</li>
<li>带宽是无限的（Bandwidth is infinite）</li>
<li>网络是安全的（The network is secure）</li>
<li>拓扑结构是一成不变的（Topology doesn’t change）</li>
<li>总会有一个管理员（There is one administrator）</li>
<li>不考虑传输成本（Transport cost is zero）</li>
<li>网络是同质化的（The network is homogeneous）</li>
</ul>
<p>这八宗罪，被认为是程序员在网络编程中经常忽略的八大问题，潜台词就是如果远程服务调用要弄透明化的话，就必须为这些罪过买单。这算是给 RPC 能否等同于 IPC 来实现，暂时定下了一个具有公信力的结论。</p>
<p>到这时为止，RPC 应该是一种高层次的，或者说语言层次的特征，而不是像 IPC 那样，是低层次的，或者说系统层次的特征，就成为了工业界、学术界的主流观点。</p>
<p>在 1980 年代初期，传奇的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/PARC_(company">施乐 Palo Alto 研究中心</a>) ，发布了基于 Cedar 语言的 RPC 框架 Lupine，并实现了世界上第一个基于 RPC 的商业应用 Courier。这里施乐 PARC 定义的”远程服务调用”的概念，就是符合上面针对 RPC 的结论的。所以，尽管此前已经有用其他名词指代 RPC 的操作，我们也一般认为 RPC 的概念，最早是由施乐公司所提出的。</p>
<blockquote>
<p><strong>首次提出远程服务调用的定义</strong></p>
<p>Remote procedure call is the synchronous language-level transfer of control between programs in address spaces whose primary communication is a narrow channel.</p>
<p>—— Bruce Jay Nelson， <a target="_blank" rel="noopener" href="http://www.bitsavers.org/pdf/xerox/parc/techReports/CSL-81-9_Remote_Procedure_Call.pdf">Remote Procedure Call</a> ，Xerox PARC，1981</p>
</blockquote>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/施乐提出RPC论文的封面.webp" alt="施乐提出RPC论文的封面"></p>
<p>到这里，我们就可以得出 RPC 的定义了：RPC 是一种语言级别的通讯协议，它允许运行于一台计算机上的程序以某种管道作为通讯媒介（即某种传输协议的网络），去调用另外一个地址空间（通常为网络上的另外一台计算机）。</p>
<h4 id="小结-5"><a href="#小结-5" class="headerlink" title="小结"></a>小结</h4><p>这一讲，我们讨论了 RPC 的起源、概念，以及它发展上的一些分歧。以此为基础，我们才能更好地理解后面几讲要学习的内容，包括 RPC 本身要解决的三大问题、RPC 框架的现状与发展，以及它与 REST 的区别。</p>
<p>RPC 以模拟进程间方法调用为起点，许多思想和概念都借鉴的是 IPC，因此这一讲我也介绍了 IPC 中的一些关键概念和实现方法。但是，RPC 原本想照着 IPC 的发展思路，却在实现层面上遇到了很大的困难。RPC 作为一种跨网络的通讯手段，能否无视通讯的成本去迁就编程和设计的原则，这一点从几十年前的 DCE 开始，直到今天学术界、工业界都还有争议。</p>
<p>在下一讲，我会和你一起学习在 RPC 的定义提出之后，工业界中出现过的、著名的 RPC 协议，以及当今常用的各种 RPC 框架，学习它们的共性，也就是它们都必须解决哪几个问题，各自以什么为关注点，以及为何不会出现”完美的”RPC 框架。</p>
<h3 id="08-远程服务调用（下）：如何选择适合自己的RPC框架？"><a href="#08-远程服务调用（下）：如何选择适合自己的RPC框架？" class="headerlink" title="08 | 远程服务调用（下）：如何选择适合自己的RPC框架？"></a>08 | 远程服务调用（下）：如何选择适合自己的RPC框架？</h3><p>上一讲，我们主要是从学术的角度出发，一起学习了 RPC 概念的形成过程。今天这一讲，我会带你从技术的角度出发，去看看工业界在 RPC 这个领域曾经出现过的各种协议，以及时至今日还在层出不穷的各种框架。你会从中了解到 RPC 要解决什么问题，以及如何选择适合自己的 RPC 框架。</p>
<h4 id="RPC-框架要解决的三个基本问题"><a href="#RPC-框架要解决的三个基本问题" class="headerlink" title="RPC 框架要解决的三个基本问题"></a>RPC 框架要解决的三个基本问题</h4><p>在第 1 讲 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/309761">“原始分布式时代”</a> 中，我曾提到过，在 80 年代中后期，惠普和 Apollo 提出了 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Network_Computing_System">网络运算架构（Network Computing Architecture，NCA）</a> 的设想，并随后在 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Distributed_Computing_Environment">DCE 项目</a> 中，发展成了在 Unix 系统下的远程服务调用框架 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/DCE/RPC">DCE/RPC</a> 。</p>
<p>这是历史上第一次对分布式有组织的探索尝试。因为 DCE 本身是基于 Unix 操作系统的，所以 DCE/RPC 也仅面向于 Unix 系统程序之间的通用。</p>
<blockquote>
<p>补充：这句话其实不全对，微软 COM/DCOM 的前身 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Microsoft_RPC">MS RPC</a>，就是 DCE 的一种变体版本，而它就可以在 Windows 系统中使用。</p>
</blockquote>
<p>在 1988 年，Sun Microsystems 起草并向互联网工程任务组（Internet Engineering Task Force，IETF）提交了RFC 1050规范，此规范中设计了一套面向广域网或混合网络环境的、基于 TCP/IP 网络的、支持 C 语言的 RPC 协议，后来也被称为是ONC RPC（Open Network Computing RPC/Sun RPC）。</p>
<p>这两个 RPC 协议，就可以算是如今各种 RPC 协议的鼻祖了。从它们开始，一直到接下来的这几十年，所有流行过的 RPC 协议，都不外乎通过各种手段来解决三个基本问题：</p>
<ol>
<li><p><strong>如何表示数据？</strong></p>
<p> 这里的数据包括了传递给方法的参数，以及方法的返回值。无论是将参数传递给另外一个进程，还是从另外一个进程中取回执行结果，都会涉及 <strong>应该如何表示</strong> 的问题。</p>
<p> 针对进程内的方法调用，我们使用程序语言内置的和程序员自定义的数据类型，就很容易解决数据表示的问题了；而远程方法调用，则可能面临交互双方分属不同程序语言的情况。</p>
<p> 所以，即使是只支持同一种语言的 RPC 协议，在不同硬件指令集、不同操作系统下，也完全可能有不一样的表现细节，比如数据宽度、字节序的差异等。</p>
<p> 行之有效的做法，是 <strong>将交互双方涉及的数据，转换为某种事先约定好的中立数据流格式来传输，将数据流转换回不同语言中对应的数据类型来使用</strong> 。这个过程说起来比较拗口，但相信你一定很熟悉它，这其实就是序列化与反序列化。</p>
<p> 每种 RPC 协议都应该有对应的序列化协议，比如：</p>
<ul>
<li>ONC RPC 的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/External_Data_Representation">External Data Representation （XDR）</a></li>
<li>CORBA 的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Common_Data_Representation">Common Data Representation（CDR）</a></li>
<li>Java RMI 的 <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/platform/serialization/spec/protocol.html#a10258">Java Object Serialization Stream Protocol</a></li>
<li>gRPC 的 <a target="_blank" rel="noopener" href="https://developers.google.com/protocol-buffers">Protocol Buffers</a></li>
<li>Web Service 的 <a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/dotnet/standard/serialization/xml-serialization-with-xml-web-services">XML Serialization</a></li>
<li>众多轻量级 RPC 支持的 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc7159">JSON Serialization</a></li>
<li>……</li>
</ul>
</li>
<li><p><strong>如何传递数据？</strong></p>
<p> 准确地说，如何传递数据是指如何通过网络，在两个服务 Endpoint 之间相互操作、交换数据。这里”传递数据”通常指的是应用层协议，实际传输一般是基于标准的 TCP、UDP 等传输层协议来完成的。<br> 两个服务交互不是只扔个序列化数据流来表示参数和结果就行了，诸如异常、超时、安全、认证、授权、事务等信息，都可能存在双方交换信息的需求。</p>
<p> 在计算机科学中，专门有一个 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Wire_protocol">“Wire Protocol”</a> ，用来表示两个 Endpoint 之间交换这类数据的行为。常见的 Wire Protocol 有以下几种：</p>
<ul>
<li>Java RMI 的 <a target="_blank" rel="noopener" href="https://docs.oracle.com/javase/8/docs/platform/rmi/spec/rmi-protocol3.html">Java Remote Message Protocol</a> （JRMP，也支持 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/w/index.php?title=RMI-IIOP&amp;action=edit&amp;redlink=1">RMI-IIOP</a> ）</li>
<li>CORBA 的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/General_Inter-ORB_Protocol">Internet Inter ORB Protocol</a> （IIOP，是 GIOP 协议在 IP 协议上的实现版本）</li>
<li>DDS 的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Data_Distribution_Service">Real Time Publish Subscribe Protocol（RTPS）</a></li>
<li>Web Service 的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/SOAP">Simple Object Access Protocol（SOAP）</a></li>
<li>如果要求足够简单，双方都是 HTTP Endpoint，直接使用 HTTP 也可以（如 JSON-RPC）</li>
<li>……</li>
</ul>
</li>
<li><p><strong>如何表示方法？</strong></p>
<p> “如何表示方法”，这在本地方法调用中其实也不成问题，因为编译器或者解释器会根据语言规范，把调用的方法转换为进程地址空间中方法入口位置的指针。</p>
<p> 不过一旦考虑到不同语言，这件事儿又麻烦起来了，因为每门语言的方法签名都可能有所差别，所以，针对”如何表示一个方法”和”如何找到这些方法”这两个问题，我们还是得有个统一的标准。<br> 这个标准做起来其实可以很简单：只要给程序中的每个方法，都规定一个通用的又绝对不会重复的编号；在调用的时候，直接传这个编号就可以找到对应的方法。这种听起来无比寒碜的办法，还真的就是 DCE/RPC 最初准备的解决方案。</p>
<p> 虽然最后，DCE 还是弄出了一套跟语言无关的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Interface_description_language">接口描述语言（Interface Description Language，IDL）</a> ，成为了此后许多 RPC 参考或依赖的基础（如 CORBA 的 OMG IDL），但那个唯一的”绝不重复”的编码方案 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Universally_unique_identifier">UUID</a> ，却意外地流行了起来，已经被广泛应用到了程序开发的方方面面。</p>
<p> 这类用于表示方法的协议还有：</p>
<ul>
<li>Android 的 <a target="_blank" rel="noopener" href="https://developer.android.com/guide/components/aidl">Android Interface Definition Language（AIDL）</a></li>
<li>CORBA 的 <a target="_blank" rel="noopener" href="https://www.omg.org/spec/IDL">OMG Interface Definition Language（OMG IDL）</a></li>
<li>Web Service 的 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/WSDL">Web Service Description Language（WSDL）</a></li>
<li>JSON-RPC 的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/JSON-WSP">JSON Web Service Protocol（JSON-WSP）</a></li>
<li>……</li>
</ul>
</li>
</ol>
<p>你看，如何表示数据、如何传递数据、如何表示方法这三个 RPC 中的基本问题，都可以在本地方法调用中找到对应的操作。RPC 的思想始于本地方法调用，尽管它早就不再追求要跟本地方法调用的实现完全一样了，但 RPC 的发展仍然带有本地方法调用的深刻烙印。因此，我们在理解 PRC 的本质时，比较轻松的方式是，以它和本地调用的联系来对比着理解。</p>
<p>好，理解了 RPC 要解决的三个基本问题以后，我们接着来看一下，现代的 RPC 框架都为我们提供了哪些可选的解决方案，以及为什么今天会有这么多的 RPC 框架在并行发展。</p>
<h4 id="统一的-RPC"><a href="#统一的-RPC" class="headerlink" title="统一的 RPC"></a>统一的 RPC</h4><p>DCE/RPC 与 ONC RPC 都有很浓厚的 Unix 痕迹，所以它们其实并没有真正地在 Unix 系统以外大规模流行过，而且它们还有一个”大问题”：只支持传递值而不支持传递对象（ONC RPC 的 XDR 的序列化器能用于序列化结构体，但结构体毕竟不是对象）。这两个 RPC 协议都是面向 C 语言设计的，根本就没有对象的概念。</p>
<p>而 90 年代，正好又是 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Object-oriented_programming">面向对象编程（Object-Oriented Programming，OOP）</a> 风头正盛的年代，所以在 1991 年， <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%AF%B9%E8%B1%A1%E7%AE%A1%E7%90%86%E7%BB%84%E7%BB%87">对象管理组织（Object Management Group，OMG）</a> 便发布了跨进程、面向异构语言的、支持面向对象的服务调用协议：CORBA 1.0（Common Object Request Broker Architecture）。</p>
<p>CORBA 1.0 和 1.1 版本只提供了对 C 和 C++ 的支持，而到了末代的 CORBA 3.0 版本，不仅支持了 C、C++、Java、Object Pascal、Python、Ruby 等多种主流编程语言，还支持了 Smalltalk、Lisp、Ada、COBOL 等已经”半截入土”的非主流语言，阵营不可谓不强大。</p>
<p>可以这么说，CORBA 是一套由国际标准组织牵头、由多个软件提供商共同参与的分布式规范。在当时，只有微软私有的 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/Distributed_COM">DCOM</a> 的影响力可以稍微跟 CORBA 抗衡一下。但是，与 DCE 一样，DCOM 也受限于操作系统（不过比 DCE 厉害的是，DCOM 能跨语言哟）。所以，能够同时支持跨系统、跨语言的 CORBA，其实原本是最有机会统一 RPC 这个细分领域的竞争者。</p>
<p>但很无奈的是，CORBA 并没有抓住这个机会。一方面，CORBA 本身的设计实在是太过于啰嗦和繁琐了，甚至有些规定简直到了荒谬的程度。比如说，我们要写一个对象请求代理（ORB，这是 CORBA 中的关键概念）大概要 200 行代码，其中大概有 170 行是纯粹无用的废话（这句带有鞭尸性质的得罪人的评价不是我说的，是 CORBA 的首席科学家 Michi Henning 在文章《 <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/1142031.1142044">The Rise and Fall of CORBA</a> 》中自己说的）。</p>
<p>另一方面，为 CORBA 制定规范的专家逐渐脱离实际了，所以做出的 CORBA 规范非常晦涩难懂，导致各家语言的厂商都有自己的解读，结果弄出来的 CORBA 实现互不兼容，实在是对 CORBA 号称支持众多异构语言的莫大讽刺。这也间接造就了后来 W3C Web Service 的出现。</p>
<p>所以，Web Service 一出现，CORBA 就在这场竞争中，犹如十八路诸侯讨董卓，互乱阵脚、一触即溃，局面可以说是惨败无比。最终下场就是，CORBA 和 DCOM 一起被扫进了计算机历史的博物馆中，而 Web Service 获得了一统 RPC 的大好机会。</p>
<p>1998 年，XML 1.0 发布，并成为了 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/World_Wide_Web_Consortium">万维网联盟（World Wide Web Consortium，W3C）</a> 的推荐标准。1999 年末，以 XML 为基础的 SOAP 1.0（Simple Object Access Protocol）规范的发布，代表着一种被称为”Web Service”的全新 RPC 协议的诞生。</p>
<p>Web Service 是由微软和 DevelopMentor 公司共同起草的远程服务协议，随后被提交给 W3C，并通过投票成为了国际标准。所以，Web Service 也被称为是 W3C Web Service。</p>
<p>Web Service 采用了 XML 作为远程过程调用的序列化、接口描述、服务发现等所有编码的载体，当时 XML 是计算机工业最新的银弹，只要是定义为 XML 的东西，几乎就都被认为是好的，风头一时无两，连微软自己都主动宣布放弃 DCOM，迅速转投 Web Service 的怀抱。</p>
<p>交给 W3C 管理后，Web Service 再没有天生属于哪家公司的烙印，商业运作非常成功，很受市场欢迎，大量的厂商都想分一杯羹。但从技术角度来看，它设计得也并不优秀，甚至同样可以说是有显著缺陷。</p>
<p>对于开发者而言， <strong>Web Service 的一大缺点，就是过于严格的数据和接口定义所带来的性能问题。</strong></p>
<p>虽然 Web Service 吸取了 CORBA 的教训，不再需要程序员手工去编写对象的描述和服务代理了，但是 XML 作为一门描述性语言，本身的信息密度就很低（都不用与二进制协议比，与今天的 JSON 或 YAML 比一下就知道了）。同时，Web Service 是一个跨语言的 RPC 协议，这使得一个简单的字段，为了在不同语言中不会产生歧义，要以 XML 描述去清楚的话，往往比原本存储这个字段值的空间多出十几倍、几十倍乃至上百倍。</p>
<p>这个特点就导致了，要想使用 Web Service，就必须要有专门的客户端去调用和解析 SOAP 内容，也需要专门的服务去部署（如 Java 中的 Apache Axis/CXF）；更关键的是，这导致了每一次数据交互都包含大量的冗余信息，性能非常差。</p>
<p>如果只是需要客户端、传输性能差也就算了， <a target="_blank" rel="noopener" href="https://www.zhihu.com/topic/20003839/hot">又不是不能用</a> 。既然选择了 XML 来获得自描述能力，也就代表着没打算把性能放到第一位。但是，Web Service 还有另外一点原罪：贪婪。</p>
<p>“贪婪”是指，它希望在一套协议上，一揽子解决分布式计算中可能遇到的所有问题。这导致 Web Service 生出了一整个家族的协议出来。</p>
<p>Web Service 协议家族中，除它本身包括了的 SOAP、WSDL、UDDI 协议之外，还有一堆以 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/List_of_web_service_specifications">WS-*</a> 命名的子功能协议，来解决事务、一致性、事件、通知、业务描述、安全、防重放等问题。这些几乎数不清个数的家族协议，对开发者来说学习负担极其沉重。结果就是，得罪惨了开发者，谁爱用谁用去。</p>
<p>当程序员们对 Web Service 的热情迅速燃起，又逐渐冷却之后，也不禁开始反思：那些 <strong>面向透明的、简单的 RPC 协议</strong> ，如 DCE/RPC、DCOM、Java RMI，要么依赖于操作系统，要么依赖于特定语言，总有一些先天约束；那些 <strong>面向通用的、普适的 RPC 协议</strong> ，如 CORBA，就无法逃过使用复杂性的困扰；而那些 <strong>意图通过技术手段来屏蔽复杂性的 RPC 协议</strong> ，如 Web Service，又不免受到性能问题的束缚。</p>
<p>简单、普适和高性能，似乎真的难以同时满足。</p>
<h4 id="分裂的-RPC"><a href="#分裂的-RPC" class="headerlink" title="分裂的 RPC"></a>分裂的 RPC</h4><p>由于一直没有一个能同时满足以上简单、普适和高性能的”完美 RPC 协议”，因此远程服务器调用这个小小的领域就逐渐进入了群雄混战、百家争鸣的”战国时代”，距离”统一”越来越远，并一直延续至今。</p>
<p>我们看看相继出现过的 RPC 协议 / 框架，就能明白了：RMI（Sun/Oracle）、Thrift（Facebook/Apache）、Dubbo（阿里巴巴 /Apache）、gRPC（Google）、Motan2（新浪）、Finagle（Twitter）、brpc（百度）、.NET Remoting（微软）、Arvo（Hadoop）、JSON-RPC 2.0（公开规范，JSON-RPC 工作组）……</p>
<p>这些 RPC 的功能、特点都不太一样，有的是某种语言私有，有的能支持跨越多门语言，有的运行在 HTTP 协议之上，有的能直接运行于 TCP/UDP 之上，但没有哪一款是”最完美的 RPC”。据此，我们也可以发现一个规律，任何一款具有生命力的 RPC 框架，都不再去追求大而全的”完美”，而是会找到一个独特的点作为主要的发展方向。</p>
<p>我们看几个典型的发展方向：</p>
<ul>
<li><strong>朝着面向对象发展。</strong> 这条线的缘由在于，在分布式系统中，开发者们不再满足于 RPC 带来的面向过程的编码方式，而是希望能够进行跨进程的面向对象编程。因此，这条线还有一个别名叫作 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Distributed_object">分布式对象（Distributed Object）</a> ，它的代表有 RMI、.NET Remoting。当然了，之前的 CORBA 和 DCOM 也可以归入这一类。</li>
<li><strong>朝着性能发展</strong> ，代表为 gRPC 和 Thrift。决定 RPC 性能主要就两个因素：序列化效率和信息密度。序列化效率很好理解，序列化输出结果的容量越小，速度越快，效率自然越高；信息密度则取决于协议中，有效荷载（Payload）所占总传输数据的比例大小，使用传输协议的层次越高，信息密度就越低，SOAP 使用 XML 拙劣的性能表现就是前车之鉴。gRPC 和 Thrift 都有自己优秀的专有序列化器，而在传输协议方面，gRPC 是基于 HTTP/2 的，支持多路复用和 Header 压缩，Thrift 则直接基于传输层的 TCP 协议来实现，省去了额外的应用层协议的开销。</li>
<li><strong>朝着简化发展</strong> ，代表为 JSON-RPC。要是说选出功能最强、速度最快的 RPC 可能会有争议，但要选出哪个功能弱的、速度慢的，JSON-RPC 肯定会是候选人之一。它牺牲了功能和效率，换来的是协议的简单。也就是说，JSON-RPC 的接口与格式的通用性很好，尤其适合用在 Web 浏览器这类一般不会有额外协议、客户端支持的应用场合。</li>
<li>……</li>
</ul>
<p>经历了 RPC 框架的”战国时代”，开发者们终于认可了，不同的 RPC 框架所提供的不同特性或多或少是互相矛盾的，很难有某一种框架说”我全部都要”。</p>
<p>要把面向对象那套全搬过来，就注定不会太简单（比如建 Stub、Skeleton 就很烦了，即使由 IDL 生成也很麻烦）；功能多起来，协议就要弄得复杂，效率一般就会受影响；要简单易用，那很多事情就必须遵循约定而不是配置才行；要重视效率，那就需要采用二进制的序列化器和较底层的传输协议，支持的语言范围容易受限。</p>
<p>也正是因为每一种 RPC 框架都有不完美的地方，才会有新的 RPC 轮子不断出现。</p>
<p>而到了最近几年，RPC 框架有明显朝着更高层次（不仅仅负责调用远程服务，还管理远程服务）与插件化方向发展的趋势， <strong>不再选择自己去解决表示数据、传递数据和表示方法这三个问题，而是将全部或者一部分问题设计为扩展点，实现核心能力的可配置</strong> ，再辅以外围功能，如负载均衡、服务注册、可观察性等方面的支持。这一类框架的代表，有 Facebook 的 Thrift 和阿里的 Dubbo（现在两者都是 Apache 的）。</p>
<p>尤其是断更多年后重启的 Dubbo 表现得更为明显，它默认有自己的传输协议（Dubbo 协议），同时也支持其他协议，它默认采用 Hessian 2 作为序列化器，如果你有 JSON 的需求，可以替换为 Fastjson；如果你对性能有更高的需求，可以替换为 <a target="_blank" rel="noopener" href="https://github.com/EsotericSoftware/kryo">Kryo</a> 、 <a target="_blank" rel="noopener" href="https://github.com/RuedigerMoeller/fast-serialization">FST</a> 、Protocol Buffers 等；如果你不想依赖其他包，直接使用 JDK 自带的序列化器也可以。这种设计，就在一定程度上缓解了 RPC 框架必须取舍，难以完美的缺憾。</p>
<h4 id="小结-6"><a href="#小结-6" class="headerlink" title="小结"></a>小结</h4><p>今天，我们一起学习了 RPC 协议在工业界的发展，包括它要解决的三个基本问题，以及层出不穷的 RPC 协议 / 框架。</p>
<p>表示数据、传递数据和表示方法，是 RPC 必须解决的三大基本问题。要解决这些问题，可以有很多方案，这也是 RPC 协议 / 框架出现群雄混战局面的一个原因。</p>
<p>出现这种分裂局面的另一个原因，是简单的框架很难能达到功能强大的要求。</p>
<p>功能强大的框架往往要在传输中加入额外的负载和控制措施，导致传输性能降低，而如果既想要高性能，又想要强功能，这就必然要依赖大量的技巧去实现，进而也就导致了框架会变得过于复杂，这就决定了不可能有一个”完美”的框架同时满足简单、普适和高性能这三个要求。</p>
<p>认识到这一点后，一个 RPC 框架要想取得成功，就要选择一个发展方向，能够非常好地满足某一方面的需求。因此，我们也就有了朝着面向对象发展、朝着性能发展和朝着简化发展这三条线。</p>
<p>以上就是这一讲我要和你分享的 RPC 在工业界的发展成果了。这也是，你在日后工作中选择 RPC 实现方案的一个参考。</p>
<p>最后，我再和你分享一点我的心得。我在讲到 DCOM、CORBA、Web Service 的失败的时候，虽然说我的口吻多少有一些戏谑，但我们得明确一点：这些框架即使没有成功，但作为早期的探索先驱，并没有什么应该被讽刺的地方。而且其后续的发展，都称得上是知耻后勇，反而值得我们的掌声赞赏。</p>
<p>比如，说到 CORBA 的消亡，OMG 痛定思痛之后，提出了基于 RTPS 协议栈的” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Data_Distribution_Service">数据分发服务</a> “商业标准（Data Distribution Service，DDS，”商业”就是要付费使用的意思）。这个标准现在主要用在物联网领域，能够做到微秒级延时，还能支持大规模并发通讯。</p>
<p>再比如，说到 DCOM 的失败和 Web Service 的衰落，微软在它们的基础上，推出了 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Windows_Communication_Foundation">.NET WCF（Windows Communication Foundation，Windows 通信基础）</a> 。</p>
<p>.NET WCF 的优势主要有两点：一是，把 REST、TCP、SOAP 等不同形式的调用，自动封装为了完全一致的、如同本地方法调用一般的程序接口；二是，依靠自家的”地表最强 IDE”Visual Studio，把工作量减少到只需要指定一个远程服务地址，就可以获取服务描述、绑定各种特性（如安全传输）、自动生成客户端调用代码，甚至还能选择同步还是异步之类细节的程度。</p>
<p>虽然.NET WCF 只支持.NET 平台，而且也是采用 XML 语言描述，但使用体验真的是非常畅快，足够挽回 Web Service 得罪开发者丢掉的全部印象分。</p>
<h3 id="09-RESTful服务（上）：从面向过程编程到面向资源编程"><a href="#09-RESTful服务（上）：从面向过程编程到面向资源编程" class="headerlink" title="09 | RESTful服务（上）：从面向过程编程到面向资源编程"></a>09 | RESTful服务（上）：从面向过程编程到面向资源编程</h3><h4 id="REST-与-RPC-的对比"><a href="#REST-与-RPC-的对比" class="headerlink" title="REST 与 RPC 的对比"></a>REST 与 RPC 的对比</h4><p>很多人都会拿 REST 来跟 RPC 对比优劣，其实，无论是思想上、概念上，还是使用范围上，REST 与 RPC 都不完全一样，它们在本质上并不是同一个类型的东西，充其量只算是有一些相似，在应用中会有一部分功能重合的地方。</p>
<p><strong>REST 与 RPC 在思想上存在差异的核心，是抽象的目标不一样，也就是面向资源的编程思想与面向过程的编程思想之间的区别。</strong></p>
<p>面向过程编程和面向对象编程，想必你应该都听说过，但什么是面向资源编程呢？这个问题等我一会儿介绍完 REST 的特征之后，再回头细说。</p>
<p><strong>那么，二者在概念上的不同，是指 REST 并不是一种远程服务调用协议，甚至我们可以把定语也去掉，它就不是一种协议。</strong></p>
<p>因为协议都带有一定的规范性和强制性，最起码也该有个规约文档，比如 JSON-RPC，它哪怕再简单，也要有个《JSON-RPC Specification》来规定协议的格式细节、异常、响应码等信息。但是 REST 并没有定义这些内容，虽然它有一些指导原则，但实际上并不受任何强制的约束。</p>
<p>经常会有人批评说，某个系统接口”设计得不够 RESTful”，其实这句话本身就有些争议。因为 REST 只能说是一种风格，而不是规范、协议，并且能完全达到 REST 所有指导原则的系统，也是很少见的。这个问题我们会在下一讲中详细讨论。</p>
<p><strong>至于使用范围上，REST 与 RPC 作为主流的两种远程调用方式，在使用上确实有重合之处，但重合的区域有多大就见仁见智了。</strong></p>
<p>上一节课，我提到了当前的 RPC 协议框架各有侧重点，并且列举了 RPC 的一些典型发展方向，比如分布式对象、提升调用效率、简化调用复杂性等等。</p>
<p>其中的分布式对象这一条线的应用，对于 REST 就可以说是毫无关系；而能够重视远程服务调用效率的应用场景，就基本上已经排除了 REST 应用得最多的供浏览器端消费的远程服务。因为以浏览器作为前端，对于传输协议、序列化器这两点都没有什么选择权，哪怕想要更高效率也有心无力。</p>
<p>而在移动端、桌面端或者分布式服务端的节点之间通讯这一块，REST 虽然照样有宽阔的用武之地，只要支持 HTTP 就可以用于任何语言之间的交互，不过使用 REST 的前提是网络没有成为性能上的瓶颈。但是在需要追求传输效率的场景里，REST 提升传输效率的潜力有限，死磕 REST 又想要好的网络性能，一般不会有好的效果。</p>
<p>另外，对于追求简化调用的场景，我在前面提到的浏览器端就属于这一类的典型，在众多 RPC 里，也就 JSON-RPC 有机会与 REST 竞争，其他 RPC 协议与框架，哪怕是能够支持 HTTP 协议，哪怕提供了 JavaScript 版本的客户端（如 gRPC-Web），也只是具备前端使用的理论可行性，很少能看到有实际项目把它们真的用到浏览器上的。</p>
<p>可是，尽管有着种种不同，REST 跟 RPC 还是产生了很频繁的比较与争论，这两种分别面向资源和面向过程的远程调用方式，就像当年面向对象与面向过程的编程思想一样，非得分出个高低不可。</p>
<h4 id="理解-REST"><a href="#理解-REST" class="headerlink" title="理解 REST"></a>理解 REST</h4><p>REST 概念的提出来自于罗伊·菲尔丁（Roy Fielding）在 2000 年发表的博士论文：《 <a target="_blank" rel="noopener" href="https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm">Architectural Styles and the Design of Network-based Software Architectures</a> 》（架构风格与网络的软件架构设计）。这篇文章的确是 REST 的源头，但我们也不能忽略 Fielding 的身份和他之前的工作背景，这对理解 REST 的设计思想也是非常重要的。</p>
<p>首先，Fielding 是一名很优秀的软件工程师，他是 Apache 服务器的核心开发者，后来成为了著名的 <a target="_blank" rel="noopener" href="https://www.apache.org/">Apache 软件基金会</a> 的联合创始人；同时，Fielding 也是 HTTP 1.0 协议（1996 年发布）的专家组成员，后来还成为了 HTTP 1.1 协议（1999 年发布）的负责人。</p>
<p>HTTP 1.1 协议设计得非常成功，以至于在发布后长达十年的时间里，都没有多少人认为有修订的必要。而用来指导设计 HTTP 1.1 协议的理论和思想，最初是以备忘录的形式，在专家组成员之间交流，这个备忘录其实就是 REST 的雏形。</p>
<p>那么从时间上看，当起草完 HTTP 1.1 协议之后，Fielding 就回到了加州大学欧文分校，继续攻读博士学位。然后到了第二年，也就是 2000 年，Fielding 更为系统、严谨地阐述了这套理论框架，并且以这套理论框架为基础，导出了一种新的编程风格，他把这种风格命名为了我们今天所熟知的 REST，即”表征状态转移”（Representational State Transfer）的缩写。</p>
<p>不过，哪怕是对编程和网络都很熟悉的同学，单从”表征状态转移”这个标题上看，也不太可能直接弄明白，什么叫”表征”、啥东西的”状态”、从哪”转移”到哪。虽然在论文当中，Fielding 有论述过这些概念，但他写得确实非常晦涩（不想读英文的话，你可以参考一下 <a target="_blank" rel="noopener" href="https://www.infoq.cn/article/2007/07/dlee-fielding-rest/">中文翻译版本</a> ）。</p>
<p>这里呢，我推荐你一种比较容易理解 REST 思想的方式，就是你 <strong>先去理解什么是 HTTP，再配合一些实际例子来进行类比</strong> ，你就会发现”REST”实际上是”HTT”（Hyper Text Transfer，超文本传输）的进一步抽象，它们就像是接口与实现类之间的关系。</p>
<p>HTTP 中使用的”超文本”一词，是美国社会学家泰德·H·尼尔森（Theodor Holm Nelson）在 1967 年于《 <a target="_blank" rel="noopener" href="https://archive.org/details/SelectedPapers1977">Brief Words on the Hypertext</a> 》一文里提出的，这里引用的是他本人在 1992 年修正后的定义：</p>
<blockquote>
<p>Hypertext</p>
<p>By now the word “hypertext” has become generally accepted for branching and responding text, but the corresponding word “hypermedia”, meaning complexes of branching and responding graphics, movies and sound – as well as text – is much less used. Instead they use the strange term “interactive multimedia”: this is four syllables longer, and does not express the idea of extending hypertext.</p>
<p>—— Theodor Holm Nelson <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Literary_Machines">Literary Machines</a> , 1992</p>
</blockquote>
<p>可以看到，”超文本（或超媒体）”指的是一种”能够对操作进行判断和响应的文本（或声音、图像等）”，这个概念在上个世纪 60 年代提出的时候，应该还属于科幻的范畴，但是到了今天，我们已经完全接受了它，互联网中的一段文字可以点击、可以触发脚本执行、可以调用服务端，都已经非常平常，毫不稀奇了。</p>
<p>所以接下来，我们就尝试着从理解”超文本”的含义开始，根据一个具体的阅读文章的例子，来理解一下什么是”表征”，以及 REST 中的其他关键概念。</p>
<ol>
<li><p><strong>资源（Resource）</strong></p>
<p> 假设，你现在正在阅读一篇名为《REST 设计风格》的文章，这篇文章的内容本身（可以将其视作是某种信息、数据），我们称之为”资源”。无论你是在网上看的网页，还是打印出来看的文字稿，或者是在电脑屏幕上阅读、手机上浏览，尽管它呈现出来的样子都不一样，但其中的信息是不变的，你阅读的仍是同一个”资源”。</p>
</li>
<li><p><strong>表征（Representation）</strong></p>
<p> 当你通过电脑浏览器阅读这篇文章的时候，浏览器会向服务端发出请求”我需要这个资源的 HTML 格式”，那么服务端向浏览器返回的这个 HTML，就被称之为”表征”，你通过其他方式拿到了文章的 PDF、Markdown、RSS 等其他形式的版本，它们也同样是一个资源的多种表征。可见， <strong>“表征”这个概念是指信息与用户交互时的表示形式</strong> ，这跟应用分层中我们常说的”表示层”（Presentation Layer）的语义其实是一致的。</p>
</li>
<li><p><strong>状态（State）</strong></p>
<p> 当你读完了这篇文章，想再接着看看下一篇文章的内容时，你向服务器发出请求”给我下一篇文章”。但是”下一篇”是个相对概念，必须依赖”当前你正在阅读的文章是哪一篇”，这样服务器才能正确回应，那么这类 <strong>在特定语境中才能产生的上下文信息就被称为”状态”。</strong></p>
<p> 这里我们要注意，有状态（Stateful）还是无状态（Stateless），都是只相对于服务端来说的，服务器要完成”取下一篇”的请求，要么是自己记住用户的状态（这个用户现在阅读的是哪一篇文章，这是有状态），要么是客户端来记住状态，在请求的时候明确告诉服务器（我正在阅读某某文章，现在要读下一篇，这是无状态）。</p>
</li>
<li><p><strong>转移（Transfer）</strong></p>
<p> 要知道，无论状态是由服务端还是客户端来提供的，”取下一篇文章”这个行为逻辑必然只能由服务端来提供。 <strong>服务器通过某种方式，把”用户当前阅读的文章”转变成”下一篇文章”，这就被称为”表征状态转移”。</strong></p>
<p> 好，通过这个”阅读文章”的例子，对资源等概念进行通俗的解释，现在你应该就能理解 REST 所说的”表征状态转移”的含义了。</p>
</li>
</ol>
<p>那么，借着这个例子的上下文，我再给你介绍几个现在不涉及，但在后面解读 REST 的 6 大核心特征时要用到的概念名词：</p>
<ol>
<li><p><strong>第一个，统一接口（Uniform Interface）。</strong></p>
<p> 在了解这个概念之前，我们先来思考一个问题，前面所说的”服务器通过某种方式”，让表征状态发生转移，具体指的是什么方式呢？</p>
<p> 如果你现在正在使用 Web 端来学习这一讲的内容，你可以看到页面的左半部分有下一讲（或者是下面几讲）的 URI 超链接地址，这是服务端在渲染这讲内容时就预置好的，点击它让页面跳转到下一讲，就是所谓”某种方式”的其中一种方式（不过若下一讲还未更新出来时，你只能看到之前的课程内容，道理其实也差不多）。</p>
<p> 现在，我们其实并不会对点击超链接网页出现跳转而感到奇怪，但你再细想一下，URI 的含义是统一资源标识符，是一个名词，那它如何能表达出”转移”这个动作的含义呢？</p>
<p> 答案是 HTTP 协议中已经提前约定好了一套”统一接口”，它包括：GET、HEAD、POST、PUT、DELETE、TRACE、OPTIONS 七种基本操作，任何一个支持 HTTP 协议的服务器都会遵守这套规定，对特定的 URI 采取这些操作，服务器就会触发相应的表征状态转移。</p>
</li>
<li><p><strong>第二个，超文本驱动（Hypertext Driven）。</strong></p>
<p> 尽管表征状态转移是由浏览器主动向服务器发出请求所引发的，该请求导致了”在浏览器屏幕上显示出了下一篇文章的内容”这个结果的出现。但是你我都清楚，这不可能真的是浏览器的主动意图，浏览器是根据用户输入的 URI 地址来找到服务器给予的首页超文本内容，通过超文本内部的链接，导航到了这篇文章，阅读结束时，也是通过超文本内部的链接再导航到下一篇。</p>
<p> 浏览器作为所有网站的通用的客户端，任何网站的导航（状态转移）行为都不可能是预置于浏览器代码之中，而是由服务器发出的请求响应信息（超文本）来驱动的。这点与其他带有客户端的软件有十分本质的区别，在那些软件中，业务逻辑往往是预置于程序代码之中的，有专门的页面控制器（无论在服务端还是在客户端中）来驱动页面的状态转移。</p>
</li>
<li><p><strong>第三个，自描述消息（Self-Descriptive Messages）。</strong></p>
<p> 前面我们知道了，资源的表征可能存在多种不同形态，因此在传输给浏览器的消息中应当有明确的信息，来告知客户端该消息的类型以及该如何处理这条消息。一种被广泛采用的自描述方法，是在名为”Content-Type”的 HTTP Header 中标识出 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E5%AA%92%E4%BD%93%E7%B1%BB%E5%9E%8B">互联网媒体类型（MIME type）</a> ，比如”Content-Type : application/json; charset=utf-8”，就说明了该资源会以 JSON 的格式返回，请使用 UTF-8 字符集进行处理。</p>
<p> 好，除了以上列出的这些看名字不容易弄懂的概念外，在理解 REST 的时候，你还要注意一个常见的误区。Fielding 在提出 REST 时，所谈论的范围是”架构风格与网络的软件架构设计”（Architectural Styles and Design of Network-based Software Architectures），而不是现在被人们所狭义理解的一种”远程服务设计风格”。</p>
<p> 这两者的范围差别，就好比这门课程所谈论的话题”软件架构”与这个小章节所谈论的话题”访问远程服务”的关系那样，前者是后者的一个很大的超集。尽管考虑到这节课的主题和多数人的关注点，我们确实是会以”远程服务设计风格”作为讨论的重点，但至少我们要知道它们在范围上的差别。</p>
</li>
</ol>
<h4 id="RESTful-风格的系统特征"><a href="#RESTful-风格的系统特征" class="headerlink" title="RESTful 风格的系统特征"></a>RESTful 风格的系统特征</h4><p>OK，理解了前面解读的这些概念以后，现在我们就可以开始讨论面向资源的编程思想，以及 Fielding 所提出的具体的软件架构设计特征了。Fielding 认为，一套理想的、完全满足 REST 的系统应该满足以下六个特征。</p>
<h5 id="服务端与客户端分离（Client-Server）"><a href="#服务端与客户端分离（Client-Server）" class="headerlink" title="服务端与客户端分离（Client-Server）"></a>服务端与客户端分离（Client-Server）</h5><p>现在，有越来越多的开发者认可，分离开用户界面和数据存储所关注的逻辑，有助于提高用户界面跨平台的可移植性。</p>
<p>以前完全基于服务端控制和渲染（如 JSF 这类）框架的实际用户，现在已经很少见了。另外，在服务端进行界面控制（Controller），通过服务端或者客户端的模版渲染引擎，来进行界面渲染的框架（如 Struts、SpringMVC 这类）也受到了颇大的冲击。而推动这个局面发展的主要原因，实际上跟 REST 的关系并不大，随着前端技术（从 ES 规范，到语言实现，到前端框架等）近年来的高速发展，前端表达能力的大幅度加强才是真正的幕后推手。</p>
<p>此外，由于前端的日渐强势，现在还流行起由前端代码反过来驱动服务端进行渲染的 SSR（Server-Side Rendering）技术，在 Serverless、SEO 等场景中已经占领了一块领地。</p>
<h5 id="无状态（Stateless）"><a href="#无状态（Stateless）" class="headerlink" title="无状态（Stateless）"></a>无状态（Stateless）</h5><p>这是 REST 的一条关键原则，部分开发者在做服务接口规划时，觉得 RESTful 风格的 API 怎么设计都别扭，一个很可能的原因就是服务端持有着比较重的状态。</p>
<p>REST 希望服务器能不负责维护状态，每一次从客户端发送的请求中，应该包括所有必要的上下文信息，会话信息也由客户端保存维护，服务器端依据客户端传递的状态信息来进行业务处理，并且驱动整个应用的状态变迁。</p>
<p>至于客户端承担状态维护职责后的认证、授权等各方面的可信问题，都会有针对性的解决方案（这部分内容，我会在后面讲解安全架构时展开介绍）。</p>
<p>但必须承认的现状是，目前大多数的系统是达不到这个要求的，越复杂、越大型的系统越是如此。服务端无状态可以在分布式环境中获得很高价值的好处，但大型系统的上下文状态数量，完全可能膨胀到，客户端在每次发送请求时，根本无法全部囊括系统里所有必要的上下文信息。在服务端的内存、会话、数据库或者缓存等地方，持有一定的状态是一种现实情况，而且会是长期存在、被广泛使用的主流方案。</p>
<h5 id="可缓存（Cacheability）"><a href="#可缓存（Cacheability）" class="headerlink" title="可缓存（Cacheability）"></a>可缓存（Cacheability）</h5><p>前面我们提到的无状态服务，虽然提升了系统的可见性、可靠性和可伸缩性，但也降低了系统的网络性。这句话通俗的解释就是，某个功能使用有状态的架构只需要一次请求就能完成，而无状态的服务则可能会需要多个请求，或者在请求中带有冗余的信息。</p>
<p>所以，为了缓解这个矛盾，REST 希望软件系统能够像万维网一样，客户端和中间的通讯传递者（代理）可以将部分服务端的应答缓存起来。当然，应答中必须明确或者间接地表明本身是否可以进行缓存，以避免客户端在将来进行请求的时候得到过时的数据。</p>
<p>运作良好的缓存机制可以减少客户端、服务器之间的交互，甚至有些场景中可以完全避免交互，这就进一步提高了性能。</p>
<h5 id="分层系统（Layered-System）"><a href="#分层系统（Layered-System）" class="headerlink" title="分层系统（Layered System）"></a>分层系统（Layered System）</h5><p>这里所指的并不是表示层、服务层、持久层这种意义上的分层，而是指客户端一般不需要知道是否直接连接到了最终的服务器，或者是连接到路径上的中间服务器。中间服务器可以通过负载均衡和共享缓存的机制，提高系统的可扩展性，这样也便于缓存、伸缩和安全策略的部署。</p>
<h5 id="统一接口（Uniform-Interface）"><a href="#统一接口（Uniform-Interface）" class="headerlink" title="统一接口（Uniform Interface）"></a>统一接口（Uniform Interface）</h5><p>REST 希望开发者面向资源编程，希望 <strong>软件系统设计的重点放在抽象系统该有哪些资源上</strong> ，而不是抽象系统该有哪些行为（服务）上。</p>
<p>这个特征，你可以类比计算机中对文件管理的操作。我们知道，管理文件可能会进行创建、修改、删除、移动等操作，这些操作数量是可数的，而且对所有文件都是固定的、统一的。如果面向资源来设计系统，同样会具有类似的操作特征，由于 REST 并没有设计新的协议，所以这些操作都借用了 HTTP 协议中固有的操作命令来完成。</p>
<p>统一接口也是 REST 最容易陷入争论的地方，基于网络的软件系统，到底是面向资源更好，还是面向服务更合适，这件事情在很长的时间里恐怕都不会有个定论，也许永远都没有。但是，有一个已经基本清晰的结论是： <strong>面向资源编程的抽象程度通常更高。</strong></p>
<p>抽象程度高有好处但也有坏处。坏处是往往距离人类的思维方式更远，而好处是往往通用程度会更好。</p>
<p>不过这样来诠释 REST，大概本身就挺抽象的，你可能不太好理解，我还是举个例子来说明。</p>
<p>几乎每个系统都有登录和注销功能，如果你理解成登录对应于 login()、注销对应于 logout() 这样两个独立服务，这是”符合人类思维”的；如果你理解成登录是 PUT Session，注销是 DELETE Session，这样你只需要设计一种”Session 资源”即可满足需求，甚至以后对 Session 的其他需求，如查询登录用户的信息，就是 GET Session 而已，其他操作如修改用户信息等等，都可以被这同一套设计囊括在内，这便是”抽象程度更高”带来的好处。</p>
<p>而如果你想要在架构设计中合理恰当地利用统一接口，Fielding 给出了三个建议：第一，系统要能做到每次请求中都包含资源的 ID，所有操作均通过资源 ID 来进行；第二，每个资源都应该是自描述的消息；第三，通过超文本来驱动应用状态的转移。</p>
<h5 id="按需代码（-Code-On-Demand-）"><a href="#按需代码（-Code-On-Demand-）" class="headerlink" title="按需代码（ Code-On-Demand ）"></a>按需代码（ <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Code_on_demand">Code-On-Demand</a> ）</h5><p>按需代码被 Fielding 列为了一条可选原则，原因其实并非是它特别难以达到，更多是出于必要性和性价比的实际考虑。按需代码是指任何按照客户端（如浏览器）的请求，将可执行的软件程序从服务器发送到客户端的技术。它赋予了客户端无需事先知道，所有来自服务端的信息应该如何处理、如何运行的宽容度。</p>
<p>举个具体例子，以前的 Java Applet 技术、今天的 WebAssembly 等都属于典型的按需代码，蕴含着具体执行逻辑的代码存放在了服务端，只有当客户端请求了某个 Java Applet 之后，代码才会被传输并在客户端机器中运行，结束后通常也会随即在客户端中被销毁掉。</p>
<p>到这里，REST 中的主要概念与思想原则就介绍完了，那么现在，我们再回过头来讨论一下这节课开篇中提出的 REST 与 RPC 在思想上的差异。</p>
<h4 id="REST-与-RPC-在思想上的差异"><a href="#REST-与-RPC-在思想上的差异" class="headerlink" title="REST 与 RPC 在思想上的差异"></a>REST 与 RPC 在思想上的差异</h4><p>我在前面提到， <strong>REST 的基本思想是面向资源来抽象问题，它与此前流行的面向过程的编程思想，在抽象主体上有本质的差别。</strong></p>
<p>在 REST 提出以前，人们设计分布式系统服务的唯一方案就只有 RPC，RPC 是将本地的方法调用思路迁移到远程方法调用上，开发者是围绕着”远程方法”去设计两个系统间的交互的，比如 CORBA、RMI、DCOM，等等。</p>
<p>这样做的坏处，不仅是”如何在异构系统间表示一个方法””如何获得接口能够提供的方法清单”，都成了需要专门协议去解决的问题（RPC 的三大基本问题之一），更在于服务的每个方法都是不同的，服务使用者必须逐个学习才能正确地使用它们。Google 在《Google API Design Guide》中曾经写下这样一段话：</p>
<blockquote>
<p>Traditionally, people design RPC APIs in terms of API interfaces and methods, such as CORBA and Windows COM. As time goes by, more and more interfaces and methods are introduced. The end result can be an overwhelming number of interfaces and methods, each of them different from the others. Developers have to learn each one carefully in order to use it correctly, which can be both time consuming and error prone.</p>
<p>以前，人们面向方法去设计 RPC API，比如 CORBA 和 DCOM，随着时间推移，接口与方法越来越多却又各不相同，开发人员必须了解每一个方法才能正确使用它们，这样既耗时又容易出错。</p>
<p>—— <a target="_blank" rel="noopener" href="https://cloud.google.com/apis/design">Google API Design Guide</a> , 2017</p>
</blockquote>
<p>而 REST 提出以资源为主体进行服务设计的风格，就为它带来了不少好处。我举几个典型例子。</p>
<ol>
<li><p><strong>第一，降低了服务接口的学习成本。</strong></p>
<p> 统一接口是 REST 的重要标志，它把对资源的标准操作都映射到了标准的 HTTP 方法上去，这些方法对每个资源的语义都是一致的，我们不需要刻意学习，更不会有什么 Interface Description Language 之类的协议存在。</p>
</li>
<li><p><strong>第二，资源天然具有集合与层次结构。</strong></p>
<p> 以方法为中心抽象的接口，由于方法是动词，逻辑上决定了每个接口都是互相独立的；但以资源为中心抽象的接口，由于资源是名词，天然就可以产生集合与层次结构。</p>
<p> 我举个例子。你可以想像一个商城用户中心的接口设计：用户资源会拥有多个不同的下级的资源，比如若干条短消息资源、一份用户资料资源、一部购物车资源，而购物车中又会有自己的下级资源，比如多本书籍资源。</p>
<p> 这样，你就很容易在程序接口中构造出这些资源的集合关系与层次关系，而且能符合人们长期在单机或网络环境中管理数据的直觉。我相信，你并不需要专门去阅读接口说明书，也能轻易推断出获取用户 icyfenix 的购物车中，第 2 本书的 REST 接口应该表示为：<code>GET /users/icyfenix/cart/2</code> 。</p>
</li>
<li><p><strong>第三，REST 绑定于 HTTP 协议。</strong></p>
<p> 面向资源编程并不是必须构筑在 HTTP 之上，但对于 REST 来说，这是优点，也是缺点。</p>
<p> 因为 HTTP 本来就是面向资源而设计的网络协议，纯粹只用 HTTP（而不是 SOAP over HTTP 那样在再构筑协议）带来的好处，是不需要再去考虑 RPC 中的 Wire Protocol 问题了，REST 可以复用 HTTP 协议中已经定义的语义和相关基础支持来解决。HTTP 协议已经有效运作了 30 年，与其相关的技术基础设施已是千锤百炼，无比成熟。而它的坏处自然就是，当你想去考虑那些 HTTP 不提供的特性时，就束手无策了。</p>
</li>
</ol>
<h4 id="小结-7"><a href="#小结-7" class="headerlink" title="小结"></a>小结</h4><p>在这节课中，虽然我列举了一些面向资源的优点，但我并非要证明它比面向过程、面向对象更优秀。是否选用 REST 的 API 设计风格，需要权衡的是你的需求场景、你团队的设计，以及开发人员是否能够适应面向资源的思想来设计软件、来编写代码。</p>
<p>在互联网中，面向资源来进行网络传输，是这三十年来 HTTP 协议精心培养出来的用户习惯，如果开发者能够适应 REST 不太符合人类思维习惯的抽象方式，那 REST 通常能够更好地匹配在 HTTP 基础上构建的互联网，在效率与扩展性方面也会有可观的收益。</p>
<h3 id="10-RESTful服务（下）：如何评价服务是否RESTful？"><a href="#10-RESTful服务（下）：如何评价服务是否RESTful？" class="headerlink" title="10 | RESTful服务（下）：如何评价服务是否RESTful？"></a>10 | RESTful服务（下）：如何评价服务是否RESTful？</h3><p>上一节课，我们一起学习了 REST 的思想、概念和指导原则等，今天我们把重心放在 REST 的实践上，把目光聚焦到具体如何设计 REST 服务接口上。这样我们也就能回答上节课提出的问题”如何评价服务是否 RESTful”了。</p>
<h4 id="Richardson-成熟度模型"><a href="#Richardson-成熟度模型" class="headerlink" title="Richardson 成熟度模型"></a>Richardson 成熟度模型</h4><p>“ <a target="_blank" rel="noopener" href="https://book.douban.com/subject/22139962/">RESTful Web APIs</a> “和” <a target="_blank" rel="noopener" href="https://book.douban.com/subject/2054201/">RESTful Web Services</a> “的作者伦纳德 · 理查德森（Leonard Richardson），曾提出过一个衡量”服务有多么 REST”的 Richardson 成熟度模型（ <a target="_blank" rel="noopener" href="https://martinfowler.com/articles/richardsonMaturityModel.html">Richardson Maturity Model</a> ，RMM）。这个模型的一个用处是，方便那些原本不使用 REST 的服务，能够逐步导入 REST。</p>
<p>Richardson 将服务接口按照”REST 的程度”，从低到高分为 0 至 3 共 4 级：</p>
<ol>
<li>The Swamp of <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Plain_Old_XML">Plain Old XML</a> ：完全不 REST。另外，关于 POX 这个说法，SOAP 表示感觉有被冒犯到。</li>
<li>Resources：开始引入资源的概念。</li>
<li>HTTP Verbs：引入统一接口，映射到 HTTP 协议的方法上。</li>
<li>Hypermedia Controls：在咱们课程里面的说法是”超文本驱动”，在 Fielding 论文里的说法是 Hypertext as the Engine of Application State（HATEOAS），都说的是同一件事情。</li>
</ol>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/REST成熟度模型.webp" alt="REST成熟度模型"></p>
<p><a target="_blank" rel="noopener" href="https://martinfowler.com/articles/richardsonMaturityModel.html">REST成熟度模型</a></p>
<p>接下来，我们通过马丁 · 福勒（Martin Fowler）的关于 RMM 的 <a target="_blank" rel="noopener" href="https://martinfowler.com/articles/richardsonMaturityModel.html">文章</a> 中的实际例子（原文是 XML 写的，我简化了一下），来看看四种不同程度的 REST 反应到实际 API 是怎样的。</p>
<p>假设，你是一名软件工程师，接到需求（也被我尽量简化了）的用户故事是这样的：现在要开发一个医生预约系统，病人通过这个系统，可以知道自己熟悉的医生在指定日期是否有空闲时间，以方便预约就诊。</p>
<ol>
<li><p><strong>第 0 级成熟度：The Swamp of Plain Old XML</strong></p>
<p> 医院开放了一个 /appointmentService 的 Web API，传入日期、医生姓名作为参数，就可以得到该时间段、该医生的空闲时间。</p>
<p> 这个 API 的一次 HTTP 调用如下所示：</p>
 <pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token request-line"><span class="token property">POST</span> /appointmentService?action=query HTTP/1.1</span>

{date: "2020-03-04", doctor: "mjones"}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 在接收到请求之后，服务器会传回一个包含所需信息的结果：</p>
 <pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">200 OK</span></span>

[
    {start:"14:00", end: "14:50", doctor: "mjones"},
    {start:"16:00", end: "16:50", doctor: "mjones"}
]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 得到了医生空闲的结果后，我觉得 14:00 的时间比较合适，于是预约确认，并提交了我的基本信息：</p>
 <pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token request-line"><span class="token property">POST</span> /appointmentService?action=comfirm HTTP/1.1</span>

{
    appointment: {date: "2020-03-04", start:"14:00", doctor: "mjones"},
    patient: {name: xx, age: 30, ……}
}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 如果预约成功，那我能够收到一个预约成功的响应：</p>
 <pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">200 OK</span></span>

{
    code: 0,
    message: "Successful confirmation of appointment"
}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 如果发生了问题，比如有人在我前面抢先预约了，那么我会在响应中收到某种错误信息：</p>
 <pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">200 OK</span></span>

{
    code: 1
    message: "doctor not available"
}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 到此，整个预约服务就完成了，可以说是直接明了。</p>
<p> 在这个方案里，我们采用的是非常直观的基于 RPC 风格的服务设计，看似是很轻松地解决了所有问题，但真的是这样吗？</p>
</li>
<li><p><strong>第 1 级成熟度：Resources</strong></p>
<p> 实际上你可以发现，第 0 级是 RPC 的风格，所以如果需求永远不会变化，也不会增加，那它完全可以良好地工作下去。但是，如果你不想为预约医生之外的其他操作、为获取空闲时间之外的其他信息去编写额外的方法，或者改动现有方法的接口，那就应该考虑一下如何使用 REST 来抽象资源。</p>
<p> 通往 REST 的第一步是引入资源的概念，在 API 中最基本的体现，就是它会围绕着资源而不是过程来设计服务。说得直白一点，你可以理解为服务的 Endpoint 应该是一个名词而不是动词。此外，每次请求中都应包含资源 ID，所有操作均通过资源 ID 来进行。</p>
 <pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token request-line"><span class="token property">POST</span> /doctors/mjones HTTP/1.1</span>

{date: "2020-03-04"}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 然后，服务器传回一个包含了 ID 的信息。注意，ID 是资源的唯一编号，有 ID 即代表”医生的档期”被视为一种资源：</p>
 <pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">200 OK</span></span>

[
    {id: 1234, start:"14:00", end: "14:50", doctor: "mjones"},
    {id: 5678, start:"16:00", end: "16:50", doctor: "mjones"}
]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 我还是觉得 14:00 的时间比较合适，于是又预约确认，并提交了我的基本信息：</p>
 <pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token request-line"><span class="token property">POST</span> /schedules/1234 HTTP/1.1</span>

{name: xx, age: 30, ……}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 后面预约成功或者失败的响应消息在这个级别里面与之前一致，就不重复了。</p>
<p> 比起第 0 级，第 1 级的服务抽象程度有所提高，但至少还有三个问题并没有解决：</p>
<ol>
<li>一是，只处理了查询和预约，如果我临时想换个时间要调整预约，或者我的病忽然好了想删除预约，这都需要提供新的服务接口。</li>
<li>二是，处理结果响应时，只能靠着结果中的 code、message 这些字段做分支判断，每一套服务都要设计可能发生错误的 code。而这很难考虑全面，而且也不利于对某些通用的错误做统一处理。</li>
<li><p>三是，并没有考虑认证授权等安全方面的内容。比如，要求只有登录过的用户才允许查询医生的档期；再比如，某些医生可能只对 VIP 开放，需要特定级别的病人才能预约等等。</p>
<p>这三个问题，其实都可以通过引入统一接口（Uniform Interface）来解决。接下来，我们就来到了第 2 级。</p>
</li>
</ol>
</li>
<li><p><strong>第 2 级成熟度：HTTP Verbs</strong></p>
<p> 前面说到，第 1 级中遗留的这三个问题，都可以靠引入统一接口来解决，而 HTTP 协议的标准方法便是最常接触到的统一接口。</p>
<p> HTTP 协议的标准方法是经过精心设计的，它几乎涵盖了资源可能遇到的所有操作场景（这其实更取决于架构师的抽象能力）。</p>
<p> 那么，REST 的做法是：</p>
<ul>
<li>针对 <strong>预约变更</strong> 的问题，把不同业务需求抽象为对资源的增加、修改、删除等操作来解决；</li>
<li>针对 <strong>响应代码</strong> 的问题，使用 HTTP 协议的 Status Code，可以涵盖大多数资源操作可能出现的异常（而且也是可以自定义扩展的）；</li>
<li><p>针对 <strong>安全性</strong> 的问题，依靠 HTTP Header 中携带的额外认证、授权信息来解决（这个在实战中并没有体现，你可以去看看后面第 23~28 讲中关于安全架构的相关内容）。</p>
<p>按这个思路，我们在获取医生档期时，应该使用具有查询语义的 GET 操作来完成：</p>
<pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token request-line"><span class="token property">GET</span> /doctors/mjones/schedule?date=2020-03-04&amp;status=open HTTP/1.1</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>然后，服务器会传回一个包含了所需信息的结果：</p>
<pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">200 OK</span></span>

[
    {id: 1234, start:"14:00", end: "14:50", doctor: "mjones"},
    {id: 5678, start:"16:00", end: "16:50", doctor: "mjones"}
]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>我还是觉得 14:00 的时间比较合适，于是就预约确认，并提交了我的基本信息用来创建预约。这是符合 POST 的语义的：</p>
<pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token request-line"><span class="token property">POST</span> /schedules/1234 HTTP/1.1</span>

{name: xx, age: 30, ……}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>如果预约成功，那我能够收到一个预约成功的响应：</p>
<pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">201 Created</span></span>

Successful confirmation of appointment<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>否则，我会在响应中收到某种错误信息：</p>
<pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">409 Conflict</span></span>

doctor not available<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>目前绝大多数的系统能够达到的 REST 级别，也就是第 2 级了。不过这种方案还不够完美，最主要的一个问题是：我们如何知道预约 mjones 医生的档期，需要访问”/schedules/1234”这个服务 Endpoint？</p>
</li>
</ul>
</li>
<li><p><strong>第 3 级成熟度：Hypermedia Controls</strong></p>
<p> 或许你第一眼看到这个问题会说，这当然是程序写的啊，我为什么会问这么奇怪的问题。但问题是，REST 并不认同这种已烙在程序员脑海中许久的想法。</p>
<p> RMM 中的第 3 级成熟度 Hypermedia Controls、Fielding 论文中的 HATEOAS 和现在提得比较多的超文本驱动，其实都是希望能达到这样一种效果： <strong>除了第一个请求是由你在浏览器地址栏输入的信息所驱动的之外，其他的请求都应该能够自己描述清楚后续可能发生的状态转移，由超文本自身来驱动。</strong></p>
<p> 所以，当你输入了查询命令后：</p>
 <pre class="line-numbers language-http" data-language="http"><code class="language-http">GET /doctors/mjones/schedule?date=2020-03-04&amp;statu s=open HTTP/1.1<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> 服务器传回的响应信息应该包括如何预约档期、如何了解医生信息等可能的后续操作：</p>
 <pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">200 OK</span></span>

{
    schedules：[
        {
            id: 1234, start:"14:00", end: "14:50", doctor: "mjones",
            links: [
                {rel: "comfirm schedule", href: "/schedules/1234"}
            ]
        },
        {
            id: 5678, start:"16:00", end: "16:50", doctor: "mjones",
            links: [
                {rel: "comfirm schedule", href: "/schedules/5678"}
            ]
        }
],
<span class="token header-name keyword">links:</span> [
    {rel: "doctor info", href: "/doctors/mjones/info"}
]
}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 如果做到了第 3 级 REST，那么服务端的 API 和客户端就可以做到完全解耦了。这样一来，你再想要调整服务数量，或者同一个服务做 API 升级，将会变得非常简单。</p>
</li>
</ol>
<p>至此，我们已经学完了 REST 的相关知识，了解了 REST 的一些优点，然而凡事总有两面，下面我们来看一看 REST 经常收到非议的方面。</p>
<h4 id="REST-的不足与争议"><a href="#REST-的不足与争议" class="headerlink" title="REST 的不足与争议"></a>REST 的不足与争议</h4><ol>
<li><p><strong>第一个有争议的问题是：面向资源的编程思想只适合做 CRUD，只有面向过程、面向对象编程才能处理真正复杂的业务逻辑。</strong></p>
<p> 这是我们在实践 REST 时遇到的最多的一个问题。有这个争议的原因也很简单，HTTP 的 4 个最基础的命令 POST、GET、PUT 和 DELETE，很容易让人联想到 CRUD 操作，因此在脑海中就自然产生了直接的对应。</p>
<p> REST 涵盖的范围当然远不止于此。不过要说 POST、GET、PUT 和 DELETE 对应于 CRUD，其实也没什么不对，只是我们必须泛化地去理解这个 CRUD：它们涵盖了信息在客户端与服务端之间流动的几种主要方式（比如 POST、GET、PUT 等标准方法），所有基于网络的操作逻辑，都可以通过解决”信息在服务端与客户端之间如何流动”这个问题来理解，有的场景里比较直观，而另一些场景中可能比较抽象。</p>
<p> 针对那些比较抽象的场景，如果确实不好把 HTTP 方法映射为资源的所需操作，REST 也并不会刻板地要求一定要做映射。这时，用户可以使用自定义方法，按 Google 推荐的 REST API 风格来拓展 HTTP 标准方法。</p>
<p> <strong>自定义方法</strong> 应该放在资源路径末尾，嵌入冒号加自定义动词的后缀。比如，我将删除操作映射到标准 DELETE 方法上，此外还要提供一个恢复删除的 API，那它可能会被设计为：</p>
 <pre class="line-numbers language-http" data-language="http"><code class="language-http">POST /user/user_id/cart/book_id:undelete<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> 要实现恢复删除，一个完全可行的设计是：设计一个回收站的资源，在那里保留还能被恢复的商品，我们把恢复删除看作是对这个资源的某个状态值的修改，映射到 PUT 或者 PATCH 方法上。</p>
<p> 最后，我要再重复一遍，面向资源的编程思想与另外两种主流编程（面向过程和面向对象编程）思想，只是抽象问题时所处的立场不同，只有选择问题，没有高下之分：</p>
<ul>
<li>面向过程编程时，为什么要以算法和处理过程为中心，输入数据，输出结果？当然是为了符合计算机世界中主流的交互方式。</li>
<li>面向对象编程时，为什么要将数据和行为统一起来、封装成对象？当然是为了符合现实世界的主流交互方式。</li>
<li>面向资源编程时，为什么要将数据（资源）作为抽象的主体，把行为看作是统一的接口？当然是为了符合网络世界的主流的交互方式。</li>
</ul>
</li>
<li><p><strong>第二个有争议的问题是：REST 与 HTTP 完全绑定，不适用于要求高性能传输的场景中。</strong></p>
<p> 其实，我在很大程度上赞同这个观点，但我并不认为这是 REST 的缺陷，因为锤子不能当扳手用，并不是锤子的质量有问题。</p>
<p> 面向资源编程与协议无关，但是 REST（特指 Fielding 论文中所定义的 REST，而不是泛指面向资源的思想）的确依赖着 HTTP 协议的标准方法、状态码和协议头等各个方面。</p>
<p> 我们也知道，HTTP 是应用层协议，而不是传输层协议，如果我们只是把 HTTP 用作传输是不恰当的（SOAP：再次感觉有被冒犯到）。因此，对于需要直接控制传输（如二进制细节 / 编码形式 / 报文格式 / 连接方式等）细节的场景，REST 确实不合适。这些场景往往存在于服务集群的内部节点之间，这也是我在上一讲提到的，虽然 REST 和 RPC 的应用场景的确有所重合，但重合的范围有多大就是见仁见智的事情了。</p>
</li>
<li><p><strong>第三个有争议的问题是：REST 不利于事务支持。</strong></p>
<p> 其实，这个问题首先要看我们怎么去理解”事务（Transaction）”这个概念了。</p>
<ul>
<li>如果”事务”指的是数据库那种狭义的刚性 ACID 事务，那分布式系统本身跟它之间就是有矛盾的（CAP 不可兼得）。这是分布式的问题，而不是 REST 的问题。</li>
<li>如果”事务”是指通过服务协议或架构，在分布式服务中，获得对多个数据同时提交的统一协调能力（2PC/3PC），比如 <a target="_blank" rel="noopener" href="http://docs.oasis-open.org/ws-tx/wstx-wsat-1.1-spec-errata-os/wstx-wsat-1.1-spec-errata-os.html">WS-AtomicTransaction</a> 和 <a target="_blank" rel="noopener" href="http://docs.oasis-open.org/ws-tx/wstx-wscoor-1.1-spec-errata-os/wstx-wscoor-1.1-spec-errata-os.html">WS-Coordination</a> 这样的功能性协议，那 REST 确实不支持。假如你已经理解了这样做的代价，仍决定要这样做的话，Web Service 是比较好的选择。</li>
<li>如果”事务”是指希望保证数据的最终一致性，说明你已经放弃刚性事务了。这才是分布式系统中的主流，使用 REST 肯定不会有什么阻碍，更谈不上”不利于”事务支持（当然，对于最终一致性的问题，REST 本身并没有提供什么帮助，而是完全取决于你系统的事务设计。我们在讲解事务处理的课程章节中，会再详细讨论）。</li>
</ul>
</li>
<li><p><strong>第四个有争议的问题是：REST 没有传输可靠性支持。</strong></p>
<p> 是的，REST 并没有提供对传输可靠性的支持。在 HTTP 中，你发送出去一个请求，通常会收到一个与之相对的响应，比如 HTTP/1.1 200 OK 或者 HTTP/1.1 404 Not Found 等。但是，如果你没有收到任何响应，那就无法确定消息到底是没有发送出去，还是没有从服务端返回回来。这其中的关键差别，是服务端到底是否被触发了某些处理？</p>
<p> 应对传输可靠性最简单粗暴的做法，就是把消息再重发一遍。这种简单处理能够成立的前提，是服务具有 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%86%AA%E7%AD%89">幂等性（Idempotency）</a> ，也就是说服务被重复执行多次的效果与执行一次是相等的。</p>
<p> HTTP 协议要求 GET、PUT 和 DELETE 操作应该具有幂等性，我们把 REST 服务映射到这些方法时，也应该保证幂等性。</p>
<p> 对于 POST 方法，曾经有过一些专门的提案（比如 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/draft-nottingham-http-poe-00">POE</a> 、POST Once Exactly），但并未得到 IETF 的通过。对于 POST 的重复提交，浏览器会出现相应警告，比如 Chrome 中会有”确认重新提交表单”的提示。而服务端就应该做预校验，如果发现可能重复，就返回 HTTP/1.1 425 Too Early。</p>
<p> 另外，Web Service 中有 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/WS-ReliableMessaging">WS-ReliableMessaging</a> 功能协议，用来支持消息可靠投递。类似的，REST 因为没有采用额外的 Wire Protocol，所以除了缺少对事务、可靠传输的支持外，一定还可以在 WS-* 协议中找到很多 REST 不支持的特性。</p>
</li>
<li><p><strong>第五个有争议的问题是：REST 缺乏对资源进行”部分”和”批量”的处理能力。</strong></p>
<p> 这个观点我是认同的，而且我认为这很可能是未来面向资源的思想和 API 设计风格的发展方向。</p>
<p> REST 开创了面向资源的服务风格，却肯定不完美。以 HTTP 协议为基础，虽然给 REST 带来了极大的便捷（不需要额外协议，不需要重复解决一堆基础网络问题，等等），但也成了束缚 REST 的无形牢笼。</p>
</li>
</ol>
<p>关于 HTTP 协议对 REST 的束缚，我会通过具体的例子和你解释。</p>
<ol>
<li><p><strong>第一种束缚，就是缺少对资源的”部分”操作的支持。</strong> 有些时候，我们只是想获得某个用户的姓名，RPC 风格中可以设计一个”getUsernameById”的服务，返回一个字符串。尽管这种服务的通用性实在称不上”设计”二字，但确实可以工作。而要是采用 REST 风格的话，你需要向服务端请求整个用户对象，然后丢弃掉返回结果中的其他属性，这就是一种请求冗余（Overfetching）。</p>
<p> REST 的应对手段是，通过位于中间节点或客户端缓存来缓解。但这治标不治本，因为这个问题的根源在于，HTTP 协议对请求资源完全没有结构化的描述能力（但有的是非结构化的部分内容获取能力，也就是今天多用于端点续传的 <a target="_blank" rel="noopener" href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Range_requests">Range Header</a>），所以返回资源的哪些内容、以什么数据类型返回等等，都不可能得到协议层面的支持。如果要实现这种能力，你就只能自己在 GET 方法的 Endpoint 上设计各种参数。</p>
</li>
<li><p><strong>而与此相对的缺陷，也是 HTTP 协议对 REST 的第二种束缚，是对资源的”批量”操作的支持。</strong> 有时候，我们不得不为此而专门设计一些抽象的资源才能应对。</p>
<p> 比如，我们要把某个用户的昵称增加一个”VIP”前缀，那提交一个 PUT 请求修改这个用户的昵称就可以了。但如果我们要给 1000 个用户的昵称加”VIP”前缀时，就不得不先创建一个（比如名为”VIP-Modify-Task”）任务资源，把 1000 个用户的 ID 交给这个任务，最后驱动任务进入执行状态（如果真去调用 1000 次 PUT，等浏览器回应我们 HTTP/1.1 429 Too Many Requests 的时候，老板就要发飙了）。</p>
<p> 又比如，我们在网店买东西的时候，下单、冻结库存、支付、加积分、扣减库存这一系列步骤会涉及多个资源的变化，这时候我们就得创建一种”事务”的抽象资源，或者用某种具体的资源（比如”结算单”），贯穿网购这个过程的始终，每次操作其他资源时都带着事务或者结算单的 ID。对于 HTTP 协议来说，由于它的无状态性，相对来说不适用于（并非不能够）处理这类业务场景。</p>
<p> 要解决批量操作这类问题，目前一种从理论上看还比较优秀的解决方案是 <a target="_blank" rel="noopener" href="https://graphql.cn/">GraphQL</a>（但实际使用人数并不多）。GraphQL 是由 Facebook 提出并开源的一种面向资源 API 的数据查询语言。它和 SQL 一样，挂了个”查询语言”的名字，但其实 CRUD 都能做。</p>
<p> 相对于依赖 HTTP 无协议的 REST 来说，GraphQL 是另一种”有协议”地、更彻底地面向资源的服务方式。但是凡事都有两面，离开了 HTTP，GraphQL 又面临着几乎所有 RPC 框架都会遇到的如何推广交互接口的问题。</p>
</li>
</ol>
<h4 id="小结-8"><a href="#小结-8" class="headerlink" title="小结"></a>小结</h4><p>介绍 REST 服务的两节课里面，我们学习了 REST 的思想内涵，讲解了 RESTful 系统的 6 个核心特征，以及如何衡量 RESTful 程度的 RMM 成熟度，同时也讨论了 REST 的争议与不足。</p>
<p>在软件行业发展的初期，程序编写都是以算法为核心的，程序员会把数据和过程分别作为独立的部分来考虑，数据代表问题空间中的客体，程序代码则用于处理这些数据。 <strong>这种直接站在计算机的角度去抽象问题和解决问题的思维方式，就是面向过程的编程思想。</strong></p>
<p>与此类似， <strong>后来出现的面向对象的编程思想，则是站在现实世界的角度去抽象和解决问题。</strong> 它把数据和行为都看作是对象的一部分，以方便程序员用符合现实世界的思维方式，来编写和组织程序。</p>
<p>我们今天再去看这两种编程思想，虽然它们出现的时间有先后，但在人类使用计算机语言来处理数据的工作中，无论用哪种思维来抽象问题都是合乎逻辑的。</p>
<p>经过了 20 世纪 90 年代末到 21 世纪初期面向对象编程的火热，如今，站在网络角度考虑如何对内封装逻辑、对外重用服务的新思想，也就是面向资源的编程思想，又成为了新的受追捧的对象。</p>
<p><strong>面向资源编程这种思想，是把问题空间中的数据对象作为抽象的主体，把解决问题时从输入数据到输出结果的处理过程，看作是一个（组）数据资源的状态不断发生变换而导致的结果。</strong> 这符合目前网络主流的交互方式，也因此 REST 常常被看作是为基于网络的分布式系统量身定做的交互方式。</p>
<h3 id="11-本地事务如何实现原子性和持久性？"><a href="#11-本地事务如何实现原子性和持久性？" class="headerlink" title="11 | 本地事务如何实现原子性和持久性？"></a>11 | 本地事务如何实现原子性和持久性？</h3><p>事务处理几乎是每一个信息系统中都会涉及到的问题，它存在的意义就是保证系统中的数据是正确的，不同数据间不会产生矛盾，也就是保证数据状态的一致性（Consistency）。</p>
<p>关于一致性，我这里先做个说明。”一致性”在数据科学中有严肃定义，并且有多种细分类型的概念。这里我们重点关注的是数据库状态的一致性，它跟课程后面第三个模块”分布式的基石”当中，即将要讨论的分布式共识算法时所说的一致性，是不一样的，具体的差别我们会在第三个模块中探讨。</p>
<p>说回数据库状态的一致性，理论上，要达成这个目标需要三方面的共同努力：</p>
<ul>
<li>原子性（Atomic）：在同一项业务处理过程中，事务保证了多个对数据的修改，要么同时成功，要么一起被撤销。</li>
<li>隔离性（Isolation）：在不同的业务处理过程中，事务保证了各自业务正在读、写的数据互相独立，不会彼此影响。</li>
<li>持久性（Durability）：事务应当保证所有被成功提交的数据修改都能够正确地被持久化，不丢失数据。</li>
</ul>
<p>以上就是事务的”ACID”的概念提法。我自己对这种已经形成习惯的”ACID”的提法是不太认同的，因为这四种特性并不正交，A、I、D 是手段，C 是目的，完全是为了拼凑个单词缩写才弄到一块去，误导的弊端已经超过了易于传播的好处。所以明确了这一点，也就明确了我们今天的讨论，就是要聚焦在事务处理的 A、I、D 上。</p>
<p>那接下来，我们先来看看事务处理的场景。</p>
<h4 id="事务场景"><a href="#事务场景" class="headerlink" title="事务场景"></a>事务场景</h4><p>事务的概念最初是源于数据库，但今天的信息系统中，所有需要保证数据正确性（一致性）的场景下，包括但不限于数据库、缓存、 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BA%8B%E5%8A%A1%E5%86%85%E5%AD%98">事务内存</a> 、消息、队列、对象文件存储等等，都有可能会涉及到事务处理。</p>
<p>当一个服务只操作一个数据源的时候，通过 A、I、D 来获得一致性是相对容易的，但当一个服务涉及到多个不同的数据源，甚至多个不同服务同时涉及到多个不同的数据源时，这件事情就变得很困难，有时需要付出很大、甚至是不切实际的代价，因此业界探索过许多其他方案，在确保可操作的前提下获得尽可能高的一致性保障。 <strong>由此，事务处理才从一个具体操作上的”编程问题”上升成一个需要仔细权衡的”架构问题”。</strong></p>
<p>人们在探索这些事务方案的过程中，产生了许多新的思路和概念，有一些概念看上去并不那么直观，因此，在接下来的这几节课中，我会带着你，一起探索 <strong>同一个事例在不同的事务方案中的不同处理</strong> ，以此来贯穿、理顺这些概念。</p>
<h4 id="场景事例"><a href="#场景事例" class="headerlink" title="场景事例"></a>场景事例</h4><p>我先来给你介绍下具体的事例。</p>
<p>Fenix’s Bookstore 是一个在线书店。一份商品成功售出，需要确保以下三件事情被正确地处理：</p>
<ol>
<li>用户的账号扣减相应的商品款项；</li>
<li>商品仓库中扣减库存，将商品标识为待配送状态；</li>
<li>商家的账号增加相应的商品款项。</li>
</ol>
<p>接下来，我将逐一介绍在”单个服务使用单个数据源””单个服务使用多个数据源””多个服务使用单个数据源”以及”多个服务使用多个数据源”的不同场景下，我们可以采用哪些手段来保证以上场景实例的正确性。</p>
<p>今天这一讲，我们先来看”单个服务使用单个数据源”，也就是本地事务场景。</p>
<h4 id="本地事务"><a href="#本地事务" class="headerlink" title="本地事务"></a>本地事务</h4><p>本地事务（Local Transactions）其实应该翻译成”局部事务”，才好与 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/321346">第 13 讲</a> 中要讲解的”全局事务”对应起来。不过，现在”本地事务”的译法似乎已经成为主流，我们就不去纠结名称了。</p>
<p><strong>本地事务是指仅操作特定单一事务资源的、不需要”全局事务管理器”进行协调的事务。</strong> 如果这个定义你现在不能理解的话，不妨暂且先放下，等学完”全局事务”这个小章节后再回过头来想想。</p>
<p>本地事务是最基础的一种事务处理方案，通常只适用于单个服务使用单个数据源的场景，它是直接依赖于数据源（通常是数据库系统）本身的事务能力来工作的。在程序代码层面，我们最多只能对事务接口做一层标准化的包装（如 JDBC 接口），并不能深入参与到事务的运作过程当中。</p>
<p>事务的开启、终止、提交、回滚、嵌套、设置隔离级别、乃至与应用代码贴近的传播方式，全部都要依赖底层数据库的支持，这一点与后面的 14、15 两讲中要介绍的 XA、TCC、SAGA 等主要靠应用程序代码来实现的事务，有着十分明显的区别（到时你可以跟今天所讲的内容相互对照下）。</p>
<p>我举个具体的例子，假设你的代码调用了 JDBC 中的 Transaction::rollback() 方法，方法的成功执行并不代表事务就已经被成功回滚，如果数据表采用引擎的是 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/MyISAM">MyISAM</a> ，那 rollback() 方法便是一项没有意义的空操作。因此， <strong>我们要想深入地讨论本地事务，便不得不越过应用代码的层次，去了解一些数据库本身的事务实现原理，弄明白传统数据库管理系统是如何实现 ACID 的。</strong></p>
<h4 id="ARIES-理论"><a href="#ARIES-理论" class="headerlink" title="ARIES 理论"></a>ARIES 理论</h4><p>如今研究事务的实现原理，必定会追溯到 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Algorithms_for_Recovery_and_Isolation_Exploiting_Semantics">ARIES理论（Algorithms for Recovery and Isolation Exploiting Semantics，基于语义的恢复与隔离算法）</a> 。起这拗口的名字应该多少也有些拼凑”ARIES”这个单词的目的（跟 ACID 一样的恶趣味）。</p>
<p>虽然，我们不能说所有的数据库都实现了 ARIES 理论，但现代的主流关系型数据库（Oracle、Microsoft SQLServer、MySQL-InnoDB、IBM DB2、PostgreSQL，等等）在事务实现上都深受该理论的影响。</p>
<p>上世纪 90 年代， <a target="_blank" rel="noopener" href="http://www.research.ibm.com/labs/almaden/">IBM Almaden 研究院</a> 总结了研发原型数据库系统”IBM System R”的经验，发表了 ARIES 理论中最主要的三篇论文，这里先给你介绍两篇。《 <a target="_blank" rel="noopener" href="https://cs.stanford.edu/people/chrismre/cs345/rl/aries.pdf">ARIES: A Transaction Recovery Method Supporting Fine-Granularity Locking and Partial Rollbacks Using Write-Ahead Logging</a> 》着重解决了事务的 ACID 三个属性中，原子性（A）和持久性（D）在算法层面上应当如何实现；而另一篇《 <a target="_blank" rel="noopener" href="http://vldb.org/conf/1990/P392.PDF">ARIES/KVL: A Key-Value Locking Method for Concurrency Control of Multiaction Transactions Operating on B-Tree Indexes</a> 》则是现代数据库隔离性（I）奠基式的文章。</p>
<p>我们先从原子性和持久性说起。至于隔离性，在下一节课中我们再接着展开介绍。</p>
<h4 id="实现原子性和持久性"><a href="#实现原子性和持久性" class="headerlink" title="实现原子性和持久性"></a>实现原子性和持久性</h4><p>原子性和持久性在事务里是密切相关的两个属性，原子性保证了事务的多个操作要么都生效要么都不生效，不会存在中间状态；持久性保证了一旦事务生效，就不会再因为任何原因而导致其修改的内容被撤销或丢失。</p>
<p>显而易见，数据必须要成功写入磁盘、磁带等持久化存储器后才能拥有持久性，只存储在内存中的数据，一旦遇到程序忽然崩溃、数据库崩溃、操作系统崩溃，机器突然断电宕机（后面我们都统称为崩溃，Crash）等情况就会丢失。 <strong>实现原子性和持久性所面临的困难是，”写入磁盘”这个操作不会是原子的</strong> ，不仅有”写入”与”未写入”，还客观地存在着”正在写”的中间状态。</p>
<p>按照上面我们列出的示例场景，从 Fenix’s Bookstore 购买一本书需要修改三个数据：在用户账户中减去货款、在商家账户中增加货款、在商品仓库中标记一本书为配送状态，由于写入存在中间状态，可能发生以下情形：</p>
<ul>
<li><strong>未提交事务</strong> ：程序还没修改完三个数据，数据库已经将其中一个或两个数据的变动写入了磁盘，此时出现崩溃，一旦重启之后，数据库必须要有办法得知崩溃前发生过一次不完整的购物操作，将已经修改过的数据从磁盘中恢复成没有改过的样子，以保证原子性。</li>
<li><strong>已提交事务</strong> ：程序已经修改完三个数据，数据库还未将全部三个数据的变动都写入到磁盘，此时出现崩溃，一旦重启之后，数据库必须要有办法得知崩溃前发生过一次完整的购物操作，将还没来得及写入磁盘的那部分数据重新写入，以保证持久性。</li>
</ul>
<p>这种数据恢复操作被称为 <strong>崩溃恢复</strong> （Crash Recovery，也有称作 Failure Recovery 或 Transaction Recovery）。为了能够顺利地完成崩溃恢复，在磁盘中写数据就不能像程序修改内存中变量值那样，直接改变某表某行某列的某个值，必须将修改数据这个操作所需的全部信息（比如修改什么数据、数据物理上位于哪个内存页和磁盘块中、从什么值改成什么值等等），以日志的形式（日志特指仅进行顺序追加的文件写入方式，这是最高效的写入方式）先记录到磁盘中。</p>
<p>只有在日志记录全部都安全落盘，见到代表事务成功提交的”Commit Record”后，数据库才会根据日志上的信息对真正的数据进行修改，修改完成后，在日志中加入一条”End Record”表示事务已完成持久化，这种事务实现方法被称为”Commit Logging”。</p>
<blockquote>
<p><strong>额外知识：Shadow Paging</strong></p>
<p>通过日志实现事务的原子性和持久性是当今的主流方案，但并非唯一的选择。除日志外，还有另外一种称为” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Shadow_paging">Shadow Paging</a> “（有中文资料翻译为”影子分页”）的事务实现机制，常用的轻量级数据库 SQLite Version 3 采用的就是 Shadow Paging。</p>
<p>Shadow Paging 的大体思路是对数据的变动会写到硬盘的数据中，但并不是直接就地修改原先的数据，而是先将数据复制一份副本，保留原数据，修改副本数据。在事务过程中，被修改的数据会同时存在两份，一份修改前的数据，一份是修改后的数据，这也是”影子”（Shadow）这个名字的由来。</p>
<p>当事务成功提交，所有数据的修改都成功持久化之后，最后一步要修改数据的引用指针，将引用从原数据改为新复制出来修改后的副本，最后的”修改指针”这个操作将被认为是原子操作，所以 Shadow Paging 也可以保证原子性和持久性。</p>
<p>Shadow Paging 相对简单，但涉及到隔离性与锁时，Shadow Paging 实现的事务并发能力相对有限，因此在高性能的数据库中应用不多。</p>
</blockquote>
<p>Commit Logging 保障数据持久性、原子性的原理并不难想明白。</p>
<p>首先，日志一旦成功写入 Commit Record，那整个事务就是成功的，即使修改数据时崩溃了，重启后根据已经写入磁盘的日志信息恢复现场、继续修改数据即可，这保证了持久性。</p>
<p>其次，如果日志没有写入成功就发生崩溃，系统重启后会看到一部分没有 Commit Record 的日志，那将这部分日志标记为回滚状态即可，整个事务就像完全没有发生过一样，这保证了原子性。</p>
<p>Commit Logging 实现事务简单清晰，也有一些数据库就是采用 Commit Logging 机制来实现事务的（较具代表性的是阿里的 OceanBase）。但是， <strong>Commit Logging 存在一个巨大的缺陷</strong> ：所有对数据的真实修改都必须发生在事务提交、日志写入了 Commit Record 之后，即使事务提交前磁盘 I/O 有足够空闲、即使某个事务修改的数据量非常庞大，占用大量的内存缓冲，无论何种理由，都决不允许在事务提交之前就开始修改磁盘上的数据，这一点对提升数据库的性能是很不利的。</p>
<p>为了解决这个缺陷，前面提到的 ARIES 理论终于可以登场了。 <strong>ARIES 提出了”Write-Ahead Logging”的日志改进方案，其名字里所谓的”提前写入”（Write-Ahead），就是允许在事务提交之前，提前写入变动数据的意思。</strong></p>
<p>Write-Ahead Logging 先将何时写入变动数据，按照事务提交时点为界，分为了 FORCE 和 STEAL 两类：</p>
<ul>
<li><strong>FORCE</strong> ：当事务提交后，要求变动数据必须同时完成写入则称为 FORCE，如果不强制变动数据必须同时完成写入则称为 NO-FORCE。现实中绝大多数数据库采用的都是 NO-FORCE 策略，只要有了日志，变动数据随时可以持久化，从优化磁盘 I/O 性能考虑，没有必要强制数据写入立即进行。</li>
<li><strong>STEAL</strong> ：在事务提交前，允许变动数据提前写入则称为 STEAL，不允许则称为 NO-STEAL。从优化磁盘 I/O 性能考虑，允许数据提前写入，有利于利用空闲 I/O 资源，也有利于节省数据库缓存区的内存。</li>
</ul>
<p>Commit  Logging 允许 NO-FORCE，但不允许 STEAL。因为假如事务提交前就有部分变动数据写入磁盘，那一旦事务要回滚，或者发生了崩溃，这些提前写入的变动数据就都成了错误。</p>
<p>Write-Ahead  Logging 允许 NO-FORCE，也允许 STEAL，它给出的解决办法是增加了另一种称为 Undo Log 的日志。当变动数据写入磁盘前，必须先记录 Undo Log，写明修改哪个位置的数据、从什么值改成什么值，以便在事务回滚或者崩溃恢复时，根据 Undo Log 对提前写入的数据变动进行擦除。</p>
<p>Undo Log 现在一般被翻译为”回滚日志”，此前记录的用于崩溃恢复时重演数据变动的日志，就相应被命名为 Redo Log，一般翻译为”重做日志”。</p>
<p>由于 Undo Log 的加入，Write-Ahead Logging 在崩溃恢复时，会以此经历以下三个阶段：</p>
<ul>
<li><strong>分析阶段（Analysis）</strong> ：该阶段从最后一次检查点（Checkpoint，可理解为在这个点之前所有应该持久化的变动都已安全落盘）开始扫描日志，找出所有没有 End Record 的事务，组成待恢复的事务集合（一般包括 Transaction Table 和 Dirty Page Table）。</li>
<li><strong>重做阶段（Redo）</strong> ：该阶段依据分析阶段中，产生的待恢复的事务集合来重演历史（Repeat History），找出所有包含 Commit Record 的日志，将它们写入磁盘，写入完成后增加一条 End Record，然后移除出待恢复事务集合。</li>
<li><strong>回滚阶段（Undo）</strong> ：该阶段处理经过分析、重做阶段后剩余的恢复事务集合，此时剩下的都是需要回滚的事务（被称为 Loser），根据 Undo  Log 中的信息回滚这些事务。</li>
</ul>
<p>重做阶段和回滚阶段的操作都应该设计为幂等的。而为了追求高性能，以上三个阶段都无可避免地会涉及到非常繁琐的概念和细节（如 Redo  Log、Undo  Log 的具体数据结构等），这里我们就不展开讲了，如果想要继续学习，前面讲到的那两篇论文就是学习的最佳途径。</p>
<p>Write-Ahead Logging 是 ARIES 理论的一部分，整套 ARIES 拥有严谨、高性能等很多的优点，但这些也是以复杂性为代价的。</p>
<p>数据库按照”是否允许 FORCE 和 STEAL”可以产生四种组合，从优化磁盘 I/O 的角度看，NO-FORCE 加 STEAL 组合的性能无疑是最高的；从算法实现与日志的角度看，NO-FORCE 加 STEAL 组合的复杂度无疑是最高的。</p>
<p>这四种组合与 Undo Log、Redo Log 之间的具体关系如下图所示：</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/FORCE和STEAL的四种组合关系.webp" alt="FORCE和STEAL的四种组合关系"></p>
<h4 id="小结-9"><a href="#小结-9" class="headerlink" title="小结"></a>小结</h4><p>今天这节课，我们学习了经典 ARIES 理论下实现本地事务中原子性与持久性的方法。通过写入日志来保证原子性和持久性是业界的主流做法，这个做法最困难的一点，就是如何处理日志”写入中”的中间状态，才能既保证严谨，也能够高效。</p>
<p>ARIES 理论提出了 Write-Ahead Logging 式的日志写入方法，通过分析、重做、回滚三个阶段实现了 STEAL、NO-FORCE，从而实现了既高效又严谨的日志记录与故障恢复。</p>
<h3 id="12-本地事务如何实现隔离性？"><a href="#12-本地事务如何实现隔离性？" class="headerlink" title="12 | 本地事务如何实现隔离性？"></a>12 | 本地事务如何实现隔离性？</h3><p>隔离性保证了每个事务各自读、写的数据互相独立，不会彼此影响。只从定义上，我们就能感觉到隔离性肯定与并发密切相关。如果没有并发，所有事务全都是串行的，那就不需要任何隔离，或者说这样的访问具备了天然的隔离性。</p>
<p>但在现实情况中不可能没有并发，要在并发下实现串行的数据访问，该怎样做？几乎所有程序员都会回答到：加锁同步呀！现代数据库都提供了以下三种锁：</p>
<ul>
<li><strong>写锁</strong> （Write Lock，也叫做排他锁 eXclusive Lock，简写为 X-Lock）：只有持有写锁的事务才能对数据进行写入操作，数据加持着写锁时，其他事务不能写入数据，也不能施加读锁。</li>
<li><strong>读锁</strong> （Read Lock，也叫做共享锁 Shared Lock，简写为 S-Lock）：多个事务可以对同一个数据添加多个读锁，数据被加上读锁后就不能再被加上写锁，所以其他事务不能对该数据进行写入，但仍然可以读取。对于持有读锁的事务，如果该数据只有一个事务加了读锁，那可以直接将其升级为写锁，然后写入数据。</li>
<li><p><strong>范围锁</strong> （Range Lock）：对于某个范围直接加排他锁，在这个范围内的数据不能被读取，也不能被写入。如下语句是典型的加范围锁的例子：</p>
  <pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> books <span class="token keyword">WHERE</span> price <span class="token operator">&lt;</span> <span class="token number">100</span> <span class="token keyword">FOR</span> <span class="token keyword">UPDATE</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>  请注意”范围不能写入”与”一批数据不能写入”的差别，也就是我们不要把范围锁理解成一组排他锁的集合。加了范围锁后，不仅无法修改该范围内已有的数据，也不能在该范围内新增或删除任何数据，这是一组排他锁的集合无法做到的。</p>
</li>
</ul>
<h4 id="本地事务的四种隔离级别"><a href="#本地事务的四种隔离级别" class="headerlink" title="本地事务的四种隔离级别"></a>本地事务的四种隔离级别</h4><ol>
<li><p><strong>可串行化</strong></p>
<p> <strong>串行化访问提供了强度最高的隔离性</strong>，ANSI/ISO SQL-92 中定义的最高等级的隔离级别便是可串行化（Serializable）。</p>
<p> 可串行化比较符合普通程序员对数据竞争加锁的理解，如果不考虑性能优化的话，对事务所有读、写的数据全都加上读锁、写锁和范围锁即可（这种可串行化的实现方案称为 Two-Phase Lock）。</p>
<p> 但数据库不考虑性能肯定是不行的，并发控制理论（Concurrency Control）决定了隔离程度与并发能力是相互抵触的，隔离程度越高，并发访问时的吞吐量就越低。现代数据库一定会提供除可串行化以外的其他隔离级别供用户使用，让用户调节隔离级别的选项，这样做的根本目的是让用户可以调节数据库的加锁方式，取得隔离性与吞吐量之间的平衡。</p>
</li>
<li><p><strong>可重复读</strong></p>
<p> 可串行化的下一个隔离级别是可重复读（Repeatable Read）。可重复读的意思就是对事务所涉及到的数据加读锁和写锁，并且一直持续到事务结束，但不再加范围锁。</p>
<p> 可重复读比可串行化弱化的地方在于 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Isolation_(database_systems">幻读问题（Phantom Reads）</a>#Phantom_reads) ，它是指在事务执行的过程中，两个完全相同的范围查询得到了不同的结果集。比如我现在准备统计一下 Fenix’s Bookstore 中售价小于 100 元的书有多少本，就可以执行以下第一条 SQL 语句：</p>
 <pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">FROM</span> books <span class="token keyword">WHERE</span> price <span class="token operator">&lt;</span> <span class="token number">100</span>          <span class="token comment">/* 时间顺序：1，事务： T1 */</span>
<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> books<span class="token punctuation">(</span>name<span class="token punctuation">,</span>price<span class="token punctuation">)</span> <span class="token keyword">VALUES</span> <span class="token punctuation">(</span><span class="token string">'深入理解Java虚拟机'</span><span class="token punctuation">,</span><span class="token number">90</span><span class="token punctuation">)</span>  <span class="token comment">/* 时间顺序：2，事务： T2 */</span>
<span class="token keyword">SELECT</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">FROM</span> books <span class="token keyword">WHERE</span> price <span class="token operator">&lt;</span> <span class="token number">100</span>          <span class="token comment">/* 时间顺序：3，事务： T1 */</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 那么，根据前面对范围锁、读锁和写锁的定义，我们可以知道，假如这条 SQL 语句在同一个事务中重复执行了两次，并且这两次执行之间，恰好有另外一个事务在数据库中插入了一本小于 100 元的书籍（这是当前隔离级别允许的操作），那这两次相同的查询就会得到不一样的结果。原因就是，可重复读没有范围锁来禁止在该范围内插入新的数据。</p>
<p> 这就是一个事务遭到其他事务影响，隔离性被破坏的表现。</p>
<p> <strong>这里我要提醒你注意一个地方，我这里的介绍实际上是以 ARIES 理论作为讨论目标的，而具体的数据库并不一定要完全遵照着这个理论去实现。</strong></p>
<p> 我给你举个例子。MySQL/InnoDB 的默认隔离级别是可重复读，但它在只读事务中就可以完全避免幻读问题。</p>
<p> 比如在前面这个例子中，事务 T1 只有查询语句，它是一个只读事务，所以这个例子里出现的幻读问题在 MySQL 中并不会出现。但在读写事务中，MySQL 仍然会出现幻读问题，比如例子中的事务 T1，如果在其他事务插入新书后，不是重新查询一次数量，而是要把所有小于 100 元的书全部改名，那就依然会受到新插入书籍的影响。</p>
</li>
<li><p><strong>读已提交</strong></p>
<p> 可重复读的下一个隔离级别是读已提交（Read Committed）。读已提交对事务涉及到的数据加的写锁，会一直持续到事务结束，但加的读锁在查询操作完成后就马上会释放。</p>
<p> 读已提交比可重复读弱化的地方在于 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Isolation_(database_systems">不可重复读问题（Non-Repeatable Reads）</a>#Non-repeatable_reads) ，它是指在事务执行过程中，对同一行数据的两次查询得到了不同的结果。</p>
<p> 比如说，现在我要获取 Fenix’s Bookstore 中《深入理解 Java 虚拟机》这本书的售价，同样让程序执行了两条 SQL 语句。而在这两条语句执行之间，恰好有另外一个事务修改了这本书的价格，从 90 元调整到了 110 元，如下所示：</p>
 <pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> books <span class="token keyword">WHERE</span> id <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>               <span class="token comment">/* 时间顺序：1，事务： T1 */</span>
<span class="token keyword">UPDATE</span> books <span class="token keyword">SET</span> price <span class="token operator">=</span> <span class="token number">110</span> <span class="token keyword">WHERE</span> ID <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token keyword">COMMIT</span><span class="token punctuation">;</span>      <span class="token comment">/* 时间顺序：2，事务： T2 */</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> books <span class="token keyword">WHERE</span> id <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token keyword">COMMIT</span><span class="token punctuation">;</span>           <span class="token comment">/* 时间顺序：3，事务： T1 */</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 所以到这里，你其实也会发现，如果隔离级别是读已提交，那么这两次重复执行的查询结果也会不一样。原因是读已提交的隔离级别缺乏贯穿整个事务周期的读锁，无法禁止读取过的数据发生变化。而此时，事务 T2 中的更新语句可以马上提供成功，这也是一个事务遭到其他事务影响，隔离性被破坏的表现。</p>
<p> 不过，假如隔离级别是可重复读的话，由于数据已被事务 T1 施加了读锁，并且读取后不会马上释放，所以事务 T2 无法获取到写锁，更新就会被阻塞，直至事务 T1 被提交或回滚后才能提交。</p>
</li>
<li><p><strong>读未提交</strong></p>
<p> 读已提交的下一个级别是读未提交（Read Uncommitted）。读未提交对事务涉及到的数据只加写锁，这会一直持续到事务结束，但完全不加读锁。</p>
<p> 读未提交比读已提交弱化的地方在于 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Isolation_(database_systems">脏读问题（Dirty Reads）</a>#Dirty_reads) ，它是指在事务执行的过程中，一个事务读取到了另一个事务未提交的数据。</p>
<p> 比如说，我觉得《深入理解 Java 虚拟机》从 90 元涨价到 110 元是损害消费者利益的行为，又执行了一条更新语句，把价格改回了 90 元。而在我提交事务之前，同事过来告诉我，这并不是随便涨价的，而是印刷成本上升导致的，按 90 元卖要亏本，于是我随即回滚了事务。那么在这个场景下，程序执行的 SQL 语句是这样的：</p>
 <pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> books <span class="token keyword">WHERE</span> id <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>               <span class="token comment">/* 时间顺序：1，事务： T1 */</span>
<span class="token comment">/* 注意没有COMMIT */</span>
<span class="token keyword">UPDATE</span> books <span class="token keyword">SET</span> price <span class="token operator">=</span> <span class="token number">90</span> <span class="token keyword">WHERE</span> ID <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>          <span class="token comment">/* 时间顺序：2，事务： T2 */</span>
<span class="token comment">/* 这条SELECT模拟购书的操作的逻辑 */</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> books <span class="token keyword">WHERE</span> id <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>                <span class="token comment">/* 时间顺序：3，事务： T1 */</span>
<span class="token keyword">ROLLBACK</span><span class="token punctuation">;</span>                            <span class="token comment">/* 时间顺序：4，事务： T2 */</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 不过，在我修改完价格之后，事务 T1 已经按 90 元的价格卖出了几本。出现这个问题的原因就在于，读未提交在数据上完全不加读锁，这反而令它能读到其他事务加了写锁的数据，也就是我前面所说的，事务 T1 中两条查询语句得到的结果并不相同。</p>
<p> 这里，你可能会有点疑问，”为什么完全不加读锁，反而令它能读到其他事务加了写锁的数据”，这句话中的”反而”代表的是什么意思呢？不理解也没关系，我们再来重新读一遍写锁的定义：写锁禁止其他事务施加读锁，而不是禁止事务读取数据。</p>
<p> 所以说，如果事务 T1 读取数据时，根本就不用去加读锁的话，就会导致事务 T2 未提交的数据也能马上就被事务 T1 所读到。这同样是一个事务遭到其他事务影响，隔离性被破坏的表现。</p>
<p> 那么，这里我们假设隔离级别是读已提交的话，由于事务 T2 持有数据的写锁，所以事务 T1 的第二次查询就无法获得读锁。而读已提交级别是要求先加读锁后读数据的，所以 T1 中的查询就会被阻塞，直到事务 T2 被提交或者回滚后才能得到结果。</p>
</li>
</ol>
<p><strong>理论上还有更低的隔离级别，就是”完全不隔离”，即读、写锁都不加。</strong> 读未提交会有脏读问题，但不会有脏写问题（Dirty Write，即一个事务没提交之前的修改可以被另外一个事务的修改覆盖掉），脏写已经不单纯是隔离性上的问题了，它会导致事务的原子性都无法实现，所以一般隔离级别不会包括它，会把读未提交看作是最低级的隔离级别。</p>
<p>这四种隔离级别属于数据库的基础知识，多数大学的计算机课程应该都会讲到，但不少教材、资料都把它们当作数据库的某种固有设定来进行讲解，导致很多人只能对这些现象死记硬背。 <strong>其实，不同隔离级别以及幻读、脏读等问题都只是表面现象，它们是各种锁在不同加锁时间上组合应用所产生的结果，锁才是根本的原因。</strong></p>
<p>除了锁之外，以上对四种隔离级别的介绍还有一个共同特点，就是一个事务在读数据过程中，受另外一个写数据的事务影响而破坏了隔离性。针对这种”一个事务读 + 另一个事务写”的隔离问题，有一种名为” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">多版本并发控制</a> “（Multi-Version Concurrency Control，MVCC）的无锁优化方案被主流的商业数据库广泛采用。</p>
<p>接下来我们就一起讨论下 MVCC。</p>
<h4 id="MVCC-的基础原理"><a href="#MVCC-的基础原理" class="headerlink" title="MVCC 的基础原理"></a>MVCC 的基础原理</h4><p><strong>MVCC 是一种读取优化策略，它的”无锁”是特指读取时不需要加锁。</strong> MVCC 的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以完全不加锁的目的。</p>
<p>这句话里的”版本”是个关键词，你不妨将其理解为数据库中每一行记录都存在两个看不见的字段：CREATE_VERSION 和 DELETE_VERSION，这两个字段记录的值都是事务 ID（事务 ID 是一个全局严格递增的数值），然后：</p>
<ul>
<li>数据被插入时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。</li>
<li>数据被删除时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。</li>
<li>数据被修改时：将修改视为”删除旧数据，插入新数据”，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。</li>
</ul>
<p>此时，当有另外一个事务要读取这些发生了变化的数据时，会根据隔离级别来决定到底应该读取哪个版本的数据：</p>
<ul>
<li><strong>隔离级别是可重复读</strong> ：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。</li>
<li><strong>隔离级别是读已提交</strong> ：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。</li>
</ul>
<p>另外，两个隔离级别都没有必要用到 MVCC，读未提交直接修改原始数据即可，其他事务查看数据的时候立刻可以查看到，根本无需版本字段。可串行化本来的语义就是要阻塞其他事务的读取操作，而 MVCC 是做读取时无锁优化的，自然就不会放到一起用。</p>
<p><strong>MVCC 是只针对”读 + 写”场景的优化，如果是两个事务同时修改数据，即”写 + 写”的情况，那就没有多少优化的空间了，加锁几乎是唯一可行的解决方案。</strong></p>
<p>稍微有点讨论余地的是” <strong>乐观加锁</strong> “（Optimistic Locking）或” <strong>悲观加锁</strong> “（Pessimistic Locking），对此我们还可以根据实际情况去商量一下。</p>
<p>前面我介绍的加锁都属于悲观加锁策略，也就是数据库认为如果不先做加锁再访问数据，就肯定会出现问题。与之相对的，乐观加锁策略认为，事务之间数据存在竞争是偶然情况，没有竞争才是普遍情况，这样就不应该一开始就加锁，而是应当出现竞争时再找补救措施。这种思路被称为” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Optimistic_concurrency_control">乐观并发控制</a> “（Optimistic Concurrency Control，OCC），这一点我就不再展开了。不过提醒一句， <strong>不要迷信什么乐观锁要比悲观锁更快的说法，这纯粹看竞争的剧烈程度，如果竞争剧烈的话，乐观锁反而会更慢。</strong></p>
<h4 id="评论"><a href="#评论" class="headerlink" title="评论"></a>评论</h4><ol>
<li><p>RED UNCOMMITTED（未提交读）</p>
<p> 在RED UNCOMMITTED级别，事务中的修改，即使没提交，对其他事务也是可见的。事务可以读取未提交的数据，这被称为”脏读”（Dirty Read），因为读取的很可能是中间过程的脏数据，而不是最终数据。</p>
</li>
<li><p>RED COMMITTED（提交读）</p>
<p> 大多数数据库系统默认的隔离级别都是RED COMMITTED，但是MYSQL不是。RED COMMITTED说的是，一个事务只能读到其他事务已经提交的数据，所以叫提交读。这个事务级别也叫做不可重复读（nonrepeatableread），因为两次同样的查询，可能会得到不同的结果。</p>
</li>
<li><p>REPEATABLE READ（可重复读）</p>
<p> REPEATABLE READ解决了脏读的问题。该级别保证了在同一事务中多次读取同样的记录结果是一致的。但是无法解决幻读的问题，所谓幻读，指的是当某个事务再读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围内的记录时，发现多了一行，会产生幻行。</p>
</li>
<li><p>SERIALIZABLE（可串行化）</p>
<p> SERIALIZABLE是最高级别的隔离。它通过强制事务串行执行，避免了前面说的幻读的问题。简单来说，SERIALIZABLE会在读取的每一行数据上都加锁，所以可能导致大量的超时和锁争用的问题。</p>
</li>
<li><p>MVCC是一种读取优化策略，它在读取时不需要加锁的情况下，实现了提交读和可重复读的隔离级别。</p>
<p> 可重复读：总是读在事务启动前就已经提交完成的数据。<br> 提交读：总是读已经提交完成的数据。</p>
</li>
</ol>
<h3 id="13-全局事务和共享事务是如何实现的？"><a href="#13-全局事务和共享事务是如何实现的？" class="headerlink" title="13 | 全局事务和共享事务是如何实现的？"></a>13 | 全局事务和共享事务是如何实现的？</h3><p>今天，我们一起来学习全局事务（Global Transactions）和共享事务（Share Transactions）的原理与实现。</p>
<p>其实，相对于我们前两节课学习的本地事务，全局事务和共享事务的使用频率已经很低了。但这两种事务类型，是分布式事务（下一讲要学习）的中间形式，起到的是承上启下的作用。</p>
<p>所以，我们还是有必要去理解它们的实现方式，这样才能更透彻地理解事务处理这个话题。</p>
<p>接下来，我们就从全局事务学起吧。</p>
<h4 id="全局事务"><a href="#全局事务" class="headerlink" title="全局事务"></a>全局事务</h4><p>与本地事务相对的是全局事务，一些资料中也会称之为外部事务（External Transactions）。在今天这一讲，我会给全局事务做个限定：一种适用于单个服务使用多个数据源场景的事务解决方案。</p>
<p>需要注意的是，理论上，真正的全局事务是没有”单个服务”这个约束的，它本来就是 DTP（ <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Distributed_transaction">Distributed Transaction Processing</a> ）模型中的概念。那我为什么要在这一讲给它做个限定呢？</p>
<p>这是因为，我们今天要学习的内容，也就是一种在分布式环境中仍追求强一致性的事务处理方案，在多节点互相调用彼此服务的场景（比如现在的微服务）中是非常不合适的。从目前的情况来看，这种方案几乎只实际应用在了单服务多数据源的场景中。</p>
<p>为了避免与我们下一讲要学习的放弃了 ACID 的弱一致性事务处理方式混淆，所以我在这一讲缩减了全局事务所指的范围；对于涉及多服务多数据源的事务，我将其称为”分布式事务”。</p>
<h4 id="XA-协议"><a href="#XA-协议" class="headerlink" title="XA 协议"></a>XA 协议</h4><p>为了解决分布式事务的一致性问题，1991 年的时候 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/X/Open">X/Open</a> 组织（后来并入了 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/The_Open_Group">The Open Group</a> ）提出了一套叫做 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/X/Open_XA">X/Open XA</a>（XA 是 eXtended Architecture 的缩写）的事务处理框架。这个框架的核心内容是，定义了全局的事务管理器（Transaction Manager，用于协调全局事务）和局部的资源管理器（Resource Manager，用于驱动本地事务）之间的通讯接口。</p>
<p>XA 接口是双向的，是一个事务管理器和多个资源管理器之间通信的桥梁，通过协调多个数据源的动作保持一致，来实现全局事务的统一提交或者统一回滚。现在，我们在 Java 代码中还偶尔能看见的 XADataSource、XAResource 等名字，其实都是源于 XA 接口。</p>
<p>这里你要注意的是，XA 并不是 Java 规范（因为当时还没有 Java），而是一套通用的技术规范。Java 后来专门定义了一套全局事务处理标准，也就是我们熟知的 JTA（ <a target="_blank" rel="noopener" href="https://www.jcp.org/en/jsr/detail?id=907">JSR 907 Java Transaction API</a> ）接口。它有两个最主要的接口：</p>
<ul>
<li>事务管理器的接口：javax.transaction.TransactionManager，这套接口是给 Java EE 服务器提供容器事务（由容器自动负责事务管理）使用的。另外它还提供了另外一套 javax.transaction.UserTransaction 接口，用于给程序员通过程序代码手动开启、提交和回滚事务。</li>
<li>满足 XA 规范的资源定义接口：javax.transaction.xa.XAResource。任何资源（JDBC、JMS 等）如果需要支持 JTA，只要实现 XAResource 接口中的方法就可以了。</li>
</ul>
<p>JTA 原本是 Java EE 中的技术，一般情况下应该由 JBoss、WebSphere、WebLogic 这些 Java EE 容器来提供支持，但现在 <a target="_blank" rel="noopener" href="https://web.archive.org/web/20100414140721/http://docs.codehaus.org/display/BTM/Home">Bittronix</a> 、 <a target="_blank" rel="noopener" href="http://www.atomikos.com/Main/TransactionsEssentials">Atomikos</a> 和 <a target="_blank" rel="noopener" href="http://www.jboss.org/jbosstm">JBossTM</a> （以前叫 Arjuna）都以 JAR 包的形式实现了 JTA 的接口，也就是 JOTM（Java Open Transaction Manager）。有了 JOTM 的支持，我们就可以在 Tomcat、Jetty 这样的 Java SE 环境下使用 JTA 了。</p>
<p>我们在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/319481">第 11 讲</a> 讲解本地事务的时候，设计了一个 Fenix’s Bookstore 在线书店场景。一份商品成功售出，需要确保以下三件事情被正确地处理：</p>
<ol>
<li>用户的账号扣减相应的商品款项；</li>
<li>商品仓库中扣减库存，将商品标识为待配送状态；</li>
<li>商家的账号增加相应的商品款项。</li>
</ol>
<p>现在，我们对这个示例场景做另外一种假设：如果书店的用户、商家、仓库分别处于不同的数据库中，其他条件不变，那会发生什么变化呢？</p>
<p>如果我们以声明式事务来编码的话，那与本地事务看起来可能没什么区别，都是标个 @Transactional 注解而已，但如果是以编程式事务来实现的话，在写法上就有差异了。我们具体看看：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java"><span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">buyBook</span><span class="token punctuation">(</span><span class="token class-name">PaymentBill</span> bill<span class="token punctuation">)</span> <span class="token punctuation">{</span>
  userTransaction<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    warehouseTransaction<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    businessTransaction<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">try</span> <span class="token punctuation">{</span>
      userAccountService<span class="token punctuation">.</span><span class="token function">pay</span><span class="token punctuation">(</span>bill<span class="token punctuation">.</span><span class="token function">getMoney</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      warehouseService<span class="token punctuation">.</span><span class="token function">deliver</span><span class="token punctuation">(</span>bill<span class="token punctuation">.</span><span class="token function">getItems</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      businessAccountService<span class="token punctuation">.</span><span class="token function">receipt</span><span class="token punctuation">(</span>bill<span class="token punctuation">.</span><span class="token function">getMoney</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        userTransaction<span class="token punctuation">.</span><span class="token function">commit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      warehouseTransaction<span class="token punctuation">.</span><span class="token function">commit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      businessTransaction<span class="token punctuation">.</span><span class="token function">commit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span> <span class="token keyword">catch</span><span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        userTransaction<span class="token punctuation">.</span><span class="token function">rollback</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      warehouseTransaction<span class="token punctuation">.</span><span class="token function">rollback</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
      businessTransaction<span class="token punctuation">.</span><span class="token function">rollback</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="两段式提交"><a href="#两段式提交" class="headerlink" title="两段式提交"></a>两段式提交</h4><p>代码上能看出程序的目的是要做三次事务提交，但实际代码并不能这样写。为什么呢？</p>
<p>我们可以试想一下：如果程序运行到 businessTransaction.commit() 中出现错误，会跳转到 catch 块中继续执行，这时候 userTransaction 和 warehouseTransaction 已经提交了，再去调用 rollback() 方法已经无济于事。因为这会导致一部分数据被提交，另一部分被回滚，无法保证整个事务的一致性。</p>
<p>为了解决这个问题，XA 将事务提交拆分成了两阶段过程，也就是准备阶段和提交阶段。</p>
<ol>
<li><p><strong>准备阶段</strong> ，又叫做投票阶段。在这一阶段，协调者询问事务的所有参与者是否准备好提交，如果已经准备好提交回复 Prepared，否则回复 Non-Prepared。</p>
<p> 这里的”准备”操作，其实和我们通常理解的”准备”不太一样：对于数据库来说，准备操作是在重做日志中记录全部事务提交操作所要做的内容，它与本地事务中真正提交的区别只是暂不写入最后一条 Commit Record。这意味着在做完数据持久化后并不会立即释放隔离性，也就是仍继续持有锁，维持数据对其他非事务内观察者的隔离状态。</p>
</li>
<li><p><strong>提交阶段</strong> ，又叫做执行阶段，协调者如果在准备阶段收到所有事务参与者回复的 Prepared 消息，就会首先在本地持久化事务状态为 Commit，然后向所有参与者发送 Commit 指令，所有参与者立即执行提交操作；否则，任意一个参与者回复了 Non-Prepared 消息，或任意一个参与者超时未回复，协调者都会将自己的事务状态持久化为”Abort”之后，向所有参与者发送 Abort 指令，参与者立即执行回滚操作。</p>
<p> 对于数据库来说，提交阶段的提交操作是相对轻量的，仅仅是持久化一条 Commit Record 而已，通常能够快速完成。回滚阶段则相对耗时，收到 Abort 指令时，需要根据回滚日志清理已提交的数据，这可能是相对重负载操作。</p>
</li>
</ol>
<p>“准备”和”提交”这两个过程，被称为” <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BA%8C%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4">两段式提交</a> “（2 Phase Commit，2PC）协议。那么，使用了两阶段提交协议，就一定可以成功保证一致性吗？也不是的，它还需要 <strong>两个前提条件</strong> 。</p>
<ol>
<li><p>第一，必须假设网络在提交阶段这个短时间内是可靠的，即提交阶段不会丢失消息。同时也假设网络通讯在全过程都不会出现误差，即可以丢失后消息，但不会传递错误的消息，XA 的设计目标并不是解决诸如 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Byzantine_fault">拜占庭将军</a> 一类的问题。</p>
<p> 两段式提交中投票阶段失败了可以补救（回滚），而提交阶段失败了无法补救（不再改变提交或回滚的结果，只能等崩溃的节点重新恢复），因而提交阶段的耗时应尽可能短，这也是为了尽量控制网络风险的考虑。</p>
</li>
<li><p>第二，必须假设因为网络分区、机器崩溃或者其他原因而导致失联的节点最终能够恢复，不会永久性地处于失联状态。由于在准备阶段已经写入了完整的重做日志，所以当失联机器一旦恢复，就能够从日志中找出已准备妥当但并未提交的事务数据，再向协调者查询该事务的状态，确定下一步应该进行提交还是回滚操作。</p>
</li>
</ol>
<p>到这里，我还要给你澄清一个概念。我们前面提到的协调者和参与者，通常都是由数据库自己来扮演的，不需要应用程序介入，应用程序相对于数据库来说只扮演客户端的角色。</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/两段式提交.webp" alt="两段式提交"></p>
<p>两段式提交的原理很简单，也不难实现，但有三个非常明显的缺点。</p>
<ol>
<li><p><strong>单点问题</strong> ：协调者在两段提交中具有举足轻重的作用，协调者等待参与者回复时可以有超时机制，允许参与者宕机，但参与者等待协调者指令时无法做超时处理。一旦协调者宕机，所有参与者都会受到影响。如果协调者一直没有恢复，没有正常发送 Commit 或者 Rollback 的指令，那所有参与者都必须一直等待。</p>
</li>
<li><p><strong>性能问题</strong> ：两段提交过程中，所有参与者相当于被绑定成为一个统一调度的整体，期间要经过两次远程服务调用、三次数据持久化（准备阶段写重做日志，协调者做状态持久化，提交阶段在日志写入 Commit Record），整个过程将持续到参与者集群中最慢的那一个处理操作结束为止。这就决定了两段式提交的性能通常都比较差。</p>
</li>
<li><p><strong>一致性风险</strong> ：当网络稳定性和宕机恢复能力的假设不成立时，两段式提交可能会出现一致性问题。</p>
</li>
</ol>
<p>宕机恢复能力这一点无需多说。1985 年 Fischer、Lynch、Paterson 用定理（被称为 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Consensus_(computer_science">FLP 不可能原理</a>#Solvability_results_for_some_agreement_problems) ，在分布式中与 CAP 定理齐名）证明了 <strong>如果宕机最后不能恢复，那就不存在任何一种分布式协议可以正确地达成一致性结果。</strong></p>
<p>我们重点看看网络稳定性带来的一致性风险。尽管提交阶段时间很短，但仍是明确存在的危险期。如果协调者在发出准备指令后，根据各个参与者发回的信息确定事务状态是可以提交的，协调者就会先持久化事务状态，并提交自己的事务。如果这时候网络忽然断开了，无法再通过网络向所有参与者发出 Commit 指令的话，就会导致部分数据（协调者的）已提交，但部分数据（参与者的）既未提交也没办法回滚，导致数据不一致。</p>
<h4 id="三段式提交"><a href="#三段式提交" class="headerlink" title="三段式提交"></a>三段式提交</h4><p>为了解决两段式提交的单点问题、性能问题和数据一致性问题，” <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%B8%89%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4">三段式提交</a> “（3 Phase Commit，3PC）协议出现了。但是三段式提交，也并没有解决一致性问题。</p>
<p>这是为什么呢？别着急，接下来我就具体和你分析下其中的缘由，以及了解三段式提交是否真正解决了单点问题和性能问题。</p>
<p>三段式提交把原本的两段式提交的准备阶段再细分为两个阶段，分别称为 CanCommit、PreCommit，把提交阶段改为 DoCommit 阶段。其中，新增的 CanCommit 是一个询问阶段，协调者让每个参与的数据库根据自身状态，评估该事务是否有可能顺利完成。</p>
<p>将准备阶段一分为二的理由是，这个阶段是重负载的操作，一旦协调者发出开始准备的消息，每个参与者都将马上开始写重做日志，这时候涉及的数据资源都会被锁住。如果此时某一个参与者无法完成提交，相当于所有的参与者都做了一轮无用功。</p>
<p>所以，增加一轮询问阶段，如果都得到了正面的响应，那事务能够成功提交的把握就比较大了，也意味着因某个参与者提交时发生崩溃而导致全部回滚的风险相对变小了。</p>
<p>因此， <strong>在事务需要回滚的场景中，三段式的性能通常要比两段式好很多，但在事务能够正常提交的场景中，两段式和三段式提交的性能都很差，三段式因为多了一次询问，性能还要更差一些。</strong></p>
<p>同样地，也是因为询问阶段使得事务失败回滚的概率变小了，所以在三段式提交中，如果协调者在 PreCommit 阶段开始之后发生了宕机，参与者没有能等到 DoCommit 的消息的话，默认的操作策略将是提交事务而不是回滚事务或者持续等待。你看，这就相当于避免了协调者的单点问题。</p>
<p>三段式提交的操作时序如下图所示。</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/三段式提交.webp" alt="三段式提交"></p>
<p>可以看出， <strong>三段式提交对单点问题和回滚时的性能问题有所改善，但是对一致性风险问题并未有任何改进</strong> ，甚至是增加了面临的一致性风险。为什么这么说呢？</p>
<p>我们看一个例子。比如，进入 PreCommit 阶段之后，协调者发出的指令不是 Ack 而是 Abort，而此时因为网络问题，有部分参与者直至超时都没能收到协调者的 Abort 指令的话，这些参与者将会错误地提交事务，这就产生了不同参与者之间数据不一致的问题。</p>
<h4 id="共享事务"><a href="#共享事务" class="headerlink" title="共享事务"></a>共享事务</h4><p>与全局事务的单个服务使用多个数据源正好相反，共享事务是指多个服务共用同一个数据源。</p>
<p>这里，我要再强调一次”数据源”与”数据库”的区别：数据源是指提供数据的逻辑设备，不必与物理设备一一对应。</p>
<p>在部署应用集群时最常采用的模式是，将同一套程序部署到多个中间件服务器上，构成多个副本实例来分担流量压力。它们虽然连接了同一个数据库，但每个节点配有自己的专属数据源，通常是中间件以 JNDI 的形式开放给程序代码使用。</p>
<p>这种情况下，所有副本实例的数据访问都是完全独立的，并没有任何交集，每个节点使用的仍是最简单的本地事务。但是有些场景下，多个服务之间是有业务交集的，它们可能会共用一个数据源，共享事务也有可能成为专门针对这种业务场景的一种解决方案。</p>
<p>举个例子。在 Fenix’s Bookstore 的场景事例中，假设用户账户、商家账户和商品仓库都存储在同一个数据库里面，但用户、商户和仓库每个领域部署了独立的微服务。此时，一次购书的业务操作将贯穿三个微服务，而且都要在数据库中修改数据。</p>
<p>如果我们直接将不同数据源视为不同的数据库，那我们完全可以用全局事务或者下一讲要学习的分布式事务来实现。不过，针对每个数据源连接的都是同一个物理数据库的特例，共享事务可能是另一条可以提高性能、降低复杂度的途径，当然这也很有可能是一个伪需求。</p>
<p><strong>一种理论可行的方案</strong> 是，直接让各个服务共享数据库连接。同一个应用进程中的不同持久化工具（JDBC、ORM、JMS 等）共享数据库连接并不困难，一些中间件服务器（比如 WebSphere），就内置了” <a target="_blank" rel="noopener" href="https://www.ibm.com/support/knowledgecenter/zh/SSAW57_8.5.5/com.ibm.websphere.nd.multiplatform.doc/ae/cdat_conshrnon.html">可共享连接</a> “功能来专门支持共享数据库的连接。</p>
<p>但这种”共享”的前提是，数据源的使用者都在同一个进程内。由于数据库连接的基础是网络连接，它是与 IP 地址和端口号绑定的，字面意义上的”不同服务节点共享数据库连接”很难做到。所以，为了实现共享事务，就必须新增一个中间角色，也就是交易服务器。无论是用户服务、商家服务还是仓库服务，它们都要通过同一台交易服务器来与数据库打交道。</p>
<p>如果将交易服务器的对外接口实现为满足 JDBC 规范，那它完全可以看作一个独立于各个服务的远程数据库连接池，或者直接作为数据库代理来看待。此时，三个服务所发出的交易请求就有可能做到，由交易服务器上的同一个数据库连接，通过本地事务的方式完成。</p>
<p>比如，交易服务器根据不同服务节点传来的同一个事务 ID，使用同一个数据库连接来处理跨越多个服务的交易事务。</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/交易服务器示意.webp" alt="交易服务器示意"></p>
<p><strong>之所以强调理论可行</strong> ，是因为这个方案，其实是与实际生产系统中的压力方向相悖的。一个服务集群里，数据库才是压力最大、最不容易伸缩拓展的重灾区。</p>
<p>所以，现实中只有类似 <a target="_blank" rel="noopener" href="https://www.proxysql.com/">ProxySQL</a> 和 <a target="_blank" rel="noopener" href="https://mariadb.com/kb/en/maxscale/">MaxScale</a> 这样用于对多个数据库实例做负载均衡的数据库代理，而几乎没有反过来代理一个数据库为多个应用提供事务协调的交易服务代理。</p>
<p>这也是为什么说它更有可能是个伪需求的原因。如果你有充足理由让多个微服务去共享数据库，那就必须找到更加站得住脚的理由，来向团队解释拆分微服务的目的是什么。</p>
<p>让多个微服务去共享一个数据库这个方案，其实还有另一种应用形式：使用消息队列服务器来代替交易服务器，用户、商家、仓库的服务操作业务时，通过消息将所有对数据库的改动传送到消息队列服务器，然后通过消息的消费者来统一处理，实现由本地事务保障的持久化操作。这就是” <a target="_blank" rel="noopener" href="https://www.infoworld.com/article/2077963/distributed-transactions-in-spring--with-and-without-xa.html">单个数据库的消息驱动更新</a> “（Message-Driven Update of a Single Database）。</p>
<p>“共享事务”这种叫法，以及我们刚刚讲到的通过交易服务器或者通过消息驱动来更新单个数据库这两种处理方式，在实际应用中并不常见，也几乎没有相应的成功案例，能够查到的资料几乎都来源于十多年前 Spring 的核心开发者 <a target="_blank" rel="noopener" href="https://spring.io/team/dsyer">Dave Syer</a> 的文章” <a target="_blank" rel="noopener" href="https://www.infoworld.com/article/2077963/distributed-transactions-in-spring--with-and-without-xa.html">Distributed Transactions in Spring, with and without XA</a> “。</p>
<p>正如我在这一讲的开头所说，我把共享事务和本地事务、全局事务、分布式事务并列成为四大事务类型，更多的考虑到事务演进过程的完备性，也是为了方便你理解这三种事务类型。同时，拆分微服务后仍然共享数据库的案例，我们经常会在实践中看到，但我个人仍旧不赞同将共享事务看作是一种常规的解决方案。</p>
<h4 id="小结-10"><a href="#小结-10" class="headerlink" title="小结"></a>小结</h4><p>这节课我们学习了全局事务和共享事务的实现方式。目前，共享事务确实已经很少见了，但是全局事务中的两段式提交和三段式提交模式仍然会在一些多数据源的场景中用到，Java 的 JTA 事务也仍然有一定规模的用户群体。</p>
<p>两段式提交和三段式提交仍然追求 ACID 的强一致性，这个目标不仅给它带来了很高的复杂度，而且吞吐量和使用效果上也不佳。因此，现在系统设计的主流，已经变成了不追求 ACID 而是强调 BASE 的弱一致性事务，这就是我们要在下一讲学习的分布式事务了。</p>
<h3 id="14-分布式事务之可靠消息队列"><a href="#14-分布式事务之可靠消息队列" class="headerlink" title="14 | 分布式事务之可靠消息队列"></a>14 | 分布式事务之可靠消息队列</h3><p>前面几节课，我们谈论了事务处理中的本地事务（单个服务、单个数据源）、全局事务（单个服务、多个数据源）和共享事务（多个服务、单个数据源），这一讲我们将聚焦于事务处理中最复杂的分布式事务（多个服务、多个数据源）。</p>
<p>在开始展开介绍之前，我想先给你强调一下，这里所说的分布式事务（Distributed Transactions），跟 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Distributed_transaction">DTP 模型</a> 中所指的”分布式事务”的含义是不一样的：DTP 模型所指的”分布式”是相对于数据源而言的，并不涉及服务，这部分内容我们在上节课已经讨论过了；而这里的”分布式”是相对于服务而言的，它特指的是多个服务同时访问多个数据源的事务处理机制，严谨地说，它更应该被称为”在分布式服务环境下的事务处理机制”。</p>
<p>其实在上一讲我们就提到过，为了解决分布式事务的一致性问题，1991 年 X/Open 组织提出了一套 XA 的事务处理架构。在 2000 年以前，人们还寄希望于这套事务处理架构能良好地应用在分布式环境中。不过很遗憾，这个美好的愿望今天已经被 CAP 理论彻底地击碎了。</p>
<p>那么，为什么会出现这种局面呢？就让我们从 CAP 与 ACID 的矛盾开始说起吧。</p>
<h4 id="CAP-与-ACID-之间的矛盾"><a href="#CAP-与-ACID-之间的矛盾" class="headerlink" title="CAP 与 ACID 之间的矛盾"></a>CAP 与 ACID 之间的矛盾</h4><p>CAP 理论又叫 Brewer 理论，这是加州大学伯克利分校的埃里克 · 布鲁尔（Eric Brewer）教授，在 2000 年 7 月”ACM 分布式计算原理研讨会（PODC）”上提出的一个猜想。</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/CAP理论原稿.webp" alt="CAP理论原稿"></p>
<p><a target="_blank" rel="noopener" href="https://people.eecs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf">CAP 理论原稿（那时候还只是猜想）</a></p>
<p>然后到了 2002 年，麻省理工学院的赛斯 · 吉尔伯特（Seth Gilbert）和南希 · 林奇（Nancy Lynch）就以严谨的数学推理证明了这个 CAP 猜想。在这之后，CAP 理论就正式成为了分布式计算领域公认的著名定理。</p>
<p>这个定理里，描述了一个分布式的系统中，当涉及到共享数据问题时，以下三个特性最多只能满足其中两个：</p>
<ol>
<li><strong>一致性（Consistency）</strong> ：代表在任何时刻、任何分布式节点中，我们所看到的数据都是没有矛盾的。这与 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/319481">第 11 讲</a> 所提到的 ACID 中的 C 是相同的单词，但它们又有不同的定义（分别指 Replication 的一致性和数据库状态的一致性）。在分布式事务中，ACID 的 C 要以满足 CAP 中的 C 为前提。</li>
<li><strong>可用性（Availability）</strong> ：代表系统不间断地提供服务的能力。</li>
<li><strong>分区容忍性（Partition Tolerance）</strong> ：代表分布式环境中，当部分节点因网络原因而彼此失联（即与其他节点形成”网络分区”）时，系统仍能正确地提供服务的能力。</li>
</ol>
<p>当然，单纯只看这个概念的话，CAP 是比较抽象的，我还是以第 11 讲开头所列的事例场景来说明一下，这三种特性对分布式系统来说都意味着什么。</p>
<blockquote>
<p>事例场景：Fenix’s Bookstore 是一个在线书店。一份商品成功售出，需要确保以下三件事情被正确地处理：</p>
<ol>
<li><p>用户的账号扣减相应的商品款项；</p>
</li>
<li><p>商品仓库中扣减库存，将商品标识为待配送状态；</p>
</li>
<li><p>商家的账号增加相应的商品款项。</p>
</li>
</ol>
</blockquote>
<p>假设，Fenix’s Bookstore 的服务拓扑如下图所示，一个来自最终用户的交易请求，将交由账号、商家和仓库服务集群中的某一个节点来完成响应：</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/FenixBookstore的服务拓扑.webp" alt="FenixBookstore的服务拓扑"></p>
<p>你可以看到，在这套系统中，每一个单独的服务节点都有着自己的数据库。</p>
<p>假设某次交易请求分别由”账号节点 1””商家节点 2””仓库节点 N”来进行响应，当用户购买一件价值 100 元的商品后，账号节点 1 首先应该给用户账号扣减 100 元货款。</p>
<p>账号节点 1 在自己的数据库扣减 100 元是很容易的，但它还要把这次交易变动告知账号节点 2 到 N，以及确保能正确变更商家和仓库集群其他账号节点中的关联数据。那么此时，我们可能会面临以下几种情况：</p>
<ol>
<li>如果该变动信息没有及时同步给其他账号节点，那么当用户购买其他商品时，会被分配给另一个节点处理，因为没有及时同步，此时系统会看到用户账户上有不正确的余额，从而错误地发生了原本无法进行的交易。 <strong>此为一致性问题。</strong></li>
<li>如果因为要把该变动信息同步给其他账号节点，就必须暂停对该用户的交易服务，直到数据同步一致后再重新恢复，那么当用户在下一次购买商品时，可能会因为系统暂时无法提供服务而被拒绝交易。 <strong>此为可用性问题。</strong></li>
<li>如果由于账号服务集群中某一部分节点，因出现网络问题，无法正常与另一部分节点交换账号变动信息，那么此时的服务集群中，无论哪一部分节点对外提供的服务，都可能是不正确的，我们需要考虑能否接受由于部分节点之间的连接中断，而影响整个集群的正确性的情况。 <strong>此为分区容忍性问题。</strong></li>
</ol>
<p>以上还只是涉及到了账号服务集群自身的 CAP 问题，而对于整个 Bookstore 站点来说，它更是面临着来自于账号、商家和仓库服务集群带来的 CAP 问题。</p>
<p>比如，用户账号扣款后，由于没有及时通知仓库服务，导致另一次交易中看到仓库中有不正确的库存数据而发生了超售。再比如，因为仓库中某个商品的交易正在进行当中，为了同步用户、商家和仓库此时的交易变动，而暂时锁定了该商品的交易服务，导致了可用性问题，等等。</p>
<p>不过既然 CAP 理论已经有了数学证明，也成为了业界公认的计算定理，我们就不去讨论为何 CAP 特性会存在不可兼得的问题了，直接来分析下在实际的应用场景中，我们要如何权衡取舍 CAP，然后看看这些不同取舍都会带来哪些问题。</p>
<ol>
<li><p><strong>如果放弃分区容错性（CA without P）</strong></p>
<p> 这意味着，我们将假设节点之间的通讯永远是可靠的。可是永远可靠的通讯在分布式系统中必定是不成立的，这不是你想不想的问题，而是网络分区现象始终会存在。</p>
<p> 在现实场景中，主流的 RDBMS（关系数据库管理系统）集群通常就是采用放弃分区容错性的工作模式。以 Oracle 的 RAC 集群为例，它的每一个节点都有自己的 SGA（系统全局区）、重做日志、回滚日志等，但各个节点是共享磁盘中的同一份数据文件和控制文件的，也就是说，RAC 集群是通过共享磁盘的方式来避免网络分区的出现。</p>
</li>
<li><p><strong>如果放弃可用性（CP without A）</strong></p>
<p> 这意味着，我们将假设一旦发生分区，节点之间的信息同步时间可以无限制地延长，那么这个问题就相当于退化到了上一讲所讨论的全局事务的场景之中，即一个系统可以使用多个数据源。我们可以通过 2PC/3PC 等手段，同时获得分区容错性和一致性。</p>
<p> 在现实中，除了 DTP 模型的分布式数据库事务外，著名的 HBase 也是属于 CP 系统。以它的集群为例，假如某个 RegionServer 宕机了，这个 RegionServer 持有的所有键值范围都将离线，直到数据恢复过程完成为止，这个时间通常会是很长的。</p>
</li>
<li><p><strong>如果放弃一致性（AP without C）</strong></p>
<p> 这意味着，我们将假设一旦发生分区，节点之间所提供的数据可能不一致。</p>
<p> AP 系统目前是分布式系统设计的主流选择，大多数的 NoSQL 库和支持分布式的缓存都是 AP 系统。因为 P 是分布式网络的天然属性，你不想要也无法丢弃；而 A 通常是建设分布式的目的，如果可用性随着节点数量增加反而降低的话，很多分布式系统可能就没有存在的价值了（除非银行这些涉及到金钱交易的服务，宁可中断也不能出错）。</p>
<p> 以 Redis 集群为例，如果某个 Redis 节点出现网络分区，那也不妨碍每个节点仍然会以自己本地的数据对外提供服务。但这时有可能出现这种情况，即请求分配到不同节点时，返回给客户端的是不同的数据。</p>
</li>
</ol>
<p>那么看到这里，你是否感受到了一丝无奈？这个小章节所讨论的话题”事务”，原本的目的就是要获得”一致性”。而在分布式环境中，”一致性”却不得不成为了通常被牺牲、被放弃的那一项属性。</p>
<p>但无论如何，我们建设信息系统，终究还是要保证操作结果（在最终被交付的时候）是正确的。为此，人们又重新给一致性下了定义，把前面我们在 CAP、ACID 中讨论的一致性称为” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Strong_consistency">强一致性</a> “（Strong Consistency），有时也称为” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Linearizability">线性一致性</a> “（Linearizability），而把牺牲了 C 的 AP 系统，又要尽可能获得正确的结果的行为，称为追求” <strong>弱一致性</strong> “。</p>
<p>不过，如果单纯只说”弱一致性”，那其实就是”不保证一致性”的意思……人类语言这东西真是博大精深。</p>
<p>所以，在弱一致性中，人们又总结出了一种特例，叫做” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Eventual_consistency">最终一致性</a> “（Eventual Consistency）。它是指，如果数据在一段时间内没有被另外的操作所更改，那它最终将会达到与强一致性过程相同的结果，有时候面向最终一致性的算法，也被称为”乐观复制算法”。</p>
<p>那么，在”分布式事务”中，我们的设计目标同样也不得不从获得强一致性，降低为获得”最终一致性”，在这个意义上，其实”事务”一词的含义也已经被拓宽了。</p>
<p>除了本地事务、全局事务和分布式事务以外，还有一种对于不同事务的叫法，那就是针对追求 ACID 的事务，我们称之为”刚性事务”。而在接下来和下一讲中，我将要介绍的几种分布式事务的常见做法，会统称为”柔性事务”。</p>
<p>这一讲我们先来讨论下，可靠消息队列这种分布式事务的实现方式。</p>
<h4 id="可靠事件队列"><a href="#可靠事件队列" class="headerlink" title="可靠事件队列"></a>可靠事件队列</h4><p>前面提到的最终一致性的概念，是由 eBay 的系统架构师丹 · 普利切特（Dan Pritchett）在 2008 年发表于 ACM 的论文” <a target="_blank" rel="noopener" href="https://queue.acm.org/detail.cfm?id=1394128">Base: An Acid Alternative</a> “中提出的。</p>
<p>这篇文章中，总结了一种独立于 ACID 获得的强一致性之外的途径，即通过 BASE 来达成一致性目的，最终一致性就是其中的”E”。</p>
<p>BASE 这个提法，比 ACID 凑缩写的痕迹更重，不过因为有 ACID vs BASE（酸 vs 碱）这个朗朗上口的梗，这篇文章传播得足够快。在这里我就不多谈 BASE 中的概念了，但这篇论文本身作为最终一致性的概念起源，并系统性地总结了一种在分布式事务的技术手段，还是非常有价值的。</p>
<p>下面，我们继续以 Fenix’s Bookstore 的事例场景，来解释下丹 · 普利切特提出的”可靠事件队列”的具体做法，下图为操作时序：</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/可靠事件队列时序图.webp" alt="可靠事件队列时序图"></p>
<p>我们按照顺序，一步步来解读一下。</p>
<ol>
<li><p>第一步，最终用户向 Fenix’s Bookstore 发送交易请求：购买一本价值 100 元的《深入理解 Java 虚拟机》。</p>
</li>
<li><p>第二步，Fenix’s Bookstore 应该对用户账户扣款、商家账户收款、库存商品出库这三个操作有一个出错概率的先验评估，根据出错概率的大小来安排它们的操作顺序（这个一般体现在程序代码中，有一些大型系统也可能动态排序）。比如，最有可能出错的地方，是用户购买了，但是系统不同意扣款，或者是账户余额不足；其次是商品库存不足；最后是商家收款，一般收款不会遇到什么意外。那么这个顺序就应该是最容易出错的最先进行，即：账户扣款 → 仓库出库 → 商家收款。</p>
</li>
<li><p>第三步，账户服务进行扣款业务，如果扣款成功，就在自己的数据库建立一张消息表，里面存入一条消息：”事务 ID：UUID；扣款：100 元（状态：已完成）；仓库出库《深入理解 Java 虚拟机》：1 本（状态：进行中）；某商家收款：100 元（状态：进行中）”。注意，这个步骤中”扣款业务”和”写入消息”是依靠同一个本地事务写入自身数据库的。</p>
</li>
<li><p>第四步，系统建立一个消息服务，定时轮询消息表，将状态是”进行中”的消息同时发送到库存和商家服务节点中去。</p>
</li>
</ol>
<p>这时候可能会产生以下几种情况：</p>
<ol>
<li><p>商家和仓库服务成功完成了收款和出库工作，向用户账户服务器返回执行结果，用户账户服务把消息状态从”进行中”更新为”已完成”。整个事务宣告顺利结束，达到最终一致性的状态。</p>
</li>
<li><p>商家或仓库服务有某些或全部因网络原因，未能收到来自用户账户服务的消息。此时，由于用户账户服务器中存储的消息状态，一直处于”进行中”，所以消息服务器将在每次轮询的时候，持续地向对应的服务重复发送消息。这个步骤的可重复性，就决定了所有被消息服务器发送的消息都必须具备幂等性。通常我们的设计是让消息带上一个唯一的事务 ID，以保证一个事务中的出库、收款动作只会被处理一次。</p>
</li>
<li><p>商家或仓库服务有某个或全部无法完成工作。比如仓库发现《深入理解 Java 虚拟机》没有库存了，此时，仍然是持续自动重发消息，直至操作成功（比如补充了库存），或者被人工介入为止。</p>
</li>
<li><p>商家和仓库服务成功完成了收款和出库工作，但回复的应答消息因网络原因丢失。此时，用户账户服务仍会重新发出下一条消息，但因消息幂等，所以不会导致重复出库和收款，只会导致商家、仓库服务器重新发送一条应答消息。此过程会一直重复，直至双方网络恢复。</p>
</li>
<li><p>也有一些支持分布式事务的消息框架，如 RocketMQ，原生就支持分布式事务操作，这时候前面提到的情况 2、4 也可以交给消息框架来保障。</p>
</li>
</ol>
<p>前面这种靠着持续重试来保证可靠性的操作，在计算机中就非常常见，它有个专门的名字，叫做” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Best-effort_delivery">最大努力交付</a> “（Best-Effort Delivery），比如 TCP 协议中的可靠性保障，就属于最大努力交付。</p>
<p>而”可靠事件队列”有一种更普通的形式，被称为”最大努力一次提交”（Best-Effort 1PC），意思就是系统会把最有可能出错的业务，以本地事务的方式完成后，通过不断重试的方式（不限于消息系统）来促使同个事务的其他关联业务完成。</p>
<p>小结</p>
<p>这节课，我第一次引入了 CAP 定理，希望你能通过事务处理的上下文场景去理解它。这套理论不仅是在事务处理中，而且在一致性、共识，乃至整个分布式所有涉及到数据的知识点中，都有重要的应用，后面讲到分布式共识算法、微服务中多种基础设施等内容的时候，我们还会多次涉及到它。</p>
<p>除了可靠事件队列之外，下一讲我还会给你介绍 TCC 和 SAGA 这两种主流的实现方式，它们都有各自的优缺点和应用场景。分布式系统中不存在放之四海皆准的万能事务解决方案，针对具体场景，选择合适的解决方案，达到一致性与可用性之间的最佳平衡，是我们作为一名设计者必须具备的技能。</p>
<h3 id="15-分布式事务之TCC与SAGA"><a href="#15-分布式事务之TCC与SAGA" class="headerlink" title="15 | 分布式事务之TCC与SAGA"></a>15 | 分布式事务之TCC与SAGA</h3><p>今天，我们接着上一节课的话题，继续讨论另外两种主流的分布式事务实现方式：TCC 和 SAGA。</p>
<h4 id="TCC-事务的实现过程"><a href="#TCC-事务的实现过程" class="headerlink" title="TCC 事务的实现过程"></a>TCC 事务的实现过程</h4><p>TCC（Try-Confirm-Cancel）是除可靠消息队列以外的另一种常见的分布式事务机制，它是由数据库专家帕特 · 赫兰德（Pat Helland）在 2007 年撰写的论文《 <a target="_blank" rel="noopener" href="https://www-db.cs.wisc.edu/cidr/cidr2007/papers/cidr07p15.pdf">Life beyond Distributed Transactions: An Apostate’s Opinion</a> 》中提出的。</p>
<p>在上一讲，我给你介绍了可靠消息队列的实现原理，虽然它也能保证最终的结果是相对可靠的，过程也足够简单（相对于 TCC 来说），但现在你已经知道，可靠消息队列的整个实现过程完全没有任何隔离性可言。</p>
<p>虽然在有些业务中，有没有隔离性不是很重要，比如说搜索系统。但在有些业务中，一旦缺乏了隔离性，就会带来许多麻烦。比如说前几讲，我一直引用的 Fenix’s Bookstore 在线书店的场景事例中，如果缺乏了隔离性，就会带来一个显而易见的问题：超售。</p>
<blockquote>
<p>事例场景：Fenix’s Bookstore 是一个在线书店。一份商品成功售出，需要确保以下三件事情被正确地处理：</p>
<ol>
<li><p>用户的账号扣减相应的商品款项；</p>
</li>
<li><p>商品仓库中扣减库存，将商品标识为待配送状态；</p>
</li>
<li><p>商家的账号增加相应的商品款项。</p>
</li>
</ol>
</blockquote>
<p>也就是说，在书店的业务场景下，很有可能会出现这样的情况：两个客户在短时间内都成功购买了同一件商品，而且他们各自购买的数量都不超过目前的库存，但他们购买的数量之和，却超过了库存。</p>
<p>如果这件事情是发生在刚性事务且隔离级别足够的情况下，其实是可以完全避免的。比如，我前面提到的”超售”场景，就需要”可重复读”（Repeatable Read）的隔离级别，以保证后面提交的事务会因为无法获得锁而导致失败。但用可靠消息队列就无法保证这一点了。我在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/319988">第 12 讲</a> 中已经给你介绍过数据库本地事务的相关知识，你可以再去回顾复习下。</p>
<p>所以，如果业务需要隔离，我们通常就应该重点考虑 <strong>TCC 方案，它天生适合用于需要强隔离性的分布式事务中。</strong></p>
<p>在具体实现上，TCC 的操作其实有点儿麻烦和复杂， <strong>它是一种业务侵入性较强的事务方案，要求业务处理过程必须拆分为”预留业务资源”和”确认 / 释放消费资源”两个子过程。</strong> 另外，你看名字也能看出来，TCC 的实现过程分为了三个阶段：</p>
<ul>
<li>Try：尝试执行阶段，完成所有业务可执行性的检查（保障一致性），并且预留好事务需要用到的所有业务资源（保障隔离性）。</li>
<li>Confirm：确认执行阶段，不进行任何业务检查，直接使用 Try 阶段准备的资源来完成业务处理。注意，Confirm 阶段可能会重复执行，因此需要满足幂等性。</li>
<li>Cancel：取消执行阶段，释放 Try 阶段预留的业务资源。注意，Cancel 阶段也可能会重复执行，因此也需要满足幂等性。</li>
</ul>
<p>那么，根据 Fenix’s Bookstore 在线书店的场景事例，TCC 的执行过程应该是这样的：</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/TCC事务操作时序.webp" alt="TCC事务操作时序"></p>
<ol>
<li><p>第一步，最终用户向 Fenix’s Bookstore 发送交易请求：购买一本价值 100 元的《深入理解 Java 虚拟机》。</p>
</li>
<li><p>第二步，创建事务，生成事务 ID，记录在活动日志中，进入 Try 阶段：</p>
<ul>
<li>用户服务：检查业务可行性，可行的话，把该用户的 100 元设置为”冻结”状态，通知下一步进入 Confirm 阶段；不可行的话，通知下一步进入 Cancel 阶段。</li>
<li>仓库服务：检查业务可行性，可行的话，将该仓库的 1 本《深入理解 Java 虚拟机》设置为”冻结”状态，通知下一步进入 Confirm 阶段；不可行的话，通知下一步进入 Cancel 阶段。</li>
<li>商家服务：检查业务可行性，不需要冻结资源。</li>
</ul>
</li>
<li><p>第三步，如果第二步中所有业务都反馈业务可行，就将活动日志中的状态记录为 Confirm，进入 Confirm 阶段：</p>
<ul>
<li>用户服务：完成业务操作（扣减被冻结的 100 元）。</li>
<li>仓库服务：完成业务操作（标记那 1 本冻结的书为出库状态，扣减相应库存）。<br>-商家服务：完成业务操作（收款 100 元）。</li>
</ul>
</li>
<li><p>第四步，如果第三步的操作全部完成了，事务就会宣告正常结束。而如果第三步中的任何一方出现了异常，不论是业务异常还是网络异常，都将会根据活动日志中的记录，来重复执行该服务的 Confirm 操作，即进行”最大努力交付”。</p>
</li>
<li><p>第五步，如果是在第二步，有任意一方反馈业务不可行，或是任意一方出现了超时，就将活动日志的状态记录为 Cancel，进入 Cancel 阶段：</p>
<ul>
<li>用户服务：取消业务操作（释放被冻结的 100 元）。</li>
<li>仓库服务：取消业务操作（释放被冻结的 1 本书）。</li>
<li>商家服务：取消业务操作（大哭一场后安慰商家谋生不易）。</li>
</ul>
</li>
<li><p>第六步，如果第五步全部完成了， <strong>事务就会宣告以失败回滚结束。</strong> 而如果第五步中的任何一方出现了异常，不论是业务异常还是网络异常，也都将会根据活动日志中的记录，来重复执行该服务的 Cancel 操作，即进行”最大努力交付”。</p>
<p>那么，你从上述的操作执行过程中可以发现，TCC 其实有点类似于 2PC 的准备阶段和提交阶段，但 TCC 是位于用户代码层面，而不是在基础设施层面，这就为它的实现带来了较高的灵活性，我们可以根据需要设计资源锁定的粒度。</p>
</li>
</ol>
<p>另外，TCC 在业务执行的时候，只操作预留资源，几乎不会涉及到锁和资源的争用，所以它 具有<strong>很高的性能潜力。</strong></p>
<p>但是，由于 TCC 的业务侵入性比较高，需要开发编码配合，在一定程度上增加了不少工作量，也就给我们带来了一些使用上的弊端，那就是我们需要投入更高的开发成本和更换事务实现方案的替换成本。</p>
<p><strong>所以，通常我们并不会完全靠裸编码来实现 TCC，而是会基于某些分布式事务中间件（如阿里开源的 <a target="_blank" rel="noopener" href="https://seata.io/zh-cn/">Seata</a> ）来完成，以尽量减轻一些编码工作量。</strong></p>
<p>好，现在你就已经知道了，TCC 事务具有较强的隔离性，能够有效避免”超售”的问题，而且它的性能可以说是包括可靠消息队列在内的几种柔性事务模式中最高的。但是，TCC 仍然不能满足所有的业务场景。</p>
<p>我在前面也提到了，TCC 最主要的限制是它的业务侵入性很强，但并不是指由此给开发编码带来的工作量，而是指它所要求的技术可控性上的约束。</p>
<p>比如说，我们把这个书店的场景事例修改一下：由于中国网络支付日益盛行，在书店系统中，现在用户和商家可以选择不再开设充值账号，至少不会强求一定要先从银行充值到系统中才能进行消费，而是允许在购物时，直接通过 U 盾或扫码支付，在银行账户中划转货款。</p>
<p>这个需求完全符合我们现在支付的习惯，但这也给系统的事务设计增加了额外的限制：如果用户、商家的账户余额由银行管理的话，其操作权限和数据结构就不可能再随心所欲地自行定义了，通常也就无法完成冻结款项、解冻、扣减这样的操作，因为银行一般不会配合你的操作。所以，在 TCC 的执行过程中，第一步 Try 阶段往往就已经无法施行了。</p>
<p>那么，我们就只能考虑采用另外一种柔性事务方案：SAGA 事务。</p>
<h4 id="SAGA-事务基于数据补偿代替回滚的解决思路"><a href="#SAGA-事务基于数据补偿代替回滚的解决思路" class="headerlink" title="SAGA 事务基于数据补偿代替回滚的解决思路"></a>SAGA 事务基于数据补偿代替回滚的解决思路</h4><p>SAGA 事务模式的历史十分悠久，比分布式事务的概念提出还要更早。SAGA 的意思是”长篇故事、长篇记叙、一长串事件”，它起源于 1987 年普林斯顿大学的赫克托 · 加西亚 · 莫利纳（Hector Garcia  Molina）和肯尼斯 · 麦克米伦（Kenneth Salem）在 ACM 发表的一篇论文《 <a target="_blank" rel="noopener" href="https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf">SAGAS</a> 》（这就是论文的全名）。</p>
<p>文中提出了一种如何提升”长时间事务”（Long Lived Transaction）运作效率的方法，大致思路是把一个大事务分解为可以交错运行的一系列子事务的集合。原本提出 SAGA 的目的，是为了避免大事务长时间锁定数据库的资源，后来才逐渐发展成将一个分布式环境中的大事务，分解为一系列本地事务的设计模式。</p>
<p>SAGA 由两部分操作组成。</p>
<p>一部分是把大事务拆分成若干个小事务，将整个分布式事务 T 分解为 n 个子事务，我们命名为 T1，T2，…，Ti，…，Tn。每个子事务都应该、或者能被看作是原子行为。如果分布式事务 T 能够正常提交，那么它对数据的影响（最终一致性）就应该与连续按顺序成功提交子事务 Ti 等价。</p>
<p>另一部分是为每一个子事务设计对应的补偿动作，我们命名为 C1，C2，…，Ci，…，Cn。Ti 与 Ci 必须满足以下条件：</p>
<ul>
<li>Ti 与 Ci 都具备幂等性；</li>
<li>Ti 与 Ci 满足交换律（Commutative），即不管是先执行 Ti 还是先执行 Ci，效果都是一样的；</li>
<li>Ci 必须能成功提交，即不考虑 Ci 本身提交失败被回滚的情况，如果出现就必须持续重试直至成功，或者要人工介入。</li>
</ul>
<p>如果 T1 到 Tn 均成功提交，那么事务就可以顺利完成。否则，我们就要采取以下两种恢复策略之一：</p>
<ul>
<li><strong>正向恢复（Forward Recovery）</strong> ：如果 Ti 事务提交失败，则一直对 Ti 进行重试，直至成功为止（最大努力交付）。这种恢复方式不需要补偿，适用于事务最终都要成功的场景，比如在别人的银行账号中扣了款，就一定要给别人发货。正向恢复的执行模式为：T1，T2，…，Ti（失败），Ti（重试）…，Ti+1，…，Tn。</li>
<li><strong>反向恢复（Backward Recovery）</strong> ：如果 Ti 事务提交失败，则一直执行 Ci 对 Ti 进行补偿，直至成功为止（最大努力交付）。这里要求 Ci 必须（在持续重试后）执行成功。反向恢复的执行模式为：T1，T2，…，Ti（失败），Ci（补偿），…，C2，C1。</li>
</ul>
<p>所以你能发现，与 TCC 相比，SAGA 不需要为资源设计冻结状态和撤销冻结的操作，补偿操作往往要比冻结操作容易实现得多。</p>
<p>我给你举个例子。我在前面提到的账户余额直接在银行维护的场景，从银行划转货款到 Fenix’s Bookstore 系统中，这步是经由用户支付操作（扫码或 U 盾）来促使银行提供服务；如果后续业务操作失败，尽管我们无法要求银行撤销掉之前的用户转账操作，但是作为补偿措施，我们让 Fenix’s Bookstore 系统将货款转回到用户账上，却是完全可行的。</p>
<p>SAGA 必须保证所有子事务都能够提交或者补偿，但 SAGA 系统本身也有可能会崩溃，所以它必须设计成与数据库类似的日志机制（被称为 SAGA Log），以保证系统恢复后可以追踪到子事务的执行情况，比如执行都到哪一步或者补偿到哪一步了。</p>
<p>另外你还要注意，尽管补偿操作通常比冻结 / 撤销更容易实现，但要保证正向、反向恢复过程能严谨地进行，也需要你花费不少的工夫。比如，你可能需要通过服务编排、可靠事件队列等方式来完成。所以， <strong>SAGA 事务通常也不会直接靠裸编码来实现，一般也是在事务中间件的基础上完成。我前面提到的 Seata 就同样支持 SAGA 事务模式。</strong></p>
<p>还有，SAGA 基于数据补偿来代替回滚的思路，也可以应用在其他事务方案上。举个例子，阿里的 GTS（Global Transaction Service，Seata 由 GTS 开源而来）所提出的” <a target="_blank" rel="noopener" href="https://seata.io/zh-cn/docs/overview/what-is-seata.html">AT 事务模式</a> “就是这样的一种应用。</p>
<h4 id="另一种应用模式：AT-事务"><a href="#另一种应用模式：AT-事务" class="headerlink" title="另一种应用模式：AT 事务"></a>另一种应用模式：AT 事务</h4><p>从整体上看，AT 事务是参照了 XA 两段提交协议来实现的，但针对 XA 2PC 的缺陷，即在准备阶段，必须等待所有数据源都返回成功后，协调者才能统一发出 Commit 命令而导致的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Liebig's_law_of_the_minimum">木桶效应</a> （所有涉及到的锁和资源，都需要等到最慢的事务完成后才能统一释放），AT 事务也设计了针对性的解决方案。</p>
<p>它大致的做法是在业务数据提交时，自动拦截所有 SQL，分别保存 SQL 对数据修改前后结果的快照，生成行锁，通过本地事务一起提交到操作的数据源中，这就相当于自动记录了重做和回滚日志。</p>
<p>如果分布式事务成功提交了，那么我们后续只需清理每个数据源中对应的日志数据即可；而如果分布式事务需要回滚，就要根据日志数据自动产生用于补偿的”逆向 SQL”。</p>
<p>所以，基于这种补偿方式，分布式事务中所涉及的每一个数据源都可以单独提交，然后立刻释放锁和资源。AT 事务这种异步提交的模式，相比 2PC 极大地提升了系统的吞吐量水平。 <strong>而使用的代价就是大幅度地牺牲了隔离性，甚至直接影响到了原子性。</strong> 因为在缺乏隔离性的前提下，以补偿代替回滚不一定总能成功。</p>
<p>比如，当在本地事务提交之后、分布式事务完成之前，该数据被补偿之前又被其他操作修改过，即出现了 <strong>脏写（Dirty Wirte）</strong> ，而这个时候一旦出现分布式事务需要回滚，就不可能再通过自动的逆向 SQL 来实现补偿，只能由人工介入处理了。</p>
<p>一般来说，对于脏写我们是一定要避免的，所有传统关系数据库在最低的隔离级别上，都仍然要加锁以避免脏写。因为脏写情况一旦发生，人工其实也很难进行有效处理。</p>
<p>所以，GTS 增加了一个” <strong>全局锁</strong> “（Global Lock）的机制来实现 <strong>写隔离</strong> ，要求本地事务提交之前，一定要先拿到针对修改记录的全局锁后才允许提交，而在没有获得全局锁之前就必须一直等待。</p>
<p>这种设计以牺牲一定性能为代价，避免了在两个分布式事务中，数据被同一个本地事务改写的情况，从而避免了脏写。</p>
<p>另外，在 <strong>读隔离</strong> 方面，AT 事务默认的隔离级别是 <strong>读未提交（Read Uncommitted）</strong> ，这意味着可能会产生 <strong>脏读（Dirty Read）</strong> 。读隔离也可以采用全局锁的方案来解决，但直接阻塞读取的话，我们要付出的代价就非常大了，一般并不会这样做。</p>
<p>所以到这里，你其实能发现，分布式事务中并没有能一揽子包治百病的解决办法，你只有因地制宜地选用合适的事务处理方案，才是唯一有效的做法。</p>
<h4 id="小结-11"><a href="#小结-11" class="headerlink" title="小结"></a>小结</h4><p>通过上一讲和今天这节课的学习，我们已经知道，CAP 定理决定了 C 与 A 不可兼得，传统的 ACID 强一致性在分布式环境中，要想能保证一致性（C），就不得不牺牲可用性（A）。那么这个时候，随着分布式系统中节点数量的增加，整个系统发生服务中断的概率和时间都会随之增长。</p>
<p>所以，我们只能退而求其次，把”最终一致性”作为分布式架构下事务处理的目标。在这两节课中，我给你介绍的可靠事件队列、TCC 和 SAGA，都是实现最终一致性的三种主流模式。</p>
<h3 id="16-域名解析系统，优化HTTP性能的第一步"><a href="#16-域名解析系统，优化HTTP性能的第一步" class="headerlink" title="16 | 域名解析系统，优化HTTP性能的第一步"></a>16 | 域名解析系统，优化HTTP性能的第一步</h3><p>从今天这节课开始，我们一起来学习下，如何引导流量分配到最合适的系统部件中进行响应。</p>
<p>那么在正式开始学习之前，我们先来了解下所谓的透明多级分流系统的定义。</p>
<h4 id="理解透明多级分流系统的设计原则"><a href="#理解透明多级分流系统的设计原则" class="headerlink" title="理解透明多级分流系统的设计原则"></a>理解透明多级分流系统的设计原则</h4><p>我们都知道，用户在使用信息系统的过程中，请求首先是从浏览器出发，在 DNS 的指引下找到系统的入口，然后经过了网关、负载均衡器、缓存、服务集群等一系列设施，最后接触到了系统末端存储于数据库服务器中的信息，然后再逐级返回到用户的浏览器之中。</p>
<p>这个过程需要经过许许多多的技术部件。那么作为系统的设计者，我们应该意识到不同的设施、部件在系统中，都具有各自不同的价值：</p>
<ul>
<li>有一些部件位于客户端或网络的边缘，能够迅速响应用户的请求，避免给后方的 I/O 与 CPU 带来压力，典型的如 <strong>本地缓存、内容分发网络、反向代理</strong> 等。</li>
<li>有一些部件的处理能力能够线性拓展，易于伸缩，可以通过使用较小的代价堆叠机器，来获得与用户数量相匹配的并发性能，并且应尽量作为业务逻辑的主要载体，典型的如 <strong>集群中能够自动扩缩的服务节点。</strong></li>
<li>有一些部件的稳定服务，对系统运行具有全局性的影响，要时刻保持着容错备份，维护着高可用性，典型的如 <strong>服务注册中心、配置中心。</strong></li>
<li>有一些设施是天生的单点部件，只能依靠升级机器本身的网络、存储和运算性能来提升处理能力，比如位于 <strong>系统入口的路由、网关或者负载均衡器</strong> （它们都可以做集群，但一次网络请求中无可避免至少有一个是单点的部件）、 <strong>位于请求调用链末端的传统关系数据库</strong> 等，都是典型的容易形成单点部件。</li>
</ul>
<p>所以，在对系统进行流量规划时，我们需要充分理解这些部件的价值差异。这里，我认为有两个简单、普适的原则，能指导我们进行设计。</p>
<p><strong>第一个原则是尽可能减少单点部件，如果某些单点是无可避免的，则应尽最大限度减少到达单点部件的流量。</strong></p>
<p>用户的请求在系统中往往会有多个部件都能够处理响应，比如要获取一张存储在数据库的用户头像图片，浏览器缓存、内容分发网络、反向代理、Web 服务器、文件服务器、数据库等，都可能会提供这张图片。</p>
<p>所以，恰如其分地引导请求分流至最合适的组件中，避免绝大多数流量汇集到单点部件（如数据库），同时依然能够、或者在绝大多数时候能够保证处理结果的准确性，在单点系统出现故障时，仍能自动而迅速地实施补救措施，这便是系统架构中多级分流的意义。</p>
<p>那么，缓存、节流、主备、负载均衡等措施，就都是为了达成该目标所采用的工具与手段，而高可用架构、高并发架构，则是通过该原则所获得的价值。</p>
<p>许多介绍架构设计的资料呢，都会以”高可用、高并发架构”为主题，主要聚焦于流量到达服务端后，如何构建强大的服务端集群来应对。</p>
<p>而在这个小章节中，我们是以”透明多级分流系统”为主题，聚焦于流量从客户端发出，到达服务端处理节点前的过程，并会去了解在这个过程中对流量削峰填谷的基础设施与通用组件。</p>
<p><strong>第二个原则是奥卡姆剃刀原则，它更为关键。</strong></p>
<blockquote>
<p><strong>奥卡姆剃刀原则</strong></p>
<p>Entities should not be multiplied without necessity.</p>
<p>如无必要，勿增实体。</p>
<p>—— <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Occam%27s_razor">Occam’s Razor</a> ，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/William_of_Ockham">William of Ockham</a></p>
</blockquote>
<p>作为一个架构设计者，你应该对前面提到的多级分流的手段，有一个全面的理解与充分的准备。同时你也要清晰地意识到，这些设施并不是越多越好，在实际构建系统的时候，你要在有明确需求、真正有必要的时候，再去考虑部署它们。</p>
<p>因为并不是每一个系统都要追求高并发、高可用的，从系统的用户量、峰值流量和团队本身的技术与运维能力出发，来考虑如何布置这些设施，才是最合理的做法。</p>
<p><strong>在能满足需求的前提下，最简单的系统就是最好的系统。</strong></p>
<p>所以，在这个章节的第一节课当中，我们就先来学习一个相对简单，但又是全世界最大规模的查询系统，即 DNS 域名解析查询系统，我们一起来看看它是如何实现多级分流的。</p>
<h4 id="DNS-的工作原理"><a href="#DNS-的工作原理" class="headerlink" title="DNS 的工作原理"></a>DNS 的工作原理</h4><p>我们都知道， <strong>DNS 的作用是把便于人类理解的域名地址，转换为便于计算机处理的 IP 地址。</strong></p>
<p>说到 DNS，我想到了一件事，你可能会觉得有点儿好笑：我在刚接触计算机网络有一小段时间以后，一直都把 DNS 想像成是一个部署在世界上某个神秘机房里的大型电话本式的翻译服务。直到后来，当我第一次了解到 DNS 的工作原理，也知道了世界根域名服务器的 ZONE 文件只有 2MB 大小，甚至可以打印出来物理备份的时候，我就对 DNS 系统的设计惊叹得不得了。</p>
<p>域名解析对于大多数信息系统，尤其是基于互联网的系统来说是必不可少的组件，可是现在想想，它在我们的开发工作里其实根本没有特别高的存在感，通常它都是不会受到重点关注的设施。这就导致了很多程序员还不太了解 DNS 本身的工作过程，以及它对系统流量能够施加的影响；而且，DNS 本身就堪称是示范性的透明多级分流系统，非常符合我们这个章节的主题，也很值得我们去借鉴。</p>
<p>无论是使用浏览器，还是在程序代码中访问某个网址域名，如果没有缓存的话，都会先经过 DNS 服务器的解析翻译，找到域名对应的 IP 地址，才能开始通讯。</p>
<p>后面我就以 www.icyfenix.com.cn 为例吧。这项操作是操作系统自动完成的，一般不需要用户程序的介入。</p>
<p>不过，DNS 服务器并不是一次性地把 www.icyfenix.com.cn 直接解析成 IP 地址的，这个解析需要经历一个递归的过程。</p>
<p>首先，DNS 会把域名还原为”www.icyfenix.com.cn.”。注意这里最后多了一个点”.”，它是”.root”的意思。早期的域名都必须得带这个点，DNS 才能正确解析，不过现在几乎所有的操作系统、DNS 服务器都可以自动补上结尾的点号了。</p>
<p>然后，DNS 就开始进行解析了。它的解析步骤是这样的：</p>
<ol>
<li><p>第一步，客户端先检查本地的 DNS 缓存，查看是否存在并且是存活着的该域名的地址记录。</p>
<p> DNS 是以 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Time_to_live">存活时间</a> （Time to Live，TTL）来衡量缓存的有效情况的，因此如果某个域名改变了 IP 地址，它也无法去通知缓存了该地址的机器来更新或失效掉缓存，只能依靠 TTL 超期后重新获取来保证一致性。后续每一级 DNS 查询的过程，都会有类似的缓存查询操作，所以我就不重复说了。</p>
</li>
<li><p>第二步，客户端将地址发送给本机操作系统中配置的本地 DNS（Local DNS）。这个本地 DNS 服务器可以由用户手工设置，也可以在 DHCP 分配时或者在拨号时，从 PPP 服务器中自动获取。</p>
</li>
<li><p>第三步，本地 DNS 收到查询请求后，会按照”是否有 www.icyfenix.com.cn 的权威服务器”→”是否有 icyfenix.com.cn 的权威服务器”→”是否有 com.cn 的权威服务器”→”是否有 cn 的权威服务器”的顺序，依次查询自己的地址记录。如果都没有查询到，本地 DNS 就会一直找到最后点号代表的根域名服务器为止。</p>
<p> 这个步骤里涉及了两个重要名词，你需要好好掌握：</p>
<ol>
<li><p><strong>权威域名服务器（Authoritative DNS）</strong> ：是指负责翻译特定域名的 DNS 服务器，”权威”的意思就是说，服务器决定了这个域名应该翻译出怎样的结果。DNS 翻译域名的时候，不需要像查电话本一样刻板地一对一翻译，它可以根据来访机器、网络链路、服务内容等各种信息，玩出很多花样。权威 DNS 的灵活应用，在后面的内容分发网络、服务发现等课程内容中都还会涉及到。</p>
</li>
<li><p><strong>根域名服务器（Root DNS）</strong> ：是指固定的、无需查询的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Top-level_domain">顶级域名</a> （Top-Level Domain）服务器，可以默认为它们已内置在操作系统代码之中。全世界一共有 13 组根域名服务器（注意并不是 13 台，每一组根域名都通过 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Anycast">任播</a> 的方式建立了一大群镜像，根据维基百科的数据，迄今已经超过 1000 台根域名服务器的镜像了），之所以有 13 这个数字的限制是因为，DNS 主要是采用 UDP 传输协议（在需要稳定性保证的时候也可以采用 TCP）来进行数据交换的，未分片的 UDP 数据包在 IPv4 下最大有效值为 512 字节，最多可以存放 13 组地址记录。</p>
</li>
</ol>
</li>
<li><p>第四步，现在假设本地 DNS 是全新的，上面不存在任何域名的权威服务器记录，所以当 DNS 查询请求按步骤 3 的顺序，一直查到根域名服务器之后，它将会得到”cn 的权威服务器”的地址记录，然后通过”cn 的权威服务器”，得到”com.cn 的权威服务器”的地址记录，以此类推，最后找到能够解释 www.icyfenix.com.cn 的权威服务器地址。</p>
</li>
<li><p>第五步，通过”www.icyfenix.com.cn 的权威服务器”，查询 www.icyfenix.com.cn 的地址记录。这里的地址记录并不一定就是指 IP 地址，在 RFC 规范中，有定义的地址记录类型已经 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/List_of_DNS_record_types">多达几十种</a> ，比如 IPv4 下的 IP 地址为 A 记录，IPv6 下的 AAAA 记录、主机别名 CNAME 记录，等等。</p>
</li>
</ol>
<p>我给你举一个例子。假设一个域名下配置了多条不同的 A 记录，此时权威服务器就可以根据自己的策略来进行选择，典型的应用是智能线路：根据访问者所处的不同地区（如华北、华南、东北）、不同服务商（如电信、联通、移动）等因素，来确定返回最合适的 A 记录，将访问者路由到最合适的数据中心，达到智能加速的目的。</p>
<p>可见，DNS 系统多级分流的设计，就让 DNS 系统能够经受住全球网络流量不间断的冲击，但它也并不是没有缺点。</p>
<p>典型的问题就是 <strong>响应速度会受影响</strong> 。在极端情况（如各级服务器均无缓存）下，域名解析可能会导致每个域名都必须递归多次才能查询到结果，显著影响传输的响应速度。</p>
<p>如下图所示，你可以看到其高达 310 毫秒的 DNS 查询速度：</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/首次DNS请求耗时.webp" alt="首次DNS请求耗时"></p>
<p>所以，为了避免产生这种问题，专门就有一种前端优化手段，叫做 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Link_prefetching">DNS 预取</a> （DNS Prefetching）：如果网站后续要使用来自于其他域的资源，那就在网页加载时便生成一个 link 请求，促使浏览器提前对该域名进行预解释，如下所示：</p>
<pre class="line-numbers language-html" data-language="html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>link</span> <span class="token attr-name">rel</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>dns-prefetch<span class="token punctuation">"</span></span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>//domain.not-icyfenx.cn<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>而另一种可能更严重的缺陷，就是 <strong>DNS 的分级查询意味着每一级都有可能受到中间人攻击的威胁，产生被劫持的风险。</strong></p>
<p>我们应该都知道，要攻陷位于递归链条顶层的（如根域名服务器，cn 权威服务器）服务器和链路是非常困难的，它们都有很专业的安全防护措施。但很多位于递归链底层的、或者来自本地运营商的 Local DNS 服务器，安全防护就相对松懈，甚至不少地区的运行商自己就会主动进行劫持，专门返回一个错的 IP，通过在这个 IP 上代理用户请求，以便给特定类型的资源（主要是 HTML）注入广告，进行牟利。</p>
<p>所以针对这种情况，最近几年出现了一种新的 DNS 工作模式： <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/DNS_over_HTTPS">HTTPDNS</a> （也称为 DNS over HTTPS，DoH）。它把原本的 DNS 解析服务开放为一个基于 HTTPS 协议的查询服务，替代基于 UDP 传输协议的 DNS 域名解析，通过程序代替操作系统直接从权威 DNS，或者可靠 Local DNS 获取解析数据，从而绕过传统 Local DNS。</p>
<p>这种做法的好处是完全免去了”中间商赚差价”的环节，不再惧怕底层的域名劫持，能有效避免 Local DNS 不可靠导致的域名生效缓慢、来源 IP 不准确、产生的智能线路切换错误等问题。</p>
<h4 id="小结-12"><a href="#小结-12" class="headerlink" title="小结"></a>小结</h4><p>这节课作为”透明多级分流系统”的第一讲，我给你介绍了这个名字的意义与来由。在开发过程中没有太多存在感的 DNS 系统，其实就很符合透明和多级分流的特点。所以我也以此为例，给你简要介绍了它的工作原理。</p>
<p>根据请求从浏览器发出到最终查询或修改数据库的信息，除了 DNS 以外，还会有客户端浏览器、网络传输链路、内容分发网络、负载均衡器和缓存中间件这些位于服务器、数据库之外的组件，可以帮助分担流量，便于我们构建出更加高并发、高可用的系统。在后面的几节课中，我们就会逐一来探讨它们的工作原理。</p>
<h3 id="17-客户端缓存是如何帮助服务器分担流量的？"><a href="#17-客户端缓存是如何帮助服务器分担流量的？" class="headerlink" title="17 | 客户端缓存是如何帮助服务器分担流量的？"></a>17 | 客户端缓存是如何帮助服务器分担流量的？</h3><p>这节课，我们继续来讨论透明多级分流系统中，最靠近用户一侧的分流部件：浏览器的客户端缓存。</p>
<p>当万维网刚刚出现的时候，浏览器的缓存机制差不多就已经存在了。在 HTTP 协议设计之初，人们便确定了服务端与客户端之间”无状态”（Stateless）的交互原则，即要求客户端的每次请求是独立的，每次请求无法感知、也不能依赖另一个请求的存在，这既简化了 HTTP 服务器的设计，也为它的水平扩展能力留下了广阔的空间。</p>
<p>但无状态并不是只有好的一面。因为客户端的每次请求都是独立的，服务端不会保存之前请求的状态和资源，所以也不可避免地导致它会携带重复的数据，造成网络性能的降低。</p>
<p>那么，HTTP 协议针对这个问题的解决方案，就是客户端缓存。从 HTTP/1.0 到 1.1、再到 2.0 版本的演进中，逐步形成了现在被称为”状态缓存”、”强制缓存”（或简称为”强缓存”）和”协商缓存”这三种 HTTP 缓存机制。</p>
<p>这其中的状态缓存，是指不经过服务器，客户端直接根据缓存信息来判断目标网站的状态。以前只有 301/Moved Permanently（永久重定向）这一种；后来在 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc6797">RFC6797</a> 中增加了 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/HTTP_Strict_Transport_Security">HSTS</a> （HTTP Strict Transport Security）机制，用来避免依赖 301/302 跳转 HTTPS 时，可能产生的降级中间人劫持问题（在第 28、29 讲中，我还会展开讲解这个问题），这也属于另一种状态缓存。</p>
<p>因为状态缓存涉及的内容只有这么一点，所以后面，我们就只聚焦在强制缓存与协商缓存这两种机制的探讨上。</p>
<p>下面我们就先来看看强制缓存的实现机制吧。</p>
<h4 id="实现强制缓存机制的两类-Headers"><a href="#实现强制缓存机制的两类-Headers" class="headerlink" title="实现强制缓存机制的两类 Headers"></a>实现强制缓存机制的两类 Headers</h4><p>就像”强制缓存”这个名字一样，它对一致性问题的处理策略十分直接：假设在某个时间点内，比如服务器收到响应后的 10 分钟内，资源的内容和状态一定不会被改变，因此客户端可以不需要经过任何请求，在该时间点到来之前一直持有和使用该资源的本地缓存副本。</p>
<p>根据约定，在浏览器的地址输入、页面链接跳转、新开窗口、前进和后退中，强制缓存都可以生效，但在用户主动刷新页面时应当自动失效。</p>
<p>在 HTTP 协议中，设置了两类可以实现强制缓存的 Headers（标头）：Expires 和 Cache-Control。</p>
<h5 id="第一类：Expires"><a href="#第一类：Expires" class="headerlink" title="第一类：Expires"></a>第一类：Expires</h5><p>Expires 是 HTTP/1.0 协议中开始提供的 Header，后面跟随了一个截止时间参数。当服务器返回某个资源时，如果带有该 Header 的话，就意味着服务器承诺在截止时间之前，资源不会发生变动，浏览器可直接缓存该数据，不再重新发请求。我们直接来看一个 Expires 头的示例程序：</p>
<pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">200 OK</span></span>
<span class="token header-name keyword">Expires:</span> Wed, 8 Apr 2020 07:28:00 GMT<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>那么，你能看到，Expires 设计得非常直观易懂，但它考虑得其实并不周全。我给你简单举几个例子。</p>
<ul>
<li><p><strong>受限于客户端的本地时间</strong></p>
<p>  比如，在收到响应后，客户端修改了本地时间，将时间点前后调整了几分钟，这就可能会造成缓存提前失效或超期持有。</p>
</li>
<li><p><strong>无法处理涉及到用户身份的私有资源</strong></p>
<p>  比如，合理的做法是，某些资源被登录用户缓存在了自己的浏览器上。但如果被代理服务器或者内容分发网络（CDN）缓存起来，就可能会被其他未认证的用户获取。</p>
</li>
<li><p><strong>无法描述”不缓存”的语义</strong></p>
<p>  比如，一般浏览器为了提高性能，往往会自动在当次会话中缓存某些 MINE 类型的资源，这会造成设计者不希望缓存的资源无法被及时更新。而在 HTTP/1.0 的设计中，Expires 并没有考虑这方面的需求，导致无法强制浏览器不允许缓存某个资源。</p>
<p>  所以，以前为了实现这类功能，我们通常不得不使用脚本，或者手工在资源后面增加时间戳（如”xx.js?t=1586359920””xx.jpg?t=1586359350”）来保证每次资源都会重新获取。</p>
<p>  不过，关于”不缓存”的语义，在 HTTP/1.0 中其实是预留了”Pragma: no-cache”来表达的，但在 HTTP/1.0 中，并没有确切地描述 Pragma 参数的具体行为，随后它就被 HTTP/1.1 中出现过的 Cache-Control 给替代了。</p>
<p>  现在，尽管主流的浏览器也通常都会支持 Pragma，但它的行为仍然是不确定的，实际上并没有什么使用价值。而 Cache-Control 的出现，进一步压缩了 Pragma 的生存空间。所以接下来，我们就一起来看看，它是如何支持强制缓存机制的实现的。</p>
</li>
</ul>
<h5 id="第二类：Cache-Control"><a href="#第二类：Cache-Control" class="headerlink" title="第二类：Cache-Control"></a>第二类：Cache-Control</h5><p>Cache-Control 是 HTTP/1.1 协议中定义的强制缓存 Header，它的语义比起 Expires 来说就丰富了很多。而如果 Cache-Control 和 Expires 同时存在，并且语义存在冲突（比如 Expires 与 max-age / s-maxage 冲突）的话，IETF 规定必须以 Cache-Control 为准。</p>
<p>同样这里，我们也看看 Cache-Control 的使用示例：</p>
<pre class="line-numbers language-httpHTTP/1.1" data-language="httpHTTP/1.1"><div class="caption"><span>200 OK</span></div><code class="language-httpHTTP/1.1">Cache-Control: max-age=600<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>那么，你能看到，这里的示例中使用的参数是 max-age。实际上，在客户端的请求 Header 或服务器的响应 Header 中，Cache-Control 都可以存在，它定义了一系列的参数，并且允许自行扩展（即不在标准 RFC 协议中，由浏览器自行支持的参数）。Cache-Control 标准的参数主要包括 6 种，下面我就带你一一了解下。</p>
<ul>
<li><p><strong>max-age 和 s-maxage</strong></p>
<p>  在前面的示例中，你会发现 max-age 后面跟随了一个数字，它是以秒为单位的，表明相对于请求时间（在 Date Header 中会注明请求时间）多少秒以内，缓存是有效的，资源不需要重新从服务器中获取。这个相对时间，就避免了 Expires 中，采用的绝对时间可能受客户端时钟影响的问题。</p>
<p>  另一个类似的参数是 s-maxage，其中的”s”是”Share”的缩写，意味着”共享缓存”的有效时间，即允许被 CDN、代理等持有的缓存有效时间，这个参数主要是用来提示 CDN 这类服务器如何对缓存进行失效。</p>
</li>
<li><p><strong>public 和 private</strong></p>
<p>  这一类参数表明了是否涉及到用户身份的私有资源。如果是 public，就意味着资源可以被代理、CDN 等缓存；如果是 private，就意味着只能由用户的客户端进行私有缓存。</p>
</li>
<li><p><strong>no-cache 和 no-store</strong></p>
<p>  no-cache 表明该资源不应该被缓存，哪怕是同一个会话中对同一个 URL 地址的请求，也必须从服务端获取，从而令强制缓存完全失效（但此时的协商缓存机制依然是生效的）；no-store 不强制会话中是否重复获取相同的 URL 资源，但它禁止浏览器、CDN 等以任何形式保存该资源。</p>
</li>
<li><p><strong>no-transform</strong></p>
<p>  no-transform 禁止资源以任何形式被修改。比如，某些 CDN、透明代理支持自动 GZip 压缩图片或文本，以提升网络性能，而 no-transform 就禁止了这样的行为，它要求 Content-Encoding、Content-Range、Content-Type 均不允许进行任何形式的修改。</p>
</li>
<li><p><strong>min-fresh 和 only-if-cached</strong></p>
<p>  这两个参数是仅用于客户端的请求 Header。min-fresh 后续跟随了一个以秒为单位的数字，用于建议服务器能返回一个不少于该时间的缓存资源（即包含 max-age 且不少于 min-fresh 的数字）；only-if-cached 表示服务器希望客户端不要发送请求，只使用缓存来进行响应，若缓存不能命中，就直接返回 503/Service Unavailable 错误。</p>
</li>
<li><p><strong>must-revalidate 和 proxy-revalidate</strong></p>
<p>  must-revalidate 表示在资源过期后，一定要从服务器中进行获取，即超过了 max-age 的时间后，就等同于 no-cache 的行为；proxy-revalidate 用于提示代理、CDN 等设备资源过期后的缓存行为，除对象不同外，语义与 must-revalidate 完全一致。</p>
</li>
</ul>
<p>好了，现在你应该就已经理解了强制缓存的实现机制了。但是，强制缓存是基于时效性的，无论是人还是服务器，在大多数情况下，其实都没有什么把握去承诺某项资源多久不会发生变化。</p>
<p>所以，接下来我就要给你介绍另一种基于变化检测的缓存机制，也就是协商缓存。它在处理一致性问题上，比强制缓存会有更好的表现。不过它需要一次变化检测的交互开销，在性能上就会略差一些。</p>
<h4 id="协商缓存的两种变动检查机制"><a href="#协商缓存的两种变动检查机制" class="headerlink" title="协商缓存的两种变动检查机制"></a>协商缓存的两种变动检查机制</h4><p>那么，在开始了解协商缓存的实现机制之前，你要先注意一个地方，就是在 HTTP 中，协商缓存与强制缓存并没有互斥性，这两套机制是并行工作的。</p>
<p>比如说，当强制缓存存在时，客户端可以直接从强制缓存中返回资源，无需进行变动检查；而当强制缓存超过时效，或者被禁止（no-cache / must-revalidate），协商缓存也仍然可以正常工作。</p>
<p>协商缓存有两种变动检查机制， <strong>一种是根据资源的修改时间进行检查，另一种是根据资源唯一标识是否发生变化来进行检查。</strong> 它们都是靠一组成对出现的请求、响应 Header 来实现的。</p>
<h5 id="根据资源的修改时间进行检查"><a href="#根据资源的修改时间进行检查" class="headerlink" title="根据资源的修改时间进行检查"></a>根据资源的修改时间进行检查</h5><p>我们先来看看根据资源的修改时间进行检查的协商缓存机制。它的语义中包含了两种标准参数：<strong>Last-Modified</strong> 和 <strong>If-Modified-Since</strong> 。</p>
<p>Last-Modified 是服务器的响应 Header，用来告诉客户端这个资源的最后修改时间。</p>
<p>而对于带有这个 Header 的资源，当客户端需要再次请求时，会通过 If-Modified-Since，把之前收到的资源最后修改时间发送回服务端。</p>
<p>如果此时，服务端发现资源在该时间后没有被修改过，就只要返回一个 304/Not Modified 的响应即可，无需附带消息体，从而达到了节省流量的目的：</p>
<pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">304 Not Modified</span></span>
<span class="token header-name keyword">Cache-Control:</span> public, max-age=600
<span class="token header-name keyword">Last-Modified:</span> Wed, 8 Apr 2020 15:31:30 GMT<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>而如果此时，服务端发现资源在该时间之后有变动，就会返回 200/OK 的完整响应，在消息体中包含最新的资源。</p>
<pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">200 OK</span></span>
<span class="token header-name keyword">Cache-Control:</span> public, max-age=600
<span class="token header-name keyword">Last-Modified:</span> Wed, 8 Apr 2020 15:31:30 GMT

Content<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h5 id="根据资源唯一标识是否发生变化来进行检查"><a href="#根据资源唯一标识是否发生变化来进行检查" class="headerlink" title="根据资源唯一标识是否发生变化来进行检查"></a>根据资源唯一标识是否发生变化来进行检查</h5><p>好，我们再来看看”根据资源唯一标识是否发生变化来进行检查”的协商缓存机制。它的语义中也包含了两种标准参数： <strong>Etag</strong> 和 <strong>If-None-Match</strong> 。</p>
<p>Etag 是服务器的响应 Header，用于告诉客户端这个资源的唯一标识。HTTP 服务器可以根据自己的意愿，来选择如何生成这个标识，比如 Apache 服务器的 Etag 值，就默认是对文件的索引节点（INode）、大小和最后修改时间进行哈希计算后而得到的。</p>
<p>然后，对于带有这个 Header 的资源，当客户端需要再次请求时，就会通过 If-None-Match，把之前收到的资源唯一标识发送回服务端。</p>
<p>如果此时，服务端计算后发现资源的唯一标识与上传回来的一致，就说明资源没有被修改过，同样也只需要返回一个 <strong>304/Not Modified</strong> 的响应即可，无需附带消息体，达到节省流量的目的：</p>
<pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">304 Not Modified</span></span>
<span class="token header-name keyword">Cache-Control:</span> public, max-age=600
<span class="token header-name keyword">ETag:</span> "28c3f612-ceb0-4ddc-ae35-791ca840c5fa"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>而如果此时，服务端发现资源的唯一标识有变动，也一样会返回 200/OK 的完整响应，在消息体中包含最新的资源。</p>
<pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">200 OK</span></span>
<span class="token header-name keyword">Cache-Control:</span> public, max-age=600
<span class="token header-name keyword">ETag:</span> "28c3f612-ceb0-4ddc-ae35-791ca840c5fa"

Content<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>另外，我还想强调的是， <strong>Etag 是 HTTP 中一致性最强的缓存机制。</strong></p>
<p>为什么会这么说呢？我直接给你举个例子。</p>
<p>前面我提到的 Last-Modified 参数，它标注的最后修改只能精确到秒级，而如果某些文件在一秒钟以内被修改多次的话，它就不能准确标注文件的修改时间了；又或者，如果某些文件会被定期生成，可能内容上并没有任何变化，但 Last-Modified 却改变了，导致文件无法有效使用缓存。而这些情况，Last-Modified 都有可能产生资源一致性的问题，只能使用 Etag 解决。</p>
<p><strong>但是，Etag 又是 HTTP 中性能最差的缓存机制。</strong> 这个”最差”体现在每次请求时，服务端都必须对资源进行哈希计算，这比起简单获取一下修改时间，开销要大了很多。</p>
<p>所以，Etag 和 Last-Modified 是允许一起使用的，服务器会优先验证 Etag，在 Etag 一致的情况下，再去对比 Last-Modified，这是为了防止有一些 HTTP 服务器没有把文件修改日期纳入哈希范围内。</p>
<h4 id="HTTP-的内容协商机制"><a href="#HTTP-的内容协商机制" class="headerlink" title="HTTP 的内容协商机制"></a>HTTP 的内容协商机制</h4><p>那到这里为止，HTTP 的协商缓存机制，就已经能很好地处理通过 URL 获取单个资源的场景了。不过你可能要问了： <strong>为什么要强调”单个资源”呢？</strong></p>
<p>我们知道，在 HTTP 协议的设计中，一个 URL 地址是有可能提供多份不同版本的资源的，比如说，一段文字的不同语言版本，一个文件的不同编码格式版本，一份数据的不同压缩方式版本，等等。因此针对请求的缓存机制，也必须能够提供对应的支持。</p>
<p>所以，针对这种情况，HTTP 协议设计了以 <code>Accept*</code> （Accept、Accept-Language、Accept-Charset、Accept-Encoding）开头的一套请求 Header，以及对应的以 <code>Content-*</code> （Content-Language、Content-Type、Content-Encoding）开头的响应 Header。 <strong>这些 Headers 被称为 HTTP 的内容协商机制。</strong></p>
<p>那么，与之对应的，对于一个 URL 能够获取多个资源的场景中，缓存同样也需要有明确的标识来获知，它要根据什么内容来对同一个 URL 返回给用户正确的资源。这个就是 Vary Header 的作用，Vary 后面应该跟随一组其他 Header 的名字，比如说：</p>
<pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">200 OK</span></span>
<span class="token header-name keyword">Vary:</span> Accept, User-Agent<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>这里你要知道，这个响应的含义是应该根据 MINE 类型和浏览器类型来缓存资源，另外服务端在获取资源时，也需要根据请求 Header 中对应的字段，来筛选出适合的资源版本。</p>
<p>根据约定，协商缓存不仅可以在浏览器的地址输入、页面链接跳转、新开窗口、前进、后退中生效，而且在用户主动刷新页面（F5）时也同样是生效的。只有用户强制刷新（Ctrl+F5）或者明确禁用缓存（比如在 DevTools 中设定）时才会失效，此时客户端向服务端发出的请求会自动带有”Cache-Control: no-cache”。</p>
<h4 id="小结-13"><a href="#小结-13" class="headerlink" title="小结"></a>小结</h4><p>HTTP 协议以”无状态”作为基本的交互原则，那么由此而来的资源重复访问问题，就需要通过网络链路中的缓存来解决了。现在你也已经知道，客户端缓存具体包括了”状态缓存”、”强制缓存”和”协商缓存”三类。</p>
<p>这节课，我们详细分析了强制缓存和协商缓存的工作原理。利用好客户端的缓存，能够节省大量网络流量，这是为后端系统分流，以实现更高并发的第一步。</p>
<h3 id="18-传输链路，优化HTTP传输速度的小技巧"><a href="#18-传输链路，优化HTTP传输速度的小技巧" class="headerlink" title="18 | 传输链路，优化HTTP传输速度的小技巧"></a>18 | 传输链路，优化HTTP传输速度的小技巧</h3><p>在经过了客户端缓存的节流和 DNS 服务的解析指引以后，程序发出的请求流量就正式离开了客户端，踏上以服务器为目的地的旅途了。而这个过程就是我们今天这节课要讨论的主角： <strong>传输链路。</strong></p>
<h4 id="以优化链路传输为目的的前端设计原则未来或许不再适用"><a href="#以优化链路传输为目的的前端设计原则未来或许不再适用" class="headerlink" title="以优化链路传输为目的的前端设计原则未来或许不再适用"></a>以优化链路传输为目的的前端设计原则未来或许不再适用</h4><p>可能不少人的第一直觉都会认为，传输链路是完全不受开发者控制的因素，觉得网络路由跳点的数量、运营商铺设线路的质量，已经决定了线路带宽的大小、速率的高低。不过事实并非如此，程序发出的请求能否与应用层、传输层协议提倡的方式相匹配，对传输的效率也会有非常大的影响。</p>
<p>最容易体现出这点的，就是那些前端网页的优化技巧。我们只要简单搜索一下，就能找到很多以优化链路传输为目的的前端设计原则，比如经典的 <a target="_blank" rel="noopener" href="https://developer.yahoo.com/performance/rules.html">雅虎 YSlow-23 条规则</a> 中，就涵盖了很多与传输相关的内容。</p>
<p>下面我来给你简单举几个例子。</p>
<ul>
<li><p><strong>Minimize HTTP Requests</strong></p>
<p>  即减少请求数量：对于客户端发出的请求，服务器每次都需要建立通信链路进行数据传输，这些开销很昂贵，所以减少请求的数量，就可以有效地提高访问性能。如果你是做前端开发的，那你可能就听说过下面这几种减少请求数量的手段：</p>
<blockquote>
<p>a. 雪碧图（ <a target="_blank" rel="noopener" href="https://en.wikipedia.org/w/index.php?title=CSS_Sprites&amp;redirect=no">CSS Sprites</a> ）</p>
<p>b. CSS、JS 文件合并 / 内联（Concatenation / Inline）</p>
<p>c. 分段文档（ <a target="_blank" rel="noopener" href="https://www.w3.org/Protocols/rfc1341/7_2_Multipart.html">Multipart Document</a> ）</p>
<p>d. 媒体（图片、音频）内联（ <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Data_URI_scheme">Data Base64 URI</a> ）</p>
<p>e. 合并 Ajax 请求（Batch Ajax Request）</p>
<p>f. ……</p>
</blockquote>
</li>
<li><p><strong>Split Components Across Domains</strong></p>
<p>  即扩大并发请求数：现代浏览器（Chrome、Firefox）一般可以为每个域名支持 6 个（IE 为 8-13 个）并发请求。如果你希望更快地加载大量图片或其他资源，就需要进行域名分片（Domain Sharding），将图片同步到不同主机或者同一个主机的不同域名上。</p>
</li>
<li><p><strong>GZip Components</strong></p>
<p>  即启用压缩传输：启用压缩能够大幅度减少需要在网络上传输内容的大小，节省网络流量。</p>
</li>
<li><p><strong>Avoid Redirects</strong></p>
<p>  即避免页面重定向：当页面发生了重定向，就会延迟整个文档的传输。在 HTML 文档到达之前，页面中不会呈现任何东西，会降低用户的体验。</p>
</li>
<li><p><strong>Put Stylesheets at the Top，Put Scripts at the Bottom</strong></p>
<p>  即按重要性调节资源优先级：将重要的、马上就要使用的、对客户端展示影响大的资源，放在 HTML 的头部，以便优先下载。</p>
</li>
<li><p>……</p>
</li>
</ul>
<p>这些原则在今天暂且仍算得上是有一定价值，但如果在若干年后的未来再回头看它们，大概率其中的多数原则已经成了奇技淫巧，有些甚至成了反模式。</p>
<p>我为什么这么说呢？这是因为 HTTP 协议还在持续发展，从上世纪 90 年代的 HTTP/1.0 和 HTTP/1.1，到 2015 年发布的 HTTP/2，再到 2019 年的 HTTP/3，由于 HTTP 协议本身的变化，造成了”适合 HTTP 传输的请求”的特征也在不断变化。</p>
<p>那么接下来，我们就来看看这里所说的特征变化指的都是什么。</p>
<h4 id="连接数优化"><a href="#连接数优化" class="headerlink" title="连接数优化"></a>连接数优化</h4><p>我们知道，HTTP（特指 HTTP/3 以前）是以 TCP 为传输层的应用层协议， <strong>但 HTTP over TCP 这种搭配，只能说是 TCP 目前在互联网中的统治性地位所造就的结果，而不能说它们两者配合工作就是合适的。</strong></p>
<p>为啥呢？一方面，你可以回想一下，平常你在上网的时候，平均每个页面停留的时间都有多长？然后你也可以大概估算一下每个页面中包含的资源（HTML、JS、CSS、图片等）数量，由此你其实就可以大致总结出 HTTP 传输对象的主要特征了，那就是数量多、时间短、资源小、切换快。</p>
<p>另一方面，TCP 协议要求必须在 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Connection_establishment">三次握手</a> 完成之后才能开始数据传输，这是一个可能高达”百毫秒”为计时尺度的事件；另外，TCP 还有 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/TCP_congestion_control#Slow_start">慢启动</a> 的特性，这就会导致通信双方在刚刚建立连接时的传输速度是最低的，后面再逐步加速直至稳定。</p>
<p><strong>由于 TCP 协议本身是面向长时间、大数据传输来设计的，所以只有在一段较长的时间尺度内，TCP 协议才能展现出稳定性和可靠性的优势，不会因为建立连接的成本太高，成为了使用瓶颈。</strong></p>
<p>所以我才说，HTTP over TCP 这种搭配在目标特征上确实是有矛盾的，以至于 HTTP/1.x 时代，大量短而小的 TCP 连接导致了网络性能的瓶颈。</p>
<h4 id="开发-Tricks-的使用困境"><a href="#开发-Tricks-的使用困境" class="headerlink" title="开发 Tricks 的使用困境"></a>开发 Tricks 的使用困境</h4><p>那么，为了缓解 HTTP 与 TCP 之间的矛盾，聪明的程序员们一面致力于减少发出的请求数量，另一面也在致力于增加客户端到服务端的连接数量。这就是我在前面提到的 Yslow 规则中，”Minimize HTTP Requests”与”Split Components Across Domains”两条优化措施的根本依据所在。</p>
<p>由此可见，通过前端开发者的各种 Tricks，确实能够减少 TCP 连接数量的消耗，这是有数据统计作为支撑的。</p>
<p><a target="_blank" rel="noopener" href="https://httparchive.org/">HTTP Archive</a> 就对最近 5 年来数百万个 URL 地址进行了采样，并得出了一个结论：页面平均请求没有改变的情况下（桌面端下降 3.8%，移动端上升 1.4%），TCP 连接正在持续且幅度较大地下降（桌面端下降 36.4%，移动端下降 28.6%）。我们一起来具体看看这个变化：</p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/HTTP平均请求数量.webp" alt="HTTP 平均请求数量，70 余个，没有明显变化"></p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/TCP连接数量.webp" alt="TCP 连接数量，约 15 个，有明显下降趋势"></p>
<p>但是，这些开发 Tricks 除了可以节省 TCP 连接以外，其实也给我们带来了不少的副作用，比如说：</p>
<ul>
<li>如果你用 CSS Sprites 合并了多张图片，就意味着在任何场景下，哪怕你只用到了其中一张小图，也必须要完整地加载整个大图片；或者哪怕只有一张小图需要修改，也都会导致整个大图的缓存失效。类似的，样式、脚本等其他文件的合并，也会造成同样的问题。</li>
<li>如果你使用了媒体内嵌，除了要承受 Base64 编码导致传输容量膨胀 1/3 的代价以外（Base64 以 8 bit 表示 6 bit 数据），也会无法有效利用缓存。</li>
<li>如果你合并了异步请求，就会导致所有请求的返回时间，都要受最慢的那个请求拖累，页面整体的响应速度会下降。</li>
<li>如果你把图片放到了不同子域下面，将会导致更大的 DNS 解析负担，而且浏览器对两个不同子域下的同一图片必须持有两份缓存，这也使得缓存效率下降。</li>
<li>……</li>
</ul>
<p>所以我们也不难看出，一旦需要使用者通过各种 Tricks，来解决基于技术根基而出现的各种问题时，就会导致 TA 再也没办法摆脱”两害相权取其轻”的困境。否则，这就不是 Tricks，而是会成为一种标准的设计模式了。</p>
<h4 id="连接复用技术的优势和缺陷"><a href="#连接复用技术的优势和缺陷" class="headerlink" title="连接复用技术的优势和缺陷"></a>连接复用技术的优势和缺陷</h4><p>实际上，HTTP 的设计者们也不是没有尝试过在 <strong>协议层面</strong> 去解决连接成本过高的问题，即使是 HTTP 协议的最初版本（指 HTTP/1.0，忽略非正式的 HTTP/0.9 版本），就已经支持（HTTP/1.0 中不是默认开启的，HTTP/1.1 中变为默认）连接复用技术了，也就是今天我们所熟知的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/HTTP_persistent_connection">持久连接</a> （Persistent Connection），或者叫连接 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Keepalive">Keep-Alive</a> 机制。</p>
<p>它的原理是，让客户端对同一个域名长期持有一个或多个不会用完即断的 TCP 连接。典型做法是在客户端维护一个 FIFO 队列，每次取完数据之后的一段时间内，不自动断开连接，以便获取下一个资源时可以直接复用，避免创建 TCP 连接的成本。</p>
<p><strong>但是，连接复用技术依然是不完美的，最明显的副作用就是” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Head-of-line_blocking">队首阻塞</a> “（Head-of-Line Blocking）问题。</strong></p>
<p>我们来设想一下这样的场景：浏览器有 10 个资源需要从服务器中获取，这个时候它把 10 个资源放入队列，入列顺序只能是按照浏览器预见这些资源的先后顺序来决定。但是，如果这 10 个资源中的第 1 个就让服务器陷入了长时间运算状态，会发生怎样的状况呢？</p>
<p>答案是，当它的请求被发送到服务端之后，服务端就会开始计算，而在运算结果出来之前，TCP 连接中并没有任何数据返回，此时后面的 9 个资源都必须阻塞等待。</p>
<p>虽然说服务端可以并行处理另外 9 个请求，比如第 1 个是复杂运算请求，消耗 CPU 资源；第 2 个是数据库访问，消耗数据库资源；第 3 个是访问某张图片，消耗磁盘 I/O 资源，等等，这就很适合并行。</p>
<p>但问题是，这些请求的处理结果无法及时发回给客户端，服务端也不能哪个请求先完成就返回哪个，更不可能把所有要返回的资源混杂到一起交叉传输。这是因为，只使用一个 TCP 连接来传输多个资源的话，一旦顺序乱了，客户端就很难区分清楚哪个数据包归属哪个资源了。</p>
<p>因此，在 2014 年 IETF 发布的 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc7230#section-6.3.2">RFC 7230</a> 中，提出了名为”HTTP 管道”（HTTP Pipelining）复用技术，试图在 HTTP 服务器中也建立类似客户端的 FIFO 队列，让客户端一次性将所有要请求的资源名单全部发给服务端，由服务端来安排返回顺序，管理传输队列。</p>
<p>不过，无论队列维护是在服务端还是在客户端，其实都无法完全避免队首阻塞的问题。这是因为很难在真正传输之前，完全精确地评估出传输队列中每一项的时间成本，但由于服务端能够较为准确地评估资源消耗情况，这样确实能更紧凑地安排资源传输，保证队列中两项工作之间尽量减少空隙，甚至可能做到并行化传输，从而提升链路传输的效率。</p>
<p>可是，因为 HTTP 管道需要多方共同支持，协调起来相当复杂，因此推广得并不算成功。</p>
<p>后来，队首阻塞问题一直持续到 HTTP/2 发布后，才算是被比较完美地解决了。</p>
<h4 id="解决方案：HTTP-2-的多路复用技术"><a href="#解决方案：HTTP-2-的多路复用技术" class="headerlink" title="解决方案：HTTP/2 的多路复用技术"></a>解决方案：HTTP/2 的多路复用技术</h4><p>在 HTTP/1.x 中，HTTP 请求就是传输过程中最小粒度的信息单位了，所以如果将多个请求切碎，再混杂在一块传输，客户端势必难以分辨重组出有效信息。</p>
<p><strong>而在 HTTP/2 中，帧（Frame）才是最小粒度的信息单位</strong> ，它可以用来描述各种数据，比如请求的 Headers、Body，或者是用来做控制标识，如打开流、关闭流。</p>
<p>这里我说的 <strong>流（Stream）</strong> ，是一个逻辑上的数据通道概念，每个帧都附带有一个流 ID，以标识这个帧属于哪个流。这样，在同一个 TCP 连接中，传输的多个数据帧就可以根据流 ID 轻易区分出来，在客户端就能毫不费力地将不同流中的数据，重组出不同 HTTP 请求和响应报文来。</p>
<p>这项设计是 HTTP/2 的最重要的技术特征之一，被称为 <strong>HTTP/2 <a target="_blank" rel="noopener" href="https://tools.ietf.org/html/rfc7540#page-15">多路复用</a> （HTTP/2 Multiplexing）技术。</strong></p>
<p><img src="https://fastly.jsdelivr.net/gh/kibaamor/kibaamor.github.io/images/《周志明的软件架构课》学习笔记/HTTP2的多路复用.webp" alt="HTTP2的多路复用"></p>
<p><a target="_blank" rel="noopener" href="https://hpbn.co/http2">HTTP/2 的多路复用</a></p>
<p>这样，有了多路复用的支持，HTTP/2 就可以对每个域名只维持一个 TCP 连接（One Connection Per Origin），来以任意顺序传输任意数量的资源。这样就既减轻了服务器的连接压力，开发者也不用去考虑域名分片这种事情，来突破浏览器对每个域名最多 6 个连接数的限制了。</p>
<p>而更重要的是，没有了 TCP 连接数的压力，客户端就不需要再刻意压缩 HTTP 请求了，所有通过合并、内联文件（无论是图片、样式、脚本）以减少请求数的需求都不再成立，甚至反而是徒增副作用的反模式。</p>
<p>当然，我说这是反模式，可能还会有一些前端开发者不同意，觉得 HTTP 请求少一些总是好的。减少请求数量，最起码还减少了传输中耗费的 Headers。</p>
<p>这里我们必须要先承认一个事实，在 HTTP 传输中，Headers 占传输成本的比重是相当地大，对于许多小资源，甚至可能出现 Headers 的容量比 Body 的还要大，以至于在 HTTP/2 中必须专门考虑如何进行 Header 压缩的问题。</p>
<p>但实际上，有这样几个因素，就决定了即使是通过合并资源文件来减少请求数，对节省 Headers 成本来说，也并没有太大的帮助：</p>
<ul>
<li>Header 的传输成本在 Ajax（尤其是只返回少量数据的请求）请求中可能是比重很大的开销，但在图片、样式、脚本这些 <strong>静态资源的请求中，一般并不占主要比重。</strong></li>
<li>在 HTTP/2 中，Header 压缩的原理是基于字典编码的信息复用，简而言之是同一个连接上产生的请求和响应越多，动态字典积累得越全，头部压缩效果也就越好。所以， <strong>HTTP/2 是单域名单连接的机制</strong> ，合并资源和域名分片反而对性能提升不利。</li>
<li>与 HTTP/1.x 相反，HTTP/2 本身反而变得 <strong>更适合传输小资源</strong> 了，比如传输 1000 张 10K 的小图，HTTP/2 要比 HTTP/1.x 快，但传输 10 张 1000K 的大图，则应该 HTTP/1.x 会更快。这其中有 TCP 连接数量（相当于多点下载）的影响，更多的是由于 TCP 协议 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Reliable_transmission">可靠传输机制</a> 导致的，一个错误的 TCP 包会导致所有的流都必须等待这个包重传成功，而这个问题就是 HTTP/3.0 要解决的目标了。因此，把小文件合并成大文件，在 HTTP/2 下是毫无好处的。</li>
</ul>
<h4 id="传输压缩"><a href="#传输压缩" class="headerlink" title="传输压缩"></a>传输压缩</h4><p>好，了解了 TCP 连接数的各种优化机制之后，我们再来讨论下，在链路优化中除缓存、连接之外的另一个重要话题： <strong>压缩</strong> 。同时，这也可以解决我们之前遗留的一个问题： <strong>如何不以断开 TCP 连接为标志，来判断资源已传输完毕？</strong></p>
<p>HTTP 很早就支持了 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Gzip">GZip</a> 压缩，因为 HTTP 传输的主要内容，比如 HTML、CSS、Script 等，主要是文本数据，因此对于文本数据启用压缩的收益是非常高的，传输数据量一般会降至原有的 20% 左右。而对于那些不适合压缩的资源，Web 服务器则能根据 MIME 类型，来自动判断是否对响应进行压缩。这样，对于已经采用过压缩算法存储的资源，比如 JPEG、PNG 图片，就不会被二次压缩，空耗性能了。</p>
<p>不过，大概没有多少人想过， <strong>压缩其实跟我们前面提到的，用于节约 TCP 的持久连接机制是存在冲突的。</strong></p>
<p>在网络时代的早期，服务器的处理能力还很薄弱，为了启用压缩，会把静态资源预先压缩为.gz 文件的形式给存放起来。当客户端可以接受压缩版本的资源时（请求的 Header 中包含 Accept-Encoding: gzip），就返回压缩后的版本（响应的 Header 中包含 Content-Encoding: gzip），否则就返回未压缩的原版。这种方式被称为” <a target="_blank" rel="noopener" href="http://nginx.org/en/docs/http/ngx_http_gzip_static_module.html">静态预压缩</a> “（Static Precompression）。</p>
<p>而现代的 Web 服务器处理能力有了大幅提升，已经没有人再采用这种麻烦的预压缩方式了，都是由服务器对符合条件的请求，在即将输出时进行” <a target="_blank" rel="noopener" href="https://www.usenix.org/legacy/publications/library/proceedings/jvm01/full_papers/hovemeyer/hovemeyer_html/node7.html">即时压缩</a> “（On-The-Fly Compression），整个压缩过程全部在内存的数据流中完成，不必等资源压缩完成再返回响应，这样可以显著提高” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Time_to_first_byte">首字节时间</a> “（Time To First Byte，TTFB），改善 Web 性能体验。</p>
<p>而这个过程中唯一不好的地方，就是 <strong>服务器再也没有办法给出 Content-Length 这个响应 Header</strong> 了。因为输出 Header 时，服务器还不知道压缩后资源的确切大小。</p>
<p>那看到这里，你想明白即时压缩与持久连接的冲突在哪了吗？</p>
<p>实际上，持久连接机制不再依靠 TCP 连接是否关闭，来判断资源请求是否结束了。它会重用同一个连接，以便向同一个域名请求多个资源。这样，客户端就必须要有除了关闭连接之外的其他机制，来判断一个资源什么时候才算是传递完毕。</p>
<p>这个机制最初（在 HTTP/1.0 时）就只有 Content-Length，即靠着请求 Header 中明确给出资源的长度，传输到达该长度即宣告一个资源的传输已经结束。不过，由于启用即时压缩后就无法给出 Content-Length 了，如果是 HTTP/1.0 的话，持久连接和即时压缩只能二选其一。事实上，在 HTTP/1.0 中这两者都支持，却默认都是不启用的。</p>
<p>另外，依靠 Content-Length 来判断传输结束的缺陷，不仅只有即时压缩这一种场景，对于动态内容（Ajax、PHP、JSP 等输出）等应用场景，服务器也同样无法事先得知 Content-Length。</p>
<p>不过，HTTP/1.1 版本中已经修复了这个缺陷，并 <strong>增加了另一种” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Chunked_transfer_encoding">分块传输编码</a> “（Chunked Transfer Encoding）的资源结束判断机制</strong> ，彻底解决了 Content-Length 与持久连接的冲突问题。</p>
<p>分块编码的工作原理相当简单：在响应 Header 中加入”Transfer-Encoding: chunked”之后，就代表这个响应报文将采用分块编码。此时，报文中的 Body 需要改为用一系列”分块”来传输。每个分块包含十六进制的长度值和对应长度的数据内容，长度值独占一行，数据从下一行开始。最后以一个长度值为 0 的分块，来表示资源结束。</p>
<p>给你举个具体的例子（例子来自于 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Chunked_transfer_encoding">维基百科</a> ，为便于观察，只分块，未压缩）：</p>
<pre class="line-numbers language-http" data-language="http"><code class="language-http"><span class="token response-status">HTTP/1.1 <span class="token property">200 OK</span></span>
<span class="token header-name keyword">Date:</span> Sat, 11 Apr 2020 04:44:00 GMT
<span class="token header-name keyword">Transfer-Encoding:</span> chunked
<span class="token header-name keyword">Connection:</span> keep-alive

25
This is the data in the first chunk

1C
and this is the second one

3
con

8
sequence

0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>根据分块长度就可以知道，前两个分块包含显式的回车换行符（CRLF，即\r\n 字符）</p>
<pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">"This is the data in the first chunk\r\n"      (37 字符 =&gt; 十六进制: 0x25)
"and this is the second one\r\n"               (28 字符 =&gt; 十六进制: 0x1C)
"con"                                          (3  字符 =&gt; 十六进制: 0x03)
"sequence"                                     (8  字符 =&gt; 十六进制: 0x08)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>所以解码后的内容为：</p>
<pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">This is the data in the first chunk
and this is the second one
consequence<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>另外，这里你要知道的是，一般来说，Web 服务器给出的数据分块大小应该（但并不强制）是一致的，而不是像这个例子一样随意。</p>
<p>HTTP/1.1 通过分块传输解决了即时压缩与持久连接并存的问题，到了 HTTP/2，由于多路复用和单域名单连接的设计，已经不需要再刻意去强调持久连接机制了，但数据压缩仍然有节约传输带宽的重要价值。</p>
<h4 id="快速-UDP-网络连接"><a href="#快速-UDP-网络连接" class="headerlink" title="快速 UDP 网络连接"></a>快速 UDP 网络连接</h4><p>OK，那么到这里，我们还需要明确一件事情，就是 HTTP 是应用层协议，而不是传输层协议，它的设计原本并不应该过多地考虑底层的传输细节。从职责上来讲，持久连接、多路复用、分块编码这些能力，已经或多或少超过了应用层的范畴。</p>
<p>所以说，要想从根本上改进 HTTP，就必须直接替换掉 HTTP over TCP 的根基，即 TCP 传输协议，这便是最新一代 HTTP/3 协议的设计重点。</p>
<p>推动替换 TCP 协议的先驱者并不是 IETF，而是 Google 公司。目前，世界上只有 Google 公司具有这样的能力，这并不是因为 Google 的技术实力雄厚，而是由于它同时持有着占浏览器市场 70% 份额的 Chrome 浏览器，与占移动领域半壁江山的 Android 操作系统。</p>
<p>2013 年，Google 在它的服务器（如 Google.com、YouTube.com 等）及 Chrome 浏览器上，同时启用了名为” <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/QUIC">快速 UDP 网络连接</a> “（Quick UDP Internet Connections，QUIC）的全新传输协议。</p>
<p>在 2015 年，Google 将 QUIC 提交给了 IETF，并在 IETF 的推动下，对 QUIC 进行重新规范化（为以示区别，业界习惯将此前的版本称为 gQUIC，规范化后的版本称为 iQUIC），使其不仅能满足 HTTP 传输协议，日后还能支持 SMTP、DNS、SSH、Telnet、NTP 等多种其他上层协议。</p>
<p>2018 年末，IETF 正式批准了 HTTP over QUIC 使用 HTTP/3 的版本号，将其确立为最新一代的互联网标准。</p>
<p>那么，你从 QUIC 的名字上就能看出，它会以 UDP 协议作为基础。UDP 协议没有丢包自动重传的特性，因此 QUIC 的可靠传输能力并不是由底层协议提供的，而是完全由自己来实现。 <strong>由 QUIC 自己实现的好处是能对每个流能做单独的控制</strong> ，如果在一个流中发生错误，协议栈仍然可以独立地继续为其他流提供服务。</p>
<p>这个特性对提高易出错链路的性能方面非常有用。因为在大多数情况下，TCP 协议接到数据包丢失或损坏通知之前，可能已经收到了大量的正确数据，但是在纠正错误之前，其他的正常请求都会等待甚至被重发。这也是前面我在讲连接数优化的时候，提到 HTTP/2 没能解决传输大文件慢的根本原因。</p>
<p>此外，QUIC 的另一个设计目标是 <strong>面向移动设备的专门支持。</strong></p>
<p>以前 TCP、UDP 传输协议在设计的时候，根本不可能设想到今天移动设备盛行的场景，因此肯定不会有任何专门的支持。 <strong>而 QUIC 在移动设备上的优势就体现在网络切换时的响应速度上</strong> ，比如当移动设备在不同 WiFi 热点之间切换，或者从 WiFi 切换到移动网络时，如果使用 TCP 协议，现存的所有连接都必定会超时、中断，然后根据需要重新创建。这个过程会带来很高的延迟，因为超时和重新握手都需要大量的时间。</p>
<p>为此，QUIC 提出了 <strong>连接标识符</strong> 的概念，该标识符可以唯一地标识客户端与服务器之间的连接，而无需依靠 IP 地址。这样，在切换网络后，只需向服务端发送一个包含此标识符的数据包，就可以重用既有的连接。因为即使用户的 IP 地址发生了变化，原始连接标识符依然是有效的。</p>
<p>到现在，无论是 TCP 协议还是 HTTP 协议，都已经存在了数十年的时间。它们积累了大量用户的同时，也承载了很重的技术惯性。就算是 Google 和 IETF，要是想把 HTTP 从 TCP 迁移出去，也不是件容易的事儿。最主要的一个问题就是，互联网基础设施中的许多中间设备，都只面向 TCP 协议去建造，也只对 UDP 做很基础的支持，有的甚至会完全阻止 UDP 的流量。</p>
<p>所以，Google 在 Chromium 的网络协议栈中，同时启用了 QUIC 和传统 TCP 连接，并在 QUIC 连接失败时，能以零延迟回退到 TCP 连接，尽可能让用户无感知地、逐步地扩大 QUIC 的使用面。</p>
<p>根据 <a target="_blank" rel="noopener" href="https://w3techs.com/technologies/overview/site_element">W3Techs</a> 的数据，截至 2020 年 10 月，全球已经有 48.9% 的网站支持了 HTTP/2 协议，按照维基百科中的记录，这个数字在 2019 年 6 月份的时候，还只是 36.5%。另外在 HTTP/3 方面，今天也已经有了 7.2% 的使用比例。</p>
<p>由此我们可以肯定地说，目前网络链路传输这个领域正处于新旧交替的时代，许多既有的设备、程序、知识，都会在未来几年的时间里出现重大更新。</p>
<h4 id="小结-14"><a href="#小结-14" class="headerlink" title="小结"></a>小结</h4><p>这节课，我们一起了解了 HTTP 传输的优化技巧。HTTP 的意思就是超文本传输协议，但它并不是只将内容顺利传输到客户端就算完成任务了，其中，如何做到高效、无状态也是很重要的目标。</p>
<p>另外你还要记住的是，在 HTTP/2 之前，要想在应用一侧优化传输，就必须要同时在其他方面付出相应的成本，而 HTTP/2 中的多路复用、头压缩等改进项，就从根本上给出了传输优化的解决方案。</p>
<h4 id="留言"><a href="#留言" class="headerlink" title="留言"></a>留言</h4><p>QUIC相对于TCP补充:</p>
<p>1.自定义重传机制:TCP是通过采样往返时间 RTT 不断调整的，但这个采样存在不准的问题。第一次发送包A超时未返回，第二次重发包A，这时收到了包A的响应，但TCP并不能识别当前包A的响应是第一次发送还是第二次重发返回的，这时不管怎么减都可能出现计时偏长或过偏短的问题。而QUIC为每次发送包都打了版本号（包括重发），所以可以很好的识别返回的包是那次发送包的。进而计算就相对准确。<br>2.自定义流量控制：TCP 的流量控制是通过滑动窗口协议，是在连接上控制的窗口。QUIC也玩滑动窗口，但是力度是可以细分到具体的stream的。</p>
<p>其实应用层的协议多种多样，直播的RTMP，物联网终端的MQTT等等，但感觉都是两害取其轻的专项优化对症下药。只有QUIC，直面TCP的问题，通过应用层的编码实现，系统的提供更好的”TCP连接”。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kibazen.cn" rel="external nofollow noreferrer">Kiba Amor</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                    </span>
                <span class="reprint-info">
                    <a href="https://kibazen.cn/zhou-zhi-ming-de-ruan-jian-jia-gou-ke-xue-xi-bi-ji-shang/">https://kibazen.cn/zhou-zhi-ming-de-ruan-jian-jia-gou-ke-xue-xi-bi-ji-shang/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY-NC-ND 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://kibazen.cn" target="_blank">Kiba Amor</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">
                                    <span class="chip bg-color">极客时间</span>
                                </a>
                            
                                <a href="/tags/%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84/">
                                    <span class="chip bg-color">软件架构</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="qq,wechat,weibo,douban" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/zhou-zhi-ming-de-ruan-jian-jia-gou-ke-xue-xi-bi-ji-shang/">
                    <div class="card-image">
                        
                        
                        <img src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/featureimages/16.jpg" class="responsive-img" alt="《周志明的软件架构课》学习笔记（上）">
                        
                        <span class="card-title">《周志明的软件架构课》学习笔记（上）</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-03-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-category">
                                    学习笔记
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">
                        <span class="chip bg-color">极客时间</span>
                    </a>
                    
                    <a href="/tags/%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84/">
                        <span class="chip bg-color">软件架构</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/rong-qi-shi-zhan-gao-shou-ke-xue-xi-bi-ji/">
                    <div class="card-image">
                        
                        
                        <img src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/featureimages/17.jpg" class="responsive-img" alt="《容器实战高手课》学习笔记">
                        
                        <span class="card-title">《容器实战高手课》学习笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-09-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-category">
                                    学习笔记
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">
                        <span class="chip bg-color">极客时间</span>
                    </a>
                    
                    <a href="/tags/docker/">
                        <span class="chip bg-color">docker</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (true) {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: 木叶禅<br />'
            + '文章作者: Kiba Amor<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者木叶禅所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('2'),
            headingSelector: 'h2, h3, h4, h5'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4, h5').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2023</span>
            
            <span id="year">2019</span>
            <a href="/about" target="_blank">Kiba Amor</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">1420.2k</span>&nbsp;字
            
            
            
            
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link ">
    <a href="https://github.com/kibaamor" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>









    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=562236616" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 562236616" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/kibaamor" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kibaamor" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    

    

    

	
    

    

    

    
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
