<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="keywords" content="《Linux性能优化实战》学习笔记, kiba, zen, amor, kibazen, kibaamor, 木叶, 木叶禅">
    <meta name="description" content="一个普通游戏程序员的博客">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>《Linux性能优化实战》学习笔记 | 木叶禅</title>
    <link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/favicon.png">

    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/css/my.css">

    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="木叶禅" type="application/atom+xml">
</head>



   <style>
    body{
       background-image: url(/medias/background.jpg);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>



<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">木叶禅</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/leetcode/" class="waves-effect waves-light">
      
      <i class="fas fa-code" style="zoom: 0.6;"></i>
      
      <span>LeetCode</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/learn/" class="waves-effect waves-light">
      
      <i class="fas fa-book" style="zoom: 0.6;"></i>
      
      <span>学习</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/softwares/" class="waves-effect waves-light">
      
      <i class="fas fa-toolbox" style="zoom: 0.6;"></i>
      
      <span>软件</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories/" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags/" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about/" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">木叶禅</div>
        <div class="logo-desc">
            
            一个普通游戏程序员的博客
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/leetcode/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-code"></i>
			
			LeetCode
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/learn/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-book"></i>
			
			学习
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/softwares/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-toolbox"></i>
			
			软件
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    
<script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = 'f65e070788a2647953051a7a1b70ada7fd2b3f70cd4d93c977207f5b762987d4';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/featureimages/7.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">《Linux性能优化实战》学习笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/">
                                <span class="chip bg-color">性能分析</span>
                            </a>
                        
                            <a href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">
                                <span class="chip bg-color">极客时间</span>
                            </a>
                        
                            <a href="/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">
                                <span class="chip bg-color">性能优化</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-category">
                                学习笔记
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-11-04
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2021-11-06
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    102.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    401 分
                </div>
                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="01-开篇词"><a href="#01-开篇词" class="headerlink" title="01-开篇词"></a><strong>01-开篇词</strong></h2><h3 id="01-如何学习Linux性能优化？"><a href="#01-如何学习Linux性能优化？" class="headerlink" title="01 | 如何学习Linux性能优化？"></a>01 | 如何学习Linux性能优化？</h3><h4 id="1-1-性能指标是什么？"><a href="#1-1-性能指标是什么？" class="headerlink" title="1.1 性能指标是什么？"></a>1.1 性能指标是什么？</h4><p>性能分析，其实就是找出应用或系统的瓶颈，并设法去避免或者缓解它们，从而更高效地利用系统资源处理更多的请求。这包含了一系列的步骤，比如下面这六个步骤：</p>
<ol>
<li>选择指标评估应用程序和系统的性能；</li>
<li>为应用程序和系统设置性能目标；</li>
<li>进行性能基准测试；</li>
<li>性能分析定位瓶颈；</li>
<li>优化系统和应用程序；</li>
<li>性能监控和告警。</li>
</ol>
<h4 id="1-2-学习的重点是什么？"><a href="#1-2-学习的重点是什么？" class="headerlink" title="1.2 学习的重点是什么？"></a>1.2 学习的重点是什么？</h4><p>想要学习好性能分析和优化，建立整体系统性能的全局观是最核心的话题。因而，</p>
<ul>
<li>理解最基本的几个系统知识原理；</li>
<li>掌握必要的性能工具；</li>
<li>通过实际的场景演练，贯穿不同的组件。</li>
</ul>
<p>千万不要把性能工具当成学习的全部。工具只是解决问题的手段，关键在于你的用法。只有真正理解了它们背后的原理，并且结合具体场景，融会贯通系统的不同组件，你才能真正掌握它们。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/Linux性能优化实战思维导图.png" alt="Linux性能优化实战思维导图"></p>
<h4 id="1-3-怎么学更高效？"><a href="#1-3-怎么学更高效？" class="headerlink" title="1.3 怎么学更高效？"></a>1.3 怎么学更高效？</h4><ul>
<li>虽然系统的原理很重要，但在刚开始一定不要试图抓住所有的实现细节。</li>
<li>边学边实践，通过大量的案例演习掌握 Linux 性能的分析和优化。</li>
<li>勤思考，多反思，善总结，多问为什么。</li>
</ul>
<h2 id="02-CPU-性能篇"><a href="#02-CPU-性能篇" class="headerlink" title="02-CPU 性能篇"></a><strong>02-CPU 性能篇</strong></h2><h3 id="02-基础篇：到底应该怎么理解“平均负载”？"><a href="#02-基础篇：到底应该怎么理解“平均负载”？" class="headerlink" title="02 | 基础篇：到底应该怎么理解“平均负载”？"></a>02 | 基础篇：到底应该怎么理解“平均负载”？</h3><h4 id="2-1-平均负载"><a href="#2-1-平均负载" class="headerlink" title="2.1 平均负载"></a>2.1 平均负载</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">uptime</span>
02:34:03 up <span class="token number">2</span> days, <span class="token number">20</span>:14,  <span class="token number">1</span> user,  load average: <span class="token number">0.63</span>, <span class="token number">0.83</span>, <span class="token number">0.88</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>输出结果分别是：系统当前时间、系统运行时间、登录用户数、系统过去 1 分钟、5 分钟、15 分钟的平均负载（Load Average）。</p>
<p>关于平均负载的解释可以查看 <code>man uptime</code>。</p>
<p>平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数。</p>
<ul>
<li>可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。</li>
<li>不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。<blockquote>
<p>比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。<br>不可中断状态实际上是系统对进程和硬件设备的一种保护机制。</p>
</blockquote>
</li>
</ul>
<p>可以简单理解为，平均负载其实就是平均活跃进程数。平均活跃进程数，直观上的理解就是单位时间内的活跃进程数，但它实际上是活跃进程数的指数衰减平均值。</p>
<h4 id="2-2-平均负载为多少时合理"><a href="#2-2-平均负载为多少时合理" class="headerlink" title="2.2 平均负载为多少时合理"></a>2.2 平均负载为多少时合理</h4><p>平均负载最理想的情况是等于 CPU 个数。</p>
<p>分析系统负载趋势：</p>
<ul>
<li>如果 1 分钟、5 分钟、15 分钟的三个值基本相同，或者相差不大，那就说明系统负载很平稳。</li>
<li>但如果 1 分钟的值远小于 15 分钟的值，就说明系统最近 1 分钟的负载在减少，而过去 15 分钟内却有很大的负载。</li>
<li>反过来，如果 1 分钟的值远大于 15 分钟的值，就说明最近 1 分钟的负载在增加，这种增加有可能只是临时性的，也有可能还会持续增加下去，所以就需要持续观察。一旦 1 分钟的平均负载接近或超过了 CPU 的个数，就意味着系统正在发生过载的问题，这时就得分析调查是哪里导致的问题，并要想办法优化了。</li>
</ul>
<p>在实际生产环境中，当平均负载高于 CPU 数量 70% 的时候，就应该分析排查负载高的问题了。</p>
<h4 id="2-3-平均负载与-CPU-使用率"><a href="#2-3-平均负载与-CPU-使用率" class="headerlink" title="2.3 平均负载与 CPU 使用率"></a>2.3 平均负载与 CPU 使用率</h4><p>平均负载是指单位时间内，处于可运行状态和不可中断状态的进程数。所以，它不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待 I/O 的进程。</p>
<p>CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如：</p>
<ul>
<li>CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的；</li>
<li>I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高；</li>
<li>大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高。</li>
</ul>
<h4 id="2-4-平均负载案例分析"><a href="#2-4-平均负载案例分析" class="headerlink" title="2.4 平均负载案例分析"></a>2.4 平均负载案例分析</h4><blockquote>
<p>机器配置：2 CPU，8GB 内存。</p>
<p>安装软件：<code>apt install stress sysstat</code>。</p>
</blockquote>
<p>观察测试前的平均负载</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">uptime</span>
<span class="token punctuation">..</span>.,  load average: <span class="token number">0.11</span>, <span class="token number">0.15</span>, <span class="token number">0.09</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<ol>
<li><p>场景一：CPU 密集型进程</p>
<ol>
<li><p>模拟高 CPU 使用率</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ stress --cpu <span class="token number">1</span> --timeout <span class="token number">600</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>在第二个终端运行 uptime 查看平均负载的变化情况</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -d 参数表示高亮显示变化的区域</span>
$ <span class="token function">watch</span> -d <span class="token function">uptime</span>
<span class="token punctuation">..</span>.,  load average: <span class="token number">1.00</span>, <span class="token number">0.75</span>, <span class="token number">0.39</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li><p>在第三个终端运行 mpstat 查看 CPU 使用率的变化情况</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据</span>
$ mpstat -P ALL <span class="token number">5</span>
Linux <span class="token number">4.15</span>.0 <span class="token punctuation">(</span>ubuntu<span class="token punctuation">)</span> 09/22/18 _x86_64_ <span class="token punctuation">(</span><span class="token number">2</span> CPU<span class="token punctuation">)</span>
<span class="token number">13</span>:30:06     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
<span class="token number">13</span>:30:11     all   <span class="token number">50.05</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">49.95</span>
<span class="token number">13</span>:30:11       <span class="token number">0</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>  <span class="token number">100.00</span>
<span class="token number">13</span>:30:11       <span class="token number">1</span>  <span class="token number">100.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 可以看到，1 分钟的平均负载会慢慢增加到 1.00，而从终端三中还可以看到，正好有一个 CPU 的使用率为 100%，但它的 iowait 只有 0。这说明，平均负载的升高正是由于 CPU 使用率为 100% 。</p>
</li>
<li><p>到底是哪个进程导致了 CPU 使用率为 100% 呢？你可以使用 pidstat 来查询</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 间隔 5 秒后输出一组数据</span>
$ pidstat -u <span class="token number">5</span> <span class="token number">1</span>
<span class="token number">13</span>:37:07      <span class="token environment constant">UID</span>       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
<span class="token number">13</span>:37:12        <span class="token number">0</span>      <span class="token number">2962</span>  <span class="token number">100.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>  <span class="token number">100.00</span>     <span class="token number">1</span>  stress<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 可以明显看到，stress 进程的 CPU 使用率为 100%。</p>
</li>
</ol>
</li>
<li><p>场景二：I/O 密集型进程</p>
<ol>
<li><p>模拟 I/O 压力，即不停地执行 sync</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">stress -i <span class="token number">1</span> --timeout <span class="token number">600</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>在第二个终端运行 uptime 查看平均负载的变化情况</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">watch</span> -d <span class="token function">uptime</span>
<span class="token punctuation">..</span>.,  load average: <span class="token number">1.06</span>, <span class="token number">0.58</span>, <span class="token number">0.37</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>在第三个终端运行 mpstat 查看 CPU 使用率的变化情况</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 显示所有 CPU 的指标，并在间隔 5 秒输出一组数据</span>
$ mpstat -P ALL <span class="token number">5</span> <span class="token number">1</span>
Linux <span class="token number">4.15</span>.0 <span class="token punctuation">(</span>ubuntu<span class="token punctuation">)</span>     09/22/18     _x86_64_    <span class="token punctuation">(</span><span class="token number">2</span> CPU<span class="token punctuation">)</span>
<span class="token number">13</span>:41:28     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
<span class="token number">13</span>:41:33     all    <span class="token number">0.21</span>    <span class="token number">0.00</span>   <span class="token number">12.07</span>   <span class="token number">32.67</span>    <span class="token number">0.00</span>    <span class="token number">0.21</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">54.84</span>
<span class="token number">13</span>:41:33       <span class="token number">0</span>    <span class="token number">0.43</span>    <span class="token number">0.00</span>   <span class="token number">23.87</span>   <span class="token number">67.53</span>    <span class="token number">0.00</span>    <span class="token number">0.43</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">7.74</span>
<span class="token number">13</span>:41:33       <span class="token number">1</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.81</span>    <span class="token number">0.20</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">98.99</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 可以看到，1 分钟的平均负载会慢慢增加到 1.06，其中一个 CPU 的系统 CPU 使用率升高到了 23.87，而 iowait 高达 67.53%。这说明，平均负载的升高是由于 iowait 的升高。</p>
</li>
<li><p>那么到底是哪个进程，导致 iowait 这么高呢？用 pidstat 来查询</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 间隔 5 秒后输出一组数据，-u 表示 CPU 指标</span>
$ pidstat -u <span class="token number">5</span> <span class="token number">1</span>
Linux <span class="token number">4.15</span>.0 <span class="token punctuation">(</span>ubuntu<span class="token punctuation">)</span>     09/22/18     _x86_64_    <span class="token punctuation">(</span><span class="token number">2</span> CPU<span class="token punctuation">)</span>
<span class="token number">13</span>:42:08      <span class="token environment constant">UID</span>       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
<span class="token number">13</span>:42:13        <span class="token number">0</span>       <span class="token number">104</span>    <span class="token number">0.00</span>    <span class="token number">3.39</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">3.39</span>     <span class="token number">1</span>  kworker/1:1H
<span class="token number">13</span>:42:13        <span class="token number">0</span>       <span class="token number">109</span>    <span class="token number">0.00</span>    <span class="token number">0.40</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.40</span>     <span class="token number">0</span>  kworker/0:1H
<span class="token number">13</span>:42:13        <span class="token number">0</span>      <span class="token number">2997</span>    <span class="token number">2.00</span>   <span class="token number">35.53</span>    <span class="token number">0.00</span>    <span class="token number">3.99</span>   <span class="token number">37.52</span>     <span class="token number">1</span>  stress
<span class="token number">13</span>:42:13        <span class="token number">0</span>      <span class="token number">3057</span>    <span class="token number">0.00</span>    <span class="token number">0.40</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.40</span>     <span class="token number">0</span>  pidstat<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 可以发现，还是 stress 进程导致的。</p>
</li>
</ol>
</li>
<li><p>场景三：大量进程的场景</p>
<p> 当系统中运行进程超出 CPU 运行能力时，就会出现等待 CPU 的进程。</p>
<ol>
<li><p>使用 stress 模拟的是 8 个进程</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ stress -c <span class="token number">8</span> --timeout <span class="token number">600</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>由于系统只有 2 个 CPU，明显比 8 个进程要少得多，因而，系统的 CPU 处于严重过载状态，平均负载高达 7.97。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">uptime</span>
<span class="token punctuation">..</span>.,  load average: <span class="token number">7.97</span>, <span class="token number">5.93</span>, <span class="token number">3.02</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>接着再运行 pidstat 来看一下进程的情况</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 间隔 5 秒后输出一组数据</span>
$ pidstat -u <span class="token number">5</span> <span class="token number">1</span>
<span class="token number">14</span>:23:25      <span class="token environment constant">UID</span>       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
<span class="token number">14</span>:23:30        <span class="token number">0</span>      <span class="token number">3190</span>   <span class="token number">25.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">74.80</span>   <span class="token number">25.00</span>     <span class="token number">0</span>  stress
<span class="token number">14</span>:23:30        <span class="token number">0</span>      <span class="token number">3191</span>   <span class="token number">25.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">75.20</span>   <span class="token number">25.00</span>     <span class="token number">0</span>  stress
<span class="token number">14</span>:23:30        <span class="token number">0</span>      <span class="token number">3192</span>   <span class="token number">25.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">74.80</span>   <span class="token number">25.00</span>     <span class="token number">1</span>  stress
<span class="token number">14</span>:23:30        <span class="token number">0</span>      <span class="token number">3193</span>   <span class="token number">25.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">75.00</span>   <span class="token number">25.00</span>     <span class="token number">1</span>  stress
<span class="token number">14</span>:23:30        <span class="token number">0</span>      <span class="token number">3194</span>   <span class="token number">24.80</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">74.60</span>   <span class="token number">24.80</span>     <span class="token number">0</span>  stress
<span class="token number">14</span>:23:30        <span class="token number">0</span>      <span class="token number">3195</span>   <span class="token number">24.80</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">75.00</span>   <span class="token number">24.80</span>     <span class="token number">0</span>  stress
<span class="token number">14</span>:23:30        <span class="token number">0</span>      <span class="token number">3196</span>   <span class="token number">24.80</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">74.60</span>   <span class="token number">24.80</span>     <span class="token number">1</span>  stress
<span class="token number">14</span>:23:30        <span class="token number">0</span>      <span class="token number">3197</span>   <span class="token number">24.80</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">74.80</span>   <span class="token number">24.80</span>     <span class="token number">1</span>  stress
<span class="token number">14</span>:23:30        <span class="token number">0</span>      <span class="token number">3200</span>    <span class="token number">0.00</span>    <span class="token number">0.20</span>    <span class="token number">0.00</span>    <span class="token number">0.20</span>    <span class="token number">0.20</span>     <span class="token number">0</span>  pidstat<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 可以看出，8 个进程在争抢 2 个 CPU，每个进程等待 CPU 的时间（也就是代码块中的 %wait 列）高达 75%。这些超出 CPU 计算能力的进程，最终导致 CPU 过载。</p>
</li>
</ol>
</li>
</ol>
<h4 id="2-5-小结"><a href="#2-5-小结" class="headerlink" title="2.5 小结"></a>2.5 小结</h4><p>平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但只看平均负载本身，我们并不能直接发现，到底是哪里出现了瓶颈。所以，在理解平均负载时，也要注意：</p>
<ul>
<li>平均负载高有可能是 CPU 密集型进程导致的；</li>
<li>平均负载高并不一定代表 CPU 使用率高，还有可能是 I/O 更繁忙了；</li>
<li>当发现负载高的时候，你可以使用 mpstat、pidstat 等工具，辅助分析负载的来源。</li>
</ul>
<h3 id="03-基础篇：经常说的-CPU-上下文切换是什么意思？（上）"><a href="#03-基础篇：经常说的-CPU-上下文切换是什么意思？（上）" class="headerlink" title="03 | 基础篇：经常说的 CPU 上下文切换是什么意思？（上）"></a>03 | 基础篇：经常说的 CPU 上下文切换是什么意思？（上）</h3><p>进程在竞争 CPU 的时候并没有真正运行，但是 CPU 上下文切换会导致系统的负载升高。</p>
<p>根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景，也就是进程上下文切换、线程上下文切换以及中断上下文切换。</p>
<h4 id="3-1-进程上下文切换"><a href="#3-1-进程上下文切换" class="headerlink" title="3.1 进程上下文切换"></a>3.1 进程上下文切换</h4><ol>
<li><p>系统调用</p>
<p> 系统调用的过程会发生 CPU 上下文。</p>
<p> CPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。</p>
<p> 而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。所以，一次系统调用的过程，其实是发生了两次 CPU 上下文切换。</p>
<p> 需要注意的是，系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程。这跟我们通常所说的进程上下文切换是不一样的：</p>
<ul>
<li>进程上下文切换，是指从一个进程切换到另一个进程运行。</li>
<li><p>而系统调用过程中一直是同一个进程在运行。</p>
<p><strong>所以，系统调用过程通常称为特权模式切换，而不是上下文切换。</strong></p>
</li>
</ul>
</li>
<li><p>进程上下文切换跟系统调用又有什么区别呢？</p>
<p> 进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。</p>
<p> 因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/进程上下文切换.png" alt="进程上下文切换"></p>
<p> 根据 <a target="_blank" rel="noopener" href="https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html">How long does it take to make a context switch?</a> 的测试报告，每次上下文切换都需要几十纳秒到数微秒的 CPU 时间。</p>
<p> 另外， Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。</p>
</li>
<li><p>进程在什么时候才会被调度到 CPU 上运行呢？</p>
<ol>
<li>进程执行完终止了，它之前使用的 CPU 会释放出来，这个时候再从就绪队列里，拿一个新的进程过来运行。</li>
<li>当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。</li>
<li>进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。</li>
<li>当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度。</li>
<li>当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行。</li>
<li>发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。</li>
</ol>
</li>
</ol>
<h4 id="3-2-线程上下文切换"><a href="#3-2-线程上下文切换" class="headerlink" title="3.2 线程上下文切换"></a>3.2 线程上下文切换</h4><p>线程与进程最大的区别在于，<strong>线程是调度的基本单位，而进程则是资源拥有的基本单位</strong> 。内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。所以，对于线程和进程，可以这么理解：</p>
<ul>
<li>当进程只有一个线程时，可以认为进程就等于线程。</li>
<li>当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。</li>
<li>另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。</li>
</ul>
<p>这么一来，线程的上下文切换其实就可以分为两种情况：</p>
<ol>
<li>前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。</li>
<li>前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。</li>
</ol>
<p>虽然同为上下文切换，但同进程内的线程切换，要比多进程间的切换消耗更少的资源，而这，也正是多线程代替多进程的一个优势。</p>
<h4 id="3-3-中断上下文切换"><a href="#3-3-中断上下文切换" class="headerlink" title="3.3 中断上下文切换"></a>3.3 中断上下文切换</h4><p>为了快速响应硬件的事件，<strong>中断处理会打断进程的正常调度和执行</strong>，转而调用中断处理程序，响应设备事件。</p>
<p>跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。</p>
<p>对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以中断上下文切换并不会与进程上下文切换同时发生。</p>
<h3 id="04-基础篇：经常说的-CPU-上下文切换是什么意思？（下）"><a href="#04-基础篇：经常说的-CPU-上下文切换是什么意思？（下）" class="headerlink" title="04 | 基础篇：经常说的 CPU 上下文切换是什么意思？（下）"></a>04 | 基础篇：经常说的 CPU 上下文切换是什么意思？（下）</h3><h4 id="4-1-怎么查看系统的上下文切换情况"><a href="#4-1-怎么查看系统的上下文切换情况" class="headerlink" title="4.1 怎么查看系统的上下文切换情况"></a>4.1 怎么查看系统的上下文切换情况</h4><ol>
<li><p>查看系统总体的上下文切换情况</p>
<p> vmstat 是一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 每隔 5 秒输出 1 组数据</span>
$ <span class="token function">vmstat</span> <span class="token number">5</span>
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   <span class="token function">free</span>   buff  cache   si   so    bi    bo   <span class="token keyword">in</span>   cs us sy <span class="token function">id</span> wa st
 <span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">7005360</span>  <span class="token number">91564</span> <span class="token number">818900</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>     <span class="token number">0</span>   <span class="token number">25</span>   <span class="token number">33</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">100</span>  <span class="token number">0</span>  <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 特别关注下面几列信息：</p>
<ul>
<li>cs（context switch）是每秒上下文切换的次数。</li>
<li>in（interrupt）则是每秒中断的次数。</li>
<li>r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。</li>
<li>b（Blocked）则是处于不可中断睡眠状态的进程数。</li>
</ul>
</li>
<li><p>查看每个进程的上下文切换情况</p>
<p> vmstat 只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，就需要使用我们前面提到过的 pidstat 了。给它加上 -w 选项，你就可以查看每个进程上下文切换的情况了。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 每隔 5 秒输出 1 组数据</span>
$ pidstat -w <span class="token number">5</span>
Linux <span class="token number">4.15</span>.0 <span class="token punctuation">(</span>ubuntu<span class="token punctuation">)</span>  09/23/18  _x86_64_  <span class="token punctuation">(</span><span class="token number">2</span> CPU<span class="token punctuation">)</span>

08:18:26      <span class="token environment constant">UID</span>       PID   cswch/s nvcswch/s  Command
08:18:31        <span class="token number">0</span>         <span class="token number">1</span>      <span class="token number">0.20</span>      <span class="token number">0.00</span>  systemd
08:18:31        <span class="token number">0</span>         <span class="token number">8</span>      <span class="token number">5.40</span>      <span class="token number">0.00</span>  rcu_sched
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 特别关注下面几列信息：</p>
<ul>
<li>cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数。</li>
<li><p>nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。</p>
<p>它们会反应出不同的性能问题：</p>
</li>
<li><p>自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。</p>
</li>
<li>非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。</li>
</ul>
</li>
</ol>
<h4 id="4-2-案例分析"><a href="#4-2-案例分析" class="headerlink" title="4.2 案例分析"></a>4.2 案例分析</h4><blockquote>
<p>机器配置： 2 CPU, 8 GB 内存。</p>
<p>安装软件：<code>apt install sysbench sysstat</code>。</p>
</blockquote>
<p>先用 vmstat 看一下空闲系统的上下文切换次数</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 间隔 1 秒后输出 1 组数据</span>
$ <span class="token function">vmstat</span> <span class="token number">1</span> <span class="token number">1</span>
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   <span class="token function">free</span>   buff  cache   si   so    bi    bo   <span class="token keyword">in</span>   cs us sy <span class="token function">id</span> wa st
 <span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6984064</span>  <span class="token number">92668</span> <span class="token number">830896</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">2</span>    <span class="token number">19</span>   <span class="token number">19</span>   <span class="token number">35</span>  <span class="token number">1</span>  <span class="token number">0</span> <span class="token number">99</span>  <span class="token number">0</span>  <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以看到，现在的上下文切换次数 cs 是 35，而中断次数 in 是 19，r 和 b 都是 0。因为这会儿没有运行其他任务，所以它们就是空闲系统的上下文切换次数。</p>
<ol>
<li><p>在第一个终端里运行 sysbench ，模拟系统多线程调度的瓶颈</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 以 10 个线程运行 5 分钟的基准测试，模拟多线程切换的问题</span>
$ sysbench --threads<span class="token operator">=</span><span class="token number">10</span> --max-time<span class="token operator">=</span><span class="token number">300</span> threads run<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>在第二个终端运行 vmstat ，观察上下文切换情况</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 每隔 1 秒输出 1 组数据（需要 Ctrl+C 才结束）</span>
$ <span class="token function">vmstat</span> <span class="token number">1</span>
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
r  b   swpd   <span class="token function">free</span>   buff  cache   si   so    bi    bo   <span class="token keyword">in</span>   cs us sy <span class="token function">id</span> wa st
<span class="token number">6</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6487428</span> <span class="token number">118240</span> <span class="token number">1292772</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>     <span class="token number">0</span> <span class="token number">9019</span> <span class="token number">1398830</span> <span class="token number">16</span> <span class="token number">84</span>  <span class="token number">0</span>  <span class="token number">0</span>  <span class="token number">0</span>
<span class="token number">8</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6487428</span> <span class="token number">118240</span> <span class="token number">1292772</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>     <span class="token number">0</span> <span class="token number">10191</span> <span class="token number">1392312</span> <span class="token number">16</span> <span class="token number">84</span>  <span class="token number">0</span>  <span class="token number">0</span>  <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 可以发现，cs 列的上下文切换次数从之前的 35 骤然上升到了 139 万。同时，注意观察其他几个指标：</p>
<ul>
<li>r 列：就绪队列的长度已经到了 8，远远超过了系统 CPU 的个数 2，所以肯定会有大量的 CPU 竞争。</li>
<li>us（user）和 sy（system）列：这两列的 CPU 使用率加起来上升到了 100%，其中系统 CPU 使用率，也就是 sy 列高达 84%，说明 CPU 主要是被内核占用了。</li>
<li><p>in 列：中断次数也上升到了 1 万左右，说明中断处理也是个潜在的问题。</p>
<p>综合这几个指标，我们可以知道，系统的就绪队列过长，也就是正在运行和等待 CPU 的进程数过多，导致了大量的上下文切换，而上下文切换又导致了系统 CPU 的占用率升高。</p>
<p>那么到底是什么进程导致了这些问题呢？</p>
</li>
</ul>
</li>
<li><p>在第三个终端再用 pidstat 来看一下， CPU 和进程上下文切换的情况</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 每隔 1 秒输出 1 组数据（需要 Ctrl+C 才结束）</span>
<span class="token comment"># -w 参数表示输出进程切换指标，而 -u 参数则表示输出 CPU 使用指标</span>
$ pidstat -w -u <span class="token number">1</span>
08:06:33      <span class="token environment constant">UID</span>       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
08:06:34        <span class="token number">0</span>     <span class="token number">10488</span>   <span class="token number">30.00</span>  <span class="token number">100.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>  <span class="token number">100.00</span>     <span class="token number">0</span>  sysbench
08:06:34        <span class="token number">0</span>     <span class="token number">26326</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>     <span class="token number">0</span>  kworker/u4:2

08:06:33      <span class="token environment constant">UID</span>       PID   cswch/s nvcswch/s  Command
08:06:34        <span class="token number">0</span>         <span class="token number">8</span>     <span class="token number">11.00</span>      <span class="token number">0.00</span>  rcu_sched
08:06:34        <span class="token number">0</span>        <span class="token number">16</span>      <span class="token number">1.00</span>      <span class="token number">0.00</span>  ksoftirqd/1
08:06:34        <span class="token number">0</span>       <span class="token number">471</span>      <span class="token number">1.00</span>      <span class="token number">0.00</span>  hv_balloon
08:06:34        <span class="token number">0</span>      <span class="token number">1230</span>      <span class="token number">1.00</span>      <span class="token number">0.00</span>  iscsid
08:06:34        <span class="token number">0</span>      <span class="token number">4089</span>      <span class="token number">1.00</span>      <span class="token number">0.00</span>  kworker/1:5
08:06:34        <span class="token number">0</span>      <span class="token number">4333</span>      <span class="token number">1.00</span>      <span class="token number">0.00</span>  kworker/0:3
08:06:34        <span class="token number">0</span>     <span class="token number">10499</span>      <span class="token number">1.00</span>    <span class="token number">224.00</span>  pidstat
08:06:34        <span class="token number">0</span>     <span class="token number">26326</span>    <span class="token number">236.00</span>      <span class="token number">0.00</span>  kworker/u4:2
08:06:34     <span class="token number">1000</span>     <span class="token number">26784</span>    <span class="token number">223.00</span>      <span class="token number">0.00</span>  sshd<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从 pidstat 的输出你可以发现，CPU 使用率的升高果然是 sysbench 导致的，它的 CPU 使用率已经达到了 100%。但上下文切换则是来自其他进程，包括非自愿上下文切换频率最高的 pidstat ，以及自愿上下文切换频率最高的内核线程 kworker 和 sshd。</p>
<p> 不过，细心的你肯定也发现了一个怪异的事儿：pidstat 输出的上下文切换次数，加起来也就几百，比 vmstat 的 139 万明显小了太多。</p>
<p> 通过运行 man pidstat ，你会发现，pidstat 默认显示进程的指标数据，加上 -t 参数后，才会输出线程的指标。</p>
<p> 所以，在第三个终端里， Ctrl+C 停止刚才的 pidstat 命令，再加上 -t 参数，重试一下看看：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 每隔 1 秒输出一组数据（需要 Ctrl+C 才结束）</span>
<span class="token comment"># -wt 参数表示输出线程的上下文切换指标</span>
$ pidstat -wt <span class="token number">1</span>
08:14:05      <span class="token environment constant">UID</span>      TGID       TID   cswch/s nvcswch/s  Command
<span class="token punctuation">..</span>.
08:14:05        <span class="token number">0</span>     <span class="token number">10551</span>         -      <span class="token number">6.00</span>      <span class="token number">0.00</span>  sysbench
08:14:05        <span class="token number">0</span>         -     <span class="token number">10551</span>      <span class="token number">6.00</span>      <span class="token number">0.00</span>  <span class="token operator">|</span>__sysbench
08:14:05        <span class="token number">0</span>         -     <span class="token number">10552</span>  <span class="token number">18911.00</span> <span class="token number">103740.00</span>  <span class="token operator">|</span>__sysbench
08:14:05        <span class="token number">0</span>         -     <span class="token number">10553</span>  <span class="token number">18915.00</span> <span class="token number">100955.00</span>  <span class="token operator">|</span>__sysbench
08:14:05        <span class="token number">0</span>         -     <span class="token number">10554</span>  <span class="token number">18827.00</span> <span class="token number">103954.00</span>  <span class="token operator">|</span>__sysbench
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 现在你就能看到了，虽然 sysbench 进程（也就是主线程）的上下文切换次数看起来并不多，但它的子线程的上下文切换次数却有很多。看来，上下文切换罪魁祸首，还是过多的 sysbench 线程。</p>
<p> 在观察系统指标时，除了上下文切换频率骤然升高，还有一个指标也有很大的变化。是的，正是中断次数。中断次数也上升到了 1 万，但到底是什么类型的中断上升了？</p>
<p> 既然是中断，我们都知道，它只发生在内核态，而 pidstat 只是一个进程的性能分析工具，并不提供任何关于中断的详细信息，怎样才能知道中断发生的类型呢？</p>
<p> 没错，那就是从 /proc/interrupts 这个只读文件中读取。/proc 实际上是 Linux 的一个虚拟文件系统，用于内核空间与用户空间之间的通信。/proc/interrupts 就是这种通信机制的一部分，提供了一个只读的中断使用情况。</p>
<p> 在第三个终端里， Ctrl+C 停止刚才的 pidstat 命令，然后运行下面的命令，观察中断的变化情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -d 参数表示高亮显示变化的区域</span>
$ <span class="token function">watch</span> -d <span class="token function">cat</span> /proc/interrupts
        CPU0       CPU1
<span class="token punctuation">..</span>.
RES:    <span class="token number">2450431</span>    <span class="token number">5279697</span>   Rescheduling interrupts
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 观察一段时间，你可以发现，变化速度最快的是重调度中断（RES），这个中断类型表示，唤醒空闲状态的 CPU 来调度新的任务运行。这是多处理器系统（SMP）中，调度器用来分散任务到不同 CPU 的机制，通常也被称为处理器间中断（Inter-Processor Interrupts，IPI）。</p>
<p> 所以，这里的中断升高还是因为过多任务的调度问题，跟前面上下文切换次数的分析结果是一致的。</p>
<p> 通过这个案例，你应该也发现了多工具、多方面指标对比观测的好处。如果最开始时，我们只用了 pidstat 观测，这些很严重的上下文切换线程，压根儿就发现不了了。</p>
<p> 现在再回到最初的问题，每秒上下文切换多少次才算正常呢？</p>
<p> 这个数值其实取决于系统本身的 CPU 性能。在我看来，如果系统的上下文切换次数比较稳定，那么从数百到一万以内，都应该算是正常的。但当上下文切换次数超过一万次，或者切换次数出现数量级的增长时，就很可能已经出现了性能问题。</p>
<p> 这时，你还需要根据上下文切换的类型，再做具体分析。比方说：</p>
<ul>
<li>自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题；</li>
<li>非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈；</li>
<li>中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文件来分析具体的中断类型。</li>
</ul>
</li>
</ol>
<h3 id="05-基础篇：某个应用的CPU使用率居然达到100-，我该怎么办？"><a href="#05-基础篇：某个应用的CPU使用率居然达到100-，我该怎么办？" class="headerlink" title="05 | 基础篇：某个应用的CPU使用率居然达到100%，我该怎么办？"></a>05 | 基础篇：某个应用的CPU使用率居然达到100%，我该怎么办？</h3><p>CPU 使用率是单位时间内 CPU 使用情况的统计，以百分比的方式展示。</p>
<h4 id="5-1-CPU-使用率"><a href="#5-1-CPU-使用率" class="headerlink" title="5.1 CPU 使用率"></a>5.1 CPU 使用率</h4><p>Linux 作为一个多任务操作系统，将每个 CPU 的时间划分为很短的时间片，再通过调度器轮流分配给各个任务使用，因此造成多任务同时运行的错觉。</p>
<p>为了维护 CPU 时间，Linux 通过事先定义的节拍率（内核中表示为 HZ），触发时间中断，并使用全局变量 Jiffies 记录了开机以来的节拍数。每发生一次时间中断，Jiffies 的值就加 1。</p>
<p>节拍率 HZ 是内核的可配选项，可以设置为 100、250、1000 等。不同的系统可能设置不同数值，你可以通过查询 /boot/config 内核选项来查看它的配置值。比如在我的系统中，节拍率设置成了 250，也就是每秒钟触发 250 次时间中断。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">grep</span> <span class="token string">'CONFIG_HZ='</span> /boot/config-<span class="token variable"><span class="token variable">$(</span><span class="token function">uname</span> -r<span class="token variable">)</span></span>
<span class="token assign-left variable">CONFIG_HZ</span><span class="token operator">=</span><span class="token number">250</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>同时，正因为节拍率 HZ 是内核选项，所以用户空间程序并不能直接访问。为了方便用户空间程序，内核还提供了一个用户空间节拍率 USER_HZ，它总是固定为 100，也就是 1/100 秒。这样，用户空间程序并不需要关心内核中 HZ 被设置成了多少，因为它看到的总是固定值 USER_HZ。</p>
<p>Linux 通过 /proc 虚拟文件系统，向用户空间提供了系统内部状态的信息，而 /proc/stat 提供的就是系统的 CPU 和任务统计信息。比方说，如果你只关注 CPU 的话，可以执行下面的命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 只保留各个 CPU 的数据</span>
$ <span class="token function">cat</span> /proc/stat <span class="token operator">|</span> <span class="token function">grep</span> ^cpu
cpu  <span class="token number">280580</span> <span class="token number">7407</span> <span class="token number">286084</span> <span class="token number">172900810</span> <span class="token number">83602</span> <span class="token number">0</span> <span class="token number">583</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
cpu0 <span class="token number">144745</span> <span class="token number">4181</span> <span class="token number">176701</span> <span class="token number">86423902</span> <span class="token number">52076</span> <span class="token number">0</span> <span class="token number">301</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
cpu1 <span class="token number">135834</span> <span class="token number">3226</span> <span class="token number">109383</span> <span class="token number">86476907</span> <span class="token number">31525</span> <span class="token number">0</span> <span class="token number">282</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出结果是一个表格。其中，第一列表示的是 CPU 编号，如 cpu0、cpu1 ，而第一行没有编号的 cpu ，表示的是所有 CPU 的累加。其他列则表示不同场景下 CPU 的累加节拍数，它的单位是 USER_HZ，也就是 10 ms（1/100 秒），所以这其实就是不同场景下的 CPU 时间。</p>
<p>每个数字的意义可以通过 <code>man proc</code> 查询。要清楚 man proc 文档里每一列的涵义，它们都是 CPU 使用率相关的重要指标，你还会在很多其他的性能工具中看到它们。下面，我来依次解读一下。</p>
<ul>
<li>user（通常缩写为 us），代表用户态 CPU 时间。注意，它不包括下面的 nice 时间，但包括了 guest 时间。</li>
<li>nice（通常缩写为 ni），代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。这里注意，nice 可取值范围是 -20 到 19，数值越大，优先级反而越低。</li>
<li>system（通常缩写为 sys），代表内核态 CPU 时间。</li>
<li>idle（通常缩写为 id），代表空闲时间。注意，它不包括等待 I/O 的时间（iowait）。</li>
<li>iowait（通常缩写为 wa），代表等待 I/O 的 CPU 时间。</li>
<li>irq（通常缩写为 hi），代表处理硬中断的 CPU 时间。</li>
<li>softirq（通常缩写为 si），代表处理软中断的 CPU 时间。</li>
<li>steal（通常缩写为 st），代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间。</li>
<li>guest（通常缩写为 guest），代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间。</li>
<li>guest_nice（通常缩写为 gnice），代表以低优先级运行虚拟机的时间。</li>
</ul>
<p>CPU 使用率，就是除了空闲时间外的其他时间占总 CPU 时间的百分比，用公式来表示就是：</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/CPU使用率公式.png" alt="CPU使用率公式"></p>
<p>根据这个公式，我们就可以从 /proc/stat 中的数据，很容易地计算出 CPU 使用率。当然，也可以用每一个场景的 CPU 时间，除以总的 CPU 时间，计算出每个场景的 CPU 使用率。</p>
<p>不过先不要着急计算，你能说出，直接用 /proc/stat 的数据，算的是什么时间段的 CPU 使用率吗？</p>
<p>看到这里，你应该想起来了，这是开机以来的节拍数累加值，所以直接算出来的，是开机以来的平均 CPU 使用率，一般没啥参考价值。</p>
<p>事实上，为了计算 CPU 使用率，性能工具一般都会取间隔一段时间（比如 3 秒）的两次值，作差后，再计算出这段时间内的平均 CPU 使用率，即</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/平均CPU使用率公式.png" alt="平均CPU使用率公式"></p>
<p>这个公式，就是我们用各种性能工具所看到的 CPU 使用率的实际计算方法。</p>
<p>现在，我们知道了系统 CPU 使用率的计算方法，那进程的呢？跟系统的指标类似，Linux 也给每个进程提供了运行情况的统计信息，也就是 /proc/[pid]/stat。不过，这个文件包含的数据就比较丰富了，总共有 52 列的数据。</p>
<p><strong>性能分析工具给出的都是间隔一段时间的平均 CPU 使用率，所以要注意间隔时间的设置，特别是用多个工具对比分析时，你一定要保证它们用的是相同的间隔时间。</strong></p>
<p>比如，对比一下 top 和 ps 这两个工具报告的 CPU 使用率，默认的结果很可能不一样，因为 top 默认使用 3 秒时间间隔，而 ps 使用的却是进程的整个生命周期。</p>
<h4 id="5-2-怎么查看-CPU-使用率"><a href="#5-2-怎么查看-CPU-使用率" class="headerlink" title="5.2 怎么查看 CPU 使用率"></a>5.2 怎么查看 CPU 使用率</h4><p>top 和 ps 是最常用的性能分析工具：</p>
<ul>
<li>top 显示了系统总体的 CPU 和内存使用情况，以及各个进程的资源使用情况。</li>
<li>ps 则只显示了每个进程的资源使用情况。</li>
</ul>
<p>top 的输出格式为：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 默认每 3 秒刷新一次</span>
$ <span class="token function">top</span>
<span class="token function">top</span> - <span class="token number">11</span>:58:59 up <span class="token number">9</span> days, <span class="token number">22</span>:47,  <span class="token number">1</span> user,  load average: <span class="token number">0.03</span>, <span class="token number">0.02</span>, <span class="token number">0.00</span>
Tasks: <span class="token number">123</span> total,   <span class="token number">1</span> running,  <span class="token number">72</span> sleeping,   <span class="token number">0</span> stopped,   <span class="token number">0</span> zombie
%Cpu<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:  <span class="token number">0.3</span> us,  <span class="token number">0.3</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">99.3</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
KiB Mem <span class="token builtin class-name">:</span>  <span class="token number">8169348</span> total,  <span class="token number">5606884</span> free,   <span class="token number">334640</span> used,  <span class="token number">2227824</span> buff/cache
KiB Swap:        <span class="token number">0</span> total,        <span class="token number">0</span> free,        <span class="token number">0</span> used.  <span class="token number">7497908</span> avail Mem

  PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
    <span class="token number">1</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">78088</span>   <span class="token number">9288</span>   <span class="token number">6696</span> S   <span class="token number">0.0</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:16.83 systemd
    <span class="token number">2</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> S   <span class="token number">0.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.05 kthreadd
    <span class="token number">4</span> root       <span class="token number">0</span> -20       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> I   <span class="token number">0.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.00 kworker/0:0H
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出结果中，第三行 %Cpu 就是系统的 CPU 使用率，具体每一列的含义上一节都讲过，只是把 CPU 时间变换成了 CPU 使用率。不过需要注意，top 默认显示的是所有 CPU 的平均值，这个时候你只需要按下数字 1 ，就可以切换到每个 CPU 的使用率了。</p>
<p>继续往下看，空白行之后是进程的实时信息，每个进程都有一个 %CPU 列，表示进程的 CPU 使用率。它是用户态和内核态 CPU 使用率的总和，包括进程用户空间使用的 CPU、通过系统调用执行的内核空间 CPU 、以及在就绪队列等待运行的 CPU。在虚拟化环境中，它还包括了运行虚拟机占用的 CPU。</p>
<p>可以发现， top 并没有细分进程的用户态 CPU 和内核态 CPU。可以使用 pidstat 专门分析每个进程 CPU 使用情况的工具。</p>
<p>比如，下面的 pidstat 命令，就间隔 1 秒展示了进程的 5 组 CPU 使用率，包括：</p>
<ul>
<li>用户态 CPU 使用率 （%usr）；</li>
<li>内核态 CPU 使用率（%system）；</li>
<li>运行虚拟机 CPU 使用率（%guest）；</li>
<li>等待 CPU 使用率（%wait）；</li>
<li>以及总的 CPU 使用率（%CPU）。</li>
</ul>
<p>最后的 Average 部分，还计算了 5 组数据的平均值。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 每隔 1 秒输出一组数据，共输出 5 组</span>
$ pidstat <span class="token number">1</span> <span class="token number">5</span>
<span class="token number">15</span>:56:02      <span class="token environment constant">UID</span>       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
<span class="token number">15</span>:56:03        <span class="token number">0</span>     <span class="token number">15006</span>    <span class="token number">0.00</span>    <span class="token number">0.99</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.99</span>     <span class="token number">1</span>  dockerd

<span class="token punctuation">..</span>.

Average:      <span class="token environment constant">UID</span>       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
Average:        <span class="token number">0</span>     <span class="token number">15006</span>    <span class="token number">0.00</span>    <span class="token number">0.99</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.99</span>     -  dockerd<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="5-3-CPU-使用率过高怎么办？"><a href="#5-3-CPU-使用率过高怎么办？" class="headerlink" title="5.3 CPU 使用率过高怎么办？"></a>5.3 CPU 使用率过高怎么办？</h4><p>通过 top、ps、pidstat 等工具，你能够轻松找到 CPU 使用率较高（比如 100% ）的进程。接下来，你可能又想知道，占用 CPU 的到底是代码里的哪个函数呢？找到它，你才能更高效、更针对性地进行优化。</p>
<p>我猜你第一个想到的，应该是 GDB（The GNU Project Debugger）， 这个功能强大的程序调试利器。的确，GDB 在调试程序错误方面很强大。但是，我又要来“挑刺”了。请你记住，GDB 并不适合在性能分析的早期应用。</p>
<p>为什么呢？因为 GDB 调试程序的过程会中断程序运行，这在线上环境往往是不允许的。所以，GDB 只适合用在性能分析的后期，当你找到了出问题的大致函数后，线下再借助它来进一步调试函数内部的问题。</p>
<p>那么哪种工具适合在第一时间分析进程的 CPU 问题呢？我的推荐是 perf。perf 是 Linux 2.6.31 以后内置的性能分析工具。它以性能事件采样为基础，不仅可以分析系统的各种事件和内核性能，还可以用来分析指定应用程序的性能问题。</p>
<p>使用 perf 分析 CPU 性能问题，我来说两种最常见、也是我最喜欢的用法。</p>
<p>第一种常见用法是 perf top，类似于 top，它能够实时显示占用 CPU 时钟最多的函数或者指令，因此可以用来查找热点函数，使用界面如下所示：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ perf <span class="token function">top</span>
Samples: <span class="token number">833</span>  of event <span class="token string">'cpu-clock'</span>, Event count <span class="token punctuation">(</span>approx.<span class="token punctuation">)</span>: <span class="token number">97742399</span>
Overhead  Shared Object       Symbol
   <span class="token number">7.28</span>%  perf                <span class="token punctuation">[</span>.<span class="token punctuation">]</span> 0x00000000001f78a4
   <span class="token number">4.72</span>%  <span class="token punctuation">[</span>kernel<span class="token punctuation">]</span>            <span class="token punctuation">[</span>k<span class="token punctuation">]</span> vsnprintf
   <span class="token number">4.32</span>%  <span class="token punctuation">[</span>kernel<span class="token punctuation">]</span>            <span class="token punctuation">[</span>k<span class="token punctuation">]</span> module_get_kallsym
   <span class="token number">3.65</span>%  <span class="token punctuation">[</span>kernel<span class="token punctuation">]</span>            <span class="token punctuation">[</span>k<span class="token punctuation">]</span> _raw_spin_unlock_irqrestore
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出结果中，第一行包含三个数据，分别是采样数（Samples）、事件类型（event）和事件总数量（Event count）。比如这个例子中，perf 总共采集了 833 个 CPU 时钟事件，而总事件数则为 97742399。</p>
<p>再往下看是一个表格式样的数据，每一行包含四列，分别是：</p>
<ul>
<li>第一列 Overhead ，是该符号的性能事件在所有采样中的比例，用百分比来表示。</li>
<li>第二列 Shared ，是该函数或指令所在的动态共享对象（Dynamic Shared Object），如内核、进程名、动态链接库名、内核模块名等。</li>
<li>第三列 Object ，是动态共享对象的类型。比如 [.] 表示用户空间的可执行程序、或者动态链接库，而 [k] 则表示内核空间。</li>
<li>最后一列 Symbol 是符号名，也就是函数名。当函数名未知时，用十六进制的地址来表示。</li>
</ul>
<p>以上面的输出为例，我们可以看到，占用 CPU 时钟最多的是 perf 工具自身，不过它的比例也只有 7.28%，说明系统并没有 CPU 性能问题。 perf top 的使用你应该很清楚了吧。</p>
<p>接着再来看第二种常见用法，也就是 perf record 和 perf report。 perf top 虽然实时展示了系统的性能信息，但它的缺点是并不保存数据，也就无法用于离线或者后续的分析。而 perf record 则提供了保存数据的功能，保存后的数据，需要你用 perf report 解析展示。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ perf record <span class="token comment"># 按 Ctrl+C 终止采样</span>
<span class="token punctuation">[</span> perf record: Woken up <span class="token number">1</span> <span class="token builtin class-name">times</span> to <span class="token function">write</span> data <span class="token punctuation">]</span>
<span class="token punctuation">[</span> perf record: Captured and wrote <span class="token number">0.452</span> MB perf.data <span class="token punctuation">(</span><span class="token number">6093</span> samples<span class="token punctuation">)</span> <span class="token punctuation">]</span>

$ perf report <span class="token comment"># 展示类似于 perf top 的报告</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在实际使用中，我们还经常为 perf top 和 perf record 加上 -g 参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。</p>
<h4 id="5-4-案例"><a href="#5-4-案例" class="headerlink" title="5.4 案例"></a>5.4 案例</h4><p>下面我们就以 Nginx + PHP 的 Web 服务为例，来看看当你发现 CPU 使用率过高的问题后，要怎么使用 top 等工具找出异常的进程，又要怎么利用 perf 找出引发性能问题的函数。</p>
<blockquote>
<p>机器配置：2 CPU，8GB 内存。</p>
<p>安装软件：<code>apt install docker.io sysstat linux-tools-common apache2-utils</code>。</p>
<blockquote>
<p>ab（apache bench）是一个常用的 HTTP 服务性能测试工具，这里用来模拟 Ngnix 的客户端。</p>
</blockquote>
</blockquote>
<ol>
<li><p>在第一个终端执行下面的命令来运行 Nginx 和 PHP 应用：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker run --name nginx -p <span class="token number">10000</span>:80 -itd feisky/nginx
$ docker run --name phpfpm -itd --network container:nginx feisky/php-fpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>在第二个终端使用 curl 访问 <a href="http://[VM1">http://[VM1</a> 的 IP]:10000，确认 Nginx 已正常启动。你应该可以看到 It works! 的响应。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 192.168.0.10 是第一台虚拟机的 IP 地址</span>
$ <span class="token function">curl</span> http://192.168.0.10:10000/
It works<span class="token operator">!</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li><p>接着，我们来测试一下这个 Nginx 服务的性能。在第二个终端运行下面的 ab 命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 并发 10 个请求测试 Nginx 性能，总共测试 100 个请求</span>
$ ab -c <span class="token number">10</span> -n <span class="token number">100</span> http://192.168.0.10:10000/
This is ApacheBench, Version <span class="token number">2.3</span> <span class="token operator">&lt;</span><span class="token variable">$Revision</span><span class="token builtin class-name">:</span> <span class="token number">1706008</span> $<span class="token operator">&gt;</span>
Copyright <span class="token number">1996</span> Adam Twiss, Zeus Technology Ltd,
<span class="token punctuation">..</span>.
Requests per second:    <span class="token number">11.63</span> <span class="token punctuation">[</span><span class="token comment">#/sec] (mean)</span>
Time per request:       <span class="token number">859.942</span> <span class="token punctuation">[</span>ms<span class="token punctuation">]</span> <span class="token punctuation">(</span>mean<span class="token punctuation">)</span>
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从 ab 的输出结果我们可以看到，Nginx 能承受的每秒平均请求数只有 11.63。太少了，那到底是哪里出了问题呢？我们用 top 和 pidstat 再来观察下。</p>
</li>
<li><p>我们在第二个终端，将测试的请求总数增加到 10000。这样当你在第一个终端使用性能分析工具时， Nginx 的压力还是继续。继续在第二个终端，运行 ab 命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ ab -c <span class="token number">10</span> -n <span class="token number">10000</span> http://10.240.0.5:10000/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>回到第一个终端运行 top 命令，并按下数字 1 ，切换到每个 CPU 的使用率：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">top</span>
<span class="token punctuation">..</span>.
%Cpu0  <span class="token builtin class-name">:</span> <span class="token number">98.7</span> us,  <span class="token number">1.3</span> sy,  <span class="token number">0.0</span> ni,  <span class="token number">0.0</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
%Cpu1  <span class="token builtin class-name">:</span> <span class="token number">99.3</span> us,  <span class="token number">0.7</span> sy,  <span class="token number">0.0</span> ni,  <span class="token number">0.0</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
<span class="token punctuation">..</span>.
PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
<span class="token number">21514</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">16384</span>   <span class="token number">8712</span> R  <span class="token number">41.9</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:06.00 php-fpm
<span class="token number">21513</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">13244</span>   <span class="token number">5572</span> R  <span class="token number">40.2</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:06.08 php-fpm
<span class="token number">21515</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">16384</span>   <span class="token number">8712</span> R  <span class="token number">40.2</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:05.67 php-fpm
<span class="token number">21512</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">13244</span>   <span class="token number">5572</span> R  <span class="token number">39.9</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:05.87 php-fpm
<span class="token number">21516</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">16384</span>   <span class="token number">8712</span> R  <span class="token number">35.9</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:05.61 php-fpm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 这里可以看到，系统中有几个 php-fpm 进程的 CPU 使用率加起来接近 200%；而每个 CPU 的用户使用率（us）也已经超过了 98%，接近饱和。这样，我们就可以确认，正是用户空间的 php-fpm 进程，导致 CPU 使用率骤升。</p>
</li>
<li><p>那再往下走，怎么知道是 php-fpm 的哪个函数导致了 CPU 使用率升高呢？我们来用 perf 分析一下。在第一个终端运行下面的 perf 命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -g 开启调用关系分析，-p 指定 php-fpm 的进程号 21515</span>
$ perf <span class="token function">top</span> -g -p <span class="token number">21515</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p> 按方向键切换到 php-fpm，再按下回车键展开 php-fpm 的调用关系，你会发现，调用关系最终到了 sqrt 和 add_function。看来，我们需要从这两个函数入手了。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/CPU使用率过高案例分析perf截图.png" alt="CPU使用率过高案例分析perf截图"></p>
<p> 我们拷贝出 <a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/blob/master/nginx-high-cpu/app/index.php">Nginx 应用的源码</a>，看看是不是调用了这两个函数：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 从容器 phpfpm 中将 PHP 源码拷贝出来</span>
$ docker <span class="token function">cp</span> phpfpm:/app <span class="token builtin class-name">.</span>

<span class="token comment"># 使用 grep 查找函数调用</span>
$ <span class="token function">grep</span> sqrt -r app/ <span class="token comment"># 找到了 sqrt 调用</span>
app/index.php:  <span class="token variable">$x</span> <span class="token operator">+=</span> sqrt<span class="token punctuation">(</span><span class="token variable">$x</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
$ <span class="token function">grep</span> add_function -r app/ <span class="token comment"># 没找到 add_function 调用，这其实是 PHP 内置函数</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> OK，原来只有 sqrt 函数在 app/index.php 文件中调用了。那最后一步，我们就该看看这个文件的源码了：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">cat</span> app/index.php
<span class="token operator">&lt;</span>?php
// <span class="token builtin class-name">test</span> only.
<span class="token variable">$x</span> <span class="token operator">=</span> <span class="token number">0.0001</span><span class="token punctuation">;</span>
<span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token variable">$i</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> <span class="token variable">$i</span> <span class="token operator">&lt;</span><span class="token operator">=</span> <span class="token number">1000000</span><span class="token punctuation">;</span> <span class="token variable">$i</span>++<span class="token punctuation">)</span> <span class="token punctuation">{</span>
<span class="token variable">$x</span> <span class="token operator">+=</span> sqrt<span class="token punctuation">(</span><span class="token variable">$x</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token builtin class-name">echo</span> <span class="token string">"It works!"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 呀，有没有发现问题在哪里呢？我想你要笑话我了，居然犯了一个这么傻的错误，测试代码没删就直接发布应用了。为了方便你验证优化后的效果，我把修复后的应用也打包成了一个 Docker 镜像，你可以在第一个终端中执行下面的命令来运行它：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 停止原来的应用</span>
$ docker <span class="token function">rm</span> -f nginx phpfpm
<span class="token comment"># 运行优化后的应用</span>
$ docker run --name nginx -p <span class="token number">10000</span>:80 -itd feisky/nginx:cpu-fix
$ docker run --name phpfpm -itd --network container:nginx feisky/php-fpm:cpu-fix<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>接着，到第二个终端来验证一下修复后的效果。首先 Ctrl+C 停止之前的 ab 命令后，再运行下面的命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ ab -c <span class="token number">10</span> -n <span class="token number">10000</span> http://10.240.0.5:10000/
<span class="token punctuation">..</span>.
Complete requests:      <span class="token number">10000</span>
Failed requests:        <span class="token number">0</span>
Total transferred:      <span class="token number">1720000</span> bytes
HTML transferred:       <span class="token number">90000</span> bytes
Requests per second:    <span class="token number">2237.04</span> <span class="token punctuation">[</span><span class="token comment">#/sec] (mean)</span>
Time per request:       <span class="token number">4.470</span> <span class="token punctuation">[</span>ms<span class="token punctuation">]</span> <span class="token punctuation">(</span>mean<span class="token punctuation">)</span>
Time per request:       <span class="token number">0.447</span> <span class="token punctuation">[</span>ms<span class="token punctuation">]</span> <span class="token punctuation">(</span>mean, across all concurrent requests<span class="token punctuation">)</span>
Transfer rate:          <span class="token number">375.75</span> <span class="token punctuation">[</span>Kbytes/sec<span class="token punctuation">]</span> received
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从这里你可以发现，现在每秒的平均请求数，已经从原来的 11 变成了 2237。</p>
</li>
</ol>
<h4 id="5-5-小结"><a href="#5-5-小结" class="headerlink" title="5.5 小结"></a>5.5 小结</h4><p>CPU 使用率是最直观和最常用的系统性能指标，更是我们在排查性能问题时，通常会关注的第一个指标。所以我们更要熟悉它的含义，尤其要弄清楚用户（%user）、Nice（%nice）、系统（%system） 、等待 I/O（%iowait） 、中断（%irq）以及软中断（%softirq）这几种不同 CPU 的使用率。比如说：</p>
<ul>
<li>用户 CPU 和 Nice CPU 高，说明用户态进程占用了较多的 CPU，所以应该着重排查进程的性能问题。</li>
<li>系统 CPU 高，说明内核态占用了较多的 CPU，所以应该着重排查内核线程或者系统调用的性能问题。</li>
<li>I/O 等待 CPU 高，说明等待 I/O 的时间比较长，所以应该着重排查系统存储是不是出现了 I/O 问题。</li>
<li>软中断和硬中断高，说明软中断或硬中断的处理程序占用了较多的 CPU，所以应该着重排查内核中的中断服务程序。</li>
</ul>
<p>碰到 CPU 使用率升高的问题，你可以借助 top、pidstat 等工具，确认引发 CPU 性能问题的来源；再使用 perf 等工具，排查出引起性能问题的具体函数。</p>
<h3 id="06-案例篇：系统的-CPU-使用率很高，但为啥却找不到高-CPU-的应用？"><a href="#06-案例篇：系统的-CPU-使用率很高，但为啥却找不到高-CPU-的应用？" class="headerlink" title="06 | 案例篇：系统的 CPU 使用率很高，但为啥却找不到高 CPU 的应用？"></a>06 | 案例篇：系统的 CPU 使用率很高，但为啥却找不到高 CPU 的应用？</h3><p>系统的 CPU 使用率，不仅包括进程用户态和内核态的运行，还包括中断处理、等待 I/O 以及内核线程等。所以，当你发现系统的 CPU 使用率很高的时候，不一定能找到相对应的高 CPU 使用率的进程。</p>
<p>今天，我就用一个 Nginx + PHP 的 Web 服务的案例，带你来分析这种情况。</p>
<h4 id="6-1-案例分析"><a href="#6-1-案例分析" class="headerlink" title="6.1 案例分析"></a>6.1 案例分析</h4><blockquote>
<p>机器配置：2 CPU，8GB 内存。</p>
<p>安装软件：<code>apt install docker.io sysstat linux-tools-common apache2-utils</code>。</p>
</blockquote>
<ol>
<li><p>在第一个终端，执行下面的命令运行 Nginx 和 PHP 应用：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker run --name nginx -p <span class="token number">10000</span>:80 -itd feisky/nginx:sp
$ docker run --name phpfpm -itd --network container:nginx feisky/php-fpm:sp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>第二个终端，使用 curl 访问 <a href="http://[VM1">http://[VM1</a> 的 IP]:10000，确认 Nginx 已正常启动。你应该可以看到 It works! 的响应。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 192.168.0.10 是第一台虚拟机的 IP 地址</span>
$ <span class="token function">curl</span> http://192.168.0.10:10000/
It works<span class="token operator">!</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li><p>来测试一下这个 Nginx 服务的性能。在第二个终端运行下面的 ab 命令。要注意，与上次操作不同的是，这次我们需要并发 100 个请求测试 Nginx 性能，总共测试 1000 个请求。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 并发 100 个请求测试 Nginx 性能，总共测试 1000 个请求</span>
$ ab -c <span class="token number">100</span> -n <span class="token number">1000</span> http://192.168.0.10:10000/
This is ApacheBench, Version <span class="token number">2.3</span> <span class="token operator">&lt;</span><span class="token variable">$Revision</span><span class="token builtin class-name">:</span> <span class="token number">1706008</span> $<span class="token operator">&gt;</span>
Copyright <span class="token number">1996</span> Adam Twiss, Zeus Technology Ltd,
<span class="token punctuation">..</span>.
Requests per second:    <span class="token number">87.86</span> <span class="token punctuation">[</span><span class="token comment">#/sec] (mean)</span>
Time per request:       <span class="token number">1138.229</span> <span class="token punctuation">[</span>ms<span class="token punctuation">]</span> <span class="token punctuation">(</span>mean<span class="token punctuation">)</span>
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从 ab 的输出结果我们可以看到，Nginx 能承受的每秒平均请求数，只有 87 多一点，是不是感觉它的性能有点差呀。那么，到底是哪里出了问题呢？我们再用 top 和 pidstat 来观察一下。</p>
<p> 这次，我们在第二个终端，将测试的并发请求数改成 5，同时把请求时长设置为 10 分钟（-t 600）。这样，当你在第一个终端使用性能分析工具时， Nginx 的压力还是继续的。</p>
</li>
<li><p>继续在第二个终端运行 ab 命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ ab -c <span class="token number">5</span> -t <span class="token number">600</span> http://192.168.0.10:10000/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>然后，我们在第一个终端运行 top 命令，观察系统的 CPU 使用情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">top</span>
<span class="token punctuation">..</span>.
%Cpu<span class="token punctuation">(</span>s<span class="token punctuation">)</span>: <span class="token number">80.8</span> us, <span class="token number">15.1</span> sy,  <span class="token number">0.0</span> ni,  <span class="token number">2.8</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">1.3</span> si,  <span class="token number">0.0</span> st
<span class="token punctuation">..</span>.

PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
<span class="token number">6882</span> root      <span class="token number">20</span>   <span class="token number">0</span>    <span class="token number">8456</span>   <span class="token number">5052</span>   <span class="token number">3884</span> S   <span class="token number">2.7</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:04.78 docker-containe
<span class="token number">6947</span> systemd+  <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">33104</span>   <span class="token number">3716</span>   <span class="token number">2340</span> S   <span class="token number">2.7</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:04.92 nginx
<span class="token number">7494</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">15012</span>   <span class="token number">7332</span> S   <span class="token number">2.0</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:03.55 php-fpm
<span class="token number">7495</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">15160</span>   <span class="token number">7480</span> S   <span class="token number">2.0</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:03.55 php-fpm
<span class="token number">10547</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">16200</span>   <span class="token number">8520</span> S   <span class="token number">2.0</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:03.13 php-fpm
<span class="token number">10155</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">16200</span>   <span class="token number">8520</span> S   <span class="token number">1.7</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:03.12 php-fpm
<span class="token number">10552</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">16200</span>   <span class="token number">8520</span> S   <span class="token number">1.7</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:03.12 php-fpm
<span class="token number">15006</span> root      <span class="token number">20</span>   <span class="token number">0</span> <span class="token number">1168608</span>  <span class="token number">66264</span>  <span class="token number">37536</span> S   <span class="token number">1.0</span>  <span class="token number">0.8</span>   <span class="token number">9</span>:39.51 dockerd
<span class="token number">4323</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> I   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.87 kworker/u4:1
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 观察 top 输出的进程列表可以发现，CPU 使用率最高的进程也只不过才 2.7%，看起来并不高。</p>
<p> 然而，再看系统 CPU 使用率（ %Cpu ）这一行，你会发现，系统的整体 CPU 使用率是比较高的：用户 CPU 使用率（us）已经到了 80%，系统 CPU 为 15.1%，而空闲 CPU （id）则只有 2.8%。</p>
<p> 为什么用户 CPU 使用率这么高呢？我们再重新分析一下进程列表，看看有没有可疑进程：</p>
<ul>
<li>docker-containerd 进程是用来运行容器的，2.7% 的 CPU 使用率看起来正常；</li>
<li>Nginx 和 php-fpm 是运行 Web 服务的，它们会占用一些 CPU 也不意外，并且 2% 的 CPU 使用率也不算高；</li>
<li><p>再往下看，后面的进程呢，只有 0.3% 的 CPU 使用率，看起来不太像会导致用户 CPU 使用率达到 80%。</p>
<p>看来 top 是不管用了，那还有其他工具可以查看进程 CPU 使用情况吗？</p>
</li>
</ul>
</li>
<li><p>接下来，我们还是在第一个终端，运行 pidstat 命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 间隔 1 秒输出一组数据（按 Ctrl+C 结束）</span>
$ pidstat <span class="token number">1</span>
<span class="token punctuation">..</span>.
04:36:24      <span class="token environment constant">UID</span>       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
04:36:25        <span class="token number">0</span>      <span class="token number">6882</span>    <span class="token number">1.00</span>    <span class="token number">3.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">4.00</span>     <span class="token number">0</span>  docker-containe
04:36:25      <span class="token number">101</span>      <span class="token number">6947</span>    <span class="token number">1.00</span>    <span class="token number">2.00</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>    <span class="token number">3.00</span>     <span class="token number">1</span>  nginx
04:36:25        <span class="token number">1</span>     <span class="token number">14834</span>    <span class="token number">1.00</span>    <span class="token number">1.00</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>    <span class="token number">2.00</span>     <span class="token number">0</span>  php-fpm
04:36:25        <span class="token number">1</span>     <span class="token number">14835</span>    <span class="token number">1.00</span>    <span class="token number">1.00</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>    <span class="token number">2.00</span>     <span class="token number">0</span>  php-fpm
04:36:25        <span class="token number">1</span>     <span class="token number">14845</span>    <span class="token number">0.00</span>    <span class="token number">2.00</span>    <span class="token number">0.00</span>    <span class="token number">2.00</span>    <span class="token number">2.00</span>     <span class="token number">1</span>  php-fpm
04:36:25        <span class="token number">1</span>     <span class="token number">14855</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>    <span class="token number">1.00</span>     <span class="token number">1</span>  php-fpm
04:36:25        <span class="token number">1</span>     <span class="token number">14857</span>    <span class="token number">1.00</span>    <span class="token number">2.00</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>    <span class="token number">3.00</span>     <span class="token number">0</span>  php-fpm
04:36:25        <span class="token number">0</span>     <span class="token number">15006</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>     <span class="token number">0</span>  dockerd
04:36:25        <span class="token number">0</span>     <span class="token number">15801</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>     <span class="token number">1</span>  pidstat
04:36:25        <span class="token number">1</span>     <span class="token number">17084</span>    <span class="token number">1.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">2.00</span>    <span class="token number">1.00</span>     <span class="token number">0</span>  stress
04:36:25        <span class="token number">0</span>     <span class="token number">31116</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">1.00</span>     <span class="token number">0</span>  atopacctd
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 观察一会儿，你是不是发现，所有进程的 CPU 使用率也都不高啊，最高的 Docker 和 Nginx 也只有 4% 和 3%，即使所有进程的 CPU 使用率都加起来，也不过是 21%，离 80% 还差得远呢！</p>
<p> 后来我发现，会出现这种情况，很可能是因为前面的分析漏了一些关键信息。你可以先暂停一下，自己往上翻，重新操作检查一遍。或者，我们一起返回去分析 top 的输出，看看能不能有新发现。</p>
<p> 现在，我们回到第一个终端，重新运行 top 命令，并观察一会儿：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">top</span>
<span class="token function">top</span> - 04:58:24 up <span class="token number">14</span> days, <span class="token number">15</span>:47,  <span class="token number">1</span> user,  load average: <span class="token number">3.39</span>, <span class="token number">3.82</span>, <span class="token number">2.74</span>
Tasks: <span class="token number">149</span> total,   <span class="token number">6</span> running,  <span class="token number">93</span> sleeping,   <span class="token number">0</span> stopped,   <span class="token number">0</span> zombie
%Cpu<span class="token punctuation">(</span>s<span class="token punctuation">)</span>: <span class="token number">77.7</span> us, <span class="token number">19.3</span> sy,  <span class="token number">0.0</span> ni,  <span class="token number">2.0</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">1.0</span> si,  <span class="token number">0.0</span> st
KiB Mem <span class="token builtin class-name">:</span>  <span class="token number">8169348</span> total,  <span class="token number">2543916</span> free,   <span class="token number">457976</span> used,  <span class="token number">5167456</span> buff/cache
KiB Swap:        <span class="token number">0</span> total,        <span class="token number">0</span> free,        <span class="token number">0</span> used.  <span class="token number">7363908</span> avail Mem

PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
<span class="token number">6947</span> systemd+  <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">33104</span>   <span class="token number">3764</span>   <span class="token number">2340</span> S   <span class="token number">4.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:32.69 nginx
<span class="token number">6882</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">12108</span>   <span class="token number">8360</span>   <span class="token number">3884</span> S   <span class="token number">2.0</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:31.40 docker-containe
<span class="token number">15465</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">15256</span>   <span class="token number">7576</span> S   <span class="token number">2.0</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:00.62 php-fpm
<span class="token number">15466</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">15196</span>   <span class="token number">7516</span> S   <span class="token number">2.0</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:00.62 php-fpm
<span class="token number">15489</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">16200</span>   <span class="token number">8520</span> S   <span class="token number">2.0</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:00.62 php-fpm
<span class="token number">6948</span> systemd+  <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">33104</span>   <span class="token number">3764</span>   <span class="token number">2340</span> S   <span class="token number">1.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.95 nginx
<span class="token number">15006</span> root      <span class="token number">20</span>   <span class="token number">0</span> <span class="token number">1168608</span>  <span class="token number">65632</span>  <span class="token number">37536</span> S   <span class="token number">1.0</span>  <span class="token number">0.8</span>   <span class="token number">9</span>:51.09 dockerd
<span class="token number">15476</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">16200</span>   <span class="token number">8520</span> S   <span class="token number">1.0</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:00.61 php-fpm
<span class="token number">15477</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">16200</span>   <span class="token number">8520</span> S   <span class="token number">1.0</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:00.61 php-fpm
<span class="token number">24340</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>    <span class="token number">8184</span>   <span class="token number">1616</span>    <span class="token number">536</span> R   <span class="token number">1.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.01 stress
<span class="token number">24342</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>    <span class="token number">8196</span>   <span class="token number">1580</span>    <span class="token number">492</span> R   <span class="token number">1.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.01 stress
<span class="token number">24344</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>    <span class="token number">8188</span>   <span class="token number">1056</span>    <span class="token number">492</span> R   <span class="token number">1.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.01 stress
<span class="token number">24347</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>    <span class="token number">8184</span>   <span class="token number">1356</span>    <span class="token number">540</span> R   <span class="token number">1.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.01 stress
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 这次从头开始看 top 的每行输出，咦？Tasks 这一行看起来有点奇怪，就绪队列中居然有 6 个 Running 状态的进程（6 running），是不是有点多呢？</p>
<p> 回想一下 ab 测试的参数，并发请求数是 5。再看进程列表里， php-fpm 的数量也是 5，再加上 Nginx，好像同时有 6 个进程也并不奇怪。但真的是这样吗？</p>
<p> 再仔细看进程列表，这次主要看 Running（R） 状态的进程。你有没有发现， Nginx 和所有的 php-fpm 都处于 Sleep（S）状态，而真正处于 Running（R）状态的，却是几个 stress 进程。这几个 stress 进程就比较奇怪了，需要我们做进一步的分析。</p>
<p> 我们还是使用 pidstat 来分析这几个进程，并且使用 -p 选项指定进程的 PID。首先，从上面 top 的结果中，找到这几个进程的 PID。比如，先随便找一个 24344，然后用 pidstat 命令看一下它的 CPU 使用情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ pidstat -p <span class="token number">24344</span>

<span class="token number">16</span>:14:55      <span class="token environment constant">UID</span>       PID    %usr %system  %guest   %wait    %CPU   CPU  Command<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 奇怪，居然没有任何输出。难道是 pidstat 命令出问题了吗？之前我说过，<strong>在怀疑性能工具出问题前，最好还是先用其他工具交叉确认一下。</strong>那用什么工具呢？ ps 应该是最简单易用的。我们在终端里运行下面的命令，看看 24344 进程的状态：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 从所有进程中查找 PID 是 24344 的进程</span>
$ <span class="token function">ps</span> aux <span class="token operator">|</span> <span class="token function">grep</span> <span class="token number">24344</span>
root      <span class="token number">9628</span>  <span class="token number">0.0</span>  <span class="token number">0.0</span>  <span class="token number">14856</span>  <span class="token number">1096</span> pts/0    S+   <span class="token number">16</span>:15   <span class="token number">0</span>:00 <span class="token function">grep</span> --color<span class="token operator">=</span>auto <span class="token number">24344</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 还是没有输出。现在终于发现问题，原来这个进程已经不存在了，所以 pidstat 就没有任何输出。既然进程都没了，那性能问题应该也跟着没了吧。我们再用 top 命令确认一下：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">top</span>
<span class="token punctuation">..</span>.
%Cpu<span class="token punctuation">(</span>s<span class="token punctuation">)</span>: <span class="token number">80.9</span> us, <span class="token number">14.9</span> sy,  <span class="token number">0.0</span> ni,  <span class="token number">2.8</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">1.3</span> si,  <span class="token number">0.0</span> st
<span class="token punctuation">..</span>.

PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
<span class="token number">6882</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">12108</span>   <span class="token number">8360</span>   <span class="token number">3884</span> S   <span class="token number">2.7</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:45.63 docker-containe
<span class="token number">6947</span> systemd+  <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">33104</span>   <span class="token number">3764</span>   <span class="token number">2340</span> R   <span class="token number">2.7</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:47.79 nginx
<span class="token number">3865</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">336696</span>  <span class="token number">15056</span>   <span class="token number">7376</span> S   <span class="token number">2.0</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:00.15 php-fpm
<span class="token number">6779</span> daemon    <span class="token number">20</span>   <span class="token number">0</span>    <span class="token number">8184</span>   <span class="token number">1112</span>    <span class="token number">556</span> R   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.01 stress
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 好像又错了。结果还跟原来一样，用户 CPU 使用率还是高达 80.9%，系统 CPU 接近 15%，而空闲 CPU 只有 2.8%，Running 状态的进程有 Nginx、stress 等。</p>
<p> 可是，刚刚我们看到 stress 进程不存在了，怎么现在还在运行呢？再细看一下 top 的输出，原来，这次 stress 进程的 PID 跟前面不一样了，原来的 PID 24344 不见了，现在的是 6779。</p>
<p> 进程的 PID 在变，这说明什么呢？在我看来，要么是这些进程在不停地重启，要么就是全新的进程，这无非也就两个原因：</p>
<ul>
<li>第一个原因，进程在不停地崩溃重启，比如因为段错误、配置错误等等，这时，进程在退出后可能又被监控系统自动重启了。</li>
<li><p>第二个原因，这些进程都是短时进程，也就是在其他应用内部通过 exec 调用的外面命令。这些命令一般都只运行很短的时间就会结束，你很难用 top 这种间隔时间比较长的工具发现（上面的案例，我们碰巧发现了）。</p>
<p>至于 stress，我们前面提到过，它是一个常用的压力测试工具。它的 PID 在不断变化中，看起来像是被其他进程调用的短时进程。要想继续分析下去，还得找到它们的父进程。</p>
<p>要怎么查找一个进程的父进程呢？没错，用 pstree 就可以用树状形式显示所有进程之间的关系：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ pstree <span class="token operator">|</span> <span class="token function">grep</span> stress
        <span class="token operator">|</span>-docker-containe-+-php-fpm-+-php-fpm---sh---stress
        <span class="token operator">|</span>         <span class="token operator">|</span>-3*<span class="token punctuation">[</span>php-fpm---sh---stress---stress<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>从这里可以看到，stress 是被 php-fpm 调用的子进程，并且进程数量不止一个（这里是 3 个）。找到父进程后，我们能进入 app 的内部分析了。</p>
<p>首先，当然应该去看看它的源码。运行下面的命令，把案例应用的源码拷贝到 app 目录，然后再执行 grep 查找是不是有代码再调用 stress 命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 拷贝源码到本地</span>
$ docker <span class="token function">cp</span> phpfpm:/app <span class="token builtin class-name">.</span>

<span class="token comment"># grep 查找看看是不是有代码在调用 stress 命令</span>
$ <span class="token function">grep</span> stress -r app
app/index.php:// fake I/O with stress <span class="token punctuation">(</span>via write<span class="token punctuation">(</span><span class="token punctuation">)</span>/unlink<span class="token punctuation">(</span><span class="token punctuation">))</span>.
app/index.php:<span class="token variable">$result</span> <span class="token operator">=</span> exec<span class="token punctuation">(</span><span class="token string">"/usr/local/bin/stress -t 1 -d 1 2&gt;&amp;1"</span>, <span class="token variable">$output</span>, <span class="token variable">$status</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>找到了，果然是 <a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/blob/master/nginx-short-process/app/index.php">app/index.php</a> 文件中直接调用了 stress 命令。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">cat</span> app/index.php
<span class="token operator">&lt;</span>?php
// fake I/O with stress <span class="token punctuation">(</span>via write<span class="token punctuation">(</span><span class="token punctuation">)</span>/unlink<span class="token punctuation">(</span><span class="token punctuation">))</span>.
<span class="token variable">$result</span> <span class="token operator">=</span> exec<span class="token punctuation">(</span><span class="token string">"/usr/local/bin/stress -t 1 -d 1 2&gt;&amp;1"</span>, <span class="token variable">$output</span>, <span class="token variable">$status</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>isset<span class="token punctuation">(</span><span class="token variable">$_GET</span><span class="token punctuation">[</span><span class="token string">"verbose"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token variable">$_GET</span><span class="token punctuation">[</span><span class="token string">"verbose"</span><span class="token punctuation">]</span><span class="token operator">==</span><span class="token number">1</span> <span class="token operator">&amp;&amp;</span> <span class="token variable">$status</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
<span class="token builtin class-name">echo</span> <span class="token string">"Server internal error: "</span><span class="token punctuation">;</span>
print_r<span class="token punctuation">(</span><span class="token variable">$output</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>
<span class="token builtin class-name">echo</span> <span class="token string">"It works!"</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
?<span class="token operator">&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以看到，源码里对每个请求都会调用一个 stress 命令，模拟 I/O 压力。从注释上看，stress 会通过 write() 和 unlink() 对 I/O 进程进行压测，看来，这应该就是系统 CPU 使用率升高的根源了。</p>
<p>不过，stress 模拟的是 I/O 压力，而之前在 top 的输出中看到的，却一直是用户 CPU 和系统 CPU 升高，并没见到 iowait 升高。这又是怎么回事呢？stress 到底是不是 CPU 使用率升高的原因呢？</p>
<p>我们还得继续往下走。从代码中可以看到，给请求加入 verbose=1 参数后，就可以查看 stress 的输出。你先试试看，在第二个终端运行：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">curl</span> http://192.168.0.10:10000?verbose<span class="token operator">=</span><span class="token number">1</span>
Server internal error: Array
<span class="token punctuation">(</span>
    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> stress: info: <span class="token punctuation">[</span><span class="token number">19607</span><span class="token punctuation">]</span> dispatching hogs: <span class="token number">0</span> cpu, <span class="token number">0</span> io, <span class="token number">0</span> vm, <span class="token number">1</span> hdd
    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> stress: FAIL: <span class="token punctuation">[</span><span class="token number">19608</span><span class="token punctuation">]</span> <span class="token punctuation">(</span><span class="token number">563</span><span class="token punctuation">)</span> mkstemp failed: Permission denied
    <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> stress: FAIL: <span class="token punctuation">[</span><span class="token number">19607</span><span class="token punctuation">]</span> <span class="token punctuation">(</span><span class="token number">394</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span>-- worker <span class="token number">19608</span> returned error <span class="token number">1</span>
    <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> stress: WARN: <span class="token punctuation">[</span><span class="token number">19607</span><span class="token punctuation">]</span> <span class="token punctuation">(</span><span class="token number">396</span><span class="token punctuation">)</span> now reaping child worker processes
    <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> stress: FAIL: <span class="token punctuation">[</span><span class="token number">19607</span><span class="token punctuation">]</span> <span class="token punctuation">(</span><span class="token number">400</span><span class="token punctuation">)</span> <span class="token function">kill</span> error: No such process
    <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">&gt;</span> stress: FAIL: <span class="token punctuation">[</span><span class="token number">19607</span><span class="token punctuation">]</span> <span class="token punctuation">(</span><span class="token number">451</span><span class="token punctuation">)</span> failed run completed <span class="token keyword">in</span> 0s
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>看错误消息 <strong>mkstemp failed: Permission denied</strong> ，以及 <strong>failed run completed in 0s</strong>。原来 stress 命令并没有成功，它因为权限问题失败退出了。看来，我们发现了一个 PHP 调用外部 stress 命令的 bug：没有权限创建临时文件。</p>
<p>从这里我们可以猜测，正是由于权限错误，大量的 stress 进程在启动时初始化失败，进而导致用户 CPU 使用率的升高。</p>
<p>分析出问题来源，下一步是不是就要开始优化了呢？当然不是！既然只是猜测，那就需要再确认一下，这个猜测到底对不对，是不是真的有大量的 stress 进程。该用什么工具或指标呢？</p>
<p>我们前面已经用了 top、pidstat、pstree 等工具，没有发现大量的 stress 进程。那么，还有什么其他的工具可以用吗？</p>
<p>还记得上一期提到的 perf 吗？它可以用来分析 CPU 性能事件，用在这里就很合适。依旧在第一个终端中运行 perf record -g 命令 ，并等待一会儿（比如 15 秒）后按 Ctrl+C 退出。然后再运行 perf report 查看报告：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 记录性能事件，等待大约 15 秒后按 Ctrl+C 退出</span>
$ perf record -g

<span class="token comment"># 查看报告</span>
$ perf report<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这样，你就可以看到下图这个性能报告：</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/系统CPU很高但找不到应该案例分析perf截图.png" alt="系统CPU很高但找不到应该案例分析perf截图"></p>
<p>你看，stress 占了所有 CPU 时钟事件的 77%，而 stress 调用调用栈中比例最高的，是随机数生成函数 random()，看来它的确就是 CPU 使用率升高的元凶了。随后的优化就很简单了，只要修复权限问题，并减少或删除 stress 的调用，就可以减轻系统的 CPU 压力。</p>
</li>
</ul>
</li>
</ol>
<h4 id="6-2-execsnoop"><a href="#6-2-execsnoop" class="headerlink" title="6.2 execsnoop"></a>6.2 execsnoop</h4><pre><code>在这个案例中，我们使用了 top、pidstat、pstree 等工具分析了系统 CPU 使用率高的问题，并发现 CPU 升高是短时进程 stress 导致的，但是整个分析过程还是比较复杂的。对于这类问题，有没有更好的方法监控呢？

[execsnoop](https://github.com/brendangregg/perf-tools/blob/master/execsnoop) 就是一个专为短时进程设计的工具。它通过 ftrace 实时监控进程的 exec() 行为，并输出短时进程的基本信息，包括进程 PID、父进程 PID、命令行参数以及执行的结果。

比如，用 execsnoop 监控上述案例，就可以直接得到 stress 进程的父进程 PID 以及它的命令行参数，并可以发现大量的 stress 进程在不停启动：

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 按 Ctrl+C 结束</span>
$ execsnoop
PCOMM            PID    <span class="token environment constant">PPID</span>   RET ARGS
<span class="token function">sh</span>               <span class="token number">30394</span>  <span class="token number">30393</span>    <span class="token number">0</span>
stress           <span class="token number">30396</span>  <span class="token number">30394</span>    <span class="token number">0</span> /usr/local/bin/stress -t <span class="token number">1</span> -d <span class="token number">1</span>
<span class="token function">sh</span>               <span class="token number">30398</span>  <span class="token number">30393</span>    <span class="token number">0</span>
stress           <span class="token number">30399</span>  <span class="token number">30398</span>    <span class="token number">0</span> /usr/local/bin/stress -t <span class="token number">1</span> -d <span class="token number">1</span>
<span class="token function">sh</span>               <span class="token number">30402</span>  <span class="token number">30400</span>    <span class="token number">0</span>
stress           <span class="token number">30403</span>  <span class="token number">30402</span>    <span class="token number">0</span> /usr/local/bin/stress -t <span class="token number">1</span> -d <span class="token number">1</span>
<span class="token function">sh</span>               <span class="token number">30405</span>  <span class="token number">30393</span>    <span class="token number">0</span>
stress           <span class="token number">30407</span>  <span class="token number">30405</span>    <span class="token number">0</span> /usr/local/bin/stress -t <span class="token number">1</span> -d <span class="token number">1</span>
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
execsnoop 所用的 ftrace 是一种常用的动态追踪技术，一般用于分析 Linux 内核的运行时行为，后面课程我也会详细介绍并带你使用。
</code></pre><h4 id="6-3-小结"><a href="#6-3-小结" class="headerlink" title="6.3 小结"></a>6.3 小结</h4><p>碰到常规问题无法解释的 CPU 使用率情况时，首先要想到有可能是短时应用导致的问题，比如有可能是下面这两种情况。</p>
<ul>
<li>第一，应用里直接调用了其他二进制程序，这些程序通常运行时间比较短，通过 top 等工具也不容易发现。</li>
<li>第二，应用本身在不停地崩溃重启，而启动过程的资源初始化，很可能会占用相当多的 CPU。</li>
</ul>
<p>对于这类进程，我们可以用 pstree 或者 execsnoop 找到它们的父进程，再从父进程所在的应用入手，排查问题的根源。</p>
<h3 id="07-案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（上）"><a href="#07-案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（上）" class="headerlink" title="07 | 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（上）"></a>07 | 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（上）</h3><h4 id="7-1-进程状态"><a href="#7-1-进程状态" class="headerlink" title="7.1 进程状态"></a>7.1 进程状态</h4><p>当 iowait 升高时，进程很可能因为得不到硬件的响应，而长时间处于不可中断状态。从 ps 或者 top 命令的输出中，你可以发现它们都处于 D 状态，也就是不可中断状态（Uninterruptible Sleep）。</p>
<p>top 和 ps 是最常用的查看进程状态的工具，我们就从 top 的输出开始。下面是一个 top 命令输出的示例，S 列（也就是 Status 列）表示进程的状态。从这个示例里，你可以看到 R、D、Z、S、I 等几个状态，它们分别是什么意思呢？</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">top</span>
  PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
<span class="token number">28961</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">43816</span>   <span class="token number">3148</span>   <span class="token number">4040</span> R   <span class="token number">3.2</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.01 <span class="token function">top</span>
  <span class="token number">620</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">37280</span>  <span class="token number">33676</span>    <span class="token number">908</span> D   <span class="token number">0.3</span>  <span class="token number">0.4</span>   <span class="token number">0</span>:00.01 app
    <span class="token number">1</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">160072</span>   <span class="token number">9416</span>   <span class="token number">6752</span> S   <span class="token number">0.0</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:37.64 systemd
 <span class="token number">1896</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> Z   <span class="token number">0.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.00 devapp
    <span class="token number">2</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> S   <span class="token number">0.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.10 kthreadd
    <span class="token number">4</span> root       <span class="token number">0</span> -20       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> I   <span class="token number">0.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.00 kworker/0:0H
    <span class="token number">6</span> root       <span class="token number">0</span> -20       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> I   <span class="token number">0.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.00 mm_percpu_wq
    <span class="token number">7</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> S   <span class="token number">0.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:06.37 ksoftirqd/0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>我们挨个来看一下：</p>
<ul>
<li>R 是 Running 或 Runnable 的缩写，表示进程在 CPU 的就绪队列中，正在运行或者正在等待运行。</li>
<li>D 是 Disk Sleep 的缩写，也就是不可中断状态睡眠（Uninterruptible Sleep），一般表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断。</li>
<li>Z 是 Zombie 的缩写，如果你玩过“植物大战僵尸”这款游戏，应该知道它的意思。它表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID 等）。</li>
<li>S 是 Interruptible Sleep 的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入 R 状态。</li>
<li>I 是 Idle 的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上。前面说了，硬件交互导致的不可中断进程用 D 表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用 Idle 正是为了区分这种情况。要注意，D 状态的进程会导致平均负载升高， I 状态的进程却不会。</li>
</ul>
<p>当然了，上面的示例并没有包括进程的所有状态。除了以上 5 个状态，进程还包括下面这 2 个状态。</p>
<ul>
<li>第一个是 T 或者 t，也就是 Stopped 或 Traced 的缩写，表示进程处于暂停或者跟踪状态。<blockquote>
<p>向一个进程发送 SIGSTOP 信号，它就会因响应这个信号变成暂停状态（Stopped）；再向它发送 SIGCONT 信号，进程又会恢复运行（如果进程是终端里直接启动的，则需要你用 fg 命令，恢复到前台运行）。</p>
<p>而当你用调试器（如 gdb）调试一个进程时，在使用断点中断进程后，进程就会变成跟踪状态，这其实也是一种特殊的暂停状态，只不过你可以用调试器来跟踪并按需要控制进程的运行。</p>
</blockquote>
</li>
<li>另一个是 X，也就是 Dead 的缩写，表示进程已经消亡，所以你不会在 top 或者 ps 命令中看到它。</li>
</ul>
<ol>
<li><p>不可中断状态</p>
<p> 先看不可中断状态，这其实是为了保证进程数据与硬件状态一致，并且正常情况下，不可中断状态在很短时间内就会结束。所以，短时的不可中断状态进程，我们一般可以忽略。</p>
<p> 但如果系统或硬件发生了故障，进程可能会在不可中断状态保持很久，甚至导致系统中出现大量不可中断进程。这时，你就得注意下，系统是不是出现了 I/O 等性能问题。</p>
</li>
<li><p>僵尸进程</p>
<p> 再看僵尸进程，这是多进程应用很容易碰到的问题。正常情况下，当一个进程创建了子进程后，它应该通过系统调用 wait() 或者 waitpid() 等待子进程结束，回收子进程的资源；而子进程在结束时，会向它的父进程发送 SIGCHLD 信号，所以，父进程还可以注册 SIGCHLD 信号的处理函数，异步回收资源。</p>
<p> 如果父进程没这么做，或是子进程执行太快，父进程还没来得及处理子进程状态，子进程就已经提前退出，那这时的子进程就会变成僵尸进程。换句话说，父亲应该一直对儿子负责，善始善终，如果不作为或者跟不上，都会导致“问题少年”的出现。</p>
<p> 通常，僵尸进程持续的时间都比较短，在父进程回收它的资源后就会消亡；或者在父进程退出后，由 init 进程回收后也会消亡。</p>
<p> 一旦父进程没有处理子进程的终止，还一直保持运行状态，那么子进程就会一直处于僵尸状态。大量的僵尸进程会用尽 PID 进程号，导致新进程不能创建，所以这种情况一定要避免。</p>
</li>
</ol>
<h4 id="7-1-案例分析"><a href="#7-1-案例分析" class="headerlink" title="7.1 案例分析"></a>7.1 案例分析</h4><blockquote>
<p>机器配置： 2 CPU, 8 GB 内存。</p>
<p>安装软件：<code>apt install docker.io dstat sysstat</code>。</p>
<blockquote>
<p>dstat 是一个新的性能工具，它吸收了 vmstat、iostat、ifstat 等几种工具的优点，可以同时观察系统的 CPU、磁盘 I/O、网络以及内存使用情况。</p>
</blockquote>
</blockquote>
<ol>
<li><p>首先执行下面的命令运行案例应用：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker run --privileged --name<span class="token operator">=</span>app -itd feisky/app:iowait<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>然后，输入 ps 命令，确认案例应用已正常启动。如果一切正常，你应该可以看到如下所示的输出：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">ps</span> aux <span class="token operator">|</span> <span class="token function">grep</span> /app
root      <span class="token number">4009</span>  <span class="token number">0.0</span>  <span class="token number">0.0</span>   <span class="token number">4376</span>  <span class="token number">1008</span> pts/0    Ss+  05:51   <span class="token number">0</span>:00 /app
root      <span class="token number">4287</span>  <span class="token number">0.6</span>  <span class="token number">0.4</span>  <span class="token number">37280</span> <span class="token number">33660</span> pts/0    D+   05:54   <span class="token number">0</span>:00 /app
root      <span class="token number">4288</span>  <span class="token number">0.6</span>  <span class="token number">0.4</span>  <span class="token number">37280</span> <span class="token number">33668</span> pts/0    D+   05:54   <span class="token number">0</span>:00 /app<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从这个界面，我们可以发现多个 app 进程已经启动，并且它们的状态分别是 Ss+ 和 D+。其中，S 表示可中断睡眠状态，D 表示不可中断睡眠状态，我们在前面刚学过，那后面的 s 和 + 是什么意思呢？不知道也没关系，查一下 <code>man ps</code> 就可以。现在记住，s 表示这个进程是一个会话的领导进程，而 + 表示前台进程组。</p>
<p> 这里又出现了两个新概念，进程组和会话。它们用来管理一组相互关联的进程，意思其实很好理解。</p>
<ul>
<li>进程组表示一组相互关联的进程，比如每个子进程都是父进程所在组的成员；</li>
<li><p>而会话是指共享同一个控制终端的一个或多个进程组。</p>
<p>比如，我们通过 SSH 登录服务器，就会打开一个控制终端（TTY），这个控制终端就对应一个会话。而我们在终端中运行的命令以及它们的子进程，就构成了一个个的进程组，其中，在后台运行的命令，构成后台进程组；在前台运行的命令，构成前台进程组。</p>
<p>明白了这些，我们再用 top 看一下系统的资源使用情况：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 按下数字 1 切换到所有 CPU 的使用情况，观察一会儿按 Ctrl+C 结束</span>
$ <span class="token function">top</span>
<span class="token function">top</span> - 05:56:23 up <span class="token number">17</span> days, <span class="token number">16</span>:45,  <span class="token number">2</span> users,  load average: <span class="token number">2.00</span>, <span class="token number">1.68</span>, <span class="token number">1.39</span>
Tasks: <span class="token number">247</span> total,   <span class="token number">1</span> running,  <span class="token number">79</span> sleeping,   <span class="token number">0</span> stopped, <span class="token number">115</span> zombie
%Cpu0  <span class="token builtin class-name">:</span>  <span class="token number">0.0</span> us,  <span class="token number">0.7</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">38.9</span> id, <span class="token number">60.5</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
%Cpu1  <span class="token builtin class-name">:</span>  <span class="token number">0.0</span> us,  <span class="token number">0.7</span> sy,  <span class="token number">0.0</span> ni,  <span class="token number">4.7</span> id, <span class="token number">94.6</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
<span class="token punctuation">..</span>.

PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
<span class="token number">4340</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">44676</span>   <span class="token number">4048</span>   <span class="token number">3432</span> R   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.05 <span class="token function">top</span>
<span class="token number">4345</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">37280</span>  <span class="token number">33624</span>    <span class="token number">860</span> D   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.01 app
<span class="token number">4344</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">37280</span>  <span class="token number">33624</span>    <span class="token number">860</span> D   <span class="token number">0.3</span>  <span class="token number">0.4</span>   <span class="token number">0</span>:00.01 app
   <span class="token number">1</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">160072</span>   <span class="token number">9416</span>   <span class="token number">6752</span> S   <span class="token number">0.0</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:38.59 systemd
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>从这里你能看出什么问题吗？</p>
</li>
<li><p>先看第一行的平均负载（ Load Average），过去 1 分钟、5 分钟和 15 分钟内的平均负载在依次减小，说明平均负载正在升高；而 1 分钟内的平均负载已经达到系统的 CPU 个数，说明系统很可能已经有了性能瓶颈。</p>
</li>
<li>再看第二行的 Tasks，有 1 个正在运行的进程，但僵尸进程比较多，而且还在不停增加，说明有子进程在退出时没被清理。</li>
<li>接下来看两个 CPU 的使用率情况，用户 CPU 和系统 CPU 都不高，但 iowait 分别是 60.5% 和 94.6%，好像有点儿不正常。</li>
<li><p>最后再看每个进程的情况， CPU 使用率最高的进程只有 0.3%，看起来并不高；但有两个进程处于 D 状态，它们可能在等待 I/O，但光凭这里并不能确定是它们导致了 iowait 升高。</p>
<p>汇总一下：</p>
</li>
<li><p>第一点，iowait 太高了，导致系统的平均负载升高，甚至达到了系统 CPU 的个数。</p>
</li>
<li>第二点，僵尸进程在不断增多，说明有程序没能正确清理子进程的资源。</li>
</ul>
</li>
</ol>
<h4 id="7-2-小结"><a href="#7-2-小结" class="headerlink" title="7.2 小结"></a>7.2 小结</h4><p>进程的状态包括运行（R）、空闲（I）、不可中断睡眠（D）、可中断睡眠（S）、僵尸（Z）以及暂停（T）等。</p>
<p>其中，不可中断状态和僵尸状态，是我们今天学习的重点。</p>
<ul>
<li>不可中断状态，表示进程正在跟硬件交互，为了保护进程数据和硬件的一致性，系统不允许其他进程或中断打断这个进程。进程长时间处于不可中断状态，通常表示系统有 I/O 性能问题。</li>
<li>僵尸进程表示进程已经退出，但它的父进程还没有回收子进程占用的资源。短暂的僵尸状态我们通常不必理会，但进程长时间处于僵尸状态，就应该注意了，可能有应用程序没有正常处理子进程的退出。</li>
</ul>
<h3 id="08-案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（下）"><a href="#08-案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（下）" class="headerlink" title="08 | 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（下）"></a>08 | 案例篇：系统中出现大量不可中断进程和僵尸进程怎么办？（下）</h3><p>打开一个终端，登录到上次的机器中。然后执行下面的命令，重新运行这个案例：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 先删除上次启动的案例</span>
$ docker <span class="token function">rm</span> -f app
<span class="token comment"># 重新运行案例</span>
$ docker run --privileged --name<span class="token operator">=</span>app -itd feisky/app:iowait<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="8-1-iowait-分析"><a href="#8-1-iowait-分析" class="headerlink" title="8.1 iowait 分析"></a>8.1 iowait 分析</h4><p>一提到 iowait 升高，你首先会想要查询系统的 I/O 情况。我一般也是这种思路，那么什么工具可以查询系统的 I/O 情况呢？</p>
<p>这里，我推荐的正是上节课要求安装的 dstat ，它的好处是，可以同时查看 CPU 和 I/O 这两种资源的使用情况，便于对比分析。</p>
<ol>
<li><p>在终端中运行 dstat 命令，观察 CPU 和 I/O 的使用情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 间隔 1 秒输出 10 组数据</span>
$ dstat <span class="token number">1</span> <span class="token number">10</span>
You did not <span class="token keyword">select</span> any stats, using -cdngy by default.
--total-cpu-usage-- -dsk/total- -net/total- ---paging-- ---system--
usr sys idl wai stl<span class="token operator">|</span> <span class="token builtin class-name">read</span>  writ<span class="token operator">|</span> recv  send<span class="token operator">|</span>  <span class="token keyword">in</span>   out <span class="token operator">|</span> int   csw
  <span class="token number">0</span>   <span class="token number">0</span>  <span class="token number">96</span>   <span class="token number">4</span>   <span class="token number">0</span><span class="token operator">|</span>1219k  408k<span class="token operator">|</span>   <span class="token number">0</span>     <span class="token number">0</span> <span class="token operator">|</span>   <span class="token number">0</span>     <span class="token number">0</span> <span class="token operator">|</span>  <span class="token number">42</span>   <span class="token number">885</span>
  <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">2</span>  <span class="token number">98</span>   <span class="token number">0</span><span class="token operator">|</span>  34M    <span class="token number">0</span> <span class="token operator">|</span> 198B  790B<span class="token operator">|</span>   <span class="token number">0</span>     <span class="token number">0</span> <span class="token operator">|</span>  <span class="token number">42</span>   <span class="token number">138</span>
  <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span> <span class="token number">100</span>   <span class="token number">0</span><span class="token operator">|</span>  34M    <span class="token number">0</span> <span class="token operator">|</span>  66B  342B<span class="token operator">|</span>   <span class="token number">0</span>     <span class="token number">0</span> <span class="token operator">|</span>  <span class="token number">42</span>   <span class="token number">135</span>
  <span class="token number">0</span>   <span class="token number">0</span>  <span class="token number">84</span>  <span class="token number">16</span>   <span class="token number">0</span><span class="token operator">|</span>5633k    <span class="token number">0</span> <span class="token operator">|</span>  66B  342B<span class="token operator">|</span>   <span class="token number">0</span>     <span class="token number">0</span> <span class="token operator">|</span>  <span class="token number">52</span>   <span class="token number">177</span>
  <span class="token number">0</span>   <span class="token number">3</span>  <span class="token number">39</span>  <span class="token number">58</span>   <span class="token number">0</span><span class="token operator">|</span>  22M    <span class="token number">0</span> <span class="token operator">|</span>  66B  342B<span class="token operator">|</span>   <span class="token number">0</span>     <span class="token number">0</span> <span class="token operator">|</span>  <span class="token number">43</span>   <span class="token number">144</span>
  <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span> <span class="token number">100</span>   <span class="token number">0</span><span class="token operator">|</span>  34M    <span class="token number">0</span> <span class="token operator">|</span> 200B  450B<span class="token operator">|</span>   <span class="token number">0</span>     <span class="token number">0</span> <span class="token operator">|</span>  <span class="token number">46</span>   <span class="token number">147</span>
  <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">2</span>  <span class="token number">98</span>   <span class="token number">0</span><span class="token operator">|</span>  34M    <span class="token number">0</span> <span class="token operator">|</span>  66B  342B<span class="token operator">|</span>   <span class="token number">0</span>     <span class="token number">0</span> <span class="token operator">|</span>  <span class="token number">45</span>   <span class="token number">134</span>
  <span class="token number">0</span>   <span class="token number">0</span>   <span class="token number">0</span> <span class="token number">100</span>   <span class="token number">0</span><span class="token operator">|</span>  34M    <span class="token number">0</span> <span class="token operator">|</span>  66B  342B<span class="token operator">|</span>   <span class="token number">0</span>     <span class="token number">0</span> <span class="token operator">|</span>  <span class="token number">39</span>   <span class="token number">131</span>
  <span class="token number">0</span>   <span class="token number">0</span>  <span class="token number">83</span>  <span class="token number">17</span>   <span class="token number">0</span><span class="token operator">|</span>5633k    <span class="token number">0</span> <span class="token operator">|</span>  66B  342B<span class="token operator">|</span>   <span class="token number">0</span>     <span class="token number">0</span> <span class="token operator">|</span>  <span class="token number">46</span>   <span class="token number">168</span>
  <span class="token number">0</span>   <span class="token number">3</span>  <span class="token number">39</span>  <span class="token number">59</span>   <span class="token number">0</span><span class="token operator">|</span>  22M    <span class="token number">0</span> <span class="token operator">|</span>  66B  342B<span class="token operator">|</span>   <span class="token number">0</span>     <span class="token number">0</span> <span class="token operator">|</span>  <span class="token number">37</span>   <span class="token number">134</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从 dstat 的输出，我们可以看到，每当 iowait 升高（wai）时，磁盘的读请求（read）都会很大。这说明 iowait 的升高跟磁盘的读请求有关，很可能就是磁盘读导致的。</p>
<p> 那到底是哪个进程在读磁盘呢？不知道你还记不记得，上节在 top 里看到的不可中断状态进程，我觉得它就很可疑，我们试着来分析下。</p>
</li>
<li><p>继续在刚才的终端中，运行 top 命令，观察 D 状态的进程：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 观察一会儿按 Ctrl+C 结束</span>
$ <span class="token function">top</span>
<span class="token punctuation">..</span>.
 PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
<span class="token number">4340</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">44676</span>   <span class="token number">4048</span>   <span class="token number">3432</span> R   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.05 <span class="token function">top</span>
<span class="token number">4345</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">37280</span>  <span class="token number">33624</span>    <span class="token number">860</span> D   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.01 app
<span class="token number">4344</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">37280</span>  <span class="token number">33624</span>    <span class="token number">860</span> D   <span class="token number">0.3</span>  <span class="token number">0.4</span>   <span class="token number">0</span>:00.01 app
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 我们从 top 的输出找到 D 状态进程的 PID，你可以发现，这个界面里有两个 D 状态的进程，PID 分别是 4344 和 4345。</p>
<p> 一般要查看某一个进程的资源使用情况，都可以用我们的老朋友 pidstat，不过这次记得加上 -d 参数，以便输出 I/O 使用情况。</p>
</li>
<li><p>以 4344 为例，我们在终端里运行下面的 pidstat 命令，并用 -p 4344 参数指定进程号：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -d 展示 I/O 统计数据，-p 指定进程号，间隔 1 秒输出 3 组数据</span>
$ pidstat -d -p <span class="token number">4344</span> <span class="token number">1</span> <span class="token number">3</span>
06:38:50      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:38:51        <span class="token number">0</span>      <span class="token number">4344</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>       <span class="token number">0</span>  app
06:38:52        <span class="token number">0</span>      <span class="token number">4344</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>       <span class="token number">0</span>  app
06:38:53        <span class="token number">0</span>      <span class="token number">4344</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>       <span class="token number">0</span>  app<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 在这个输出中， kB_rd 表示每秒读的 KB 数， kB_wr 表示每秒写的 KB 数，iodelay 表示 I/O 的延迟（单位是时钟周期）。它们都是 0，那就表示此时没有任何的读写，说明问题不是 4344 进程导致的。</p>
<p> 可是，用同样的方法分析进程 4345，你会发现，它也没有任何磁盘读写。</p>
<p> 那要怎么知道，到底是哪个进程在进行磁盘读写呢？我们继续使用 pidstat，但这次去掉进程号，干脆就来观察所有进程的 I/O 使用情况。</p>
</li>
<li><p>在终端中运行下面的 pidstat 命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 间隔 1 秒输出多组数据 (这里是 20 组)</span>
$ pidstat -d <span class="token number">1</span> <span class="token number">20</span>
<span class="token punctuation">..</span>.
06:48:46      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:48:47        <span class="token number">0</span>      <span class="token number">4615</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>       <span class="token number">1</span>  kworker/u4:1
06:48:47        <span class="token number">0</span>      <span class="token number">6080</span>  <span class="token number">32768.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">170</span>  app
06:48:47        <span class="token number">0</span>      <span class="token number">6081</span>  <span class="token number">32768.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">184</span>  app

06:48:47      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:48:48        <span class="token number">0</span>      <span class="token number">6080</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">110</span>  app

06:48:48      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:48:49        <span class="token number">0</span>      <span class="token number">6081</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">191</span>  app

06:48:49      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command

06:48:50      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:48:51        <span class="token number">0</span>      <span class="token number">6082</span>  <span class="token number">32768.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>       <span class="token number">0</span>  app
06:48:51        <span class="token number">0</span>      <span class="token number">6083</span>  <span class="token number">32768.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>       <span class="token number">0</span>  app

06:48:51      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:48:52        <span class="token number">0</span>      <span class="token number">6082</span>  <span class="token number">32768.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">184</span>  app
06:48:52        <span class="token number">0</span>      <span class="token number">6083</span>  <span class="token number">32768.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">175</span>  app

06:48:52      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:48:53        <span class="token number">0</span>      <span class="token number">6083</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">105</span>  app
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 观察一会儿可以发现，的确是 app 进程在进行磁盘读，并且每秒读的数据有 32 MB，看来就是 app 的问题。不过，app 进程到底在执行啥 I/O 操作呢？</p>
<p> 这里，我们需要回顾一下进程用户态和内核态的区别。进程想要访问磁盘，就必须使用系统调用，所以接下来，重点就是找出 app 进程的系统调用了。</p>
</li>
<li><p>strace 正是最常用的跟踪进程系统调用的工具。所以，我们从 pidstat 的输出中拿到进程的 PID 号，比如 6082，然后在终端中运行 strace 命令，并用 -p 参数指定 PID 号：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">strace</span> -p <span class="token number">6082</span>
strace: attach: ptrace<span class="token punctuation">(</span>PTRACE_SEIZE, <span class="token number">6082</span><span class="token punctuation">)</span>: Operation not permitted<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p> <strong>一般遇到这种问题时，我会先检查一下进程的状态是否正常。</strong> 比如，继续在终端中运行 ps 命令，并使用 grep 找出刚才的 6082 号进程：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">ps</span> aux <span class="token operator">|</span> <span class="token function">grep</span> <span class="token number">6082</span>
root      <span class="token number">6082</span>  <span class="token number">0.0</span>  <span class="token number">0.0</span>      <span class="token number">0</span>     <span class="token number">0</span> pts/0    Z+   <span class="token number">13</span>:43   <span class="token number">0</span>:00 <span class="token punctuation">[</span>app<span class="token punctuation">]</span> <span class="token operator">&lt;</span>defunct<span class="token operator">&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p> 果然，进程 6082 已经变成了 Z 状态，也就是僵尸进程。僵尸进程都是已经退出的进程，所以就没法儿继续分析它的系统调用。关于僵尸进程的处理方法，我们一会儿再说，现在还是继续分析 iowait 的问题。</p>
<p> 到这一步，你应该注意到了，系统 iowait 的问题还在继续，但是 top、pidstat 这类工具已经不能给出更多的信息了。这时，我们就应该求助那些基于事件记录的动态追踪工具了。</p>
</li>
<li><p>你可以用 perf top 看看有没有新发现。再或者，可以像我一样，在终端中运行 perf record，持续一会儿（例如 15 秒），然后按 Ctrl+C 退出，再运行 perf report 查看报告：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ perf record -g
$ perf report<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p> 接着，找到我们关注的 app 进程，按回车键展开调用栈，你就会得到下面这张调用关系图：</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/大量不可中断进程和僵尸进程案例iowait分析perf截图.png" alt="大量不可中断进程和僵尸进程案例iowait分析perf截图"></p>
<p> 这个图里的 swapper 是内核中的调度进程，你可以先忽略掉。</p>
<p> 我们来看其他信息，你可以发现， app 的确在通过系统调用 sys_read() 读取数据。并且从 new_sync_read 和 blkdev_direct_IO 能看出，进程正在对磁盘进行<strong>直接读</strong>，也就是绕过了系统缓存，每个读请求都会从磁盘直接读，这就可以解释我们观察到的 iowait 升高了。</p>
<p> 看来，罪魁祸首是 app 内部进行了磁盘的直接 I/O 啊！</p>
<p> 查看源码文件 <a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/blob/master/high-iowait-process/app.c">app.c</a>，你会发现它果然使用了 O_DIRECT 选项打开磁盘，于是绕过了系统缓存，直接对磁盘进行读写。</p>
 <pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token function">open</span><span class="token punctuation">(</span>disk<span class="token punctuation">,</span> O_RDONLY<span class="token operator">|</span>O_DIRECT<span class="token operator">|</span>O_LARGEFILE<span class="token punctuation">,</span> <span class="token number">0755</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> 直接读写磁盘，对 I/O 敏感型应用（比如数据库系统）是很友好的，因为你可以在应用中，直接控制磁盘的读写。但在大部分情况下，我们最好还是通过系统缓存来优化磁盘 I/O，换句话说，删除 O_DIRECT 这个选项就是了。</p>
<p> <a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/blob/master/high-iowait-process/app-fix1.c">app-fix1.c</a> 就是修改后的文件，我也打包成了一个镜像文件，运行下面的命令，你就可以启动它了：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 首先删除原来的应用</span>
$ docker <span class="token function">rm</span> -f app
<span class="token comment"># 运行新的应用</span>
$ docker run --privileged --name<span class="token operator">=</span>app -itd feisky/app:iowait-fix1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>最后，再用 top 检查一下：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">top</span>
<span class="token function">top</span> - <span class="token number">14</span>:59:32 up <span class="token number">19</span> min,  <span class="token number">1</span> user,  load average: <span class="token number">0.15</span>, <span class="token number">0.07</span>, <span class="token number">0.05</span>
Tasks: <span class="token number">137</span> total,   <span class="token number">1</span> running,  <span class="token number">72</span> sleeping,   <span class="token number">0</span> stopped,  <span class="token number">12</span> zombie
%Cpu0  <span class="token builtin class-name">:</span>  <span class="token number">0.0</span> us,  <span class="token number">1.7</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">98.0</span> id,  <span class="token number">0.3</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
%Cpu1  <span class="token builtin class-name">:</span>  <span class="token number">0.0</span> us,  <span class="token number">1.3</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">98.7</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
<span class="token punctuation">..</span>.

 PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
<span class="token number">3084</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> Z   <span class="token number">1.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.04 app
<span class="token number">3085</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> Z   <span class="token number">1.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.04 app
    <span class="token number">1</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">159848</span>   <span class="token number">9120</span>   <span class="token number">6724</span> S   <span class="token number">0.0</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:09.03 systemd
    <span class="token number">2</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> S   <span class="token number">0.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.00 kthreadd
    <span class="token number">3</span> root<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 你会发现， iowait 已经非常低了，只有 0.3%，说明刚才的改动已经成功修复了 iowait 高的问题。</p>
</li>
</ol>
<h4 id="8-2-僵尸进程"><a href="#8-2-僵尸进程" class="headerlink" title="8.2 僵尸进程"></a>8.2 僵尸进程</h4><p>既然僵尸进程是因为父进程没有回收子进程的资源而出现的，那么，要解决掉它们，就要找到它们的根儿，也就是找出父进程，然后在父进程里解决。</p>
<ol>
<li><p>父进程的找法我们前面讲过，最简单的就是运行 pstree 命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -a 表示输出命令行选项</span>
<span class="token comment"># p 表 PID</span>
<span class="token comment"># s 表示指定进程的父进程</span>
$ pstree -aps <span class="token number">3084</span>
systemd,1
└─dockerd,15006 -H fd://
    └─docker-containe,15024 --config /var/run/docker/containerd/containerd.toml
        └─docker-containe,3991 -namespace moby -workdir<span class="token punctuation">..</span>.
            └─app,4009
                └─<span class="token punctuation">(</span>app,3084<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 运行完，你会发现 3084 号进程的父进程是 4009，也就是 app 应用。</p>
<p> 所以，我们接着查看 app 应用程序的代码，看看子进程结束的处理是否正确，比如有没有调用 wait() 或 waitpid() ，抑或是，有没有注册 SIGCHLD 信号的处理函数。</p>
</li>
<li><p>现在我们查看修复 iowait 后的源码文件 <a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/blob/master/high-iowait-process/app-fix1.c">app-fix1.c</a> ，找到子进程的创建和清理的地方：</p>
 <pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> status <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token punctuation">;</span><span class="token punctuation">;</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">2</span><span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token function">fork</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token function">sub_process</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    <span class="token function">sleep</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token keyword">while</span><span class="token punctuation">(</span><span class="token function">wait</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>status<span class="token punctuation">)</span><span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 循环语句本来就容易出错，你能找到这里的问题吗？这段代码虽然看起来调用了 wait() 函数等待子进程结束，但却错误地把 wait() 放到了 for 死循环的外面，也就是说，wait() 函数实际上并没被调用到，我们把它挪到 for 循环的里面就可以了。</p>
</li>
<li><p>修改后的文件我放到了 <a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/blob/master/high-iowait-process/app-fix2.c">app-fix2.c</a> 中，也打包成了一个 Docker 镜像，运行下面的命令，你就可以启动它：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 先停止产生僵尸进程的 app</span>
$ docker <span class="token function">rm</span> -f app
<span class="token comment"># 然后启动新的 app</span>
$ docker run --privileged --name<span class="token operator">=</span>app -itd feisky/app:iowait-fix2
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>启动后，再用 top 最后来检查一遍：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">top</span>
<span class="token function">top</span> - <span class="token number">15</span>:00:44 up <span class="token number">20</span> min,  <span class="token number">1</span> user,  load average: <span class="token number">0.05</span>, <span class="token number">0.05</span>, <span class="token number">0.04</span>
Tasks: <span class="token number">125</span> total,   <span class="token number">1</span> running,  <span class="token number">72</span> sleeping,   <span class="token number">0</span> stopped,   <span class="token number">0</span> zombie
%Cpu0  <span class="token builtin class-name">:</span>  <span class="token number">0.0</span> us,  <span class="token number">1.7</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">98.3</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
%Cpu1  <span class="token builtin class-name">:</span>  <span class="token number">0.0</span> us,  <span class="token number">1.3</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">98.7</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
<span class="token punctuation">..</span>.

PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
<span class="token number">3198</span> root      <span class="token number">20</span>   <span class="token number">0</span>    <span class="token number">4376</span>    <span class="token number">840</span>    <span class="token number">780</span> S   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.01 app
    <span class="token number">2</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> S   <span class="token number">0.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.00 kthreadd
    <span class="token number">3</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> I   <span class="token number">0.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.41 kworker/0:0
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 好了，僵尸进程（Z 状态）没有了， iowait 也是 0，问题终于全部解决了。</p>
</li>
</ol>
<h4 id="8-3-小结"><a href="#8-3-小结" class="headerlink" title="8.3 小结"></a>8.3 小结</h4><p>虽然这个案例是磁盘 I/O 导致了 iowait 升高，不过， <strong>iowait 高不一定代表 I/O 有性能瓶颈。当系统中只有 I/O 类型的进程在运行时，iowait 也会很高，但实际上，磁盘的读写远没有达到性能瓶颈的程度。</strong></p>
<p>因此，碰到 iowait 升高时，需要先用 dstat、pidstat 等工具，确认是不是磁盘 I/O 的问题，然后再找是哪些进程导致了 I/O。</p>
<p>等待 I/O 的进程一般是不可中断状态，所以用 ps 命令找到的 D 状态（即不可中断状态）的进程，多为可疑进程。但这个案例中，在 I/O 操作后，进程又变成了僵尸进程，所以不能用 strace 直接分析这个进程的系统调用。</p>
<p>这种情况下，我们用了 perf 工具，来分析系统的 CPU 时钟事件，最终发现是直接 I/O 导致的问题。这时，再检查源码中对应位置的问题，就很轻松了。</p>
<p>而僵尸进程的问题相对容易排查，使用 pstree 找出父进程后，去查看父进程的代码，检查 wait() / waitpid() 的调用，或是 SIGCHLD 信号处理函数的注册就行了。</p>
<h3 id="09-基础篇：怎么理解Linux软中断？"><a href="#09-基础篇：怎么理解Linux软中断？" class="headerlink" title="09 | 基础篇：怎么理解Linux软中断？"></a>09 | 基础篇：怎么理解Linux软中断？</h3><h4 id="9-1-从“取外卖”看中断"><a href="#9-1-从“取外卖”看中断" class="headerlink" title="9.1 从“取外卖”看中断"></a>9.1 从“取外卖”看中断</h4><p>中断是系统用来响应硬件设备请求的一种机制，它会打断进程的正常调度和执行，然后调用内核中的中断处理程序来响应设备的请求。</p>
<p>为什么要有中断呢？</p>
<p>比如说你订了一份外卖，但是不确定外卖什么时候送到，也没有别的方法了解外卖的进度，但是，配送员送外卖是不等人的，到了你这儿没人取的话，就直接走人了。所以你只能苦苦等着，时不时去门口看看外卖送到没，而不能干其他事情。</p>
<p>不过呢，如果在订外卖的时候，你就跟配送员约定好，让他送到后给你打个电话，那你就不用苦苦等待了，就可以去忙别的事情，直到电话一响，接电话、取外卖就可以了。</p>
<p>这里的“打电话”，其实就是一个中断。没接到电话的时候，你可以做其他的事情；只有接到了电话（也就是发生中断），你才要进行另一个动作：取外卖。</p>
<p>可以发现，<strong>中断其实是一种异步的事件处理机制，可以提高系统的并发处理能力。</strong></p>
<p>由于中断处理程序会打断其他进程的运行，所以，<strong>为了减少对正常进程运行调度的影响，中断处理程序就需要尽可能快地运行</strong>。如果中断本身要做的事情不多，那么处理起来也不会有太大问题；但如果中断要处理的事情很多，中断服务程序就有可能要运行很长时间。</p>
<p>特别是，中断处理程序在响应中断时，还会临时关闭中断。这就会导致上一次中断处理完成之前，其他中断都不能响应，也就是说中断有可能会丢失。</p>
<h4 id="9-2-软中断"><a href="#9-2-软中断" class="headerlink" title="9.2 软中断"></a>9.2 软中断</h4><p>为了解决中断处理程序执行过长和中断丢失的问题，Linux 将中断处理过程分成了两个阶段，也就是<strong>上半部和下半部</strong>：</p>
<ul>
<li>上半部用来快速处理中断，它在中断禁止模式下运行，主要处理跟硬件紧密相关的或时间敏感的工作。</li>
<li>下半部用来延迟处理上半部未完成的工作，通常以内核线程的方式运行。</li>
</ul>
<p>举个最常见的网卡接收数据包的例子。</p>
<p>网卡接收到数据包后，会通过<strong>硬件中断</strong>的方式，通知内核有新的数据到了。这时，内核就应该调用中断处理程序来响应它。</p>
<p>对上半部来说，既然是快速处理，其实就是要把网卡的数据读到内存中，然后更新一下硬件寄存器的状态（表示数据已经读好了），最后再发送一个<strong>软中断</strong>信号，通知下半部做进一步的处理。</p>
<p>而下半部被软中断信号唤醒后，需要从内存中找到网络数据，再按照网络协议栈，对数据进行逐层解析和处理，直到把它送给应用程序。</p>
<p>所以，这两个阶段你也可以这样理解：</p>
<ul>
<li>上半部直接处理硬件请求，也就是我们常说的硬中断，特点是快速执行；</li>
<li>而下半部则是由内核触发，也就是我们常说的软中断，特点是延迟执行。</li>
</ul>
<p>实际上，上半部会打断 CPU 正在执行的任务，然后立即执行中断处理程序。而下半部以内核线程的方式执行，并且每个 CPU 都对应一个软中断内核线程，名字为 “ksoftirqd/CPU 编号”，比如说， 0 号 CPU 对应的软中断内核线程的名字就是 ksoftirqd/0。</p>
<p>不过要注意的是，软中断不只包括了刚刚所讲的硬件设备中断处理程序的下半部，一些内核自定义的事件也属于软中断，比如内核调度和 RCU 锁（Read-Copy Update 的缩写，RCU 是 Linux 内核中最常用的锁之一）等。</p>
<h4 id="9-3-查看软中断和内核线程"><a href="#9-3-查看软中断和内核线程" class="headerlink" title="9.3 查看软中断和内核线程"></a>9.3 查看软中断和内核线程</h4><p>proc 文件系统可以用来查看内核的数据结构，或者用来动态修改内核的配置。其中：</p>
<ul>
<li>/proc/softirqs 提供了软中断的运行情况；</li>
<li>/proc/interrupts 提供了硬中断的运行情况。</li>
</ul>
<p>运行下面的命令，查看 /proc/softirqs 文件的内容，你就可以看到各种类型软中断在不同 CPU 上的累积运行次数：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">cat</span> /proc/softirqs
                    CPU0       CPU1
          HI:          <span class="token number">0</span>          <span class="token number">0</span>
       TIMER:     <span class="token number">811613</span>    <span class="token number">1972736</span>
      NET_TX:         <span class="token number">49</span>          <span class="token number">7</span>
      NET_RX:    <span class="token number">1136736</span>    <span class="token number">1506885</span>
       BLOCK:          <span class="token number">0</span>          <span class="token number">0</span>
    IRQ_POLL:          <span class="token number">0</span>          <span class="token number">0</span>
     TASKLET:     <span class="token number">304787</span>       <span class="token number">3691</span>
       SCHED:     <span class="token number">689718</span>    <span class="token number">1897539</span>
     HRTIMER:          <span class="token number">0</span>          <span class="token number">0</span>
         RCU:    <span class="token number">1330771</span>    <span class="token number">1354737</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在查看 /proc/softirqs 文件内容时，你要特别注意以下这两点。</p>
<ul>
<li>第一，要注意软中断的类型，也就是这个界面中第一列的内容。从第一列你可以看到，软中断包括了 10 个类别，分别对应不同的工作类型。比如 NET_RX 表示网络接收中断，而 NET_TX 表示网络发送中断。</li>
<li>第二，要注意同一种软中断在不同 CPU 上的分布情况，也就是同一行的内容。正常情况下，同一种中断在不同 CPU 上的累积次数应该差不多。比如这个界面中，NET_RX 在 CPU0 和 CPU1 上的中断次数基本是同一个数量级，相差不大。</li>
</ul>
<p>不过你可能发现，TASKLET 在不同 CPU 上的分布并不均匀。TASKLET 是最常用的软中断实现机制，每个 TASKLET 只运行一次就会结束 ，并且只在调用它的函数所在的 CPU 上运行。</p>
<p>因此，使用 TASKLET 特别简便，当然也会存在一些问题，比如说由于只在一个 CPU 上运行导致的调度不均衡，再比如因为不能在多个 CPU 上并行运行带来了性能限制。</p>
<p>另外，刚刚提到过，软中断实际上是以内核线程的方式运行的，每个 CPU 都对应一个软中断内核线程，这个软中断内核线程就叫做 ksoftirqd/CPU 编号。那要怎么查看这些线程的运行状况呢？</p>
<p>其实用 ps 命令就可以做到，比如执行下面的指令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">ps</span> aux <span class="token operator">|</span> <span class="token function">grep</span> softirq
root         <span class="token number">7</span>  <span class="token number">0.0</span>  <span class="token number">0.0</span>      <span class="token number">0</span>     <span class="token number">0</span> ?        S    Oct10   <span class="token number">0</span>:01 <span class="token punctuation">[</span>ksoftirqd/0<span class="token punctuation">]</span>
root        <span class="token number">16</span>  <span class="token number">0.0</span>  <span class="token number">0.0</span>      <span class="token number">0</span>     <span class="token number">0</span> ?        S    Oct10   <span class="token number">0</span>:01 <span class="token punctuation">[</span>ksoftirqd/1<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>注意，这些线程的名字外面都有中括号，这说明 ps 无法获取它们的命令行参数（cmline）。一般来说，ps 的输出中，名字括在中括号里的，一般都是内核线程。</p>
<h3 id="10-案例篇：系统的软中断CPU使用率升高，我该怎么办？"><a href="#10-案例篇：系统的软中断CPU使用率升高，我该怎么办？" class="headerlink" title="10 | 案例篇：系统的软中断CPU使用率升高，我该怎么办？"></a>10 | 案例篇：系统的软中断CPU使用率升高，我该怎么办？</h3><h4 id="10-1-案例"><a href="#10-1-案例" class="headerlink" title="10.1 案例"></a>10.1 案例</h4><blockquote>
<p>机器配置： 2 CPU, 8 GB 内存。</p>
<p>安装软件：<code>apt-get install docker.io sysstat hping3 tcpdump</code>。</p>
<ul>
<li>sar 是一个系统活动报告工具，既可以实时查看系统的当前活动，又可以配置保存和报告历史统计数据。</li>
<li>hping3 是一个可以构造 TCP/IP 协议数据包的工具，可以对系统进行安全审计、防火墙测试等。</li>
<li>tcpdump 是一个常用的网络抓包工具，常用来分析各种网络问题。</li>
</ul>
</blockquote>
<ol>
<li><p>在第一个终端，执行下面的命令运行案例，也就是一个最基本的 Nginx 应用：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 运行 Nginx 服务并对外开放 80 端口</span>
$ docker run -itd --name<span class="token operator">=</span>nginx -p <span class="token number">80</span>:80 nginx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>在第二个终端，使用 curl 访问 Nginx 监听的端口，确认 Nginx 正常启动。假设 192.168.0.30 是 Nginx 所在虚拟机的 IP 地址，运行 curl 命令后你应该会看到下面这个输出界面：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">curl</span> http://192.168.0.30/
<span class="token operator">&lt;</span><span class="token operator">!</span>DOCTYPE html<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>html<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>head<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>title<span class="token operator">&gt;</span>Welcome to nginx<span class="token operator">!</span><span class="token operator">&lt;</span>/title<span class="token operator">&gt;</span>
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>还是在第二个终端，我们运行 hping3 命令，来模拟 Nginx 的客户端请求：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -S 参数表示设置 TCP 协议的 SYN（同步序列号），-p 表示目的端口为 80</span>
<span class="token comment"># -i u100 表示每隔 100 微秒发送一个网络帧</span>
<span class="token comment"># 注：如果你在实践过程中现象不明显，可以尝试把 100 调小，比如调成 10 甚至 1</span>
$ hping3 -S -p <span class="token number">80</span> -i u100 <span class="token number">192.168</span>.0.30<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 现在我们再回到第一个终端，你应该发现了异常。是不是感觉系统响应明显变慢了，即便只是在终端中敲几个回车，都得很久才能得到响应？这个时候应该怎么办呢？</p>
</li>
<li><p>先看看系统的整体资源使用情况应该是个不错的注意，比如执行下 top 看看是不是出现了 CPU 的瓶颈。我们在第一个终端运行 top 命令，看一下系统整体的资源使用情况。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># top 运行后按数字 1 切换到显示所有 CPU</span>
$ <span class="token function">top</span>
<span class="token function">top</span> - <span class="token number">10</span>:50:58 up <span class="token number">1</span> days, <span class="token number">22</span>:10,  <span class="token number">1</span> user,  load average: <span class="token number">0.00</span>, <span class="token number">0.00</span>, <span class="token number">0.00</span>
Tasks: <span class="token number">122</span> total,   <span class="token number">1</span> running,  <span class="token number">71</span> sleeping,   <span class="token number">0</span> stopped,   <span class="token number">0</span> zombie
%Cpu0  <span class="token builtin class-name">:</span>  <span class="token number">0.0</span> us,  <span class="token number">0.0</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">96.7</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">3.3</span> si,  <span class="token number">0.0</span> st
%Cpu1  <span class="token builtin class-name">:</span>  <span class="token number">0.0</span> us,  <span class="token number">0.0</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">95.6</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">4.4</span> si,  <span class="token number">0.0</span> st
<span class="token punctuation">..</span>.

  PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
    <span class="token number">7</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> S   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:01.64 ksoftirqd/0
   <span class="token number">16</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> S   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:01.97 ksoftirqd/1
 <span class="token number">2663</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">923480</span>  <span class="token number">28292</span>  <span class="token number">13996</span> S   <span class="token number">0.3</span>  <span class="token number">0.3</span>   <span class="token number">4</span>:58.66 docker-containe
 <span class="token number">3699</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> I   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.13 kworker/u4:0
 <span class="token number">3708</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">44572</span>   <span class="token number">4176</span>   <span class="token number">3512</span> R   <span class="token number">0.3</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:00.07 <span class="token function">top</span>
    <span class="token number">1</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">225384</span>   <span class="token number">9136</span>   <span class="token number">6724</span> S   <span class="token number">0.0</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:23.25 systemd
    <span class="token number">2</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> S   <span class="token number">0.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:00.03 kthreadd
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 我们从第一行开始，逐个看一下：</p>
<ul>
<li>平均负载全是 0，就绪队列里面只有一个进程（1 running）。</li>
<li>每个 CPU 的使用率都挺低，最高的 CPU1 的使用率也只有 4.4%，并不算高。</li>
<li><p>再看进程列表，CPU 使用率最高的进程也只有 0.3%，还是不高呀。</p>
<p>仔细看 top 的输出，两个 CPU 的使用率虽然分别只有 3.3% 和 4.4%，但都用在了软中断上；而从进程列表上也可以看到，CPU 使用率最高的也是软中断进程 ksoftirqd。看起来，软中断有点可疑了。</p>
<p>根据上一期的内容，既然软中断可能有问题，那你先要知道，究竟是哪类软中断的问题。停下来想想，上一节我们用了什么方法，来判断软中断类型呢？没错，还是 proc 文件系统。观察 /proc/softirqs 文件的内容，你就能知道各种软中断类型的次数。</p>
<p>不过，这里的各类软中断次数，又是什么时间段里的次数呢？它是系统运行以来的累积中断次数。所以我们直接查看文件内容，得到的只是累积中断次数，对这里的问题并没有直接参考意义。因为，这些中断次数的变化速率才是我们需要关注的。</p>
<p>那什么工具可以观察命令输出的变化情况呢？我想你应该想起来了，在前面案例中用过的 watch 命令，就可以定期运行一个命令来查看输出；如果再加上 -d 参数，还可以高亮出变化的部分，从高亮部分我们就可以直观看出，哪些内容变化得更快。</p>
</li>
</ul>
</li>
<li><p>在第一个终端，我们运行下面的命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">watch</span> -d <span class="token function">cat</span> /proc/softirqs
                    CPU0       CPU1
          HI:          <span class="token number">0</span>          <span class="token number">0</span>
       TIMER:    <span class="token number">1083906</span>    <span class="token number">2368646</span>
      NET_TX:         <span class="token number">53</span>          <span class="token number">9</span>
      NET_RX:    <span class="token number">1550643</span>    <span class="token number">1916776</span>
       BLOCK:          <span class="token number">0</span>          <span class="token number">0</span>
    IRQ_POLL:          <span class="token number">0</span>          <span class="token number">0</span>
     TASKLET:     <span class="token number">333637</span>       <span class="token number">3930</span>
       SCHED:     <span class="token number">963675</span>    <span class="token number">2293171</span>
     HRTIMER:          <span class="token number">0</span>          <span class="token number">0</span>
         RCU:    <span class="token number">1542111</span>    <span class="token number">1590625</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 通过 /proc/softirqs 文件内容的变化情况，你可以发现， TIMER（定时中断）、NET_RX（网络接收）、SCHED（内核调度）、RCU（RCU 锁）等这几个软中断都在不停变化。</p>
<p> 其中，NET_RX，也就是网络数据包接收软中断的变化速率最快。而其他几种类型的软中断，是保证 Linux 调度、时钟和临界区保护这些正常工作所必需的，所以它们有一定的变化倒是正常的。</p>
<p> 那么接下来，我们就从网络接收的软中断着手，继续分析。既然是网络接收的软中断，第一步应该就是观察系统的网络接收情况。这里你可能想起了很多网络工具，不过，我推荐今天的主人公工具 sar 。</p>
<p> sar 可以用来查看系统的网络收发情况，还有一个好处是，不仅可以观察网络收发的吞吐量（BPS，每秒收发的字节数），还可以观察网络收发的 PPS，即每秒收发的网络帧数。</p>
</li>
<li><p>在第一个终端中运行 sar 命令，并添加 -n DEV 参数显示网络收发的报告：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -n DEV 表示显示网络收发的报告，间隔 1 秒输出一组数据</span>
$ sar -n DEV <span class="token number">1</span>
<span class="token number">15</span>:03:46        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
<span class="token number">15</span>:03:47         eth0  <span class="token number">12607.00</span>   <span class="token number">6304.00</span>    <span class="token number">664.86</span>    <span class="token number">358.11</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.01</span>
<span class="token number">15</span>:03:47      docker0   <span class="token number">6302.00</span>  <span class="token number">12604.00</span>    <span class="token number">270.79</span>    <span class="token number">664.66</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>
<span class="token number">15</span>:03:47           lo      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>
<span class="token number">15</span>:03:47  veth9f6bbcd   <span class="token number">6302.00</span>  <span class="token number">12604.00</span>    <span class="token number">356.95</span>    <span class="token number">664.66</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.05</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 对于 sar 的输出界面，我先来简单介绍一下，从左往右依次是：</p>
<ul>
<li>第一列：表示报告的时间。</li>
<li>第二列：IFACE 表示网卡。</li>
<li>第三、四列：rxpck/s 和 txpck/s 分别表示每秒接收、发送的网络帧数，也就是 PPS。</li>
<li><p>第五、六列：rxkB/s 和 txkB/s 分别表示每秒接收、发送的千字节数，也就是 BPS。</p>
<p>后面的其他参数基本接近 0，显然跟今天的问题没有直接关系，你可以先忽略掉。</p>
<p>我们具体来看输出的内容，你可以发现：</p>
</li>
<li><p>对网卡 eth0 来说，每秒接收的网络帧数比较大，达到了 12607，而发送的网络帧数则比较小，只有 6304；每秒接收的千字节数只有 664 KB，而发送的千字节数更小，只有 358 KB。</p>
</li>
<li><p>docker0 和 veth9f6bbcd 的数据跟 eth0 基本一致，只是发送和接收相反，发送的数据较大而接收的数据较小。这是 Linux 内部网桥转发导致的，你暂且不用深究，只要知道这是系统把 eth0 收到的包转发给 Nginx 服务即可。具体工作原理，我会在后面的网络部分详细介绍。</p>
<p>既然怀疑是网络接收中断的问题，我们还是重点来看 eth0 ：接收的 PPS 比较大，达到 12607，而接收的 BPS 却很小，只有 664 KB。直观来看网络帧应该都是比较小的，我们稍微计算一下，664*1024/12607 = 54 字节，说明平均每个网络帧只有 54 字节，这显然是很小的网络帧，也就是我们通常所说的小包问题。</p>
<p>那么，有没有办法知道这是一个什么样的网络帧，以及从哪里发过来的呢？</p>
<p>使用 tcpdump 抓取 eth0 上的包就可以了。我们事先已经知道， Nginx 监听在 80 端口，它所提供的 HTTP 服务是基于 TCP 协议的，所以我们可以指定 TCP 协议和 80 端口精确抓包。</p>
</li>
</ul>
</li>
<li><p>接下来，我们在第一个终端中运行 tcpdump 命令，通过 -i eth0 选项指定网卡 eth0，并通过 tcp port 80 选项指定 TCP 协议的 80 端口：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -i eth0 只抓取 eth0 网卡，-n 不解析协议名和主机名</span>
<span class="token comment"># tcp port 80 表示只抓取 tcp 协议并且端口号为 80 的网络帧</span>
$ tcpdump -i eth0 -n tcp port <span class="token number">80</span>
<span class="token number">15</span>:11:32.678966 IP <span class="token number">192.168</span>.0.2.18238 <span class="token operator">&gt;</span> <span class="token number">192.168</span>.0.30.80: Flags <span class="token punctuation">[</span>S<span class="token punctuation">]</span>, <span class="token function">seq</span> <span class="token number">458303614</span>, win <span class="token number">512</span>, length <span class="token number">0</span>
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从 tcpdump 的输出中，你可以发现：</p>
<ul>
<li>192.168.0.2.18238 &gt; 192.168.0.30.80 ，表示网络帧从 192.168.0.2 的 18238 端口发送到 192.168.0.30 的 80 端口，也就是从运行 hping3 机器的 18238 端口发送网络帧，目的为 Nginx 所在机器的 80 端口。</li>
<li><p>Flags [S] 则表示这是一个 SYN 包。</p>
<p>再加上前面用 sar 发现的， PPS 超过 12000 的现象，现在我们可以确认，这就是从 192.168.0.2 这个地址发送过来的 SYN FLOOD 攻击。</p>
<p>SYN FLOOD 问题最简单的解决方法，就是从交换机或者硬件防火墙中封掉来源 IP，这样 SYN FLOOD 网络帧就不会发送到服务器中。</p>
</li>
</ul>
</li>
</ol>
<h4 id="10-2-终端卡顿的问题"><a href="#10-2-终端卡顿的问题" class="headerlink" title="10.2 终端卡顿的问题"></a>10.2 终端卡顿的问题</h4><p>这个是由于网络延迟增大（甚至是丢包）导致的。比如你可以再拿另外一台机器（也就是第三台）在 hping3 运行的前后 ping 一下案例机器，ping -c3 <ip></ip></p>
<p>hping3 运行前，你可能看到最长的也不超过 1 ms：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">3 packets transmitted, 3 received, 0% packet loss, time 2028ms
rtt min/avg/max/mdev = 0.815/0.914/0.989/0.081 ms<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>而 hping3 运行时，不仅平均延迟增长到了 245 ms，而且还会有丢包的发生：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">3 packets transmitted, 2 received, 33% packet loss, time 2026ms
rtt min/avg/max/mdev = 240.637/245.758/250.880/5.145 ms<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="11-套路篇：如何迅速分析出系统CPU的瓶颈在哪里？"><a href="#11-套路篇：如何迅速分析出系统CPU的瓶颈在哪里？" class="headerlink" title="11 | 套路篇：如何迅速分析出系统CPU的瓶颈在哪里？"></a>11 | 套路篇：如何迅速分析出系统CPU的瓶颈在哪里？</h3><h4 id="11-1-CPU-性能指标"><a href="#11-1-CPU-性能指标" class="headerlink" title="11.1 CPU 性能指标"></a>11.1 CPU 性能指标</h4><ol>
<li><p>最容易想到的应该是 CPU 使用率。</p>
<p> CPU 使用率描述了非空闲时间占总 CPU 时间的百分比，根据 CPU 上运行任务的不同，又被分为用户 CPU、系统 CPU、等待 I/O CPU、软中断和硬中断等。</p>
<ul>
<li>用户 CPU 使用率，包括用户态 CPU 使用率（user）和低优先级用户态 CPU 使用率（nice），表示 CPU 在用户态运行的时间百分比。用户 CPU 使用率高，通常说明有应用程序比较繁忙。</li>
<li>系统 CPU 使用率，表示 CPU 在内核态运行的时间百分比（不包括中断）。系统 CPU 使用率高，说明内核比较繁忙。</li>
<li>等待 I/O 的 CPU 使用率，通常也称为 iowait，表示等待 I/O 的时间百分比。iowait 高，通常说明系统与硬件设备的 I/O 交互时间比较长。</li>
<li>软中断和硬中断的 CPU 使用率，分别表示内核调用软中断处理程序、硬中断处理程序的时间百分比。它们的使用率高，通常说明系统发生了大量的中断。</li>
<li>除了上面这些，还有在虚拟化环境中会用到的窃取 CPU 使用率（steal）和客户 CPU 使用率（guest），分别表示被其他虚拟机占用的 CPU 时间百分比，和运行客户虚拟机的 CPU 时间百分比。</li>
</ul>
</li>
<li><p>第二个比较容易想到的，应该是平均负载（Load Average）。</p>
<p> 平均负载（Load Average），也就是系统的平均活跃进程数。它反应了系统的整体负载情况，主要包括三个数值，分别指过去 1 分钟、过去 5 分钟和过去 15 分钟的平均负载。</p>
<p> 理想情况下，平均负载等于逻辑 CPU 个数，这表示每个 CPU 都恰好被充分利用。如果平均负载大于逻辑 CPU 个数，就表示负载比较重了。</p>
</li>
<li><p>第三个，也是在专栏学习前你估计不太会注意到的，进程上下文切换。</p>
<p> 包括：</p>
<ul>
<li>无法获取资源而导致的自愿上下文切换；</li>
<li><p>被系统强制调度导致的非自愿上下文切换。</p>
<p>上下文切换，本身是保证 Linux 正常运行的一项核心功能。但过多的上下文切换，会将原本运行进程的 CPU 时间，消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，缩短进程真正运行的时间，成为性能瓶颈。</p>
</li>
</ul>
</li>
<li><p>还有一个指标，CPU 缓存的命中率。</p>
<p> 由于 CPU 发展的速度远快于内存的发展，CPU 的处理速度就比内存的访问速度快得多。这样，CPU 在访问内存的时候，免不了要等待内存的响应。为了协调这两者巨大的性能差距，CPU 缓存（通常是多级缓存）就出现了。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/CPU缓存架构.png" alt="CPU缓存架构"></p>
<p> 就像上面这张图显示的，CPU 缓存的速度介于 CPU 和内存之间，缓存的是热点的内存数据。根据不断增长的热点数据，这些缓存按照大小不同分为 L1、L2、L3 等三级缓存，其中 L1 和 L2 常用在单核中， L3 则用在多核中。</p>
<p> 从 L1 到 L3，三级缓存的大小依次增大，相应的，性能依次降低（当然比内存还是好得多）。而它们的命中率，衡量的是 CPU 缓存的复用情况，命中率越高，则表示性能越好。</p>
</li>
</ol>
<p><img src="/images/《Linux性能优化实战》学习笔记/CPU性能指标筛选清单.png" alt="CPU性能指标筛选清单"></p>
<h4 id="11-2-性能工具"><a href="#11-2-性能工具" class="headerlink" title="11.2 性能工具"></a>11.2 性能工具</h4><ol>
<li><p>平均负载的案例。</p>
<p> 我们先用 uptime， 查看了系统的平均负载；而在平均负载升高后，又用 mpstat 和 pidstat ，分别观察了每个 CPU 和每个进程 CPU 的使用情况，进而找出了导致平均负载升高的进程，也就是我们的压测工具 stress。</p>
</li>
<li><p>上下文切换的案例。</p>
<p> 我们先用 vmstat ，查看了系统的上下文切换次数和中断次数；然后通过 pidstat ，观察了进程的自愿上下文切换和非自愿上下文切换情况；最后通过 pidstat ，观察了线程的上下文切换情况，找出了上下文切换次数增多的根源，也就是我们的基准测试工具 sysbench。</p>
</li>
<li><p>进程 CPU 使用率升高的案例。</p>
<p> 我们先用 top ，查看了系统和进程的 CPU 使用情况，发现 CPU 使用率升高的进程是 php-fpm；再用 perf top ，观察 php-fpm 的调用链，最终找出 CPU 升高的根源，也就是库函数 sqrt() 。</p>
</li>
<li><p>系统的 CPU 使用率升高的案例。</p>
<p> 我们先用 top 观察到了系统 CPU 升高，但通过 top 和 pidstat ，却找不出高 CPU 使用率的进程。于是，我们重新审视 top 的输出，又从 CPU 使用率不高但处于 Running 状态的进程入手，找出了可疑之处，最终通过 perf record 和 perf report ，发现原来是短时进程在捣鬼。</p>
<p> 另外，对于短时进程，我还介绍了一个专门的工具 execsnoop，它可以实时监控进程调用的外部命令。</p>
</li>
<li><p>不可中断进程和僵尸进程的案例。</p>
<p> 我们先用 top 观察到了 iowait 升高的问题，并发现了大量的不可中断进程和僵尸进程；接着我们用 dstat 发现是这是由磁盘读导致的，于是又通过 pidstat 找出了相关的进程。但我们用 strace 查看进程系统调用却失败了，最终还是用 perf 分析进程调用链，才发现根源在于磁盘直接 I/O 。</p>
</li>
<li><p>软中断的案例。</p>
<p> 我们通过 top 观察到，系统的软中断 CPU 使用率升高；接着查看 /proc/softirqs， 找到了几种变化速率较快的软中断；然后通过 sar 命令，发现是网络小包的问题，最后再用 tcpdump ，找出网络帧的类型和来源，确定是一个 SYN FLOOD 攻击导致的。</p>
</li>
</ol>
<h4 id="11-3-活学活用，把性能指标和性能工具联系起来"><a href="#11-3-活学活用，把性能指标和性能工具联系起来" class="headerlink" title="11.3 活学活用，把性能指标和性能工具联系起来"></a>11.3 活学活用，把性能指标和性能工具联系起来</h4><ol>
<li><p>第一个维度，从 CPU 的性能指标出发。也就是说，当你要查看某个性能指标时，要清楚知道哪些工具可以做到。</p>
<p> 根据不同的性能指标，对提供指标的性能工具进行分类和理解。这样，在实际排查性能问题时，你就可以清楚知道，什么工具可以提供你想要的指标，而不是毫无根据地挨个尝试，撞运气。</p>
<p> 比如用 top 发现了软中断 CPU 使用率高后，下一步自然就想知道具体的软中断类型。那在哪里可以观察各类软中断的运行情况呢？当然是 proc 文件系统中的 /proc/softirqs 这个文件。</p>
<p> 紧接着，比如说，我们找到的软中断类型是网络接收，那就要继续往网络接收方向思考。系统的网络接收情况是什么样的？什么工具可以查到网络接收情况呢？在我们案例中，用的正是 dstat。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/根据指标找工具（CPU性能）.png" alt="根据指标找工具（CPU性能）"></p>
</li>
<li><p>第二个维度，从工具出发。也就是当你已经安装了某个工具后，要知道这个工具能提供哪些指标。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/根据工具查指标（CPU性能）.png" alt="根据工具查指标（CPU性能）"></p>
</li>
</ol>
<h4 id="11-4-如何迅速分析-CPU-的性能瓶颈"><a href="#11-4-如何迅速分析-CPU-的性能瓶颈" class="headerlink" title="11.4 如何迅速分析 CPU 的性能瓶颈"></a>11.4 如何迅速分析 CPU 的性能瓶颈</h4><p>虽然 CPU 的性能指标比较多，但要知道，既然都是描述系统的 CPU 性能，它们就不会是完全孤立的，很多指标间都有一定的关联。<strong>想弄清楚性能指标的关联性，就要通晓每种性能指标的工作原理</strong>。这也是为什么我在介绍每个性能指标时，都要穿插讲解相关的系统原理，希望你能记住这一点。</p>
<p>举个例子，用户 CPU 使用率高，我们应该去排查进程的用户态而不是内核态。因为用户 CPU 使用率反映的就是用户态的 CPU 使用情况，而内核态的 CPU 使用情况只会反映到系统 CPU 使用率上。</p>
<p>所以，<strong>为了缩小排查范围，我通常会先运行几个支持指标较多的工具，如 top、vmstat 和 pidstat</strong>。为什么是这三个工具呢？仔细看看下面这张图，你就清楚了。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/如何迅速分析CPU的性能瓶颈.png" alt="如何迅速分析CPU的性能瓶颈"></p>
<p>这张图里，我列出了 top、vmstat 和 pidstat 分别提供的重要的 CPU 指标，并用虚线表示关联关系，对应出了性能分析下一步的方向。</p>
<p>通过这张图你可以发现，这三个命令，几乎包含了所有重要的 CPU 性能指标，比如：</p>
<ul>
<li>从 top 的输出可以得到各种 CPU 使用率以及僵尸进程和平均负载等信息。</li>
<li>从 vmstat 的输出可以得到上下文切换次数、中断次数、运行状态和不可中断状态的进程数。</li>
<li>从 pidstat 的输出可以得到进程的用户 CPU 使用率、系统 CPU 使用率、以及自愿上下文切换和非自愿上下文切换情况。</li>
</ul>
<p>另外，这三个工具输出的很多指标是相互关联的，所以，我也用虚线表示了它们的关联关系，举几个例子你可能会更容易理解。</p>
<ol>
<li><p>第一个例子，pidstat 输出的进程用户 CPU 使用率升高，会导致 top 输出的用户 CPU 使用率升高。所以，当发现 top 输出的用户 CPU 使用率有问题时，可以跟 pidstat 的输出做对比，观察是否是某个进程导致的问题。</p>
<p> 而找出导致性能问题的进程后，就要用进程分析工具来分析进程的行为，比如使用 strace 分析系统调用情况，以及使用 perf 分析调用链中各级函数的执行情况。</p>
</li>
<li><p>第二个例子，top 输出的平均负载升高，可以跟 vmstat 输出的运行状态和不可中断状态的进程数做对比，观察是哪种进程导致的负载升高。</p>
<ul>
<li>如果是不可中断进程数增多了，那么就需要做 I/O 的分析，也就是用 dstat 或 sar 等工具，进一步分析 I/O 的情况。</li>
<li>如果是运行状态进程数增多了，那就需要回到 top 和 pidstat，找出这些处于运行状态的到底是什么进程，然后再用进程分析工具，做进一步分析。</li>
</ul>
</li>
<li><p>最后一个例子，当发现 top 输出的软中断 CPU 使用率升高时，可以查看 /proc/softirqs 文件中各种类型软中断的变化情况，确定到底是哪种软中断出的问题。比如，发现是网络接收中断导致的问题，那就可以继续用网络分析工具 sar 和 tcpdump 来分析。</p>
</li>
</ol>
<h3 id="12-套路篇：CPU-性能优化的几个思路"><a href="#12-套路篇：CPU-性能优化的几个思路" class="headerlink" title="12 | 套路篇：CPU 性能优化的几个思路"></a>12 | 套路篇：CPU 性能优化的几个思路</h3><h4 id="12-1-性能优化方法论"><a href="#12-1-性能优化方法论" class="headerlink" title="12.1 性能优化方法论"></a>12.1 性能优化方法论</h4><p>通过各种性能分析方法，终于找到引发性能问题的瓶颈后，是不是立刻就要开始优化了呢？别急，动手之前，你可以先看看下面这三个问题。</p>
<ul>
<li>首先，既然要做性能优化，那要怎么判断它是不是有效呢？特别是优化后，到底能提升多少性能呢？</li>
<li>第二，性能问题通常不是独立的，如果有多个性能问题同时发生，你应该先优化哪一个呢？</li>
<li>第三，提升性能的方法并不是唯一的，当有多种方法可以选择时，你会选用哪一种呢？是不是总选那个最大程度提升性能的方法就行了呢？</li>
</ul>
<p>如果你可以轻松回答这三个问题，那么二话不说就可以开始优化。</p>
<p>比如，在前面的不可中断进程案例中，通过性能分析，我们发现是因为一个进程的直接 I/O ，导致了 iowait 高达 90%。那是不是用“直接 I/O 换成缓存 I/O”的方法，就可以立即优化了呢？</p>
<p>按照上面讲的，你可以先自己思考下那三点。如果不能确定，我们一起来看看。</p>
<ul>
<li>第一个问题，直接 I/O 换成缓存 I/O，可以把 iowait 从 90% 降到接近 0，性能提升很明显。</li>
<li>第二个问题，我们没有发现其他性能问题，直接 I/O 是唯一的性能瓶颈，所以不用挑选优化对象。</li>
<li>第三个问题，缓存 I/O 是我们目前用到的最简单的优化方法，而且这样优化并不会影响应用的功能。</li>
</ul>
<p>好的，这三个问题很容易就能回答，所以立即优化没有任何问题。</p>
<h4 id="12-2-怎么评估性能优化的效果？"><a href="#12-2-怎么评估性能优化的效果？" class="headerlink" title="12.2 怎么评估性能优化的效果？"></a>12.2 怎么评估性能优化的效果？</h4><p>我们解决性能问题的目的，自然是想得到一个性能提升的效果。为了评估这个效果，我们需要对系统的性能指标进行量化，并且要分别测试出优化前、后的性能指标，用前后指标的变化来对比呈现效果。我把这个方法叫做性能评估“三步走”。</p>
<ol>
<li><p>确定性能的量化指标。</p>
<p> 我的建议是不要局限在单一维度的指标上，你至少要从应用程序和系统资源这两个维度，分别选择不同的指标。比如，以 Web 应用为例：</p>
<ul>
<li>应用程序的维度，我们可以用吞吐量和请求延迟来评估应用程序的性能。</li>
<li><p>系统资源的维度，我们可以用 CPU 使用率来评估系统的 CPU 使用情况。</p>
<p>之所以从这两个不同维度选择指标，主要是因为应用程序和系统资源这两者间相辅相成的关系。</p>
</li>
<li><p>好的应用程序是性能优化的最终目的和结果，系统优化总是为应用程序服务的。所以，必须要使用应用程序的指标，来评估性能优化的整体效果。</p>
</li>
<li>系统资源的使用情况是影响应用程序性能的根源。所以，需要用系统资源的指标，来观察和分析瓶颈的来源。</li>
</ul>
</li>
<li><p>测试优化前的性能指标。</p>
</li>
<li><p>测试优化后的性能指标。</p>
</li>
</ol>
<p>以刚刚的 Web 应用为例，对应上面提到的几个指标，我们可以选择 ab 等工具，测试 Web 应用的并发请求数和响应延迟。而测试的同时，还可以用 vmstat、pidstat 等性能工具，观察系统和进程的 CPU 使用率。这样，我们就同时获得了应用程序和系统资源这两个维度的指标数值。</p>
<p>不过，在进行性能测试时，有两个特别重要的地方你需要注意下。</p>
<ol>
<li><p>第一，要避免性能测试工具干扰应用程序的性能。通常，对 Web 应用来说，性能测试工具跟目标应用程序要在不同的机器上运行。</p>
<p> 比如，在之前的 Nginx 案例中，我每次都会强调要用两台虚拟机，其中一台运行 Nginx 服务，而另一台运行模拟客户端的工具，就是为了避免这个影响。</p>
</li>
<li><p>第二，避免外部环境的变化影响性能指标的评估。这要求优化前、后的应用程序，都运行在相同配置的机器上，并且它们的外部依赖也要完全一致。</p>
<p> 比如还是拿 Nginx 来说，就可以运行在同一台机器上，并用相同参数的客户端工具来进行性能测试。</p>
</li>
</ol>
<h4 id="12-3-多个性能问题同时存在，要怎么选择？"><a href="#12-3-多个性能问题同时存在，要怎么选择？" class="headerlink" title="12.3 多个性能问题同时存在，要怎么选择？"></a>12.3 多个性能问题同时存在，要怎么选择？</h4><p>系统性能总是牵一发而动全身，所以性能问题通常也不是独立存在的。那当多个性能问题同时发生的时候，应该先去优化哪一个呢？</p>
<p>在性能测试的领域，流传很广的一个说法是“二八原则”，也就是说 80% 的问题都是由 20% 的代码导致的。只要找出这 20% 的位置，你就可以优化 80% 的性能。所以，我想表达的是，<strong>并不是所有的性能问题都值得优化</strong>。</p>
<p>我的建议是，动手优化之前先动脑，先把所有这些性能问题给分析一遍，找出最重要的、可以最大程度提升性能的问题，从它开始优化。这样的好处是，不仅性能提升的收益最大，而且很可能其他问题都不用优化，就已经满足了性能要求。</p>
<p>那关键就在于，怎么判断出哪个性能问题最重要。这其实还是我们性能分析要解决的核心问题，只不过这里要分析的对象，从原来的一个问题，变成了多个问题，思路其实还是一样的。</p>
<p>所以，你依然可以用我前面讲过的方法挨个分析，分别找出它们的瓶颈。分析完所有问题后，再按照因果等关系，排除掉有因果关联的性能问题。最后，再对剩下的性能问题进行优化。</p>
<p>如果剩下的问题还是好几个，你就得分别进行性能测试了。比较不同的优化效果后，选择能明显提升性能的那个问题进行修复。这个过程通常会花费较多的时间，这里，我推荐两个可以简化这个过程的方法。</p>
<ol>
<li>第一，如果发现是系统资源达到了瓶颈，比如 CPU 使用率达到了 100%，那么首先优化的一定是系统资源使用问题。完成系统资源瓶颈的优化后，我们才要考虑其他问题。</li>
<li>第二，针对不同类型的指标，首先去优化那些由瓶颈导致的，性能指标变化幅度最大的问题。比如产生瓶颈后，用户 CPU 使用率升高了 10%，而系统 CPU 使用率却升高了 50%，这个时候就应该首先优化系统 CPU 的使用。</li>
</ol>
<h4 id="12-4-有多种优化方法时，要如何选择"><a href="#12-4-有多种优化方法时，要如何选择" class="headerlink" title="12.4 有多种优化方法时，要如何选择?"></a>12.4 有多种优化方法时，要如何选择?</h4><p>一般情况下，我们当然想选能最大提升性能的方法，这其实也是性能优化的目标。</p>
<p>但要注意，现实情况要考虑的因素却没那么简单。最直观来说，性能优化并非没有成本。性能优化通常会带来复杂度的提升，降低程序的可维护性，还可能在优化一个指标时，引发其他指标的异常。也就是说，很可能你优化了一个指标，另一个指标的性能却变差了。</p>
<p>一个很典型的例子是我将在网络部分讲到的 DPDK（Data Plane Development Kit）。DPDK 是一种优化网络处理速度的方法，它通过绕开内核网络协议栈的方法，提升网络的处理能力。</p>
<p>不过它有一个很典型的要求，就是要独占一个 CPU 以及一定数量的内存大页，并且总是以 100% 的 CPU 使用率运行。所以，如果你的 CPU 核数很少，就有点得不偿失了。</p>
<p>所以，在考虑选哪个性能优化方法时，你要综合多方面的因素。切记，不要想着“一步登天”，试图一次性解决所有问题；也不要只会“拿来主义”，把其他应用的优化方法原封不动拿来用，却不经过任何思考和分析。</p>
<h4 id="12-5-CPU-优化"><a href="#12-5-CPU-优化" class="headerlink" title="12.5 CPU 优化"></a>12.5 CPU 优化</h4><p>清楚了性能优化最基本的三个问题后，我们接下来从应用程序和系统的角度，分别来看看如何才能降低 CPU 使用率，提高 CPU 的并行处理能力。</p>
<ol>
<li><p>应用程序优化</p>
<p> 首先，从应用程序的角度来说，降低 CPU 使用率的最好方法当然是，排除所有不必要的工作，只保留最核心的逻辑。比如减少循环的层次、减少递归、减少动态内存分配等等。</p>
<p> 除此之外，应用程序的性能优化也包括很多种方法，我在这里列出了最常见的几种，你可以记下来。</p>
<ul>
<li><strong>编译器优化</strong>：很多编译器都会提供优化选项，适当开启它们，在编译阶段你就可以获得编译器的帮助，来提升性能。比如， gcc 就提供了优化选项 -O2，开启后会自动对应用程序的代码进行优化。</li>
<li><strong>算法优化</strong>：使用复杂度更低的算法，可以显著加快处理速度。比如，在数据比较大的情况下，可以用 O(nlogn) 的排序算法（如快排、归并排序等），代替 O(n^2) 的排序算法（如冒泡、插入排序等）。</li>
<li><strong>异步处理</strong>：使用异步处理，可以避免程序因为等待某个资源而一直阻塞，从而提升程序的并发处理能力。比如，把轮询替换为事件通知，就可以避免轮询耗费 CPU 的问题。</li>
<li><strong>多线程代替多进程</strong>：前面讲过，相对于进程的上下文切换，线程的上下文切换并不切换进程地址空间，因此可以降低上下文切换的成本。</li>
<li><strong>善用缓存</strong>：经常访问的数据或者计算过程中的步骤，可以放到内存中缓存起来，这样在下次用时就能直接从内存中获取，加快程序的处理速度。</li>
</ul>
</li>
<li><p>系统优化</p>
<p> 从系统的角度来说，优化 CPU 的运行，一方面要充分利用 CPU 缓存的本地性，加速缓存访问；另一方面，就是要控制进程的 CPU 使用情况，减少进程间的相互影响。</p>
<p> 具体来说，系统层面的 CPU 优化方法也有不少，这里我同样列举了最常见的一些方法，方便你记忆和使用。</p>
<ul>
<li><p><strong>CPU 绑定</strong>：把进程绑定到一个或者多个 CPU 上，可以提高 CPU 缓存的命中率，减少跨 CPU 调度带来的上下文切换问题。</p>
</li>
<li><p><strong>CPU 独占</strong>：跟 CPU 绑定类似，进一步将 CPU 分组，并通过 CPU 亲和性机制为其分配进程。这样，这些 CPU 就由指定的进程独占，换句话说，不允许其他进程再来使用这些 CPU。</p>
</li>
<li><p><strong>优先级调整</strong>：使用 nice 调整进程的优先级，正值调低优先级，负值调高优先级。优先级的数值含义前面我们提到过，忘了的话及时复习一下。在这里，适当降低非核心应用的优先级，增高核心应用的优先级，可以确保核心应用得到优先处理。</p>
</li>
<li><p><strong>为进程设置资源限制</strong>：使用 Linux cgroups 来设置进程的 CPU 使用上限，可以防止由于某个应用自身的问题，而耗尽系统资源。</p>
</li>
<li><p><strong>NUMA（Non-Uniform Memory Access）优化</strong>：支持 NUMA 的处理器会被划分为多个 node，每个 node 都有自己的本地内存空间。NUMA 优化，其实就是让 CPU 尽可能只访问本地内存。</p>
</li>
<li><p><strong>中断负载均衡</strong>：无论是软中断还是硬中断，它们的中断处理程序都可能会耗费大量的 CPU。开启 irqbalance 服务或者配置 smp_affinity，就可以把中断处理过程自动负载均衡到多个 CPU 上。</p>
</li>
</ul>
</li>
</ol>
<h4 id="12-6-千万避免过早优化"><a href="#12-6-千万避免过早优化" class="headerlink" title="12.6 千万避免过早优化"></a>12.6 千万避免过早优化</h4><p>“过早优化是万恶之源”。</p>
<p>因为，一方面，优化会带来复杂性的提升，降低可维护性；另一方面，需求不是一成不变的。针对当前情况进行的优化，很可能并不适应快速变化的新需求。这样，在新需求出现时，这些复杂的优化，反而可能阻碍新功能的开发。</p>
<p>所以，性能优化最好是逐步完善，动态进行，不追求一步到位，而要首先保证能满足当前的性能要求。当发现性能不满足要求或者出现性能瓶颈时，再根据性能评估的结果，选择最重要的性能问题进行优化。</p>
<h3 id="13-答疑（一）：无法模拟出-RES-中断的问题，怎么办？"><a href="#13-答疑（一）：无法模拟出-RES-中断的问题，怎么办？" class="headerlink" title="13 | 答疑（一）：无法模拟出 RES 中断的问题，怎么办？"></a>13 | 答疑（一）：无法模拟出 RES 中断的问题，怎么办？</h3><h4 id="13-1-问题-1：性能工具版本太低，导致指标不全"><a href="#13-1-问题-1：性能工具版本太低，导致指标不全" class="headerlink" title="13.1 问题 1：性能工具版本太低，导致指标不全"></a>13.1 问题 1：性能工具版本太低，导致指标不全</h4><p>工具只是查找分析的手段，指标才是我们重点分析的对象。</p>
<p>proc 文件系统提供各项指标。</p>
<h4 id="13-2-问题-2：使用-stress-命令，无法模拟-iowait-高的场景"><a href="#13-2-问题-2：使用-stress-命令，无法模拟-iowait-高的场景" class="headerlink" title="13.2 问题 2：使用 stress 命令，无法模拟 iowait 高的场景"></a>13.2 问题 2：使用 stress 命令，无法模拟 iowait 高的场景</h4><p>使用 stress 无法模拟 iowait 升高，但是却看到了 sys 升高。这是因为案例中 的 stress -i 参数，它表示通过系统调用 sync() 来模拟 I/O 的问题，但这种方法实际上并不可靠。</p>
<p>因为 sync() 的本意是刷新内存缓冲区的数据到磁盘中，以确保同步。如果缓冲区内本来就没多少数据，那读写到磁盘中的数据也就不多，也就没法产生 I/O 压力。</p>
<p>这一点，在使用 SSD 磁盘的环境中尤为明显，很可能你的 iowait 总是 0，却单纯因为大量的系统调用，导致了系统 CPU 使用率 sys 升高。</p>
<p>推荐使用 stress-ng 来代替 stress。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -i 的含义还是调用 sync，而—hdd 则表示读写临时文件</span>
$ stress-ng -i <span class="token number">1</span> --hdd <span class="token number">1</span> --timeout <span class="token number">600</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h4 id="13-3-问题-3：无法模拟出-RES-中断的问题"><a href="#13-3-问题-3：无法模拟出-RES-中断的问题" class="headerlink" title="13.3 问题 3：无法模拟出 RES 中断的问题"></a>13.3 问题 3：无法模拟出 RES 中断的问题</h4><p>这个问题是说，即使运行了大量的线程，也无法模拟出重调度中断 RES 升高的问题。</p>
<p>其实我在 CPU 上下文切换的案例中已经提到，重调度中断是调度器用来分散任务到不同 CPU 的机制，也就是可以唤醒空闲状态的 CPU ，来调度新任务运行，而这通常借助处理器间中断（Inter-Processor Interrupts，IPI）来实现。</p>
<p>所以，这个中断在单核（只有一个逻辑 CPU）的机器上当然就没有意义了，因为压根儿就不会发生重调度的情况。</p>
<p>在这里顺便提一下，留言中很常见的一个错误。有些同学会拿 pidstat 中的 %wait 跟 top 中的 iowait% （缩写为 wa）对比，其实这是没有意义的，因为它们是完全不相关的两个指标。</p>
<ul>
<li>pidstat 中， %wait 表示进程等待 CPU 的时间百分比。</li>
<li>top 中 ，iowait% 则表示等待 I/O 的 CPU 时间百分比。</li>
</ul>
<h4 id="13-4-问题-4：无法模拟出-I-O-性能瓶颈，以及-I-O-压力过大的问题"><a href="#13-4-问题-4：无法模拟出-I-O-性能瓶颈，以及-I-O-压力过大的问题" class="headerlink" title="13.4 问题 4：无法模拟出 I/O 性能瓶颈，以及 I/O 压力过大的问题"></a>13.4 问题 4：无法模拟出 I/O 性能瓶颈，以及 I/O 压力过大的问题</h4><p>这个问题可以看成是上一个问题的延伸，只是把 stress 命令换成了一个在容器中运行的 app 应用。</p>
<p>事实上，在 I/O 瓶颈案例中，除了上面这个模拟不成功的留言，还有更多留言的内容刚好相反，说的是案例 I/O 压力过大，导致自己的机器出各种问题，甚至连系统都没响应了。</p>
<p>之所以这样，其实还是因为每个人的机器配置不同，既包括了 CPU 和内存配置的不同，更是因为磁盘的巨大差异。比如，机械磁盘（HDD）、低端固态磁盘（SSD）与高端固态磁盘相比，性能差异可能达到数倍到数十倍。</p>
<p>其实，我自己所用的案例机器也只是低端的 SSD，比机械磁盘稍微好一些，但跟高端固态磁盘还是比不了的。所以，相同操作下，我的机器上刚好出现 I/O 瓶颈，但换成一台使用机械磁盘的机器，可能磁盘 I/O 就被压死了（表现为使用率长时间 100%），而换上好一些的 SSD 磁盘，可能又无法产生足够的 I/O 压力。</p>
<p>另外，由于我在案例中只查找了 /dev/xvd 和 /dev/sd 前缀的磁盘，而没有考虑到使用其他前缀磁盘（比如 /dev/nvme）的同学。如果你正好用的是其他前缀，你可能会碰到跟 Vicky 类似的问题，也就是 app 启动后又很快退出，变成 exited 状态。</p>
<p>所以，在最新的案例中，我为 app 应用增加了三个选项。</p>
<ul>
<li>-d 设置要读取的磁盘，默认前缀为 /dev/sd 或者 /dev/xvd 的磁盘。</li>
<li>-s 设置每次读取的数据量大小，单位为字节，默认为 67108864（也就是 64MB）。</li>
<li>-c 设置每个子进程读取的次数，默认为 20 次，也就是说，读取 20*64MB 数据后，子进程退出。</li>
</ul>
<p>你可以点击 <a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/tree/master/high-iowait-process">Github</a> 查看它的源码，使用方法我写在了这里：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker run --privileged --name<span class="token operator">=</span>app -itd feisky/app:iowait /app -d /dev/sdb -s <span class="token number">67108864</span> -c <span class="token number">20</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>案例运行后，你可以执行 docker logs 查看它的日志。正常情况下，你可以看到下面的输出：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker logs app
Reading data from disk /dev/sdb with buffer size <span class="token number">67108864</span> and count <span class="token number">20</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h4 id="13-5-问题-5：性能工具（如-vmstat）输出中，第一行数据跟其他行差别巨大"><a href="#13-5-问题-5：性能工具（如-vmstat）输出中，第一行数据跟其他行差别巨大" class="headerlink" title="13.5 问题 5：性能工具（如 vmstat）输出中，第一行数据跟其他行差别巨大"></a>13.5 问题 5：性能工具（如 vmstat）输出中，第一行数据跟其他行差别巨大</h4><p>这个问题主要是说，在执行 vmstat 时，第一行数据跟其他行相比较，数值相差特别大。我相信不少同学都注意到了这个现象，这里我简单解释一下。</p>
<p>首先还是要记住，我总强调的那句话，<strong>在碰到直观上解释不了的现象时，要第一时间去查命令手册</strong>。</p>
<p>比如，运行 man vmstat 命令，你可以在手册中发现下面这句话：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">The first report produced gives averages since the last reboot.  Additional reports give information on a sampling period of length delay.  The process and memory reports are instantaneous in either case.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>也就是说，第一行数据是系统启动以来的平均值，其他行才是你在运行 vmstat 命令时，设置的间隔时间的平均值。另外，进程和内存的报告内容都是即时数值。</p>
<h3 id="14-答疑（二）：如何用perf工具分析Java程序？"><a href="#14-答疑（二）：如何用perf工具分析Java程序？" class="headerlink" title="14 | 答疑（二）：如何用perf工具分析Java程序？"></a>14 | 答疑（二）：如何用perf工具分析Java程序？</h3><h4 id="14-1-问题-1：-使用-perf-工具时，看到的是-16-进制地址而不是函数名"><a href="#14-1-问题-1：-使用-perf-工具时，看到的是-16-进制地址而不是函数名" class="headerlink" title="14.1 问题 1： 使用 perf 工具时，看到的是 16 进制地址而不是函数名"></a>14.1 问题 1： 使用 perf 工具时，看到的是 16 进制地址而不是函数名</h4><p>这也是留言比较多的一个问题，在 CentOS 系统中，使用 perf 工具看不到函数名，只能看到一些 16 进制格式的函数地址。</p>
<p>其实，只要你观察一下 perf 界面最下面的那一行，就会发现一个警告信息：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">Failed to open /opt/bitnami/php/lib/php/extensions/opcache.so, continuing without symbols<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>这说明，perf 找不到待分析进程依赖的库。当然，实际上这个案例中有很多依赖库都找不到，只不过，perf 工具本身只在最后一行显示警告信息，所以你只能看到这一条警告。</p>
<p>这个问题，其实也是在分析 Docker 容器应用时，我们经常碰到的一个问题，因为容器应用依赖的库都在镜像里面。</p>
<p>针对这种情况，我总结了下面四个解决方法。</p>
<ol>
<li><p>第一个方法，在容器外面构建相同路径的依赖库。这种方法从原理上可行，但是我并不推荐，一方面是因为找出这些依赖库比较麻烦，更重要的是，构建这些路径，会污染容器主机的环境。</p>
</li>
<li><p>第二个方法，在容器内部运行 perf。不过，这需要容器运行在特权模式下，但实际的应用程序往往只以普通容器的方式运行。所以，容器内部一般没有权限执行 perf 分析。</p>
<p> 比方说，如果你在普通容器内部运行 perf record ，你将会看到下面这个错误提示：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ perf_4.9 record -a -g
perf_event_open<span class="token punctuation">(</span><span class="token punctuation">..</span>., PERF_FLAG_FD_CLOEXEC<span class="token punctuation">)</span> failed with unexpected error <span class="token number">1</span> <span class="token punctuation">(</span>Operation not permitted<span class="token punctuation">)</span>
perf_event_open<span class="token punctuation">(</span><span class="token punctuation">..</span>., <span class="token number">0</span><span class="token punctuation">)</span> failed unexpectedly with error <span class="token number">1</span> <span class="token punctuation">(</span>Operation not permitted<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 当然，其实你还可以通过配置 /proc/sys/kernel/perf_event_paranoid （比如改成 -1），来允许非特权用户执行 perf 事件分析。</p>
<p> 不过还是那句话，为了安全起见，这种方法我也不推荐。</p>
</li>
<li><p>第三个方法，指定符号路径为容器文件系统的路径。比如对于第 05 讲的应用，你可以执行下面这个命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">mkdir</span> /tmp/foo
$ <span class="token assign-left variable">PID</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span>docker inspect --format <span class="token punctuation">{</span><span class="token punctuation">{</span>.State.Pid<span class="token punctuation">}</span><span class="token punctuation">}</span> phpfpm<span class="token variable">)</span></span>
$ bindfs /proc/<span class="token variable">$PID</span>/root /tmp/foo
$ perf report --symfs /tmp/foo

<span class="token comment"># 使用完成后不要忘记解除绑定</span>
$ <span class="token function">umount</span> /tmp/foo/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 不过这里要注意，bindfs 这个工具需要你额外安装。bindfs 的基本功能是实现目录绑定（类似于 mount —bind），这里需要你安装的是 1.13.10 版本（这也是它的最新发布版）。</p>
<p> 如果你安装的是旧版本，你可以到 <a target="_blank" rel="noopener" href="https://github.com/mpartel/bindfs">GitHub</a> 上面下载源码，然后编译安装。</p>
</li>
<li><p>第四个方法，在容器外面把分析纪录保存下来，再去容器里查看结果。这样，库和符号的路径也就都对了。</p>
<p> 比如，你可以这么做。先运行 perf record -g -p &lt; pid&gt;，执行一会儿（比如 15 秒）后，按 Ctrl+C 停止。</p>
<p> 然后，把生成的 perf.data 文件，拷贝到容器里面来分析：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker <span class="token function">cp</span> perf.data phpfpm:/tmp
$ docker <span class="token builtin class-name">exec</span> -i -t phpfpm <span class="token function">bash</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p> 接下来，在容器的 bash 中继续运行下面的命令，安装 perf 并使用 perf report 查看报告：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token builtin class-name">cd</span> /tmp/
$ <span class="token function">apt-get</span> update <span class="token operator">&amp;&amp;</span> <span class="token function">apt-get</span> <span class="token function">install</span> -y linux-tools linux-perf procps
$ perf_4.9 report<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 不过，这里也有两点需要你注意。</p>
<ol>
<li>首先是 perf 工具的版本问题。在最后一步中，我们运行的工具是容器内部安装的版本 perf_4.9，而不是普通的 perf 命令。这是因为， perf 命令实际上是一个软连接，会跟内核的版本进行匹配，但镜像里安装的 perf 版本跟虚拟机的内核版本有可能并不一致。</li>
<li>另外，php-fpm 镜像是基于 Debian 系统的，所以安装 perf 工具的命令，跟 Ubuntu 也并不完全一样。</li>
</ol>
</li>
</ol>
<p>事实上，抛开我们的案例来说，即使是在非容器化的应用中，你也可能会碰到这个问题。假如你的应用程序在编译时，使用 strip 删除了 ELF 二进制文件的符号表，那么你同样也只能看到函数的地址。</p>
<h4 id="14-2-问题-2：如何用-perf-工具分析-Java-程序"><a href="#14-2-问题-2：如何用-perf-工具分析-Java-程序" class="headerlink" title="14.2 问题 2：如何用 perf 工具分析 Java 程序"></a>14.2 问题 2：如何用 perf 工具分析 Java 程序</h4><p>这两个问题，其实是上一个 perf 问题的延伸。 像是 Java 这种通过 JVM 来运行的应用程序，运行堆栈用的都是 JVM 内置的函数和堆栈管理。所以，从系统层面你只能看到 JVM 的函数堆栈，而不能直接得到 Java 应用程序的堆栈。</p>
<p>perf_events 实际上已经支持了 JIT，但还需要一个 /tmp/perf-PID.map 文件，来进行符号翻译。当然，开源项目 <a target="_blank" rel="noopener" href="https://github.com/jvm-profiling-tools/perf-map-agent">perf-map-agent</a> 可以帮你生成这个符号表。</p>
<p>此外，为了生成全部调用栈，你还需要开启 JDK 的选项 -XX:+PreserveFramePointer。因为这里涉及到大量的 Java 知识，我就不再详细展开了。如果你的应用刚好基于 Java ，那么你可以参考 NETFLIX 的技术博客 <a target="_blank" rel="noopener" href="https://medium.com/netflix-techblog/java-in-flames-e763b3d32166">Java in Flames</a>，来查看详细的使用步骤。</p>
<p>说到这里，我也想强调一个问题，那就是学习性能优化时，不要一开始就把自己限定在具体的某个编程语言或者性能工具中，纠结于语言或工具的细节出不来。</p>
<p>掌握整体的分析思路，才是我们首先要做的。因为，性能优化的原理和思路，在任何编程语言中都是相通的。</p>
<h4 id="14-3-问题-3：为什么-perf-的报告中，很多符号都不显示调用栈"><a href="#14-3-问题-3：为什么-perf-的报告中，很多符号都不显示调用栈" class="headerlink" title="14.3 问题 3：为什么 perf 的报告中，很多符号都不显示调用栈"></a>14.3 问题 3：为什么 perf 的报告中，很多符号都不显示调用栈</h4><p>perf report 是一个可视化展示 perf.data 的工具。在第 08 讲的案例中，我直接给出了最终结果，并没有详细介绍它的参数。估计很多同学的机器在运行时，都碰到了跟路过同学一样的问题，看到的是下面这个界面。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/perf报告中很多符号都不显示调用栈.png" alt="perf报告中很多符号都不显示调用栈"></p>
<p>这个界面可以清楚看到，perf report 的输出中，只有 swapper 显示了调用栈，其他所有符号都不能查看堆栈情况，包括我们案例中的 app 应用。</p>
<p>这种情况我们以前也遇到过，当你发现性能工具的输出无法理解时，应该怎么办呢？当然还是查工具的手册。比如，你可以执行 man perf-report 命令，找到 -g 参数的说明：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">-g, --call-graph=&lt;print_type,threshold[,print_limit],order,sort_key[,branch],value&gt;
           Display call chains using type, min percent threshold, print limit, call order, sort key, optional branch and value. Note that
           ordering is not fixed so any parameter can be given in an arbitrary order. One exception is the print_limit which should be
           preceded by threshold.

               print_type can be either:
               - flat: single column, linear exposure of call chains.
               - graph: use a graph tree, displaying absolute overhead rates. (default)
               - fractal: like graph, but displays relative rates. Each branch of
                        the tree is considered as a new profiled object.
               - folded: call chains are displayed in a line, separated by semicolons
               - none: disable call chain display.

               threshold is a percentage value which specifies a minimum percent to be
               included in the output call graph.  Default is 0.5 (%).

               print_limit is only applied when stdio interface is used.  It's to limit
               number of call graph entries in a single hist entry.  Note that it needs
               to be given after threshold (but not necessarily consecutive).
               Default is 0 (unlimited).

               order can be either:
               - callee: callee based call graph.
               - caller: inverted caller based call graph.
               Default is 'caller' when --children is used, otherwise 'callee'.

               sort_key can be:
               - function: compare on functions (default)
               - address: compare on individual code addresses
               - srcline: compare on source filename and line number

               branch can be:
               - branch: include last branch information in callgraph when available.
                         Usually more convenient to use --branch-history for this.

               value can be:
               - percent: diplay overhead percent (default)
               - period: display event period
               - count: display event count<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>通过这个说明可以看到，-g 选项等同于 —call-graph，它的参数是后面那些被逗号隔开的选项，意思分别是输出类型、最小阈值、输出限制、排序方法、排序关键词、分支以及值的类型。</p>
<p>我们可以看到，这里默认的参数是 graph,0.5,caller,function,percent，具体含义文档中都有详细讲解，这里我就不再重复了。</p>
<p>现在再回过头来看我们的问题，堆栈显示不全，相关的参数当然就是最小阈值 threshold。通过手册中对 threshold 的说明，我们知道，当一个事件发生比例高于这个阈值时，它的调用栈才会显示出来。</p>
<p>threshold 的默认值为 0.5%，也就是说，事件比例超过 0.5% 时，调用栈才能被显示。再观察我们案例应用 app 的事件比例，只有 0.34%，低于 0.5%，所以看不到 app 的调用栈就很正常了。</p>
<p>这种情况下，你只需要给 perf report 设置一个小于 0.34% 的阈值，就可以显示我们想看到的调用图了。比如执行下面的命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ perf report -g graph,0.3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="14-4-问题-4：怎么理解-perf-report-报告"><a href="#14-4-问题-4：怎么理解-perf-report-报告" class="headerlink" title="14.4 问题 4：怎么理解 perf report 报告"></a>14.4 问题 4：怎么理解 perf report 报告</h4><p>看到这里，我估计你也曾嘀咕过，为啥不一上来就用 perf 工具解决，还要执行那么多其他工具呢？ 这个问题其实就给出了很好的解释。</p>
<p>在问题 4 的 perf report 界面中，你也一定注意到了， swapper 高达 99% 的比例。直觉来说，我们应该直接观察它才对，为什么没那么做呢？</p>
<p>其实，当你清楚了 swapper 的原理后，就很容易理解我们为什么可以忽略它了。</p>
<p>看到 swapper，你可能首先想到的是 SWAP 分区。实际上， swapper 跟 SWAP 没有任何关系，它只在系统初始化时创建 init 进程，之后，它就成了一个最低优先级的空闲任务。也就是说，当 CPU 上没有其他任务运行时，就会执行 swapper 。所以，你可以称它为“空闲任务”。</p>
<p>回到我们的问题，在 perf report 的界面中，展开它的调用栈，你会看到， swapper 时钟事件都耗费在了 do_idle 上，也就是在执行空闲任务。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/怎么理解perfreport报告.png" alt="怎么理解perfreport报告"></p>
<p>所以，分析案例时，我们直接忽略了前面这个 99% 的符号，转而分析后面只有 0.3% 的 app。其实从这里你也能理解，为什么我们一开始不先用 perf 分析。</p>
<p>因为在多任务系统中，次数多的事件，不一定就是性能瓶颈。所以，只观察到一个大数值，并不能说明什么问题。具体有没有瓶颈，还需要你观测多个方面的多个指标，来交叉验证。这也是我在套路篇中不断强调的一点。</p>
<p>另外，关于 Children 和 Self 的含义，手册里其实有详细说明，还很友好地举了一个例子，来说明它们的百分比的计算方法。简单来说，</p>
<ul>
<li>Self 是最后一列的符号（可以理解为函数）本身所占比例；</li>
<li>Children 是这个符号调用的其他符号（可以理解为子函数，包括直接和间接调用）占用的比例之和。</li>
</ul>
<p>所以，使用性能工具时，确实应该考虑工具本身对系统性能的影响。而这种情况，就需要你了解这些工具的原理。比如，</p>
<ul>
<li>perf 这种动态追踪工具，会给系统带来一定的性能损失。</li>
<li>vmstat、pidstat 这些直接读取 proc 文件系统来获取指标的工具，不会带来性能损失。</li>
</ul>
<h4 id="14-5-问题-5：性能优化书籍和参考资料推荐"><a href="#14-5-问题-5：性能优化书籍和参考资料推荐" class="headerlink" title="14.5 问题 5：性能优化书籍和参考资料推荐"></a>14.5 问题 5：性能优化书籍和参考资料推荐</h4><p>Brendan Gregg</p>
<p>《Systems Performance: Enterprise and the Cloud》</p>
<blockquote>
<p>中文版 《性能之巅：洞悉系统、企业与云计算》</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="http://www.brendangregg.com/linuxperf.html">Linux Performance</a></p>
<h2 id="03-内存性能篇"><a href="#03-内存性能篇" class="headerlink" title="03-内存性能篇"></a><strong>03-内存性能篇</strong></h2><h3 id="15-基础篇：Linux内存是怎么工作的？"><a href="#15-基础篇：Linux内存是怎么工作的？" class="headerlink" title="15 | 基础篇：Linux内存是怎么工作的？"></a>15 | 基础篇：Linux内存是怎么工作的？</h3><h4 id="15-1-内存映射"><a href="#15-1-内存映射" class="headerlink" title="15.1 内存映射"></a>15.1 内存映射</h4><p>通常所说的内存容量，其实指的是物理内存。物理内存也称为主存，大多数计算机用的主存都是动态随机访问内存（DRAM）。只有内核才可以直接访问物理内存。那么，进程要访问内存时，该怎么办呢？</p>
<p>Linux 内核给每个进程都提供了一个独立的虚拟地址空间，并且这个地址空间是连续的。这样，进程就可以很方便地访问内存，更确切地说是访问虚拟内存。</p>
<p>虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同字长（也就是单个 CPU 指令可以处理数据的最大长度）的处理器，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，我画了两张图来分别表示它们的虚拟地址空间，如下所示：</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/内存虚拟地址空间.png" alt="内存虚拟地址空间"></p>
<p>通过这里可以看出，32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间。而 64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。</p>
<p>还记得进程的用户态和内核态吗？进程在用户态时，只能访问用户空间内存；只有进入内核态后，才可以访问内核空间内存。虽然每个进程的地址空间都包含了内核空间，但这些内核空间，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。</p>
<p>既然每个进程都有一个这么大的地址空间，那么所有进程的虚拟内存加起来，自然要比实际的物理内存大得多。所以，并不是所有的虚拟内存都会分配物理内存，只有那些实际使用的虚拟内存才分配物理内存，并且分配后的物理内存，是通过<strong>内存映射</strong>来管理的。</p>
<p>内存映射，其实就是将虚拟内存地址映射到物理内存地址。为了完成内存映射，内核为每个进程都维护了一张页表，记录虚拟地址与物理地址的映射关系，如下图所示：</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/内存映射.png" alt="内存映射"></p>
<p>页表实际上存储在 CPU 的内存管理单元 MMU 中，这样，正常情况下，处理器就可以直接通过硬件，找出要访问的内存。</p>
<p>而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。</p>
<p> TLB（Translation Lookaside Buffer，转译后备缓冲器）其实就是 MMU 中页表的高速缓存。由于进程的虚拟地址空间是独立的，而 TLB 的访问速度又比 MMU 快得多，所以，通过减少进程的上下文切换，减少 TLB 的刷新次数，就可以提高 TLB 缓存的使用率，进而提高 CPU 的内存访问性能。</p>
<p> 不过要注意，MMU 并不以字节为单位来管理内存，而是规定了一个内存映射的最小单位，也就是页，通常是 4 KB 大小。这样，每一次内存映射，都需要关联 4 KB 或者 4KB 整数倍的内存空间。</p>
<p>页的大小只有 4 KB ，导致的另一个问题就是，整个页表会变得非常大。比方说，仅 32 位系统就需要 100 多万个页表项（4GB/4KB），才可以实现整个地址空间的映射。为了解决页表项过多的问题，Linux 提供了两种机制，也就是多级页表和大页（HugePage）。</p>
<p>多级页表就是把内存分成区块来管理，将原来的映射关系改成区块索引和区块内的偏移。由于虚拟内存空间通常只用了很少一部分，那么，多级页表就只保存这些使用中的区块，这样就可以大大地减少页表的项数。</p>
<p>Linux 用的正是四级页表来管理内存页，如下图所示，虚拟地址被分为 5 个部分，前 4 个表项用于选择页，而最后一个索引表示页内偏移。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/四级页表.png" alt="四级页表"></p>
<p>再看大页，顾名思义，就是比普通页更大的内存块，常见的大小有 2MB 和 1GB。大页通常用在使用大量内存的进程上，比如 Oracle、DPDK 等。</p>
<p>通过这些机制，在页表的映射下，进程就可以通过虚拟地址来访问物理内存了。那么具体到一个 Linux 进程中，这些内存又是怎么使用的呢？</p>
<h4 id="15-2-虚拟内存空间分布"><a href="#15-2-虚拟内存空间分布" class="headerlink" title="15.2 虚拟内存空间分布"></a>15.2 虚拟内存空间分布</h4><p>首先，我们需要进一步了解虚拟内存空间的分布情况。最上方的内核空间不用多讲，下方的用户空间内存，其实又被分成了多个不同的段。以 32 位系统为例，我画了一张图来表示它们的关系。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/虚拟内存空间的分布.png" alt="虚拟内存空间的分布"></p>
<p>通过这张图你可以看到，用户空间内存，从低到高分别是五种不同的内存段。</p>
<ol>
<li>只读段，包括代码和常量等。</li>
<li>数据段，包括全局变量等。</li>
<li>堆，包括动态分配的内存，从低地址开始向上增长。</li>
<li>文件映射段，包括动态库、共享内存等，从高地址开始向下增长。</li>
<li>栈，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。</li>
</ol>
<p>在这五个内存段中，堆和文件映射段的内存是动态分配的。比如说，使用 C 标准库的 malloc() 或者 mmap() ，就可以分别在堆和文件映射段动态分配内存。</p>
<p>其实 64 位系统的内存分布也类似，只不过内存空间要大得多。那么，更重要的问题来了，内存究竟是怎么分配的呢？</p>
<h4 id="15-3-内存分配与回收"><a href="#15-3-内存分配与回收" class="headerlink" title="15.3 内存分配与回收"></a>15.3 内存分配与回收</h4><p>malloc() 是 C 标准库提供的内存分配函数，对应到系统调用上，有两种实现方式，即 brk() 和 mmap()。</p>
<ol>
<li>对小块内存（小于 128K），C 标准库使用 brk() 来分配，也就是通过移动堆顶的位置来分配内存。这些内存释放后并不会立刻归还系统，而是被缓存起来，这样就可以重复使用。</li>
<li>而大块内存（大于 128K），则直接使用内存映射 mmap() 来分配，也就是在文件映射段找一块空闲内存分配出去。</li>
</ol>
<p>这两种方式，自然各有优缺点。</p>
<ol>
<li>brk() 方式的缓存，可以减少缺页异常的发生，提高内存访问效率。不过，由于这些内存没有归还系统，在内存工作繁忙时，频繁的内存分配和释放会造成内存碎片。</li>
<li>而 mmap() 方式分配的内存，会在释放时直接归还系统，所以每次 mmap 都会发生缺页异常。在内存工作繁忙时，频繁的内存分配会导致大量的缺页异常，使内核的管理负担增大。这也是 malloc 只对大块内存使用 mmap 的原因。</li>
</ol>
<p>了解这两种调用方式后，我们还需要清楚一点，那就是，当这两种调用发生后，其实并没有真正分配内存。这些内存，都只在首次访问时才分配，也就是通过缺页异常进入内核中，再由内核来分配内存。</p>
<p>整体来说，Linux 使用伙伴系统来管理内存分配。前面我们提到过，这些内存在 MMU 中以页为单位进行管理，伙伴系统也一样，以页为单位来管理内存，并且会通过相邻页的合并，减少内存碎片化（比如 brk 方式造成的内存碎片）。</p>
<p>你可能会想到一个问题，如果遇到比页更小的对象，比如不到 1K 的时候，该怎么分配内存呢？</p>
<p>实际系统运行中，确实有大量比页还小的对象，如果为它们也分配单独的页，那就太浪费内存了。</p>
<p>所以，在用户空间，malloc 通过 brk() 分配的内存，在释放时并不立即归还系统，而是缓存起来重复利用。在内核空间，Linux 则通过 slab 分配器来管理小内存。你可以把 slab 看成构建在伙伴系统上的一个缓存，主要作用就是分配并释放内核中的小对象。</p>
<p>当然，系统也不会任由某个进程用完所有内存。在发现内存紧张时，系统就会通过一系列机制来回收内存，比如下面这三种方式：</p>
<ul>
<li>回收缓存，比如使用 LRU（Least Recently Used）算法，回收最近使用最少的内存页面；</li>
<li>回收不常访问的内存，把不常用的内存通过交换分区直接写到磁盘中；</li>
<li>杀死进程，内存紧张时系统还会通过 OOM（Out of Memory），直接杀掉占用大量内存的进程。</li>
</ul>
<p>其中，第二种方式回收不常访问的内存时，会用到交换分区（以下简称 Swap）。Swap 其实就是把一块磁盘空间当成内存来用。它可以把进程暂时不用的数据存储到磁盘中（这个过程称为换出），当进程访问这些内存时，再从磁盘读取这些数据到内存中（这个过程称为换入）。</p>
<p>所以，你可以发现，Swap 把系统的可用内存变大了。不过要注意，通常只在内存不足时，才会发生 Swap 交换。并且由于磁盘读写的速度远比内存慢，Swap 会导致严重的内存性能问题。</p>
<p>第三种方式提到的 OOM（Out of Memory），其实是内核的一种保护机制。它监控进程的内存使用情况，并且使用 oom_score 为每个进程的内存使用情况进行评分：</p>
<ul>
<li>一个进程消耗的内存越大，oom_score 就越大；</li>
<li>一个进程运行占用的 CPU 越多，oom_score 就越小。</li>
</ul>
<p>这样，进程的 oom_score 越大，代表消耗的内存越多，也就越容易被 OOM 杀死，从而可以更好保护系统。</p>
<p>当然，为了实际工作的需要，管理员可以通过 /proc 文件系统，手动设置进程的 oom_adj ，从而调整进程的 oom_score。</p>
<p>oom_adj 的范围是 [-17, 15]，数值越大，表示进程越容易被 OOM 杀死；数值越小，表示进程越不容易被 OOM 杀死，其中 -17 表示禁止 OOM。</p>
<p>比如用下面的命令，你就可以把 sshd 进程的 oom_adj 调小为 -16，这样， sshd 进程就不容易被 OOM 杀死。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">echo</span> -16 <span class="token operator">&gt;</span> /proc/<span class="token variable"><span class="token variable">$(</span>pidof sshd<span class="token variable">)</span></span>/oom_adj<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="15-4-如何查看内存使用情况"><a href="#15-4-如何查看内存使用情况" class="headerlink" title="15.4 如何查看内存使用情况"></a>15.4 如何查看内存使用情况</h4><p>下面是一个 free 的输出示例：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 注意不同版本的 free 输出可能会有所不同</span>
$ <span class="token function">free</span>
              total        used        <span class="token function">free</span>      shared  buff/cache   available
Mem:        <span class="token number">8169348</span>      <span class="token number">263524</span>     <span class="token number">6875352</span>         <span class="token number">668</span>     <span class="token number">1030472</span>     <span class="token number">7611064</span>
Swap:             <span class="token number">0</span>           <span class="token number">0</span>           <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>free 输出的是一个表格，其中的数值都默认以字节为单位。表格总共有两行六列，这两行分别是物理内存 Mem 和交换分区 Swap 的使用情况，而六列中，每列数据的含义分别为：</p>
<ul>
<li>第一列，total 是总内存大小；</li>
<li>第二列，used 是已使用内存的大小，包含了共享内存；</li>
<li>第三列，free 是未使用内存的大小；</li>
<li>第四列，shared 是共享内存的大小；</li>
<li>第五列，buff/cache 是缓存和缓冲区的大小；</li>
<li>最后一列，available 是新进程可用内存的大小。</li>
</ul>
<p>available 不仅包含未使用内存，还包括了可回收的缓存，所以一般会比未使用内存更大。不过，并不是所有缓存都可以回收，因为有些缓存可能正在使用中。</p>
<p>如果你想查看进程的内存使用情况，可以用 top 或者 ps 等工具。比如，下面是 top 的输出示例：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 按下 M 切换到内存排序</span>
$ <span class="token function">top</span>
<span class="token punctuation">..</span>.
KiB Mem <span class="token builtin class-name">:</span>  <span class="token number">8169348</span> total,  <span class="token number">6871440</span> free,   <span class="token number">267096</span> used,  <span class="token number">1030812</span> buff/cache
KiB Swap:        <span class="token number">0</span> total,        <span class="token number">0</span> free,        <span class="token number">0</span> used.  <span class="token number">7607492</span> avail Mem


  PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
  <span class="token number">430</span> root      <span class="token number">19</span>  -1  <span class="token number">122360</span>  <span class="token number">35588</span>  <span class="token number">23748</span> S   <span class="token number">0.0</span>  <span class="token number">0.4</span>   <span class="token number">0</span>:32.17 systemd-journal
 <span class="token number">1075</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">771860</span>  <span class="token number">22744</span>  <span class="token number">11368</span> S   <span class="token number">0.0</span>  <span class="token number">0.3</span>   <span class="token number">0</span>:38.89 snapd
 <span class="token number">1048</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">170904</span>  <span class="token number">17292</span>   <span class="token number">9488</span> S   <span class="token number">0.0</span>  <span class="token number">0.2</span>   <span class="token number">0</span>:00.24 networkd-dispat
    <span class="token number">1</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">78020</span>   <span class="token number">9156</span>   <span class="token number">6644</span> S   <span class="token number">0.0</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:22.92 systemd
<span class="token number">12376</span> azure     <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">76632</span>   <span class="token number">7456</span>   <span class="token number">6420</span> S   <span class="token number">0.0</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:00.01 systemd
<span class="token number">12374</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">107984</span>   <span class="token number">7312</span>   <span class="token number">6304</span> S   <span class="token number">0.0</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:00.00 sshd
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>top 输出界面的顶端，也显示了系统整体的内存使用情况，这些数据跟 free 类似，我就不再重复解释。我们接着看下面的内容，跟内存相关的几列数据，比如 VIRT、RES、SHR 以及 %MEM 等。</p>
<p>这些数据，包含了进程最重要的几个内存使用情况，我们挨个来看。</p>
<ul>
<li>VIRT 是进程虚拟内存的大小，只要是进程申请过的内存，即便还没有真正分配物理内存，也会计算在内。</li>
<li>RES 是常驻内存的大小，也就是进程实际使用的物理内存大小，但不包括 Swap 和共享内存。</li>
<li>SHR 是共享内存的大小，比如与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等。</li>
<li>%MEM 是进程使用物理内存占系统总内存的百分比。</li>
</ul>
<p>除了要认识这些基本信息，在查看 top 输出时，你还要注意两点。</p>
<ul>
<li>第一，虚拟内存通常并不会全部分配物理内存。从上面的输出，你可以发现每个进程的虚拟内存都比常驻内存大得多。</li>
<li>第二，共享内存 SHR 并不一定是共享的，比方说，程序的代码段、非共享的动态链接库，也都算在 SHR 里。当然，SHR 也包括了进程间真正共享的内存。所以在计算多个进程的内存使用时，不要把所有进程的 SHR 直接相加得出结果。</li>
</ul>
<h3 id="16-基础篇：怎么理解内存中的Buffer和Cache？"><a href="#16-基础篇：怎么理解内存中的Buffer和Cache？" class="headerlink" title="16 | 基础篇：怎么理解内存中的Buffer和Cache？"></a>16 | 基础篇：怎么理解内存中的Buffer和Cache？</h3><h4 id="16-1-free-数据的来源"><a href="#16-1-free-数据的来源" class="headerlink" title="16.1 free 数据的来源"></a>16.1 free 数据的来源</h4><p>用 man 命令查询 free 的文档，就可以找到 Buffer 和 Cache 指标的详细说明。比如，我们执行 man free ，就可以看到下面这个界面。</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">buffers
       Memory used by kernel buffers (Buffers in /proc/meminfo)
cache  Memory used by the page cache and slabs (Cached and SReclaimable in /proc/meminfo)
buff/cache
       Sum of buffers and cache<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>从 free 的手册中，你可以看到 buffer 和 cache 的说明。</p>
<ul>
<li>Buffers 是内核缓冲区用到的内存，对应的是 /proc/meminfo 中的 Buffers 值。</li>
<li>Cache 是内核页缓存和 Slab 用到的内存，对应的是 /proc/meminfo 中的 Cached 与 SReclaimable 之和。</li>
</ul>
<p>这里的说明告诉我们，这些数值都来自 /proc/meminfo，但更具体的 Buffers、Cached 和 SReclaimable 的含义，还是没有说清楚。</p>
<p>要弄明白它们到底是什么，我估计你第一反应就是去百度或者 Google 一下。虽然大部分情况下，网络搜索能给出一个答案。但是，且不说筛选信息花费的时间精力，对你来说，这个答案的准确性也是很难保证的。</p>
<p>要注意，网上的结论可能是对的，但是很可能跟你的环境并不匹配。最简单来说，同一个指标的具体含义，就可能因为内核版本、性能工具版本的不同而有挺大差别。这也是为什么，我总在专栏中强调通用思路和方法，而不是让你死记结论。对于案例实践来说，机器环境就是我们的最大限制。</p>
<p>那么，有没有更简单、更准确的方法，来查询它们的含义呢？</p>
<h4 id="16-2-proc-文件系统"><a href="#16-2-proc-文件系统" class="headerlink" title="16.2 proc 文件系统"></a>16.2 proc 文件系统</h4><p>proc 文件系统同时也是很多性能工具的最终数据来源。比如我们刚才看到的 free ，就是通过读取 /proc/meminfo ，得到内存的使用情况。</p>
<p>执行 man proc ，你就可以得到 proc 文件系统的详细文档。</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">Buffers %lu
    Relatively temporary storage for raw disk blocks that shouldn't get tremendously large (20MB or so).

Cached %lu
   In-memory cache for files read from the disk (the page cache).  Doesn't include SwapCached.
...
SReclaimable %lu (since Linux 2.6.19)
    Part of Slab, that might be reclaimed, such as caches.

SUnreclaim %lu (since Linux 2.6.19)
    Part of Slab, that cannot be reclaimed on memory pressure.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>通过这个文档，我们可以看到：</p>
<ul>
<li>Buffers 是对原始磁盘块的临时存储，也就是用来缓存磁盘的数据，通常不会特别大（20MB 左右）。这样，内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写合并成单次大的写等等。</li>
<li>Cached 是从磁盘读取文件的页缓存，也就是用来缓存从文件读取的数据。这样，下次访问这些文件数据时，就可以直接从内存中快速获取，而不需要再次访问缓慢的磁盘。</li>
<li>SReclaimable 是 Slab 的一部分。Slab 包括两部分，其中的可回收部分，用 SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录。</li>
</ul>
<p>不过，知道这个定义就真的理解了吗？这里我给你提了两个问题，你先想想能不能回答出来。</p>
<ul>
<li>第一个问题，Buffer 的文档没有提到这是磁盘读数据还是写数据的缓存，而在很多网络搜索的结果中都会提到 Buffer 只是对将要写入磁盘数据的缓存。那反过来说，它会不会也缓存从磁盘中读取的数据呢？</li>
<li>第二个问题，文档中提到，Cache 是对从文件读取数据的缓存，那么它是不是也会缓存写文件的数据呢？</li>
</ul>
<p>为了解答这两个问题，接下来，我将用几个案例来展示， Buffer 和 Cache 在不同场景下的使用情况。</p>
<h4 id="16-3-案例"><a href="#16-3-案例" class="headerlink" title="16.3 案例"></a>16.3 案例</h4><blockquote>
<p>机器配置： 2 CPU, 8 GB 内存。</p>
<p>安装软件：<code>apt install sysstat</code>。</p>
</blockquote>
<p>为了减少缓存的影响，记得在第一个终端中，运行下面的命令来清理系统缓存：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 清理文件页、目录项、Inodes 等各种缓存</span>
$ <span class="token builtin class-name">echo</span> <span class="token number">3</span> <span class="token operator">&gt;</span> /proc/sys/vm/drop_caches<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<ol>
<li><p>场景 1：磁盘和文件写案例</p>
<p> 在第一个终端，运行下面这个 vmstat 命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 每隔 1 秒输出 1 组数据</span>
$ <span class="token function">vmstat</span> <span class="token number">1</span>
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
r  b   swpd   <span class="token function">free</span>   buff  cache   si   so    bi    bo   <span class="token keyword">in</span>   cs us sy  <span class="token function">id</span> wa st
<span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">7743608</span>  <span class="token number">1112</span>  <span class="token number">92168</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>     <span class="token number">0</span>   <span class="token number">52</span>  <span class="token number">152</span>  <span class="token number">0</span>  <span class="token number">1</span> <span class="token number">100</span>  <span class="token number">0</span>  <span class="token number">0</span>
<span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">7743608</span>  <span class="token number">1112</span>  <span class="token number">92168</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>     <span class="token number">0</span>   <span class="token number">36</span>   <span class="token number">92</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">100</span>  <span class="token number">0</span>  <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 输出界面里， 内存部分的 buff 和 cache ，以及 io 部分的 bi 和 bo 就是我们要关注的重点。</p>
<ul>
<li>buff 和 cache 就是我们前面看到的 Buffers 和 Cache，单位是 KB。</li>
<li><p>bi 和 bo 则分别表示块设备读取和写入的大小，单位为块 / 秒。因为 Linux 中块的大小是 1KB，所以这个单位也就等价于 KB/s。</p>
<blockquote>
<p><code>man vmstat</code>: <a target="_blank" rel="noopener" href="https://linux.die.net/man/8/vmstat">All linux blocks are currently 1024 bytes.</a></p>
</blockquote>
<p>正常情况下，空闲系统中，你应该看到的是，这几个值在多次结果中一直保持不变。</p>
<p>接下来，到第二个终端执行 dd 命令，通过读取随机设备，生成一个 500MB 大小的文件：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">dd</span> <span class="token assign-left variable">if</span><span class="token operator">=</span>/dev/urandom <span class="token assign-left variable">of</span><span class="token operator">=</span>/tmp/file <span class="token assign-left variable">bs</span><span class="token operator">=</span>1M <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">500</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>然后再回到第一个终端，观察 Buffer 和 Cache 的变化情况：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
0  0      0 7499460   1344 230484    0    0     0     0   29  145  0  0 100  0  0
1  0      0 7338088   1752 390512    0    0   488     0   39  558  0 47 53  0  0
1  0      0 7158872   1752 568800    0    0     0     4   30  376  1 50 49  0  0
1  0      0 6980308   1752 747860    0    0     0     0   24  360  0 50 50  0  0
0  0      0 6977448   1752 752072    0    0     0     0   29  138  0  0 100  0  0
0  0      0 6977440   1760 752080    0    0     0   152   42  212  0  1 99  1  0
...
0  1      0 6977216   1768 752104    0    0    4 122880   33  234  0  1 51 49  0
0  1      0 6977440   1768 752108    0    0    0  10240   38  196  0  0 50 50  0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>通过观察 vmstat 的输出，我们发现，在 dd 命令运行时， Cache 在不停地增长，而 Buffer 基本保持不变。</p>
</li>
<li><p>在 Cache 刚开始增长时，块设备 I/O 很少，bi 只出现了一次 488 KB/s，bo 则只有一次 4KB。而过一段时间后，才会出现大量的块设备写，比如 bo 变成了 122880。</p>
</li>
<li><p>当 dd 命令结束后，Cache 不再增长，但块设备写还会持续一段时间，并且，多次 I/O 写的结果加起来，才是 dd 要写的 500M 的数据。</p>
<p>把这个结果，跟我们刚刚了解到的 Cache 的定义做个对比，你可能会有点晕乎。为什么前面文档上说 Cache 是文件读的页缓存，怎么现在写文件也有它的份？</p>
<p>这个疑问，我们暂且先记下来，接着再来看另一个磁盘写的案例。两个案例结束后，我们再统一进行分析。</p>
<p>不过，对于接下来的案例，我必须强调一点：</p>
<p>下面的命令对环境要求很高，需要你的系统配置多块磁盘，并且磁盘分区 /dev/sdb1 还要处于未使用状态。如果你只有一块磁盘，千万不要尝试，否则将会对你的磁盘分区造成损坏。</p>
<p>如果你的系统符合标准，就可以继续在第二个终端中，运行下面的命令。清理缓存后，向磁盘分区 /dev/sdb1 写入 2GB 的随机数据：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 首先清理缓存</span>
$ <span class="token builtin class-name">echo</span> <span class="token number">3</span> <span class="token operator">&gt;</span> /proc/sys/vm/drop_caches
<span class="token comment"># 然后运行 dd 命令向磁盘分区 /dev/sdb1 写入 2G 数据</span>
$ <span class="token function">dd</span> <span class="token assign-left variable">if</span><span class="token operator">=</span>/dev/urandom <span class="token assign-left variable">of</span><span class="token operator">=</span>/dev/sdb1 <span class="token assign-left variable">bs</span><span class="token operator">=</span>1M <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">2048</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>然后，再回到终端一，观察内存和 I/O 的变化情况：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
1  0      0 7584780 153592  97436    0    0   684     0   31  423  1 48 50  2  0
1  0      0 7418580 315384 101668    0    0     0     0   32  144  0 50 50  0  0
1  0      0 7253664 475844 106208    0    0     0     0   20  137  0 50 50  0  0
1  0      0 7093352 631800 110520    0    0     0     0   23  223  0 50 50  0  0
1  1      0 6930056 790520 114980    0    0     0 12804   23  168  0 50 42  9  0
1  0      0 6757204 949240 119396    0    0     0 183804   24  191  0 53 26 21  0
1  1      0 6591516 1107960 123840    0    0     0 77316   22  232  0 52 16 33  0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>从这里你会看到，虽然同是写数据，写磁盘跟写文件的现象还是不同的。写磁盘时（也就是 bo 大于 0 时），Buffer 和 Cache 都在增长，但显然 Buffer 的增长快得多。</p>
<p>这说明，写磁盘用到了大量的 Buffer，这跟我们在文档中查到的定义是一样的。</p>
<p>对比两个案例，我们发现，<strong>写文件时会用到 Cache 缓存数据，而写磁盘则会用到 Buffer 来缓存数据</strong>。所以，回到刚刚的问题，虽然文档上只提到，Cache 是文件读的缓存，但实际上，<strong>Cache 也会缓存写文件时的数据</strong>。</p>
</li>
</ul>
</li>
<li><p>场景 2：磁盘和文件读案例</p>
<p> 回到第二个终端，运行下面的命令。清理缓存后，从文件 /tmp/file 中，读取数据写入空设备：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 首先清理缓存</span>
$ <span class="token builtin class-name">echo</span> <span class="token number">3</span> <span class="token operator">&gt;</span> /proc/sys/vm/drop_caches
<span class="token comment"># 运行 dd 命令读取文件数据</span>
$ <span class="token function">dd</span> <span class="token assign-left variable">if</span><span class="token operator">=</span>/tmp/file <span class="token assign-left variable">of</span><span class="token operator">=</span>/dev/null<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 然后，再回到终端一，观察内存和 I/O 的变化情况：</p>
 <pre class="line-numbers language-text" data-language="text"><code class="language-text">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
0  1      0 7724164   2380 110844    0    0 16576     0   62  360  2  2 76 21  0
0  1      0 7691544   2380 143472    0    0 32640     0   46  439  1  3 50 46  0
0  1      0 7658736   2380 176204    0    0 32640     0   54  407  1  4 50 46  0
0  1      0 7626052   2380 208908    0    0 32640    40   44  422  2  2 50 46  0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 观察 vmstat 的输出，你会发现读取文件时（也就是 bi 大于 0 时），Buffer 保持不变，而 Cache 则在不停增长。这跟我们查到的定义“Cache 是对文件读的页缓存”是一致的。</p>
<p> 那么，磁盘读又是什么情况呢？我们再运行第二个案例来看看。</p>
<p> 首先，回到第二个终端，运行下面的命令。清理缓存后，从磁盘分区 /dev/sda1 中读取数据，写入空设备：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 首先清理缓存</span>
$ <span class="token builtin class-name">echo</span> <span class="token number">3</span> <span class="token operator">&gt;</span> /proc/sys/vm/drop_caches
<span class="token comment"># 运行 dd 命令读取文件</span>
$ <span class="token function">dd</span> <span class="token assign-left variable">if</span><span class="token operator">=</span>/dev/sda1 <span class="token assign-left variable">of</span><span class="token operator">=</span>/dev/null <span class="token assign-left variable">bs</span><span class="token operator">=</span>1M <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">1024</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 然后，再回到终端一，观察内存和 I/O 的变化情况：</p>
 <pre class="line-numbers language-text" data-language="text"><code class="language-text">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
0  0      0 7225880   2716 608184    0    0     0     0   48  159  0  0 100  0  0
0  1      0 7199420  28644 608228    0    0 25928     0   60  252  0  1 65 35  0
0  1      0 7167092  60900 608312    0    0 32256     0   54  269  0  1 50 49  0
0  1      0 7134416  93572 608376    0    0 32672     0   53  253  0  0 51 49  0
0  1      0 7101484 126320 608480    0    0 32748     0   80  414  0  1 50 49  0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 观察 vmstat 的输出，你会发现读磁盘时（也就是 bi 大于 0 时），Buffer 和 Cache 都在增长，但显然 Buffer 的增长快很多。这说明读磁盘时，数据缓存到了 Buffer 中。</p>
<p> 当然，我想，经过上一个场景中两个案例的分析，你自己也可以对比得出这个结论：<strong>读文件时数据会缓存到 Cache 中，而读磁盘时数据会缓存到 Buffer 中</strong>。</p>
</li>
</ol>
<p>到这里你应该发现了，虽然文档提供了对 Buffer 和 Cache 的说明，但是仍不能覆盖到所有的细节。比如说，今天我们了解到的这两点：</p>
<ul>
<li>Buffer 既可以用作“将要写入磁盘数据的缓存”，也可以用作“从磁盘读取数据的缓存”。</li>
<li>Cache 既可以用作“从文件读取数据的页缓存”，也可以用作“写文件的页缓存”。</li>
</ul>
<p>这样，我们就回答了案例开始前的两个问题。</p>
<p>简单来说，<strong>Buffer 是对磁盘数据的缓存，而 Cache 是文件数据的缓存，它们既会用在读请求中，也会用在写请求中</strong>。</p>
<h3 id="17-案例篇：如何利用系统缓存优化程序的运行效率？"><a href="#17-案例篇：如何利用系统缓存优化程序的运行效率？" class="headerlink" title="17 | 案例篇：如何利用系统缓存优化程序的运行效率？"></a>17 | 案例篇：如何利用系统缓存优化程序的运行效率？</h3><p>简单复习一下，Buffer 和 Cache 的设计目的，是为了提升系统的 I/O 性能。它们利用内存，充当起慢速磁盘与快速 CPU 之间的桥梁，可以加速 I/O 的访问速度。</p>
<p>Buffer 和 Cache 分别缓存的是对磁盘和文件系统的读写数据。</p>
<ul>
<li>从写的角度来说，不仅可以优化磁盘和文件的写入，对应用程序也有好处，应用程序可以在数据真正落盘前，就返回去做其他工作。</li>
<li>从读的角度来说，不仅可以提高那些频繁访问数据的读取速度，也降低了频繁 I/O 对磁盘的压力。</li>
</ul>
<p>既然 Buffer 和 Cache 对系统性能有很大影响，那我们在软件开发的过程中，能不能利用这一点，来优化 I/O 性能，提升应用程序的运行效率呢？</p>
<h4 id="17-1-缓存命中率"><a href="#17-1-缓存命中率" class="headerlink" title="17.1 缓存命中率"></a>17.1 缓存命中率</h4><p><strong>缓存命中率</strong>，是指直接通过缓存获取数据的请求次数，占所有数据请求次数的百分比。</p>
<p><strong>命中率越高，表示使用缓存带来的收益越高，应用程序的性能也就越好</strong>。</p>
<p>实际上，缓存是现在所有高并发系统必需的核心模块，主要作用就是把经常访问的数据（也就是热点数据），提前读入到内存中。这样，下次访问时就可以直接从内存读取数据，而不需要经过硬盘，从而加快应用程序的响应速度。</p>
<p>这些独立的缓存模块通常会提供查询接口，方便我们随时查看缓存的命中情况。不过 Linux 系统中并没有直接提供这些接口，所以这里我要介绍一下，cachestat 和 cachetop ，它们正是查看系统缓存命中情况的工具。</p>
<ul>
<li>cachestat 提供了整个操作系统缓存的读写命中情况。</li>
<li>cachetop 提供了每个进程的缓存命中情况。</li>
</ul>
<p>这两个工具都是 <a target="_blank" rel="noopener" href="https://github.com/iovisor/bcc">bcc</a> 软件包的一部分，它们基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制，来跟踪内核中管理的缓存，并输出缓存的使用和命中情况。</p>
<p>使用 cachestat 和 cachetop 前，我们首先要安装 bcc 软件包。比如，在 Ubuntu 系统中，你可以运行下面的命令来安装：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4052245BD4284CDD
<span class="token builtin class-name">echo</span> <span class="token string">"deb https://repo.iovisor.org/apt/xenial xenial main"</span> <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/iovisor.list
<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> -y bcc-tools libbcc-examples linux-headers-<span class="token variable"><span class="token variable">$(</span><span class="token function">uname</span> -r<span class="token variable">)</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<blockquote>
<p>注意：bcc-tools 需要内核版本为 4.1 或者更新的版本，如果你用的是 CentOS，那就需要手动 <a target="_blank" rel="noopener" href="https://github.com/iovisor/bcc/issues/462">升级内核版本后再安装</a>。</p>
</blockquote>
<p>操作完这些步骤，bcc 提供的所有工具就都安装到 /usr/share/bcc/tools 这个目录中了。不过这里提醒你，bcc 软件包默认不会把这些工具配置到系统的 PATH 路径中，所以你得自己手动配置：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span>:/usr/share/bcc/tools<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>配置完，你就可以运行 cachestat 和 cachetop 命令了。比如，下面就是一个 cachestat 的运行界面，它以 1 秒的时间间隔，输出了 3 组缓存统计数据：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ cachestat <span class="token number">1</span> <span class="token number">3</span>
   TOTAL   MISSES     HITS  DIRTIES   BUFFERS_MB  CACHED_MB
       <span class="token number">2</span>        <span class="token number">0</span>        <span class="token number">2</span>        <span class="token number">1</span>           <span class="token number">17</span>        <span class="token number">279</span>
       <span class="token number">2</span>        <span class="token number">0</span>        <span class="token number">2</span>        <span class="token number">1</span>           <span class="token number">17</span>        <span class="token number">279</span>
       <span class="token number">2</span>        <span class="token number">0</span>        <span class="token number">2</span>        <span class="token number">1</span>           <span class="token number">17</span>        <span class="token number">279</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>你可以看到，cachestat 的输出其实是一个表格。每行代表一组数据，而每一列代表不同的缓存统计指标。这些指标从左到右依次表示：</p>
<ul>
<li>TOTAL ，表示总的 I/O 次数；</li>
<li>MISSES ，表示缓存未命中的次数；</li>
<li>HITS ，表示缓存命中的次数；</li>
<li>DIRTIES， 表示新增到缓存中的脏页数；</li>
<li>BUFFERS_MB 表示 Buffers 的大小，以 MB 为单位；</li>
<li>CACHED_MB 表示 Cache 的大小，以 MB 为单位。</li>
</ul>
<p>接下来我们再来看一个 cachetop 的运行界面：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ cachetop
<span class="token number">11</span>:58:50 Buffers MB: <span class="token number">258</span> / Cached MB: <span class="token number">347</span> / Sort: HITS / Order: ascending
PID      <span class="token environment constant">UID</span>      CMD              HITS     MISSES   DIRTIES  READ_HIT%  WRITE_HIT%
<span class="token number">13029</span>    root     python              <span class="token number">1</span>          <span class="token number">0</span>         <span class="token number">0</span>     <span class="token number">100.0</span>%        <span class="token number">0.0</span>%<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>它的输出跟 top 类似，默认按照缓存的命中次数（HITS）排序，展示了每个进程的缓存命中情况。具体到每一个指标，这里的 HITS、MISSES 和 DIRTIES ，跟 cachestat 里的含义一样，分别代表间隔时间内的缓存命中次数、未命中次数以及新增到缓存中的脏页数。</p>
<p>而 READ_HIT 和 WRITE_HIT ，分别表示读和写的缓存命中率。</p>
<h4 id="17-2-指定文件的缓存大小"><a href="#17-2-指定文件的缓存大小" class="headerlink" title="17.2 指定文件的缓存大小"></a>17.2 指定文件的缓存大小</h4><p>除了缓存的命中率外，还有一个指标你可能也会很感兴趣，那就是指定文件在内存中的缓存大小。你可以使用 <a target="_blank" rel="noopener" href="https://github.com/tobert/pcstat">pcstat</a> 这个工具，来查看文件在内存中的缓存大小以及缓存比例。</p>
<p>安装完 Go 语言，再运行下面的命令安装 pcstat：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token builtin class-name">export</span> <span class="token assign-left variable">GOPATH</span><span class="token operator">=</span>~/go
$ <span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span>~/go/bin:<span class="token environment constant">$PATH</span>
$ go get golang.org/x/sys/unix
$ go get github.com/tobert/pcstat/pcstat<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>全部安装完成后，你就可以运行 pcstat 来查看文件的缓存情况了。比如，下面就是一个 pcstat 运行的示例，它展示了 /bin/ls 这个文件的缓存情况：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ pcstat /bin/ls
+---------+----------------+------------+-----------+---------+
<span class="token operator">|</span> Name    <span class="token operator">|</span> Size <span class="token punctuation">(</span>bytes<span class="token punctuation">)</span>   <span class="token operator">|</span> Pages      <span class="token operator">|</span> Cached    <span class="token operator">|</span> Percent <span class="token operator">|</span>
<span class="token operator">|</span>---------+----------------+------------+-----------+---------<span class="token operator">|</span>
<span class="token operator">|</span> /bin/ls <span class="token operator">|</span> <span class="token number">133792</span>         <span class="token operator">|</span> <span class="token number">33</span>         <span class="token operator">|</span> <span class="token number">0</span>         <span class="token operator">|</span> 000.000 <span class="token operator">|</span>
+---------+----------------+------------+-----------+---------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这个输出中，Cached 就是 /bin/ls 在缓存中的大小，而 Percent 则是缓存的百分比。你看到它们都是 0，这说明 /bin/ls 并不在缓存中。</p>
<p>接着，如果你执行一下 ls 命令，再运行相同的命令来查看的话，就会发现 /bin/ls 都在缓存中了。</p>
<h4 id="17-3-案例"><a href="#17-3-案例" class="headerlink" title="17.3 案例"></a>17.3 案例</h4><blockquote>
<p>机器配置： 2 CPU, 8 GB 内存。</p>
<p>安装软件：<code>apt install docker.io</code> 以及 bcc 和 pcstat。</p>
</blockquote>
<ol>
<li><p>dd 作为一个磁盘和文件的拷贝工具，经常被拿来测试磁盘或者文件系统的读写性能。不过，既然缓存会影响到性能，如果用 dd 对同一个文件进行多次读取测试，测试的结果会怎么样呢？</p>
<p> 首先，打开两个终端，连接到 Ubuntu 机器上，确保 bcc 已经安装配置成功。</p>
<p> 然后，使用 dd 命令生成一个临时文件，用于后面的文件读取测试：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 生成一个 512MB 的临时文件</span>
$ <span class="token function">dd</span> <span class="token assign-left variable">if</span><span class="token operator">=</span>/dev/sda1 <span class="token assign-left variable">of</span><span class="token operator">=</span>file <span class="token assign-left variable">bs</span><span class="token operator">=</span>1M <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">512</span>
<span class="token comment"># 清理缓存</span>
$ <span class="token builtin class-name">echo</span> <span class="token number">3</span> <span class="token operator">&gt;</span> /proc/sys/vm/drop_caches<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 继续在第一个终端，运行 pcstat 命令，确认刚刚生成的文件不在缓存中。如果一切正常，你会看到 Cached 和 Percent 都是 0:</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ pcstat <span class="token function">file</span>
+-------+----------------+------------+-----------+---------+
<span class="token operator">|</span> Name  <span class="token operator">|</span> Size <span class="token punctuation">(</span>bytes<span class="token punctuation">)</span>   <span class="token operator">|</span> Pages      <span class="token operator">|</span> Cached    <span class="token operator">|</span> Percent <span class="token operator">|</span>
<span class="token operator">|</span>-------+----------------+------------+-----------+---------<span class="token operator">|</span>
<span class="token operator">|</span> <span class="token function">file</span>  <span class="token operator">|</span> <span class="token number">536870912</span>      <span class="token operator">|</span> <span class="token number">131072</span>     <span class="token operator">|</span> <span class="token number">0</span>         <span class="token operator">|</span> 000.000 <span class="token operator">|</span>
+-------+----------------+------------+-----------+---------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 在第一个终端中，现在运行 cachetop 命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 每隔 5 秒刷新一次数据</span>
$ cachetop <span class="token number">5</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p> 第二个终端，运行 dd 命令测试文件的读取速度：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">dd</span> <span class="token assign-left variable">if</span><span class="token operator">=</span>file <span class="token assign-left variable">of</span><span class="token operator">=</span>/dev/null <span class="token assign-left variable">bs</span><span class="token operator">=</span>1M
<span class="token number">512</span>+0 records <span class="token keyword">in</span>
<span class="token number">512</span>+0 records out
<span class="token number">536870912</span> bytes <span class="token punctuation">(</span><span class="token number">537</span> MB, <span class="token number">512</span> MiB<span class="token punctuation">)</span> copied, <span class="token number">16.0509</span> s, <span class="token number">33.4</span> MB/s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从 dd 的结果可以看出，这个文件的读性能是 33.4 MB/s。由于在 dd 命令运行前我们已经清理了缓存，所以 dd 命令读取数据时，肯定要通过文件系统从磁盘中读取。</p>
<p> 不过，这是不是意味着， dd 所有的读请求都能直接发送到磁盘呢？</p>
<p> 我们再回到第一个终端， 查看 cachetop 界面的缓存命中情况：</p>
 <pre class="line-numbers language-text" data-language="text"><code class="language-text">PID      UID      CMD              HITS     MISSES   DIRTIES  READ_HIT%  WRITE_HIT%
\.\.\.
    3264 root     dd                  37077    37330        0      49.8%      50.2%<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 从 cachetop 的结果可以发现，并不是所有的读都落到了磁盘上，事实上读请求的缓存命中率只有 50% 。</p>
<p> 接下来，我们继续尝试相同的测试命令。先切换到第二个终端，再次执行刚才的 dd 命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">dd</span> <span class="token assign-left variable">if</span><span class="token operator">=</span>file <span class="token assign-left variable">of</span><span class="token operator">=</span>/dev/null <span class="token assign-left variable">bs</span><span class="token operator">=</span>1M
<span class="token number">512</span>+0 records <span class="token keyword">in</span>
<span class="token number">512</span>+0 records out
<span class="token number">536870912</span> bytes <span class="token punctuation">(</span><span class="token number">537</span> MB, <span class="token number">512</span> MiB<span class="token punctuation">)</span> copied, <span class="token number">0.118415</span> s, <span class="token number">4.5</span> GB/s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 看到这次的结果，有没有点小惊讶？磁盘的读性能居然变成了 4.5 GB/s，比第一次的结果明显高了太多。为什么这次的结果这么好呢？</p>
<p> 不妨再回到第一个终端，看看 cachetop 的情况：</p>
 <pre class="line-numbers language-text" data-language="text"><code class="language-text">10:45:22 Buffers MB: 4 / Cached MB: 719 / Sort: HITS / Order: ascending
PID      UID      CMD              HITS     MISSES   DIRTIES  READ_HIT%  WRITE_HIT%
\.\.\.
32642 root     dd                 131637        0        0     100.0%       0.0%<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 显然，cachetop 也有了不小的变化。你可以发现，这次的读的缓存命中率是 100.0%，也就是说这次的 dd 命令全部命中了缓存，所以才会看到那么高的性能。</p>
<p> 然后，回到第二个终端，再次执行 pcstat 查看文件 file 的缓存情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ pcstat <span class="token function">file</span>
+-------+----------------+------------+-----------+---------+
<span class="token operator">|</span> Name  <span class="token operator">|</span> Size <span class="token punctuation">(</span>bytes<span class="token punctuation">)</span>   <span class="token operator">|</span> Pages      <span class="token operator">|</span> Cached    <span class="token operator">|</span> Percent <span class="token operator">|</span>
<span class="token operator">|</span>-------+----------------+------------+-----------+---------<span class="token operator">|</span>
<span class="token operator">|</span> <span class="token function">file</span>  <span class="token operator">|</span> <span class="token number">536870912</span>      <span class="token operator">|</span> <span class="token number">131072</span>     <span class="token operator">|</span> <span class="token number">131072</span>    <span class="token operator">|</span> <span class="token number">100.000</span> <span class="token operator">|</span>
+-------+----------------+------------+-----------+---------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从 pcstat 的结果你可以发现，测试文件 file 已经被全部缓存了起来，这跟刚才观察到的缓存命中率 100% 是一致的。</p>
<p> 这两次结果说明，系统缓存对第二次 dd 操作有明显的加速效果，可以大大提高文件读取的性能。</p>
<p> 但同时也要注意，如果我们把 dd 当成测试文件系统性能的工具，由于缓存的存在，就会导致测试结果严重失真。</p>
</li>
<li><p>再来看一个文件读写的案例。这个案例类似于前面学过的不可中断状态进程的例子。它的基本功能比较简单，也就是每秒从磁盘分区 /dev/sda1 中读取 32MB 的数据，并打印出读取数据花费的时间。</p>
<p> 为了方便你运行案例，我把它打包成了一个 <a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/tree/master/io-cached">Docker 镜像</a>。 跟前面案例类似，我提供了下面两个选项，你可以根据系统配置，自行调整磁盘分区的路径以及 I/O 的大小。</p>
<ul>
<li>-d 选项，设置要读取的磁盘或分区路径，默认是查找前缀为 /dev/sd 或者 /dev/xvd 的磁盘。</li>
<li><p>-s 选项，设置每次读取的数据量大小，单位为字节，默认为 33554432（也就是 32MB）。</p>
<p>这个案例同样需要你开启两个终端。分别 SSH 登录到机器上后，先在第一个终端中运行 cachetop 命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 每隔 5 秒刷新一次数据</span>
$ cachetop <span class="token number">5</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>接着，再到第二个终端，执行下面的命令运行案例：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker run --privileged --name<span class="token operator">=</span>app -itd feisky/app:io-direct<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>案例运行后，我们还需要运行下面这个命令，来确认案例已经正常启动。如果一切正常，你应该可以看到类似下面的输出：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker logs app
Reading data from disk /dev/sdb1 with buffer size <span class="token number">33554432</span>
Time used: <span class="token number">0.929935</span> s to <span class="token builtin class-name">read</span> <span class="token number">33554432</span> bytes
Time used: <span class="token number">0.949625</span> s to <span class="token builtin class-name">read</span> <span class="token number">33554432</span> bytes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>从这里你可以看到，每读取 32 MB 的数据，就需要花 0.9 秒。这个时间合理吗？我想你第一反应就是，太慢了吧。那这是不是没用系统缓存导致的呢？</p>
<p>我们再来检查一下。回到第一个终端，先看看 cachetop 的输出，在这里，我们找到案例进程 app 的缓存使用情况：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token number">16</span>:39:18 Buffers MB: <span class="token number">73</span> / Cached MB: <span class="token number">281</span> / Sort: HITS / Order: ascending
PID      <span class="token environment constant">UID</span>      CMD              HITS     MISSES   DIRTIES  READ_HIT%  WRITE_HIT%
  <span class="token number">21881</span> root     app                  <span class="token number">1024</span>        <span class="token number">0</span>        <span class="token number">0</span>     <span class="token number">100.0</span>%       <span class="token number">0.0</span>%<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>这个输出似乎有点意思了。1024 次缓存全部命中，读的命中率是 100%，看起来全部的读请求都经过了系统缓存。但是问题又来了，如果真的都是缓存 I/O，读取速度不应该这么慢。</p>
<p>至于为什么只能看到 0.8 MB 的 HITS，我们后面再解释，这里你先知道怎么根据结果来分析就可以了。</p>
<p>这也进一步验证了我们的猜想，这个案例估计没有充分利用系统缓存。其实前面我们遇到过类似的问题，如果为系统调用设置直接 I/O 的标志，就可以绕过系统缓存。</p>
<p>那么，要判断应用程序是否用了直接 I/O，最简单的方法当然是观察它的系统调用，查找应用程序在调用它们时的选项。使用什么工具来观察系统调用呢？自然还是 strace。</p>
<p>继续在终端二中运行下面的 strace 命令，观察案例应用的系统调用情况。注意，这里使用了 pgrep 命令来查找案例进程的 PID 号：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># strace -p $(pgrep app)</span>
strace: Process <span class="token number">4988</span> attached
restart_syscall<span class="token punctuation">(</span><span class="token operator">&lt;</span><span class="token punctuation">\</span>.<span class="token punctuation">\</span>.<span class="token punctuation">\</span>. resuming interrupted nanosleep <span class="token punctuation">\</span>.<span class="token punctuation">\</span>.<span class="token punctuation">\</span>.<span class="token operator">&gt;</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0</span>
openat<span class="token punctuation">(</span>AT_FDCWD, <span class="token string">"/dev/sdb1"</span>, O_RDONLY<span class="token operator">|</span>O_DIRECT<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">4</span>
mmap<span class="token punctuation">(</span>NULL, <span class="token number">33558528</span>, PROT_READ<span class="token operator">|</span>PROT_WRITE, MAP_PRIVATE<span class="token operator">|</span>MAP_ANONYMOUS, -1, <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">=</span> 0x7f448d240000
read<span class="token punctuation">(</span><span class="token number">4</span>, <span class="token string">"8vq<span class="token entity" title="\213">\213</span><span class="token entity" title="\314">\314</span><span class="token entity" title="\264">\264</span>u<span class="token entity" title="\373">\373</span><span class="token entity" title="\4">\4</span><span class="token entity" title="\336">\336</span>K<span class="token entity" title="\224">\224</span><span class="token entity" title="\25">\25</span>@<span class="token entity" title="\371">\371</span><span class="token entity" title="\1">\1</span><span class="token entity" title="\252">\252</span><span class="token entity" title="\2">\2</span><span class="token entity" title="\262">\262</span><span class="token entity" title="\252">\252</span>q<span class="token entity" title="\221">\221</span><span class="token entity" title="\n">\n</span>0<span class="token entity" title="\30">\30</span><span class="token entity" title="\225">\225</span>bD<span class="token entity" title="\252">\252</span><span class="token entity" title="\266">\266</span>@J"</span><span class="token punctuation">\</span>.<span class="token punctuation">\</span>.<span class="token punctuation">\</span>., <span class="token number">33554432</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">33554432</span>
write<span class="token punctuation">(</span><span class="token number">1</span>, <span class="token string">"Time used: 0.948897 s to read 33"</span><span class="token punctuation">\</span>.<span class="token punctuation">\</span>.<span class="token punctuation">\</span>., <span class="token number">45</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">45</span>
close<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>                                <span class="token operator">=</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>从 strace 的结果可以看到，案例应用调用了 openat 来打开磁盘分区 /dev/sdb1，并且传入的参数为 O_RDONLY|O_DIRECT（中间的竖线表示或）。</p>
<p>O_RDONLY 表示以只读方式打开，而 O_DIRECT 则表示以直接读取的方式打开，这会绕过系统的缓存。</p>
<p>验证了这一点，就很容易理解为什么读 32 MB 的数据就都要那么久了。直接从磁盘读写的速度，自然远慢于对缓存的读写。这也是缓存存在的最大意义了。</p>
<p>找出问题后，我们还可以在再看看案例应用的<a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/blob/master/io-cached/app.c">源代码</a>，再次验证一下：</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> flags <span class="token operator">=</span> O_RDONLY <span class="token operator">|</span> O_LARGEFILE <span class="token operator">|</span> O_DIRECT<span class="token punctuation">;</span>
<span class="token keyword">int</span> fd <span class="token operator">=</span> <span class="token function">open</span><span class="token punctuation">(</span>disk<span class="token punctuation">,</span> flags<span class="token punctuation">,</span> <span class="token number">0755</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>上面的代码，很清楚地告诉我们：它果然用了直接 I/O。</p>
<p>找出了磁盘读取缓慢的原因，优化磁盘读的性能自然不在话下。修改源代码，删除 O_DIRECT 选项，让应用程序使用缓存 I/O ，而不是直接 I/O，就可以加速磁盘读取速度。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/blob/master/io-cached/app-cached.c">app-cached.c</a> 就是修复后的源码，我也把它打包成了一个容器镜像。在第二个终端中，按 Ctrl+C 停止刚才的 strace 命令，运行下面的命令，你就可以启动它：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 删除上述案例应用</span>
$ docker <span class="token function">rm</span> -f app

<span class="token comment"># 运行修复后的应用</span>
$ docker run --privileged --name<span class="token operator">=</span>app -itd feisky/app:io-cached<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>还是第二个终端，再来运行下面的命令查看新应用的日志，你应该能看到下面这个输出：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker logs app
Reading data from disk /dev/sdb1 with buffer size <span class="token number">33554432</span>
Time used: <span class="token number">0.037342</span> s s to <span class="token builtin class-name">read</span> <span class="token number">33554432</span> bytes
Time used: <span class="token number">0.029676</span> s to <span class="token builtin class-name">read</span> <span class="token number">33554432</span> bytes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>现在，每次只需要 0.03 秒，就可以读取 32MB 数据，明显比之前的 0.9 秒快多了。所以，这次应该用了系统缓存。</p>
<p>我们再回到第一个终端，查看 cachetop 的输出来确认一下：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">16:40:08 Buffers MB: 73 / Cached MB: 281 / Sort: HITS / Order: ascending
PID      UID      CMD              HITS     MISSES   DIRTIES  READ_HIT%  WRITE_HIT%
   22106 root     app                 40960        0        0     100.0%       0.0%<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>果然，读的命中率还是 100%，HITS （即命中数）却变成了 40960，同样的方法计算一下，换算成每秒字节数正好是 32 MB（即 40960*4k/5/1024=32M）。</p>
<p>这个案例说明，在进行 I/O 操作时，充分利用系统缓存可以极大地提升性能。 但在观察缓存命中率时，还要注意结合应用程序实际的 I/O 大小，综合分析缓存的使用情况。</p>
<p>案例的最后，再回到开始的问题，为什么优化前，通过 cachetop 只能看到很少一部分数据的全部命中，而没有观察到大量数据的未命中情况呢？这是因为，cachetop 工具并不把直接 I/O 算进来。这也又一次说明了，了解工具原理的重要。</p>
<blockquote>
<p>cachetop 的计算方法涉及到 I/O 的原理以及一些内核的知识，如果你想了解它的原理的话，可以点击<a target="_blank" rel="noopener" href="https://github.com/iovisor/bcc/blob/master/tools/cachetop.py">这里</a>查看它的源代码。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<h3 id="18-案例篇：内存泄漏了，我该如何定位和处理？"><a href="#18-案例篇：内存泄漏了，我该如何定位和处理？" class="headerlink" title="18 | 案例篇：内存泄漏了，我该如何定位和处理？"></a>18 | 案例篇：内存泄漏了，我该如何定位和处理？</h3><h4 id="18-1-内存的分配和回收"><a href="#18-1-内存的分配和回收" class="headerlink" title="18.1 内存的分配和回收"></a>18.1 内存的分配和回收</h4><p>用户空间内存包括多个不同的内存段，比如只读段、数据段、堆、栈以及文件映射段等。这些内存段正是应用程序使用内存的基本方式。</p>
<p>栈内存由系统自动分配和管理。一旦程序运行超出了这个局部变量的作用域，栈内存就会被系统自动回收，所以不会产生内存泄漏的问题。</p>
<p>堆内存由应用程序自己来分配和管理。除非程序退出，这些堆内存并不会被系统自动释放，而是需要应用程序明确调用库函数 free() 来释放它们。如果应用程序没有正确释放堆内存，就会造成内存泄漏。</p>
<p>其他内存段是否也会导致内存泄漏呢？</p>
<ul>
<li>只读段，包括程序的代码和常量，由于是只读的，不会再去分配新的内存，所以也不会产生内存泄漏。</li>
<li>数据段，包括全局变量和静态变量，这些变量在定义时就已经确定了大小，所以也不会产生内存泄漏。</li>
<li>最后一个内存映射段，包括动态链接库和共享内存，其中共享内存由程序动态分配和管理。所以，如果程序在分配后忘了回收，就会导致跟堆内存类似的泄漏问题。</li>
</ul>
<p><strong>内存泄漏的危害非常大，这些忘记释放的内存，不仅应用程序自己不能访问，系统也不能把它们再次分配给其他应用</strong>。内存泄漏不断累积，甚至会耗尽系统内存。</p>
<p>虽然，系统最终可以通过 OOM （Out of Memory）机制杀死进程，但进程在 OOM 前，可能已经引发了一连串的反应，导致严重的性能问题。</p>
<p>比如，其他需要内存的进程，可能无法分配新的内存；内存不足，又会触发系统的缓存回收以及 SWAP 机制，从而进一步导致 I/O 的性能问题等等。</p>
<p>如果你已经发现了内存泄漏，该如何定位和处理呢。</p>
<h4 id="18-2-案例"><a href="#18-2-案例" class="headerlink" title="18.2 案例"></a>18.2 案例</h4><blockquote>
<p>机器配置： 2 CPU, 8 GB 内存。</p>
<p>安装软件：<code>apt install docker.io sysstat</code> 以及 bcc。</p>
</blockquote>
<ol>
<li><p>执行下面的命令来运行案例：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker run --name<span class="token operator">=</span>app -itd feisky/app:mem-leak<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>案例成功运行后，你需要输入下面的命令，确认案例应用已经正常启动。如果一切正常，你应该可以看到下面这个界面：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker logs app
2th <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token number">1</span>
3th <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token number">2</span>
4th <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token number">3</span>
5th <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token number">5</span>
6th <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token number">8</span>
7th <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token number">13</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 我们应该怎么检查内存情况，判断有没有泄漏发生呢？你首先想到的可能是 top 工具，不过，top 虽然能观察系统和进程的内存占用情况，但今天的案例并不适合。内存泄漏问题，我们更应该关注内存使用的变化趋势。</p>
</li>
<li><p>运行下面的 vmstat ，等待一段时间，观察内存的变化情况。如果忘了 vmstat 里各指标的含义，记得复习前面内容，或者执行 man vmstat 查询。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 每隔 3 秒输出一组数据</span>
$ <span class="token function">vmstat</span> <span class="token number">3</span>
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
r  b   swpd   <span class="token function">free</span>   buff  cache   si   so    bi    bo   <span class="token keyword">in</span>   cs us sy <span class="token function">id</span> wa st
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
r  b   swpd   <span class="token function">free</span>   buff  cache   si   so    bi    bo   <span class="token keyword">in</span>   cs us sy <span class="token function">id</span> wa st
<span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6601824</span>  <span class="token number">97620</span> <span class="token number">1098784</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>     <span class="token number">0</span>   <span class="token number">62</span>  <span class="token number">322</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">100</span>  <span class="token number">0</span>  <span class="token number">0</span>
<span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6601700</span>  <span class="token number">97620</span> <span class="token number">1098788</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>     <span class="token number">0</span>   <span class="token number">57</span>  <span class="token number">251</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">100</span>  <span class="token number">0</span>  <span class="token number">0</span>
<span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6601320</span>  <span class="token number">97620</span> <span class="token number">1098788</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>     <span class="token number">3</span>   <span class="token number">52</span>  <span class="token number">306</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">100</span>  <span class="token number">0</span>  <span class="token number">0</span>
<span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6601452</span>  <span class="token number">97628</span> <span class="token number">1098788</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>    <span class="token number">27</span>   <span class="token number">63</span>  <span class="token number">326</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">100</span>  <span class="token number">0</span>  <span class="token number">0</span>
<span class="token number">2</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6601328</span>  <span class="token number">97628</span> <span class="token number">1098788</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>    <span class="token number">44</span>   <span class="token number">52</span>  <span class="token number">299</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">100</span>  <span class="token number">0</span>  <span class="token number">0</span>
<span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6601080</span>  <span class="token number">97628</span> <span class="token number">1098792</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>     <span class="token number">0</span>   <span class="token number">56</span>  <span class="token number">285</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">100</span>  <span class="token number">0</span>  <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从输出中你可以看到，内存的 free 列在不停的变化，并且是下降趋势；而 buffer 和 cache 基本保持不变。</p>
<p> 未使用内存在逐渐减小，而 buffer 和 cache 基本不变，这说明，系统中使用的内存一直在升高。但这并不能说明有内存泄漏，因为应用程序运行中需要的内存也可能会增大。比如说，程序中如果用了一个动态增长的数组来缓存计算结果，占用内存自然会增长。</p>
<p> 那怎么确定是不是内存泄漏呢？或者换句话说，有没有简单方法找出让内存增长的进程，并定位增长内存用在哪儿呢？</p>
<p> 根据前面内容，你应该想到了用 top 或 ps 来观察进程的内存使用情况，然后找出内存使用一直增长的进程，最后再通过 pmap 查看进程的内存分布。</p>
<p> 但这种方法并不太好用，因为要判断内存的变化情况，还需要你写一个脚本，来处理 top 或者 ps 的输出。</p>
<p> 这里，我介绍一个专门用来检测内存泄漏的工具，memleak。memleak 可以跟踪系统或指定进程的内存分配、释放请求，然后定期输出一个未释放内存和相应调用栈的汇总情况（默认 5 秒）。</p>
</li>
<li><p>memleak 是 bcc 软件包中的一个工具，我们一开始就装好了，执行 /usr/share/bcc/tools/memleak 就可以运行它。比如，我们运行下面的命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -a 表示显示每个内存分配请求的大小以及地址</span>
<span class="token comment"># -p 指定案例应用的 PID 号</span>
$ /usr/share/bcc/tools/memleak -a -p <span class="token variable"><span class="token variable">$(</span>pidof app<span class="token variable">)</span></span>
WARNING: Couldn<span class="token string">'t find .text section in /app
WARNING: BCC can'</span>t handle sym <span class="token function">look</span> ups <span class="token keyword">for</span> /app
    addr <span class="token operator">=</span> 7f8f704732b0 size <span class="token operator">=</span> <span class="token number">8192</span>
    addr <span class="token operator">=</span> 7f8f704772d0 size <span class="token operator">=</span> <span class="token number">8192</span>
    addr <span class="token operator">=</span> 7f8f704712a0 size <span class="token operator">=</span> <span class="token number">8192</span>
    addr <span class="token operator">=</span> 7f8f704752c0 size <span class="token operator">=</span> <span class="token number">8192</span>
    <span class="token number">32768</span> bytes <span class="token keyword">in</span> <span class="token number">4</span> allocations from stack
        <span class="token punctuation">[</span>unknown<span class="token punctuation">]</span> <span class="token punctuation">[</span>app<span class="token punctuation">]</span>
        <span class="token punctuation">[</span>unknown<span class="token punctuation">]</span> <span class="token punctuation">[</span>app<span class="token punctuation">]</span>
        start_thread+0xdb <span class="token punctuation">[</span>libpthread-2.27.so<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从 memleak 的输出可以看到，案例应用在不停地分配内存，并且这些分配的地址没有被回收。</p>
<p> 这里有一个问题，Couldn’t find .text section in /app，所以调用栈不能正常输出，最后的调用栈部分只能看到 [unknown] 的标志。</p>
<p> 为什么会有这个错误呢？实际上，这是由于案例应用运行在容器中导致的。memleak 工具运行在容器之外，并不能直接访问进程路径 /app。</p>
<p> 类似的问题，我在 CPU 模块中的 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/73738">perf 使用方法</a> 中已经提到好几个解决思路。最简单的方法，就是在容器外部构建相同路径的文件以及依赖库。这个案例只有一个二进制文件，所以只要把案例应用的二进制文件放到 /app 路径中，就可以修复这个问题。</p>
<p> 比如，你可以运行下面的命令，把 app 二进制文件从容器中复制出来，然后重新运行 memleak 工具：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ /usr/share/bcc/tools/memleak -p <span class="token variable"><span class="token variable">$(</span>pidof app<span class="token variable">)</span></span> -a
Attaching to pid <span class="token number">12512</span>, Ctrl+C to quit.
<span class="token punctuation">[</span>03:00:41<span class="token punctuation">]</span> Top <span class="token number">10</span> stacks with outstanding allocations:
    addr <span class="token operator">=</span> 7f8f70863220 size <span class="token operator">=</span> <span class="token number">8192</span>
    addr <span class="token operator">=</span> 7f8f70861210 size <span class="token operator">=</span> <span class="token number">8192</span>
    addr <span class="token operator">=</span> 7f8f7085b1e0 size <span class="token operator">=</span> <span class="token number">8192</span>
    addr <span class="token operator">=</span> 7f8f7085f200 size <span class="token operator">=</span> <span class="token number">8192</span>
    addr <span class="token operator">=</span> 7f8f7085d1f0 size <span class="token operator">=</span> <span class="token number">8192</span>
    <span class="token number">40960</span> bytes <span class="token keyword">in</span> <span class="token number">5</span> allocations from stack
        fibonacci+0x1f <span class="token punctuation">[</span>app<span class="token punctuation">]</span>
        child+0x4f <span class="token punctuation">[</span>app<span class="token punctuation">]</span>
        start_thread+0xdb <span class="token punctuation">[</span>libpthread-2.27.so<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 这一次，我们终于看到了内存分配的调用栈，原来是 fibonacci() 函数分配的内存没释放。</p>
<p> 定位了内存泄漏的来源，下一步自然就应该查看源码，想办法修复它。我们一起来看案例应用的源代码 <a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/blob/master/mem-leak/app.c">app.c</a>：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker <span class="token builtin class-name">exec</span> app <span class="token function">cat</span> /app.c
<span class="token punctuation">..</span>.
long long *fibonacci<span class="token punctuation">(</span>long long *n0, long long *n1<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    // 分配 <span class="token number">1024</span> 个长整数空间方便观测内存的变化情况
    long long *v <span class="token operator">=</span> <span class="token punctuation">(</span>long long *<span class="token punctuation">)</span> calloc<span class="token punctuation">(</span><span class="token number">1024</span>, sizeof<span class="token punctuation">(</span>long long<span class="token punctuation">))</span><span class="token punctuation">;</span>
    *v <span class="token operator">=</span> *n0 + *n1<span class="token punctuation">;</span>
    <span class="token builtin class-name">return</span> <span class="token function">v</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>


void *child<span class="token punctuation">(</span>void *arg<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    long long n0 <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    long long n1 <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
    long long *v <span class="token operator">=</span> NULL<span class="token punctuation">;</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span>int n <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span> n <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">;</span> n++<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token function">v</span> <span class="token operator">=</span> fibonacci<span class="token punctuation">(</span><span class="token operator">&amp;</span>n0, <span class="token operator">&amp;</span>n1<span class="token punctuation">)</span><span class="token punctuation">;</span>
        n0 <span class="token operator">=</span> n1<span class="token punctuation">;</span>
        n1 <span class="token operator">=</span> *v<span class="token punctuation">;</span>
        printf<span class="token punctuation">(</span><span class="token string">"%dth =&gt; %lld<span class="token entity" title="\n">\n</span>"</span>, n, *v<span class="token punctuation">)</span><span class="token punctuation">;</span>
        sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>我把修复后的代码放到了 <a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/blob/master/mem-leak/app-fix.c">app-fix.c</a>，也打包成了一<br>个 Docker 镜像。你可以运行下面的命令，验证一下内存泄漏是否修复：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 清理原来的案例应用</span>
$ docker <span class="token function">rm</span> -f app

<span class="token comment"># 运行修复后的应用</span>
$ docker run --name<span class="token operator">=</span>app -itd feisky/app:mem-leak-fix

<span class="token comment"># 重新执行 memleak 工具检查内存泄漏情况</span>
$ /usr/share/bcc/tools/memleak -a -p <span class="token variable"><span class="token variable">$(</span>pidof app<span class="token variable">)</span></span>
Attaching to pid <span class="token number">18808</span>, Ctrl+C to quit.
<span class="token punctuation">[</span><span class="token number">10</span>:23:18<span class="token punctuation">]</span> Top <span class="token number">10</span> stacks with outstanding allocations:
<span class="token punctuation">[</span><span class="token number">10</span>:23:23<span class="token punctuation">]</span> Top <span class="token number">10</span> stacks with outstanding allocations:<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="19-案例篇：为什么系统的Swap变高了（上）"><a href="#19-案例篇：为什么系统的Swap变高了（上）" class="headerlink" title="19 | 案例篇：为什么系统的Swap变高了（上）"></a>19 | 案例篇：为什么系统的Swap变高了（上）</h3></li>
</ol>
<p>当发生了内存泄漏时，或者运行了大内存的应用程序，导致系统的内存资源紧张时，系统又会如何应对呢？</p>
<p>这其实会导致两种可能结果，内存回收和 OOM 杀死进程。</p>
<p>内存资源紧张导致的 OOM（Out Of Memory），相对容易理解，指的是系统杀死占用大量内存的进程，释放这些内存，再分配给其他更需要的进程。</p>
<p>内存回收，也就是系统释放掉可以回收的内存，比如我前面讲过的缓存和缓冲区，就属于可回收内存。它们在内存管理中，通常被叫做<strong>文件页</strong>（File-backed Page）。</p>
<p>大部分文件页，都可以直接回收，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。</p>
<p>这些脏页，一般可以通过两种方式写入磁盘。</p>
<ul>
<li>可以在应用程序中，通过系统调用 fsync ，把脏页同步到磁盘中；</li>
<li>也可以交给系统，由内核线程 pdflush 负责这些脏页的刷新。</li>
</ul>
<p>除了缓存和缓冲区，通过内存映射获取的文件映射页，也是一种常见的文件页。它也可以被释放掉，下次再访问的时候，从文件重新读取。</p>
<p>除了文件页外，还有没有其他的内存可以回收呢？比如，应用程序动态分配的堆内存，也就是我们在内存管理中说到的匿名页（Anonymous Page），是不是也可以回收呢？</p>
<p>我想，你肯定会说，它们很可能还要再次被访问啊，当然不能直接回收了。非常正确，这些内存自然不能直接释放。</p>
<p>但是，如果这些内存在分配后很少被访问，似乎也是一种资源浪费。是不是可以把它们暂时先存在磁盘里，释放内存给其他更需要的进程？</p>
<p>其实，这正是 Linux 的 Swap 机制。Swap 把这些不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。</p>
<h4 id="19-1-Swap-原理"><a href="#19-1-Swap-原理" class="headerlink" title="19.1 Swap 原理"></a>19.1 Swap 原理</h4><p>Swap 说白了就是把一块磁盘空间或者一个本地文件（以下讲解以磁盘为例），当成内存来使用。它包括换出和换入两个过程。</p>
<ul>
<li>所谓换出，就是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存。</li>
<li>而换入，则是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来。</li>
</ul>
<p>Swap 其实是把系统的可用内存变大了。这样，即使服务器的内存不足，也可以运行大内存的应用程序。</p>
<p>现在的内存便宜多了，服务器一般也会配置很大的内存，那是不是说 Swap 就没有用武之地了呢？</p>
<p>当然不是。事实上，内存再大，对应用程序来说，也有不够用的时候。</p>
<p>一个很典型的场景就是，即使内存不足时，有些应用程序也并不想被 OOM 杀死，而是希望能缓一段时间，等待人工介入，或者等系统自动释放其他进程的内存，再分配给它。</p>
<p>除此之外，我们常见的笔记本电脑的休眠和快速开机的功能，也基于 Swap 。休眠时，把系统的内存存入磁盘，这样等到再次开机时，只要从磁盘中加载内存就可以。这样就省去了很多应用程序的初始化过程，加快了开机速度。</p>
<p>话说回来，既然 Swap 是为了回收内存，那么 Linux 到底在什么时候需要回收内存呢？前面一直在说内存资源紧张，又该怎么来衡量内存是不是紧张呢？</p>
<ol>
<li><p>一个最容易想到的场景就是，有新的大块内存分配请求，但是剩余内存不足。这个时候系统就需要回收一部分内存（比如前面提到的缓存），进而尽可能地满足新内存请求。这个过程通常被称为<strong>直接内存回收</strong>。</p>
</li>
<li><p>除了直接内存回收，还有一个专门的内核线程用来定期回收内存，也就是<strong>kswapd0</strong>。为了衡量内存的使用情况，kswapd0 定义了三个内存阈值（watermark，也称为水位），分别是</p>
<p> 页最小阈值（pages_min）、页低阈值（pages_low）和页高阈值（pages_high）。剩余内存，则使用 pages_free 表示。</p>
<p> 这里，我画了一张图表示它们的关系。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/kswapd0的三个内存阈值.png" alt="kswapd0的三个内存阈值.png"></p>
<p> kswapd0 定期扫描内存的使用情况，并根据剩余内存落在这三个阈值的空间位置，进行内存的回收操作。</p>
<ul>
<li>剩余内存小于<strong>页最小阈值</strong>，说明进程可用内存都耗尽了，只有内核才可以分配内存。</li>
<li>剩余内存落在<strong>页最小阈值</strong>和<strong>页低阈值</strong>中间，说明内存压力比较大，剩余内存不多了。这时 kswapd0 会执行内存回收，直到剩余内存大于高阈值为止。</li>
<li>剩余内存落在<strong>页低阈值</strong>和<strong>页高阈值</strong>中间，说明内存有一定压力，但还可以满足新内存请求。</li>
<li><p>剩余内存大于<strong>页高阈值</strong>，说明剩余内存比较多，没有内存压力。</p>
<p>我们可以看到，一旦剩余内存小于页低阈值，就会触发内存的回收。这个页低阈值，其实可以通过内核选项 /proc/sys/vm/min_free_kbytes 来间接设置。min_free_kbytes 设置了页最小阈值，而其他两个阈值，都是根据页最小阈值计算生成的，计算方法如下 ：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pages_low <span class="token operator">=</span> pages_min*5/4
pages_high <span class="token operator">=</span> pages_min*3/2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h4 id="19-2-NUMA-与-Swap"><a href="#19-2-NUMA-与-Swap" class="headerlink" title="19.2 NUMA 与 Swap"></a>19.2 NUMA 与 Swap</h4></li>
</ul>
</li>
</ol>
<p>很多情况下，你明明发现了 Swap 升高，可是在分析系统的内存使用时，却很可能发现，系统剩余内存还多着呢。为什么剩余内存很多的情况下，也会发生 Swap 呢？</p>
<p>看到上面的标题，你应该已经想到了，这正是处理器的 NUMA （Non-Uniform Memory Access）架构导致的。</p>
<p>在 NUMA 架构下，多个处理器被划分到不同 Node 上，且每个 Node 都拥有自己的本地内存空间。</p>
<p>而同一个 Node 内部的内存空间，实际上又可以进一步分为不同的内存域（Zone），比如直接内存访问区（DMA）、普通内存区（NORMAL）、伪内存区（MOVABLE）等，如下图所示：</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/NUMA与Swap.png" alt="NUMA与Swap"></p>
<p>先不用特别关注这些内存域的具体含义，我们只要会查看阈值的配置，以及缓存、匿名页的实际使用情况就够了。</p>
<p>既然 NUMA 架构下的每个 Node 都有自己的本地内存空间，那么，在分析内存的使用时，我们也应该针对每个 Node 单独分析。</p>
<p>你可以通过 numactl 命令，来查看处理器在 Node 的分布情况，以及每个 Node 的内存使用情况。比如，下面就是一个 numactl 输出的示例：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ numactl --hardware
available: <span class="token number">1</span> nodes <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
node <span class="token number">0</span> cpus: <span class="token number">0</span> <span class="token number">1</span>
node <span class="token number">0</span> size: <span class="token number">7977</span> MB
node <span class="token number">0</span> free: <span class="token number">4416</span> MB
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这个界面显示，我的系统中只有一个 Node，也就是 Node 0 ，而且编号为 0 和 1 的两个 CPU， 都位于 Node 0 上。另外，Node 0 的内存大小为 7977 MB，剩余内存为 4416 MB。</p>
<p>实际上，前面提到的三个内存阈值（页最小阈值、页低阈值和页高阈值），都可以通过内存域在 proc 文件系统中的接口 /proc/zoneinfo 来查看。</p>
<p>比如，下面就是一个 /proc/zoneinfo 文件的内容示例：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">cat</span> /proc/zoneinfo
<span class="token punctuation">..</span>.
Node <span class="token number">0</span>, zone   Normal
 pages <span class="token function">free</span>     <span class="token number">227894</span>
       min      <span class="token number">14896</span>
       low      <span class="token number">18620</span>
       high     <span class="token number">22344</span>
<span class="token punctuation">..</span>.
     nr_free_pages <span class="token number">227894</span>
     nr_zone_inactive_anon <span class="token number">11082</span>
     nr_zone_active_anon <span class="token number">14024</span>
     nr_zone_inactive_file <span class="token number">539024</span>
     nr_zone_active_file <span class="token number">923986</span>
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这个输出中有大量指标，我来解释一下比较重要的几个。</p>
<ul>
<li>pages 处的 min、low、high，就是上面提到的三个内存阈值，而 free 是剩余内存页数，它跟后面的 nr_free_pages 相同。</li>
<li>nr_zone_active_anon 和 nr_zone_inactive_anon，分别是活跃和非活跃的匿名页数。</li>
<li>nr_zone_active_file 和 nr_zone_inactive_file，分别是活跃和非活跃的文件页数。</li>
</ul>
<p>从这个输出结果可以发现，剩余内存远大于页高阈值，所以此时的 kswapd0 不会回收内存。</p>
<p>当然，某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存中回收内存。具体选哪种模式，你可以通过 /proc/sys/vm/zone_reclaim_mode 来调整。它支持以下几个选项：</p>
<ul>
<li>默认的 0 ，也就是刚刚提到的模式，表示既可以从其他 Node 寻找空闲内存，也可以从本地回收内存。</li>
<li>1、2、4 都表示只回收本地内存，2 表示可以回写脏数据回收内存，4 表示可以用 Swap 方式回收内存。</li>
</ul>
<h4 id="19-3-swappiness"><a href="#19-3-swappiness" class="headerlink" title="19.3 swappiness"></a>19.3 swappiness</h4><p>到这里，我们就可以理解内存回收的机制了。这些回收的内存既包括了文件页，又包括了匿名页。</p>
<ul>
<li>对文件页的回收，当然就是直接回收缓存，或者把脏页写回磁盘后再回收。</li>
<li>而对匿名页的回收，其实就是通过 Swap 机制，把它们写入磁盘后再释放内存。</li>
</ul>
<p>不过，你可能还有一个问题。既然有两种不同的内存回收机制，那么在实际回收内存时，到底该先回收哪一种呢？</p>
<p>其实，Linux 提供了一个 /proc/sys/vm/swappiness 选项，用来调整使用 Swap 的积极程度。</p>
<p>swappiness 的范围是 0-100，数值越大，越积极使用 Swap，也就是更倾向于回收匿名页；数值越小，越消极使用 Swap，也就是更倾向于回收文件页。</p>
<p>虽然 swappiness 的范围是 0-100，不过要注意，这并不是内存的百分比，而是调整 Swap 积极程度的权重，即使你把它设置成 0，当<a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/sysctl/vm.txt">剩余内存 + 文件页小于页高阈值</a>时，还是会发生 Swap。</p>
<blockquote>
<p>A value of 0 instructs the kernel not to initiate swap until the amount of free and file-backed pages is less than the high water mark in a zone.</p>
</blockquote>
<h3 id="20-案例篇：为什么系统的Swap变高了？（下）"><a href="#20-案例篇：为什么系统的Swap变高了？（下）" class="headerlink" title="20 | 案例篇：为什么系统的Swap变高了？（下）"></a>20 | 案例篇：为什么系统的Swap变高了？（下）</h3><h4 id="20-1-案例"><a href="#20-1-案例" class="headerlink" title="20.1 案例"></a>20.1 案例</h4><blockquote>
<p>机器配置： 2 CPU, 8 GB 内存。</p>
<p>安装软件：<code>apt install sysstat</code>。</p>
</blockquote>
<ol>
<li><p>在终端中运行 free 命令，查看 Swap 的使用情况。比如，在我的机器中，输出如下：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">free</span>
             total        used        <span class="token function">free</span>      shared  buff/cache   available
Mem:        <span class="token number">8169348</span>      <span class="token number">331668</span>     <span class="token number">6715972</span>         <span class="token number">696</span>     <span class="token number">1121708</span>     <span class="token number">7522896</span>
Swap:             <span class="token number">0</span>           <span class="token number">0</span>           <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从这个 free 输出你可以看到，Swap 的大小是 0，这说明我的机器没有配置 Swap。</p>
</li>
<li><p>要开启 Swap，我们首先要清楚，Linux 本身支持两种类型的 Swap，即 Swap 分区和 Swap 文件。以 Swap 文件为例，在第一个终端中运行下面的命令开启 Swap，我这里配置 Swap 文件的大小为 8GB：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 创建 Swap 文件</span>
$ fallocate -l 8G /mnt/swapfile
<span class="token comment"># 修改权限只有根用户可以访问</span>
$ <span class="token function">chmod</span> <span class="token number">600</span> /mnt/swapfile
<span class="token comment"># 配置 Swap 文件</span>
$ <span class="token function">mkswap</span> /mnt/swapfile
<span class="token comment"># 开启 Swap</span>
$ <span class="token function">swapon</span> /mnt/swapfile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>然后，再执行 free 命令，确认 Swap 配置成功：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">free</span>
            total        used        <span class="token function">free</span>      shared  buff/cache   available
Mem:        <span class="token number">8169348</span>      <span class="token number">331668</span>     <span class="token number">6715972</span>         <span class="token number">696</span>     <span class="token number">1121708</span>     <span class="token number">7522896</span>
Swap:       <span class="token number">8388604</span>           <span class="token number">0</span>     <span class="token number">8388604</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>在第一个终端中，运行下面的 dd 命令，模拟大文件的读取：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 写入空设备，实际上只有磁盘的读请求</span>
$ <span class="token function">dd</span> <span class="token assign-left variable">if</span><span class="token operator">=</span>/dev/sda1 <span class="token assign-left variable">of</span><span class="token operator">=</span>/dev/null <span class="token assign-left variable">bs</span><span class="token operator">=</span>1G <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">2048</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>接着，在第二个终端中运行 sar 命令，查看内存各个指标的变化情况。你可以多观察一会儿，查看这些指标的变化情况。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 间隔 1 秒输出一组数据</span>
<span class="token comment"># -r 表示显示内存使用情况，-S 表示显示 Swap 使用情况</span>
$ sar -r -S <span class="token number">1</span>
04:39:56    kbmemfree   kbavail kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
04:39:57      <span class="token number">6249676</span>   <span class="token number">6839824</span>   <span class="token number">1919632</span>     <span class="token number">23.50</span>    <span class="token number">740512</span>     <span class="token number">67316</span>   <span class="token number">1691736</span>     <span class="token number">10.22</span>    <span class="token number">815156</span>    <span class="token number">841868</span>         <span class="token number">4</span>

04:39:56    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad
04:39:57      <span class="token number">8388604</span>         <span class="token number">0</span>      <span class="token number">0.00</span>         <span class="token number">0</span>      <span class="token number">0.00</span>

04:39:57    kbmemfree   kbavail kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
04:39:58      <span class="token number">6184472</span>   <span class="token number">6807064</span>   <span class="token number">1984836</span>     <span class="token number">24.30</span>    <span class="token number">772768</span>     <span class="token number">67380</span>   <span class="token number">1691736</span>     <span class="token number">10.22</span>    <span class="token number">847932</span>    <span class="token number">874224</span>        <span class="token number">20</span>

04:39:57    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad
04:39:58      <span class="token number">8388604</span>         <span class="token number">0</span>      <span class="token number">0.00</span>         <span class="token number">0</span>      <span class="token number">0.00</span>

…

04:44:06    kbmemfree   kbavail kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
04:44:07       <span class="token number">152780</span>   <span class="token number">6525716</span>   <span class="token number">8016528</span>     <span class="token number">98.13</span>   <span class="token number">6530440</span>     <span class="token number">51316</span>   <span class="token number">1691736</span>     <span class="token number">10.22</span>    <span class="token number">867124</span>   <span class="token number">6869332</span>         <span class="token number">0</span>

04:44:06    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad
04:44:07      <span class="token number">8384508</span>      <span class="token number">4096</span>      <span class="token number">0.05</span>        <span class="token number">52</span>      <span class="token number">1.27</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 我们可以看到，sar 的输出结果是两个表格，第一个表格表示内存的使用情况，第二个表格表示 Swap 的使用情况。其中，各个指标名称前面的 kb 前缀，表示这些指标的单位是 KB。</p>
<p> 几个新出现的指标，我来简单介绍一下。</p>
<ul>
<li>kbcommit，表示当前系统负载需要的内存。它实际上是为了保证系统内存不溢出，对需要内存的估计值。%commit，就是这个值相对总内存的百分比。</li>
<li>kbactive，表示活跃内存，也就是最近使用过的内存，一般不会被系统回收。</li>
<li><p>kbinact，表示非活跃内存，也就是不常访问的内存，有可能会被系统回收。</p>
<p>清楚了界面指标的含义后，我们再结合具体数值，来分析相关的现象。你可以清楚地看到，总的内存使用率（%memused）在不断增长，从开始的 23% 一直长到了 98%，并且主要内存都被缓冲区（kbbuffers）占用。具体来说：</p>
</li>
<li><p>刚开始，剩余内存（kbmemfree）不断减少，而缓冲区（kbbuffers）则不断增大，由此可知，剩余内存不断分配给了缓冲区。</p>
</li>
<li><p>一段时间后，剩余内存已经很小，而缓冲区占用了大部分内存。这时候，Swap 的使用开始逐渐增大，缓冲区和剩余内存则只在小范围内波动。</p>
<p>你可能困惑了，为什么缓冲区在不停增大？这又是哪些进程导致的呢？</p>
<p>显然，我们还得看看进程缓存的情况。在前面缓存的案例中我们学过， cachetop 正好能满足这一点。那我们就来 cachetop 一下。</p>
</li>
</ul>
</li>
<li><p>在第二个终端中，按下 Ctrl+C 停止 sar 命令，然后运行下面的 cachetop 命令，观察缓存的使用情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ cachetop <span class="token number">5</span>
<span class="token number">12</span>:28:28 Buffers MB: <span class="token number">6349</span> / Cached MB: <span class="token number">87</span> / Sort: HITS / Order: ascending
PID      <span class="token environment constant">UID</span>      CMD              HITS     MISSES   DIRTIES  READ_HIT%  WRITE_HIT%
   <span class="token number">18280</span> root     python                 <span class="token number">22</span>        <span class="token number">0</span>        <span class="token number">0</span>     <span class="token number">100.0</span>%       <span class="token number">0.0</span>%
   <span class="token number">18279</span> root     <span class="token function">dd</span>                  <span class="token number">41088</span>    <span class="token number">41022</span>        <span class="token number">0</span>      <span class="token number">50.0</span>%      <span class="token number">50.0</span>%<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 通过 cachetop 的输出，我们看到，dd 进程的读写请求只有 50% 的命中率，并且未命中的缓存页数（MISSES）为 41022（单位是页）。这说明，正是案例开始时运行的 dd，导致了缓冲区使用升高。</p>
<p> 你可能接着会问，为什么 Swap 也跟着升高了呢？直观来说，缓冲区占了系统绝大部分内存，还属于可回收内存，内存不够用时，不应该先回收缓冲区吗？</p>
<p> 这种情况，我们还得进一步通过 /proc/zoneinfo ，观察剩余内存、内存阈值以及匿名页和文件页的活跃情况。</p>
</li>
<li><p>你可以在第二个终端中，按下 Ctrl+C，停止 cachetop 命令。然后运行下面的命令，观察 /proc/zoneinfo 中这几个指标的变化情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -d 表示高亮变化的字段</span>
<span class="token comment"># -A 表示仅显示 Normal 行以及之后的 15 行输出</span>
$ <span class="token function">watch</span> -d <span class="token function">grep</span> -A <span class="token number">15</span> <span class="token string">'Normal'</span> /proc/zoneinfo
Node <span class="token number">0</span>, zone   Normal
  pages <span class="token function">free</span>     <span class="token number">21328</span>
        min      <span class="token number">14896</span>
        low      <span class="token number">18620</span>
        high     <span class="token number">22344</span>
        spanned  <span class="token number">1835008</span>
        present  <span class="token number">1835008</span>
        managed  <span class="token number">1796710</span>
        protection: <span class="token punctuation">(</span><span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span><span class="token punctuation">)</span>
      nr_free_pages <span class="token number">21328</span>
      nr_zone_inactive_anon <span class="token number">79776</span>
      nr_zone_active_anon <span class="token number">206854</span>
      nr_zone_inactive_file <span class="token number">918561</span>
      nr_zone_active_file <span class="token number">496695</span>
      nr_zone_unevictable <span class="token number">2251</span>
      nr_zone_write_pending <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 你可以发现，剩余内存（pages_free）在一个小范围内不停地波动。当它小于页低阈值（pages_low) 时，又会突然增大到一个大于页高阈值（pages_high）的值。</p>
<p> 再结合刚刚用 sar 看到的剩余内存和缓冲区的变化情况，我们可以推导出，剩余内存和缓冲区的波动变化，正是由于内存回收和缓存再次分配的循环往复。</p>
<ul>
<li>当剩余内存小于页低阈值时，系统会回收一些缓存和匿名内存，使剩余内存增大。其中，缓存的回收导致 sar 中的缓冲区减小，而匿名内存的回收导致了 Swap 的使用增大。</li>
<li><p>紧接着，由于 dd 还在继续，剩余内存又会重新分配给缓存，导致剩余内存减少，缓冲区增大。</p>
<p>其实还有一个有趣的现象，如果多次运行 dd 和 sar，你可能会发现，在多次的循环重复中，有时候是 Swap 用得比较多，有时候 Swap 很少，反而缓冲区的波动更大。</p>
<p>换句话说，系统回收内存时，有时候会回收更多的文件页，有时候又回收了更多的匿名页。</p>
<p>显然，系统回收不同类型内存的倾向，似乎不那么明显。你应该想到了上节课提到的 swappiness，正是调整不同类型内存回收的配置选项。</p>
</li>
</ul>
</li>
<li><p>还是在第二个终端中，按下 Ctrl+C 停止 watch 命令，然后运行下面的命令，查看 swappiness 的配置：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">cat</span> /proc/sys/vm/swappiness
<span class="token number">60</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p> swappiness 显示的是默认值 60，这是一个相对中和的配置，所以系统会根据实际运行情况，选择合适的回收类型，比如回收不活跃的匿名页，或者不活跃的文件页。</p>
<p> 到这里，我们已经找出了 Swap 发生的根源。另一个问题就是，刚才的 Swap 到底影响了哪些应用程序呢？换句话说，Swap 换出的是哪些进程的内存？</p>
<p> 这里我还是推荐 proc 文件系统，用来查看进程 Swap 换出的虚拟内存大小，它保存在 /proc/pid/status 中的 VmSwap 中（推荐你执行 man proc 来查询其他字段的含义）。</p>
<p> 在第二个终端中运行下面的命令，就可以查看使用 Swap 最多的进程。注意 for、awk、sort 都是最常用的 Linux 命令，如果你还不熟悉，可以用 man 来查询它们的手册，或上网搜索教程来学习。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 按 VmSwap 使用量对进程排序，输出进程名称、进程 ID 以及 SWAP 用量</span>
$ <span class="token keyword">for</span> <span class="token for-or-select variable">file</span> <span class="token keyword">in</span> /proc/*/status <span class="token punctuation">;</span> <span class="token keyword">do</span> <span class="token function">awk</span> <span class="token string">'/VmSwap|Name|^Pid/{printf <span class="token variable">$2</span> " " <span class="token variable">$3</span>}END{ print ""}'</span> <span class="token variable">$file</span><span class="token punctuation">;</span> <span class="token keyword">done</span> <span class="token operator">|</span> <span class="token function">sort</span> -k <span class="token number">3</span> -n -r <span class="token operator">|</span> <span class="token function">head</span>
dockerd <span class="token number">2226</span> <span class="token number">10728</span> kB
docker-containe <span class="token number">2251</span> <span class="token number">8516</span> kB
snapd <span class="token number">936</span> <span class="token number">4020</span> kB
networkd-dispat <span class="token number">911</span> <span class="token number">836</span> kB
polkitd <span class="token number">1004</span> <span class="token number">44</span> kB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<blockquote>
<p>也可以使用命令 <code>smem --sort swap</code>。</p>
</blockquote>
<p> 这也说明了一点，虽然缓存属于可回收内存，但在类似大文件拷贝这类场景下，系统还是会用 Swap 机制来回收匿名内存，而不仅仅是回收占用绝大部分内存的文件页。</p>
</li>
<li><p>最后，如果你在一开始配置了 Swap，不要忘记在案例结束后关闭。你可以运行下面的命令，关闭 Swap：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ swapoff -a<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>实际上，关闭 Swap 后再重新打开，也是一种常用的 Swap 空间清理方法，比如：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ swapoff -a <span class="token operator">&amp;&amp;</span> <span class="token function">swapon</span> -a<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="20-2-小结"><a href="#20-2-小结" class="headerlink" title="20.2 小结"></a>20.2 小结</h4></li>
</ol>
<p>在内存资源紧张时，Linux 会通过 Swap ，把不常访问的匿名页换出到磁盘中，下次访问的时候再从磁盘换入到内存中来。你可以设置 /proc/sys/vm/min_free_kbytes，来调整系统定期回收内存的阈值；也可以设置 /proc/sys/vm/swappiness，来调整文件页和匿名页的回收倾向。</p>
<p>当 Swap 变高时，你可以用 sar、/proc/zoneinfo、/proc/pid/status 等方法，查看系统和进程的内存使用情况，进而找出 Swap 升高的根源和受影响的进程。</p>
<p>反过来说，通常，降低 Swap 的使用，可以提高系统的整体性能。要怎么做呢？这里，我也总结了几种常见的降低方法。</p>
<ul>
<li>禁止 Swap，现在服务器的内存足够大，所以除非有必要，禁用 Swap 就可以了。随着云计算的普及，大部分云平台中的虚拟机都默认禁止 Swap。</li>
<li>如果实在需要用到 Swap，可以尝试降低 swappiness 的值，减少内存回收时 Swap 的使用倾向。</li>
<li>响应延迟敏感的应用，如果它们可能在开启 Swap 的服务器中运行，你还可以用库函数 mlock() 或者 mlockall() 锁定内存，阻止它们的内存换出。</li>
</ul>
<h3 id="21-套路篇：如何“快准狠”找到系统内存的问题？"><a href="#21-套路篇：如何“快准狠”找到系统内存的问题？" class="headerlink" title="21 | 套路篇：如何“快准狠”找到系统内存的问题？"></a>21 | 套路篇：如何“快准狠”找到系统内存的问题？</h3><h4 id="21-1-内存性能指标"><a href="#21-1-内存性能指标" class="headerlink" title="21.1 内存性能指标"></a>21.1 内存性能指标</h4><p>为了分析内存的性能瓶颈，首先你要知道，怎样衡量内存的性能，也就是性能指标问题。</p>
<ol>
<li><p>首先，你最容易想到的是系统内存使用情况，比如已用内存、剩余内存、共享内存、可用内存、缓存和缓冲区的用量等。</p>
<ul>
<li>已用内存和剩余内存很容易理解，就是已经使用和还未使用的内存。</li>
<li>共享内存是通过 tmpfs 实现的，所以它的大小也就是 tmpfs 使用的内存大小。tmpfs 其实也是一种特殊的缓存。</li>
<li>可用内存是新进程可以使用的最大内存，它包括剩余内存和可回收缓存。</li>
<li>缓存包括两部分，一部分是磁盘读取文件的页缓存，用来缓存从磁盘读取的数据，可以加快以后再次访问的速度。另一部分，则是 Slab 分配器中的可回收内存。</li>
<li>缓冲区是对原始磁盘块的临时存储，用来缓存将要写入磁盘的数据。这样，内核就可以把分散的写集中起来，统一优化磁盘写入。</li>
</ul>
</li>
<li><p>第二类很容易想到的，应该是进程内存使用情况，比如进程的虚拟内存、常驻内存、共享内存以及 Swap 内存等。</p>
<ul>
<li>虚拟内存，包括了进程代码段、数据段、共享内存、已经申请的堆内存和已经换出的内存等。这里要注意，已经申请的内存，即使还没有分配物理内存，也算作虚拟内存。</li>
<li>常驻内存是进程实际使用的物理内存，不过，它不包括 Swap 和共享内存。</li>
<li>共享内存，既包括与其他进程共同使用的真实的共享内存，还包括了加载的动态链接库以及程序的代码段等。</li>
<li><p>Swap 内存，是指通过 Swap 换出到磁盘的内存。</p>
<p>当然，这些指标中，常驻内存一般会换算成占系统总内存的百分比，也就是进程的内存使用率。</p>
</li>
</ul>
</li>
<li><p>除了这些很容易想到的指标外，我还想再强调一下，缺页异常。</p>
<p> 在内存分配的原理中，我曾经讲到过，系统调用内存分配请求后，并不会立刻为其分配物理内存，而是在请求首次访问时，通过缺页异常来分配。缺页异常又分为下面两种场景。</p>
<ul>
<li>可以直接从物理内存中分配时，被称为次缺页异常。</li>
<li><p>需要磁盘 I/O 介入（比如 Swap）时，被称为主缺页异常。</p>
<p>显然，主缺页异常升高，就意味着需要磁盘 I/O，那么内存访问也会慢很多。</p>
</li>
</ul>
</li>
<li><p>除了系统内存和进程内存，第三类重要指标就是 Swap 的使用情况，比如 Swap 的已用空间、剩余空间、换入速度和换出速度等。</p>
<ul>
<li>已用空间和剩余空间很好理解，就是字面上的意思，已经使用和没有使用的内存空间。</li>
<li>换入和换出速度，则表示每秒钟换入和换出内存的大小。</li>
</ul>
</li>
</ol>
<p><img src="/images/《Linux性能优化实战》学习笔记/内存性能指标分析思维导图.png" alt="内存性能指标分析思维导图"></p>
<h4 id="21-2-内存性能工具"><a href="#21-2-内存性能工具" class="headerlink" title="21.2 内存性能工具"></a>21.2 内存性能工具</h4><ol>
<li><p>所有的案例中都用到了 free。这是个最常用的内存工具，可以查看系统的整体内存和 Swap 使用情况。相对应的，你可以用 top 或 ps，查看进程的内存使用情况。</p>
</li>
<li><p>在缓存和缓冲区的原理篇中，我们通过 proc 文件系统，找到了内存指标的来源；并通过 vmstat，动态观察了内存的变化情况。与 free 相比，vmstat 除了可以动态查看内存变化，还可以区分缓存和缓冲区、Swap 换入和换出的内存大小。</p>
</li>
<li><p>在缓存和缓冲区的案例篇中，为了弄清楚缓存的命中情况，我们又用了 cachestat ，查看整个系统缓存的读写命中情况，并用 cachetop 来观察每个进程缓存的读写命中情况。</p>
</li>
<li><p>在内存泄漏的案例中，我们用 vmstat，发现了内存使用在不断增长，又用 memleak，确认发生了内存泄漏。通过 memleak 给出的内存分配栈，我们找到了内存泄漏的可疑位置。</p>
</li>
<li><p>在 Swap 的案例中，我们用 sar 发现了缓冲区和 Swap 升高的问题。通过 cachetop，我们找到了缓冲区升高的根源；通过对比剩余内存跟 /proc/zoneinfo 的内存阈，我们发现 Swap 升高是内存回收导致的。案例最后，我们还通过 /proc 文件系统，找出了 Swap 所影响的进程。</p>
</li>
</ol>
<p>理解内存的工作原理，结合性能指标来记忆，拿下工具的使用方法并不难。</p>
<h4 id="21-3-性能指标和工具的联系"><a href="#21-3-性能指标和工具的联系" class="headerlink" title="21.3 性能指标和工具的联系"></a>21.3 性能指标和工具的联系</h4><p>同 CPU 性能分析一样，我的经验是两个不同维度出发，整理和记忆。</p>
<ul>
<li>从内存指标出发，更容易把工具和内存的工作原理关联起来。</li>
<li>从性能工具出发，可以更快地利用工具，找出我们想观察的性能指标。特别是在工具有限的情况下，我们更得充分利用手头的每一个工具，挖掘出更多的问题。</li>
</ul>
<ol>
<li><p>从内存指标出发，列举了哪些性能工具可以提供这些指标。这样，在实际排查性能问题时，你就可以清楚知道，究竟要用什么工具来辅助分析，提供你想要的指标。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/根据指标找工具（内存性能）.png" alt="根据指标找工具（内存性能）"></p>
</li>
<li><p>从性能工具出发，整理了这些常见工具能提供的内存指标。掌握了这个表格，你可以最大化利用已有的工具，尽可能多地找到你要的指标。真正用到时， man 一下查它们的使用手册就可以了。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/根据工具查指标（内存性能）.png" alt="根据工具查指标（内存性能）"></p>
</li>
</ol>
<h4 id="21-4-如何迅速分析内存的性能瓶颈"><a href="#21-4-如何迅速分析内存的性能瓶颈" class="headerlink" title="21.4 如何迅速分析内存的性能瓶颈"></a>21.4 如何迅速分析内存的性能瓶颈</h4><p>为了迅速定位内存问题，我通常会先运行几个覆盖面比较大的性能工具，比如 free、top、vmstat、pidstat 等。</p>
<p>具体的分析思路主要有这几步。</p>
<ul>
<li>先用 free 和 top，查看系统整体的内存使用情况。</li>
<li>再用 vmstat 和 pidstat，查看一段时间的趋势，从而判断出内存问题的类型。</li>
<li>最后进行详细分析，比如内存分配分析、缓存 / 缓冲区分析、具体进程的内存使用分析等。</li>
</ul>
<p><img src="/images/《Linux性能优化实战》学习笔记/如何迅速分析内存的性能瓶颈.png" alt="如何迅速分析内存的性能瓶颈.png"></p>
<p>举几个例子你可能会更容易理解。</p>
<ol>
<li><p>当你通过 free，发现大部分内存都被缓存占用后，可以使用 vmstat 或者 sar 观察一下缓存的变化趋势，确认缓存的使用是否还在继续增大。</p>
<p> 如果继续增大，则说明导致缓存升高的进程还在运行，那你就能用缓存 / 缓冲区分析工具（比如 cachetop、slabtop 等），分析这些缓存到底被哪里占用。</p>
</li>
<li><p>当你 free 一下，发现系统可用内存不足时，首先要确认内存是否被缓存 / 缓冲区占用。排除缓存 / 缓冲区后，你可以继续用 pidstat 或者 top，定位占用内存最多的进程。</p>
<p> 找出进程后，再通过进程内存空间工具（比如 pmap），分析进程地址空间中内存的使用情况就可以了。</p>
</li>
<li><p>当你通过 vmstat 或者 sar 发现内存在不断增长后，可以分析中是否存在内存泄漏的问题。</p>
<p> 比如你可以使用内存分配分析工具 memleak ，检查是否存在内存泄漏。如果存在内存泄漏问题，memleak 会为你输出内存泄漏的进程以及调用堆栈。</p>
</li>
</ol>
<p>注意，这个图里我没有列出所有性能工具，只给出了最核心的几个。这么做，一方面，确实不想让大量的工具列表吓到你。</p>
<p>另一方面，希望你能把重心先放在核心工具上，通过我提供的案例和真实环境的实践，掌握使用方法和分析思路。 毕竟熟练掌握它们，你就可以解决大多数的内存问题。</p>
<h4 id="21-5-小结"><a href="#21-5-小结" class="headerlink" title="21.5 小结"></a>21.5 小结</h4><p>找到内存问题的来源后，下一步就是相应的优化工作了。在我看来，内存调优最重要的就是，保证应用程序的热点数据放到内存中，并尽量减少换页和交换。</p>
<p>常见的优化思路有这么几种。</p>
<ol>
<li>最好禁止 Swap。如果必须开启 Swap，降低 swappiness 的值，减少内存回收时 Swap 的使用倾向。</li>
<li>减少内存的动态分配。比如，可以使用内存池、大页（HugePage）等。</li>
<li>尽量使用缓存和缓冲区来访问数据。比如，可以使用堆栈明确声明内存空间，来存储需要缓存的数据；或者用 Redis 这类的外部缓存组件，优化数据的访问。</li>
<li>使用 cgroups 等方式限制进程的内存使用情况。这样，可以确保系统内存不会被异常进程耗尽。</li>
<li>通过 /proc/pid/oom_adj ，调整核心应用的 oom_score。这样，可以保证即使内存紧张，核心应用也不会被 OOM 杀死。</li>
</ol>
<h3 id="22-答疑（三）：文件系统与磁盘的区别是什么？"><a href="#22-答疑（三）：文件系统与磁盘的区别是什么？" class="headerlink" title="22 | 答疑（三）：文件系统与磁盘的区别是什么？"></a>22 | 答疑（三）：文件系统与磁盘的区别是什么？</h3><h4 id="22-1-问题-1：内存回收与-OOM"><a href="#22-1-问题-1：内存回收与-OOM" class="headerlink" title="22.1 问题 1：内存回收与 OOM"></a>22.1 问题 1：内存回收与 OOM</h4><p>虎虎的这个问题，实际上包括四个子问题，即，</p>
<ol>
<li>怎么理解 LRU 内存回收？</li>
<li>回收后的内存又到哪里去了？</li>
<li>OOM 是按照虚拟内存还是实际内存来打分？</li>
<li>怎么估计应用程序的最小内存？</li>
</ol>
<p>一旦发现内存紧张，系统会通过三种方式回收内存。</p>
<ul>
<li>基于 LRU（Least Recently Used）算法，回收缓存；</li>
<li>基于 Swap 机制，回收不常访问的匿名页；</li>
<li>基于 OOM（Out of Memory）机制，杀掉占用大量内存的进程。</li>
</ul>
<p>前两种方式，缓存回收和 Swap 回收，实际上都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中：</p>
<ul>
<li>active 记录活跃的内存页；</li>
<li>inactive 记录非活跃的内存页。</li>
</ul>
<p>越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。</p>
<p>活跃和非活跃的内存页，按照类型的不同，又分别分为文件页和匿名页，对应着缓存回收和 Swap 回收。</p>
<p>当然，你可以从 /proc/meminfo 中，查询它们的大小，比如：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># grep 表示只保留包含 active 的指标（忽略大小写）</span>
<span class="token comment"># sort 表示按照字母顺序排序</span>
$ <span class="token function">cat</span> /proc/meminfo <span class="token operator">|</span> <span class="token function">grep</span> -i active <span class="token operator">|</span> <span class="token function">sort</span>
Active<span class="token punctuation">(</span>anon<span class="token punctuation">)</span>:     <span class="token number">167976</span> kB
Active<span class="token punctuation">(</span>file<span class="token punctuation">)</span>:     <span class="token number">971488</span> kB
Active:          <span class="token number">1139464</span> kB
Inactive<span class="token punctuation">(</span>anon<span class="token punctuation">)</span>:      <span class="token number">720</span> kB
Inactive<span class="token punctuation">(</span>file<span class="token punctuation">)</span>:  <span class="token number">2109536</span> kB
Inactive:        <span class="token number">2110256</span> kB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>第三种方式，OOM 机制按照 oom_score 给进程排序。oom_score 越大，进程就越容易被系统杀死。</p>
<p>当系统发现内存不足以分配新的内存请求时，就会尝试直接内存回收。这种情况下，如果回收完文件页和匿名页后，内存够用了，当然皆大欢喜，把回收回来的内存分配给进程就可以了。但如果内存还是不足，OOM 就要登场了。</p>
<p>OOM 发生时，你可以在 dmesg 中看到 Out of memory 的信息，从而知道是哪些进程被 OOM 杀死了。比如，你可以执行下面的命令，查询 OOM 日志：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">dmesg</span> <span class="token operator">|</span> <span class="token function">grep</span> -i <span class="token string">"Out of memory"</span>
Out of memory: Kill process <span class="token number">9329</span> <span class="token punctuation">(</span>java<span class="token punctuation">)</span> score <span class="token number">321</span> or sacrifice child<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>当然了，如果你不希望应用程序被 OOM 杀死，可以调整进程的 oom_score_adj，减小 OOM 分值，进而降低被杀死的概率。或者，你还可以开启内存的 overcommit，允许进程申请超过物理内存的虚拟内存（这儿实际上假设的是，进程不会用光申请到的虚拟内存）。</p>
<p>这三种方式，我们就复习完了。接下来，我们回到开始的四个问题，相信你自己已经有了答案。</p>
<ol>
<li>LRU 算法的原理刚才已经提到了，这里不再重复。</li>
<li>内存回收后，会被重新放到未使用内存中。这样，新的进程就可以请求、使用它们。</li>
<li>OOM 触发的时机基于虚拟内存。换句话说，进程在申请内存时，如果申请的虚拟内存加上服务器实际已用的内存之和，比总的物理内存还大，就会触发 OOM。</li>
<li>要确定一个进程或者容器的最小内存，最简单的方法就是让它运行起来，再通过 ps 或者 smap ，查看它的内存使用情况。不过要注意，进程刚启动时，可能还没开始处理实际业务，一旦开始处理实际业务，就会占用更多内存。所以，要记得给内存留一定的余量。</li>
</ol>
<h4 id="22-2-问题-2-文件系统与磁盘的区别"><a href="#22-2-问题-2-文件系统与磁盘的区别" class="headerlink" title="22.2 问题 2: 文件系统与磁盘的区别"></a>22.2 问题 2: 文件系统与磁盘的区别</h4><p>在学习 Buffer 和 Cache 的原理时，我曾提到，Buffer 用于磁盘，而 Cache 用于文件。因此，有不少同学困惑了，比如 JJ 留言中的这两个问题。</p>
<ul>
<li>读写文件最终也是读写磁盘，到底要怎么区分，是读写文件还是读写磁盘呢？</li>
<li>读写磁盘难道可以不经过文件系统吗？</li>
</ul>
<p>磁盘是一个存储设备（确切地说是块设备），可以被划分为不同的磁盘分区。而在磁盘或者磁盘分区上，还可以再创建文件系统，并挂载到系统的某个目录中。这样，系统就可以通过这个挂载目录，来读写文件。</p>
<p>换句话说，磁盘是存储数据的块设备，也是文件系统的载体。所以，文件系统确实还是要通过磁盘，来保证数据的持久化存储。</p>
<p>你在很多地方都会看到这句话， Linux 中一切皆文件。换句话说，你可以通过相同的文件接口，来访问磁盘和文件（比如 open、read、write、close 等）。</p>
<ul>
<li>我们通常说的“文件”，其实是指普通文件。</li>
<li>而磁盘或者分区，则是指块设备文件。</li>
</ul>
<p>你可以执行 “ls -l &lt; 路径 &gt;” 查看它们的区别。如果不懂 ls 输出的含义，别忘了 man 一下就可以。执行 man ls 命令，以及 info ‘(coreutils) ls invocation’ 命令，就可以查到了。</p>
<p>在读写普通文件时，I/O 请求会首先经过文件系统，然后由文件系统负责，来与磁盘进行交互。而在读写块设备文件时，会跳过文件系统，直接与磁盘交互，也就是所谓的“裸 I/O”。</p>
<p>这两种读写方式使用的缓存自然不同。文件系统管理的缓存，其实就是 Cache 的一部分。而裸磁盘的缓存，用的正是 Buffer。</p>
<h4 id="22-3-问题-3-如何统计所有进程的物理内存使用量"><a href="#22-3-问题-3-如何统计所有进程的物理内存使用量" class="headerlink" title="22.3 问题 3: 如何统计所有进程的物理内存使用量"></a>22.3 问题 3: 如何统计所有进程的物理内存使用量</h4><p>把所有进程的 RSS 全部累加这种方法，实际上导致不少地方会被重复计算。RSS 表示常驻内存，把进程用到的共享内存也算了进去。所以，直接累加会导致共享内存被重复计算，不能得到准确的答案。</p>
<p>可以通过 stackexchange 上的<a target="_blank" rel="noopener" href="https://unix.stackexchange.com/questions/33381/getting-information-about-a-process-memory-usage-from-proc-pid-smaps">链接</a>找到答案，不过，我还是更推荐，直接查 proc 文件系统的文档：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">The “proportional set size” (PSS) of a process is the count of pages it has in memory, where each page is divided by the number of processes sharing it. So if a process has 1000 pages all to itself, and 1000 shared with one other process, its PSS will be 1500.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>解释一下，每个进程的 PSS ，是指把共享内存平分到各个进程后，再加上进程本身的非共享内存大小的和。</p>
<p>就像文档中的这个例子，一个进程的非共享内存为 1000 页，它和另一个进程的共享进程也是 1000 页，那么它的 PSS=1000/2+1000=1500 页。</p>
<p>这样，你就可以直接累加 PSS ，不用担心共享内存重复计算的问题了。</p>
<p>比如，你可以运行下面的命令来计算：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 使用 grep 查找 Pss 指标后，再用 awk 计算累加值</span>
$ <span class="token function">grep</span> Pss /proc/<span class="token punctuation">[</span><span class="token number">1</span>-9<span class="token punctuation">]</span>*/smaps <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'{total+=<span class="token variable">$2</span>}; END {printf "%d kB<span class="token entity" title="\n">\n</span>", total }'</span>
<span class="token number">391266</span> kB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h4 id="22-4-问题-4-CentOS-系统中如何安装-bcc-tools"><a href="#22-4-问题-4-CentOS-系统中如何安装-bcc-tools" class="headerlink" title="22.4 问题 4: CentOS 系统中如何安装 bcc-tools"></a>22.4 问题 4: CentOS 系统中如何安装 bcc-tools</h4><p>以 CentOS 7 为例，整个安装主要可以分两步。</p>
<p>第一步，升级内核。你可以运行下面的命令来操作：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 升级系统</span>
yum update -y

<span class="token comment"># 安装 ELRepo</span>
<span class="token function">rpm</span> --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org
<span class="token function">rpm</span> -Uvh https://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm

<span class="token comment"># 安装新内核</span>
yum remove -y kernel-headers kernel-tools kernel-tools-libs
yum --enablerepo<span class="token operator">=</span><span class="token string">"elrepo-kernel"</span> <span class="token function">install</span> -y kernel-ml kernel-ml-devel kernel-ml-headers kernel-ml-tools kernel-ml-tools-libs kernel-ml-tools-libs-devel

<span class="token comment"># 更新 Grub 后重启</span>
grub2-mkconfig -o /boot/grub2/grub.cfg
grub2-set-default <span class="token number">0</span>
<span class="token function">reboot</span>

<span class="token comment"># 重启后确认内核版本已升级为 4.20.0-1.el7.elrepo.x86_64</span>
<span class="token function">uname</span> -r<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>第二步，安装 bcc-tools：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 安装 bcc-tools</span>
yum <span class="token function">install</span> -y bcc-tools

<span class="token comment"># 配置 PATH 路径</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span>:/usr/share/bcc/tools

<span class="token comment"># 验证安装成功</span>
cachestat<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="22-5-问题-5-内存泄漏案例的优化方法"><a href="#22-5-问题-5-内存泄漏案例的优化方法" class="headerlink" title="22.5 问题 5: 内存泄漏案例的优化方法"></a>22.5 问题 5: 内存泄漏案例的优化方法</h4><p>这是我在 <a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/75670">内存泄漏了，我该如何定位和处理</a> 中留的一个思考题。这个问题是这样的：</p>
<p>在内存泄漏案例的最后，我们通过增加 free() 调用，释放了函数 fibonacci() 分配的内存，修复了内存泄漏的问题。就这个案例而言，还有没有其他更好的修复方法呢？</p>
<p>很多同学留言写下了自己的想法，都很不错。这里，我重点表扬下郭江伟同学，他给出的方法非常好：</p>
<p>他的思路是不用动态内存分配的方法，而是用数组来暂存计算结果。这样就可以由系统自动管理这些栈内存，也不存在内存泄漏的问题了。</p>
<p>这种减少动态内存分配的思路，除了可以解决内存泄漏问题，其实也是常用的内存优化方法。比如，在需要大量内存的场景中，你就可以考虑用栈内存、内存池、HugePage 等方法，来优化内存的分配和管理。</p>
<h2 id="04-I-O-性能篇"><a href="#04-I-O-性能篇" class="headerlink" title="04-I-O 性能篇"></a><strong>04-I-O 性能篇</strong></h2><h3 id="23-基础篇：Linux-文件系统是怎么工作的？"><a href="#23-基础篇：Linux-文件系统是怎么工作的？" class="headerlink" title="23 | 基础篇：Linux 文件系统是怎么工作的？"></a>23 | 基础篇：Linux 文件系统是怎么工作的？</h3><h4 id="23-1-索引节点和目录项"><a href="#23-1-索引节点和目录项" class="headerlink" title="23.1 索引节点和目录项"></a>23.1 索引节点和目录项</h4><p>文件系统，本身是对存储设备上的文件，进行组织管理的机制。组织方式不同，就会形成不同的文件系统。</p>
<p>你要记住最重要的一点，在 Linux 中一切皆文件。不仅普通的文件和目录，就连块设备、套接字、管道等，也都要通过统一的文件系统来管理。</p>
<p>为了方便管理，Linux 文件系统为每个文件都分配两个数据结构，索引节点（index node）和目录项（directory entry）。它们主要用来记录文件的元信息和目录结构。</p>
<ul>
<li>索引节点，简称为 inode，用来记录文件的元数据，比如 inode 编号、文件大小、访问权限、修改日期、数据的位置等。索引节点和文件一一对应，它跟文件内容一样，都会被持久化存储到磁盘中。所以记住，索引节点同样占用磁盘空间。</li>
<li>目录项，简称为 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的关联关系。多个关联的目录项，就构成了文件系统的目录结构。不过，不同于索引节点，目录项是由内核维护的一个内存数据结构，所以通常也被叫做目录项缓存。</li>
</ul>
<p>换句话说，索引节点是每个文件的唯一标志，而目录项维护的正是文件系统的树状结构。目录项和索引节点的关系是多对一，你可以简单理解为，一个文件可以有多个别名。</p>
<p>举个例子，通过硬链接为文件创建的别名，就会对应不同的目录项，不过这些目录项本质上还是链接同一个文件，所以，它们的索引节点相同。</p>
<p>索引节点和目录项纪录了文件的元数据，以及文件间的目录关系，那么具体来说，文件数据到底是怎么存储的呢？是不是直接写到磁盘中就好了呢？</p>
<p>实际上，磁盘读写的最小单位是扇区，然而扇区只有 512B 大小，如果每次都读写这么小的单位，效率一定很低。所以，文件系统又把连续的扇区组成了逻辑块，然后每次都以逻辑块为最小单元，来管理数据。常见的逻辑块大小为 4KB，也就是由连续的 8 个扇区组成。</p>
<p>为了帮助你理解目录项、索引节点以及文件数据的关系，我画了一张示意图。你可以对照着这张图，来回忆刚刚讲过的内容，把知识和细节串联起来。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/目录项、索引节点以及文件数据的关系.png" alt="目录项、索引节点以及文件数据的关系"></p>
<p>不过，这里有两点需要你注意。</p>
<ol>
<li><p>第一，目录项本身就是一个内存缓存，而索引节点则是存储在磁盘中的数据。在前面的 Buffer 和 Cache 原理中，我曾经提到过，为了协调慢速磁盘与快速 CPU 的性能差异，文件内容会缓存到页缓存 Cache 中。</p>
<p> 那么，你应该想到，这些索引节点自然也会缓存到内存中，加速文件的访问。</p>
</li>
<li><p>第二，磁盘在执行文件系统格式化时，会被分成三个存储区域，超级块、索引节点区和数据块区。其中，</p>
<ul>
<li>超级块，存储整个文件系统的状态。</li>
<li>索引节点区，用来存储索引节点。</li>
<li>数据块区，则用来存储文件数据。</li>
</ul>
</li>
</ol>
<h4 id="23-2-虚拟文件系统"><a href="#23-2-虚拟文件系统" class="headerlink" title="23.2 虚拟文件系统"></a>23.2 虚拟文件系统</h4><p>目录项、索引节点、逻辑块以及超级块，构成了 Linux 文件系统的四大基本要素。不过，为了支持各种不同的文件系统，Linux 内核在用户进程和文件系统的中间，又引入了一个抽象层，也就是虚拟文件系统 VFS（Virtual File System）。</p>
<p>VFS 定义了一组所有文件系统都支持的数据结构和标准接口。这样，用户进程和内核中的其他子系统，只需要跟 VFS 提供的统一接口进行交互就可以了，而不需要再关心底层各种文件系统的实现细节。</p>
<p>这里，我画了一张 Linux 文件系统的架构图，帮你更好地理解系统调用、VFS、缓存、文件系统以及块存储之间的关系。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/Linux文件系统的架构图.png" alt="Linux文件系统的架构图"></p>
<p>通过这张图，你可以看到，在 VFS 的下方，Linux 支持各种各样的文件系统，如 Ext4、XFS、NFS 等等。按照存储位置的不同，这些文件系统可以分为三类。</p>
<ol>
<li>第一类是基于磁盘的文件系统，也就是把数据直接存储在计算机本地挂载的磁盘中。常见的 Ext4、XFS、OverlayFS 等，都是这类文件系统。</li>
<li>第二类是基于内存的文件系统，也就是我们常说的虚拟文件系统。这类文件系统，不需要任何磁盘分配存储空间，但会占用内存。我们经常用到的 /proc 文件系统，其实就是一种最常见的虚拟文件系统。此外，/sys 文件系统也属于这一类，主要向用户空间导出层次化的内核对象。</li>
<li>第三类是网络文件系统，也就是用来访问其他计算机数据的文件系统，比如 NFS、SMB、iSCSI 等。</li>
</ol>
<p>这些文件系统，要先挂载到 VFS 目录树中的某个子目录（称为挂载点），然后才能访问其中的文件。拿第一类，也就是基于磁盘的文件系统为例，在安装系统时，要先挂载一个根目录（/），在根目录下再把其他文件系统（比如其他的磁盘分区、/proc 文件系统、/sys 文件系统、NFS 等）挂载进来。</p>
<h4 id="23-3-文件系统-I-O"><a href="#23-3-文件系统-I-O" class="headerlink" title="23.3 文件系统 I/O"></a>23.3 文件系统 I/O</h4><p>把文件系统挂载到挂载点后，你就能通过挂载点，再去访问它管理的文件了。VFS 提供了一组标准的文件访问接口。这些接口以系统调用的方式，提供给应用程序使用。</p>
<p>就拿 cat 命令来说，它首先调用 open() ，打开一个文件；然后调用 read() ，读取文件的内容；最后再调用 write() ，把文件内容输出到控制台的标准输出中：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">int open<span class="token punctuation">(</span>const char *pathname, int flags, mode_t mode<span class="token punctuation">)</span><span class="token punctuation">;</span>
ssize_t read<span class="token punctuation">(</span>int fd, void *buf, size_t count<span class="token punctuation">)</span><span class="token punctuation">;</span>
ssize_t write<span class="token punctuation">(</span>int fd, const void *buf, size_t count<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>文件读写方式的各种差异，导致 I/O 的分类多种多样。最常见的有，缓冲与非缓冲 I/O、直接与非直接 I/O、阻塞与非阻塞 I/O、同步与异步 I/O 等。 接下来，我们就详细看这四种分类。</p>
<ol>
<li><p>第一种，根据是否利用标准库缓存，可以把文件 I/O 分为缓冲 I/O 与非缓冲 I/O。</p>
<ul>
<li>缓冲 I/O，是指利用标准库缓存来加速文件的访问，而标准库内部再通过系统调度访问文件。</li>
<li><p>非缓冲 I/O，是指直接通过系统调用来访问文件，不再经过标准库缓存。</p>
<p>注意，这里所说的“缓冲”，是指标准库内部实现的缓存。比方说，你可能见到过，很多程序遇到换行时才真正输出，而换行前的内容，其实就是被标准库暂时缓存了起来。</p>
<p>无论缓冲 I/O 还是非缓冲 I/O，它们最终还是要经过系统调用来访问文件。而根据上一节内容，我们知道，系统调用后，还会通过页缓存，来减少磁盘的 I/O 操作。</p>
</li>
</ul>
</li>
<li><p>第二，根据是否利用操作系统的页缓存，可以把文件 I/O 分为直接 I/O 与非直接 I/O。</p>
<ul>
<li>直接 I/O，是指跳过操作系统的页缓存，直接跟文件系统交互来访问文件。</li>
<li><p>非直接 I/O 正好相反，文件读写时，先要经过系统的页缓存，然后再由内核或额外的系统调用，真正写入磁盘。</p>
<p>想要实现直接 I/O，需要你在系统调用中，指定 O_DIRECT 标志。如果没有设置过，默认的是非直接 I/O。</p>
<p>不过要注意，直接 I/O、非直接 I/O，本质上还是和文件系统交互。如果是在数据库等场景中，你还会看到，跳过文件系统读写磁盘的情况，也就是我们通常所说的裸 I/O。</p>
</li>
</ul>
</li>
<li><p>第三，根据应用程序是否阻塞自身运行，可以把文件 I/O 分为阻塞 I/O 和非阻塞 I/O：</p>
<ul>
<li>所谓阻塞 I/O，是指应用程序执行 I/O 操作后，如果没有获得响应，就会阻塞当前线程，自然就不能执行其他任务。</li>
<li><p>所谓非阻塞 I/O，是指应用程序执行 I/O 操作后，不会阻塞当前的线程，可以继续执行其他的任务，随后再通过轮询或者事件通知的形式，获取调用的结果。</p>
<p>比方说，访问管道或者网络套接字时，设置 O_NONBLOCK 标志，就表示用非阻塞方式访问；而如果不做任何设置，默认的就是阻塞访问。</p>
</li>
</ul>
</li>
<li><p>第四，根据是否等待响应结果，可以把文件 I/O 分为同步和异步 I/O：</p>
<ul>
<li>所谓同步 I/O，是指应用程序执行 I/O 操作后，要一直等到整个 I/O 完成后，才能获得 I/O 响应。</li>
<li><p>所谓异步 I/O，是指应用程序执行 I/O 操作后，不用等待完成和完成后的响应，而是继续执行就可以。等到这次 I/O 完成后，响应会用事件通知的方式，告诉应用程序。</p>
<p>举个例子，在操作文件时，如果你设置了 O_SYNC 或者 O_DSYNC 标志，就代表同步 I/O。如果设置了 O_DSYNC，就要等文件数据写入磁盘后，才能返回；而 O_SYNC，则是在 O_DSYNC 基础上，要求文件元数据也要写入磁盘后，才能返回。</p>
<p>再比如，在访问管道或者网络套接字时，设置了 O_ASYNC 选项后，相应的 I/O 就是异步 I/O。这样，内核会再通过 SIGIO 或者 SIGPOLL，来通知进程文件是否可读写。</p>
</li>
</ul>
</li>
</ol>
<p>你也应该可以理解，“Linux 一切皆文件”的深刻含义。无论是普通文件和块设备、还是网络套接字和管道等，它们都通过统一的 VFS 接口来访问。</p>
<h4 id="23-4-性能观测"><a href="#23-4-性能观测" class="headerlink" title="23.4 性能观测"></a>23.4 性能观测</h4><p>观察一下文件系统的性能情况。</p>
<ol>
<li><p>容量。</p>
<p> 对文件系统来说，最常见的一个问题就是空间不足。当然，你可能本身就知道，用 df 命令，就能查看文件系统的磁盘空间使用情况。比如：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">df</span> /dev/sda1
Filesystem     1K-blocks    Used Available Use% Mounted on
/dev/sda1       <span class="token number">30308240</span> <span class="token number">3167020</span>  <span class="token number">27124836</span>  <span class="token number">11</span>% /<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 你可以看到，我的根文件系统只使用了 11% 的空间。这里还要注意，总空间用 1K-blocks 的数量来表示，你可以给 df 加上 -h 选项，以获得更好的可读性：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">df</span> -h /dev/sda1
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda1        29G  <span class="token number">3</span>.1G   26G  <span class="token number">11</span>% /<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 不过有时候，明明你碰到了空间不足的问题，可是用 df 查看磁盘空间后，却发现剩余空间还有很多。这是怎么回事呢？</p>
<p> 不知道你还记不记得，刚才我强调的一个细节。除了文件数据，索引节点也占用磁盘空间。你可以给 df 命令加上 -i 参数，查看索引节点的使用情况，如下所示：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">df</span> -i /dev/sda1
Filesystem      Inodes  IUsed   IFree IUse% Mounted on
/dev/sda1      <span class="token number">3870720</span> <span class="token number">157460</span> <span class="token number">3713260</span>    <span class="token number">5</span>% /<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 索引节点的容量，（也就是 Inode 个数）是在格式化磁盘时设定好的，一般由格式化工具自动生成。当你发现索引节点空间不足，但磁盘空间充足时，很可能就是过多小文件导致的。</p>
<p> 所以，一般来说，删除这些小文件，或者把它们移动到索引节点充足的其他磁盘中，就可以解决这个问题。</p>
</li>
<li><p>缓存</p>
<p> free 输出的 Cache，是页缓存和可回收 Slab 缓存的和，你可以从 /proc/meminfo ，直接得到它们的大小：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">cat</span> /proc/meminfo <span class="token operator">|</span> <span class="token function">grep</span> -E <span class="token string">"SReclaimable|Cached"</span>
Cached:           <span class="token number">748316</span> kB
SwapCached:            <span class="token number">0</span> kB
SReclaimable:     <span class="token number">179508</span> kB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 话说回来，文件系统中的目录项和索引节点缓存，又该如何观察呢？</p>
<p> 实际上，内核使用 Slab 机制，管理目录项和索引节点的缓存。/proc/meminfo 只给出了 Slab 的整体大小，具体到每一种 Slab 缓存，还要查看 /proc/slabinfo 这个文件。</p>
<p> 比如，运行下面的命令，你就可以得到，所有目录项和各种文件系统索引节点的缓存情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">cat</span> /proc/slabinfo <span class="token operator">|</span> <span class="token function">grep</span> -E <span class="token string">'^#|dentry|inode'</span>
<span class="token comment"># name            &lt;active_objs&gt; &lt;num_objs&gt; &lt;objsize&gt; &lt;objperslab&gt; &lt;pagesperslab&gt; : tunables &lt;limit&gt; &lt;batchcount&gt; &lt;sharedfactor&gt; : slabdata &lt;active_slabs&gt; &lt;num_slabs&gt;     &lt;sharedavail&gt;</span>
xfs_inode              <span class="token number">0</span>      <span class="token number">0</span>    <span class="token number">960</span>   <span class="token number">17</span>    <span class="token number">4</span> <span class="token builtin class-name">:</span> tunables    <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token builtin class-name">:</span> slabdata      <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span>
<span class="token punctuation">..</span>.
ext4_inode_cache   <span class="token number">32104</span>  <span class="token number">34590</span>   <span class="token number">1088</span>   <span class="token number">15</span>    <span class="token number">4</span> <span class="token builtin class-name">:</span> tunables    <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token builtin class-name">:</span> slabdata   <span class="token number">2306</span>   <span class="token number">2306</span>      0hugetlbfs_inode_cache     <span class="token number">13</span>     <span class="token number">13</span>    <span class="token number">624</span>   <span class="token number">13</span>    <span class="token number">2</span> <span class="token builtin class-name">:</span> tunables        <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token builtin class-name">:</span> slabdata      <span class="token number">1</span>      <span class="token number">1</span>      <span class="token number">0</span>
sock_inode_cache    <span class="token number">1190</span>   <span class="token number">1242</span>    <span class="token number">704</span>   <span class="token number">23</span>    <span class="token number">4</span> <span class="token builtin class-name">:</span> tunables    <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token builtin class-name">:</span> slabdata     <span class="token number">54</span>     <span class="token number">54</span>      <span class="token number">0</span>
shmem_inode_cache   <span class="token number">1622</span>   <span class="token number">2139</span>    <span class="token number">712</span>   <span class="token number">23</span>    <span class="token number">4</span> <span class="token builtin class-name">:</span> tunables    <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token builtin class-name">:</span> slabdata     <span class="token number">93</span>     <span class="token number">93</span>      <span class="token number">0</span>
proc_inode_cache    <span class="token number">3560</span>   <span class="token number">4080</span>    <span class="token number">680</span>   <span class="token number">12</span>    <span class="token number">2</span> <span class="token builtin class-name">:</span> tunables    <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token builtin class-name">:</span> slabdata    <span class="token number">340</span>    <span class="token number">340</span>      <span class="token number">0</span>
inode_cache        <span class="token number">25172</span>  <span class="token number">25818</span>    <span class="token number">608</span>   <span class="token number">13</span>    <span class="token number">2</span> <span class="token builtin class-name">:</span> tunables    <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token builtin class-name">:</span> slabdata   <span class="token number">1986</span>   <span class="token number">1986</span>      <span class="token number">0</span>
dentry             <span class="token number">76050</span> <span class="token number">121296</span>    <span class="token number">192</span>   <span class="token number">21</span>    <span class="token number">1</span> <span class="token builtin class-name">:</span> tunables    <span class="token number">0</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token builtin class-name">:</span> slabdata   <span class="token number">5776</span>   <span class="token number">5776</span>      <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 这个界面中，dentry 行表示目录项缓存，inode_cache 行，表示 VFS 索引节点缓存，其余的则是各种文件系统的索引节点缓存。</p>
<p> /proc/slabinfo 的列比较多，具体含义你可以查询 man slabinfo。在实际性能分析中，我们更常使用 slabtop ，来找到占用内存最多的缓存类型。</p>
<p> 比如，下面就是我运行 slabtop 得到的结果：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 按下 c 按照缓存大小排序，按下 a 按照活跃对象数排序</span>
$ slabtop
Active / Total Objects <span class="token punctuation">(</span>% used<span class="token punctuation">)</span>    <span class="token builtin class-name">:</span> <span class="token number">277970</span> / <span class="token number">358914</span> <span class="token punctuation">(</span><span class="token number">77.4</span>%<span class="token punctuation">)</span>
Active / Total Slabs <span class="token punctuation">(</span>% used<span class="token punctuation">)</span>      <span class="token builtin class-name">:</span> <span class="token number">12414</span> / <span class="token number">12414</span> <span class="token punctuation">(</span><span class="token number">100.0</span>%<span class="token punctuation">)</span>
Active / Total Caches <span class="token punctuation">(</span>% used<span class="token punctuation">)</span>     <span class="token builtin class-name">:</span> <span class="token number">83</span> / <span class="token number">135</span> <span class="token punctuation">(</span><span class="token number">61.5</span>%<span class="token punctuation">)</span>
Active / Total Size <span class="token punctuation">(</span>% used<span class="token punctuation">)</span>       <span class="token builtin class-name">:</span> <span class="token number">57816</span>.88K / <span class="token number">73307</span>.70K <span class="token punctuation">(</span><span class="token number">78.9</span>%<span class="token punctuation">)</span>
Minimum / Average / Maximum Object <span class="token builtin class-name">:</span> <span class="token number">0</span>.01K / <span class="token number">0</span>.20K / <span class="token number">22</span>.88K

 OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ/SLAB CACHE SIZE NAME
<span class="token number">69804</span>  <span class="token number">23094</span>   <span class="token number">0</span>%    <span class="token number">0</span>.19K   <span class="token number">3324</span>       <span class="token number">21</span>     13296K dentry
<span class="token number">16380</span>  <span class="token number">15854</span>   <span class="token number">0</span>%    <span class="token number">0</span>.59K   <span class="token number">1260</span>       <span class="token number">13</span>     10080K inode_cache
<span class="token number">58260</span>  <span class="token number">55397</span>   <span class="token number">0</span>%    <span class="token number">0</span>.13K   <span class="token number">1942</span>       <span class="token number">30</span>      7768K kernfs_node_cache
  <span class="token number">485</span>    <span class="token number">413</span>   <span class="token number">0</span>%    <span class="token number">5</span>.69K     <span class="token number">97</span>        <span class="token number">5</span>      3104K task_struct
 <span class="token number">1472</span>   <span class="token number">1397</span>   <span class="token number">0</span>%    <span class="token number">2</span>.00K     <span class="token number">92</span>       <span class="token number">16</span>      2944K kmalloc-2048<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从这个结果你可以看到，在我的系统中，目录项和索引节点占用了最多的 Slab 缓存。不过它们占用的内存其实并不大，加起来也只有 23MB 左右。</p>
</li>
</ol>
<h3 id="24-基础篇：Linux-磁盘I-O是怎么工作的（上）"><a href="#24-基础篇：Linux-磁盘I-O是怎么工作的（上）" class="headerlink" title="24 | 基础篇：Linux 磁盘I/O是怎么工作的（上）"></a>24 | 基础篇：Linux 磁盘I/O是怎么工作的（上）</h3><p>回顾一下，文件系统是对存储设备上的文件，进行组织管理的一种机制。而 Linux 在各种文件系统实现上，又抽象了一层虚拟文件系统 VFS，它定义了一组，所有文件系统都支持的，数据结构和标准接口。</p>
<p>这样，对应用程序来说，只需要跟 VFS 提供的统一接口交互，而不需要关注文件系统的具体实现；对具体的文件系统来说，只需要按照 VFS 的标准，就可以无缝支持各种应用程序。</p>
<p>VFS 内部又通过目录项、索引节点、逻辑块以及超级块等数据结构，来管理文件。</p>
<ul>
<li>目录项，记录了文件的名字，以及文件与其他目录项之间的目录关系。</li>
<li>索引节点，记录了文件的元数据。</li>
<li>逻辑块，是由连续磁盘扇区构成的最小读写单元，用来存储文件数据。</li>
<li>超级块，用来记录文件系统整体的状态，如索引节点和逻辑块的使用情况等。</li>
</ul>
<p>其中，目录项是一个内存缓存；而超级块、索引节点和逻辑块，都是存储在磁盘中的持久化数据。</p>
<p>接下来，我就带你一起看看， Linux 磁盘 I/O 的工作原理。</p>
<h4 id="24-1-磁盘"><a href="#24-1-磁盘" class="headerlink" title="24.1 磁盘"></a>24.1 磁盘</h4><p>磁盘是可以持久化存储的设备，根据存储介质的不同，常见磁盘可以分为两类：机械磁盘和固态磁盘。</p>
<p>第一类，机械磁盘，也称为硬盘驱动器（Hard Disk Driver），通常缩写为 HDD。机械磁盘主要由盘片和读写磁头组成，数据就存储在盘片的环状磁道中。在读写数据前，需要移动读写磁头，定位到数据所在的磁道，然后才能访问数据。</p>
<p>显然，如果 I/O 请求刚好连续，那就不需要磁道寻址，自然可以获得最佳性能。这其实就是我们熟悉的，连续 I/O 的工作原理。与之相对应的，当然就是随机 I/O，它需要不停地移动磁头，来定位数据位置，所以读写速度就会比较慢。</p>
<p>第二类，固态磁盘（Solid State Disk），通常缩写为 SSD，由固态电子元器件组成。固态磁盘不需要磁道寻址，所以，不管是连续 I/O，还是随机 I/O 的性能，都比机械磁盘要好得多。</p>
<p>其实，无论机械磁盘，还是固态磁盘，相同磁盘的随机 I/O 都要比连续 I/O 慢很多，原因也很明显。</p>
<ul>
<li>对机械磁盘来说，我们刚刚提到过的，由于随机 I/O 需要更多的磁头寻道和盘片旋转，它的性能自然要比连续 I/O 慢。</li>
<li>而对固态磁盘来说，虽然它的随机性能比机械硬盘好很多，但同样存在“先擦除再写入”的限制。随机读写会导致大量的垃圾回收，所以相对应的，随机 I/O 的性能比起连续 I/O 来，也还是差了很多。</li>
<li>此外，连续 I/O 还可以通过预读的方式，来减少 I/O 请求的次数，这也是其性能优异的一个原因。很多性能优化的方案，也都会从这个角度出发，来优化 I/O 性能。</li>
</ul>
<p>此外，机械磁盘和固态磁盘还分别有一个最小的读写单位。</p>
<ul>
<li>机械磁盘的最小读写单位是扇区，一般大小为 512 字节。</li>
<li>而固态磁盘的最小读写单位是页，通常大小是 4KB、8KB 等。</li>
</ul>
<p>在上一节中，我也提到过，如果每次都读写 512 字节这么小的单位的话，效率很低。所以，文件系统会把连续的扇区或页，组成逻辑块，然后以逻辑块作为最小单元来管理数据。常见的逻辑块的大小是 4KB，也就是说，连续 8 个扇区，或者单独的一个页，都可以组成一个逻辑块。</p>
<p>除了可以按照存储介质来分类，另一个常见的分类方法，是按照接口来分类，比如可以把硬盘分为 IDE（Integrated Drive Electronics）、SCSI（Small Computer System Interface） 、SAS（Serial Attached SCSI） 、SATA（Serial ATA） 、FC（Fibre Channel） 等。</p>
<p>不同的接口，往往分配不同的设备名称。比如， IDE 设备会分配一个 hd 前缀的设备名，SCSI 和 SATA 设备会分配一个 sd 前缀的设备名。如果是多块同类型的磁盘，就会按照 a、b、c 等的字母顺序来编号。</p>
<p>除了磁盘本身的分类外，当你把磁盘接入服务器后，按照不同的使用方式，又可以把它们划分为多种不同的架构。</p>
<p>最简单的，就是直接作为独立磁盘设备来使用。这些磁盘，往往还会根据需要，划分为不同的逻辑分区，每个分区再用数字编号。比如我们前面多次用到的 /dev/sda ，还可以分成两个分区 /dev/sda1 和 /dev/sda2。</p>
<p>另一个比较常用的架构，是把多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列，也就是 RAID（Redundant Array of Independent Disks），从而可以提高数据访问的性能，并且增强数据存储的可靠性。</p>
<p>根据容量、性能和可靠性需求的不同，RAID 一般可以划分为多个级别，如 RAID0、RAID1、RAID5、RAID10 等。</p>
<ul>
<li>RAID0 有最优的读写性能，但不提供数据冗余的功能。</li>
<li>而其他级别的 RAID，在提供数据冗余的基础上，对读写性能也有一定程度的优化。</li>
</ul>
<p>最后一种架构，是把这些磁盘组合成一个网络存储集群，再通过 NFS、SMB、iSCSI 等网络存储协议，暴露给服务器使用。</p>
<p>其实在 Linux 中，<strong>磁盘实际上是作为一个块设备来管理的</strong>，也就是以块为单位读写数据，并且支持随机读写。每个块设备都会被赋予两个设备号，分别是主、次设备号。主设备号用在驱动程序中，用来区分设备类型；而次设备号则是用来给多个同类设备编号。</p>
<h4 id="24-2-通用块层"><a href="#24-2-通用块层" class="headerlink" title="24.2 通用块层"></a>24.2 通用块层</h4><p>跟我们上一节讲到的虚拟文件系统 VFS 类似，为了减小不同块设备的差异带来的影响，Linux 通过一个统一的通用块层，来管理各种不同的块设备。</p>
<p>通用块层，其实是处在文件系统和磁盘驱动中间的一个块设备抽象层。它主要有两个功能 。</p>
<ol>
<li>第一个功能跟虚拟文件系统的功能类似。向上，为文件系统和应用程序，提供访问块设备的标准接口；向下，把各种异构的磁盘设备抽象为统一的块设备，并提供统一框架来管理这些设备的驱动程序。</li>
<li>第二个功能，通用块层还会给文件系统和应用程序发来的 I/O 请求排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率。</li>
</ol>
<p>其中，对 I/O 请求排序的过程，也就是我们熟悉的 I/O 调度。事实上，Linux 内核支持四种 I/O 调度算法，分别是 NONE、NOOP、CFQ 以及 DeadLine。这里我也分别介绍一下。</p>
<ol>
<li><p>第一种 NONE ，更确切来说，并不能算 I/O 调度算法。因为它完全不使用任何 I/O 调度器，对文件系统和应用程序的 I/O 其实不做任何处理，常用在虚拟机中（此时磁盘 I/O 调度完全由物理机负责）。</p>
</li>
<li><p>第二种 NOOP ，是最简单的一种 I/O 调度算法。它实际上是一个先入先出的队列，只做一些最基本的请求合并，常用于 SSD 磁盘。</p>
</li>
<li><p>第三种 CFQ（Completely Fair Scheduler），也被称为完全公平调度器，是现在很多发行版的默认 I/O 调度器，它为每个进程维护了一个 I/O 调度队列，并按照时间片来均匀分布每个进程的 I/O 请求。</p>
<p> 类似于进程 CPU 调度，CFQ 还支持进程 I/O 的优先级调度，所以它适用于运行大量进程的系统，像是桌面环境、多媒体应用等。</p>
</li>
<li><p>最后一种 DeadLine 调度算法，分别为读、写请求创建了不同的 I/O 队列，可以提高机械磁盘的吞吐量，并确保达到最终期限（deadline）的请求被优先处理。DeadLine 调度算法，多用在 I/O 压力比较重的场景，比如数据库等。</p>
</li>
</ol>
<h4 id="24-3-I-O-栈"><a href="#24-3-I-O-栈" class="headerlink" title="24.3. I/O 栈"></a>24.3. I/O 栈</h4><p>可以把 Linux 存储系统的 I/O 栈，由上到下分为三个层次，分别是文件系统层、通用块层和设备层。这三个 I/O 层的关系如下图所示，这其实也是 Linux 存储系统的 I/O 栈全景图。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/Linux存储系统的IO栈全景图.png" alt="Linux存储系统的IO栈全景图.png"></p>
<blockquote>
<p>图片来源：<a target="_blank" rel="noopener" href="https://www.thomas-krenn.com/en/wiki/Linux_Storage_Stack_Diagram">Linux Storage Stack Diagram</a></p>
</blockquote>
<p>根据这张 I/O 栈的全景图，我们可以更清楚地理解，存储系统 I/O 的工作原理。</p>
<ol>
<li>文件系统层，包括虚拟文件系统和其他各种文件系统的具体实现。它为上层的应用程序，提供标准的文件访问接口；对下会通过通用块层，来存储和管理磁盘数据。</li>
<li>通用块层，包括块设备 I/O 队列和 I/O 调度器。它会对文件系统的 I/O 请求进行排队，再通过重新排序和请求合并，然后才要发送给下一级的设备层。</li>
<li>设备层，包括存储设备和相应的驱动程序，负责最终物理设备的 I/O 操作。</li>
</ol>
<p>存储系统的 I/O ，通常是整个系统中最慢的一环。所以， Linux 通过多种缓存机制来优化 I/O 效率。</p>
<p>比方说，为了优化文件访问的性能，会使用页缓存、索引节点缓存、目录项缓存等多种缓存机制，以减少对下层块设备的直接调用。</p>
<p>同样，为了优化块设备的访问效率，会使用缓冲区，来缓存块设备的数据。</p>
<h4 id="24-4-小结"><a href="#24-4-小结" class="headerlink" title="24.4 小结"></a>24.4 小结</h4><p>通用块层是 Linux 磁盘 I/O 的核心。向上，它为文件系统和应用程序，提供访问了块设备的标准接口；向下，把各种异构的磁盘设备，抽象为统一的块设备，并会对文件系统和应用程序发来的 I/O 请求进行重新排序、请求合并等，提高了磁盘访问的效率。</p>
<h3 id="25-基础篇：Linux-磁盘I-O是怎么工作的（下）"><a href="#25-基础篇：Linux-磁盘I-O是怎么工作的（下）" class="headerlink" title="25 | 基础篇：Linux 磁盘I/O是怎么工作的（下）"></a>25 | 基础篇：Linux 磁盘I/O是怎么工作的（下）</h3><h4 id="25-1-磁盘性能指标"><a href="#25-1-磁盘性能指标" class="headerlink" title="25.1 磁盘性能指标"></a>25.1 磁盘性能指标</h4><p>说到磁盘性能的衡量标准，必须要提到五个常见指标，也就是我们经常用到的，使用率、饱和度、IOPS、吞吐量以及响应时间等。这五个指标，是衡量磁盘性能的基本指标。</p>
<ul>
<li>使用率，是指磁盘处理 I/O 的时间百分比。过高的使用率（比如超过 80%），通常意味着磁盘 I/O 存在性能瓶颈。</li>
<li>饱和度，是指磁盘处理 I/O 的繁忙程度。过高的饱和度，意味着磁盘存在严重的性能瓶颈。当饱和度为 100% 时，磁盘无法接受新的 I/O 请求。</li>
<li>IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。</li>
<li>吞吐量，是指每秒的 I/O 请求大小。</li>
<li>响应时间，是指 I/O 请求从发出到收到响应的间隔时间。</li>
</ul>
<p>这里要注意的是，使用率只考虑有没有 I/O，而不考虑 I/O 的大小。换句话说，当使用率是 100% 的时候，磁盘依然有可能接受新的 I/O 请求。</p>
<p>这些指标，很可能是你经常挂在嘴边的，一讨论磁盘性能必定提起的对象。不过我还是要强调一点，不要孤立地去比较某一指标，而要结合读写比例、I/O 类型（随机还是连续）以及 I/O 的大小，综合来分析。</p>
<p>举个例子，在数据库、大量小文件等这类随机读写比较多的场景中，IOPS 更能反映系统的整体性能；而在多媒体等顺序读写较多的场景中，吞吐量才更能反映系统的整体性能。</p>
<p>一般来说，我们在为应用程序的服务器选型时，要先对磁盘的 I/O 性能进行基准测试，以便可以准确评估，磁盘性能是否可以满足应用程序的需求。</p>
<p>这一方面，我推荐用性能测试工具 fio ，来测试磁盘的 IOPS、吞吐量以及响应时间等核心指标。但还是那句话，因地制宜，灵活选取。在基准测试时，一定要注意根据应用程序 I/O 的特点，来具体评估指标。</p>
<p>当然，这就需要你测试出，不同 I/O 大小（一般是 512B 至 1MB 中间的若干值）分别在随机读、顺序读、随机写、顺序写等各种场景下的性能情况。</p>
<p>用性能工具得到的这些指标，可以作为后续分析应用程序性能的依据。一旦发生性能问题，你就可以把它们作为磁盘性能的极限值，进而评估磁盘 I/O 的使用情况。</p>
<h4 id="25-2-磁盘-I-O-观测"><a href="#25-2-磁盘-I-O-观测" class="headerlink" title="25.2 磁盘 I/O 观测"></a>25.2 磁盘 I/O 观测</h4><p>第一个要观测的，是每块磁盘的使用情况。</p>
<p>iostat 是最常用的磁盘 I/O 性能观测工具，它提供了每个磁盘的使用率、IOPS、吞吐量等各种常见的性能指标，当然，这些指标实际上来自 /proc/diskstats。</p>
<p>iostat 的输出界面如下。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -d -x 表示显示所有磁盘 I/O 的指标</span>
$ iostat -d -x <span class="token number">1</span>
Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
loop0            <span class="token number">0.00</span>    <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>
loop1            <span class="token number">0.00</span>    <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>
sda              <span class="token number">0.00</span>    <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>
sdb              <span class="token number">0.00</span>    <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="/images/《Linux性能优化实战》学习笔记/iostat指标解读.png" alt="iostat指标解读"></p>
<p>这些指标中，你要注意：</p>
<ul>
<li>%util ，就是我们前面提到的磁盘 I/O 使用率；</li>
<li>r/s+ w/s ，就是 IOPS；</li>
<li>rkB/s+wkB/s ，就是吞吐量；</li>
<li>r_await+w_await ，就是响应时间。</li>
</ul>
<p>在观测指标时，也别忘了结合请求的大小（ rareq-sz 和 wareq-sz）一起分析。</p>
<p>你可能注意到，从 iostat 并不能直接得到磁盘饱和度。事实上，饱和度通常也没有其他简单的观测方法，不过，你可以把观测到的，平均请求队列长度或者读写请求完成的等待时间，跟基准测试的结果（比如通过 fio）进行对比，综合评估磁盘的饱和情况。</p>
<h4 id="25-3-进程-I-O-观测"><a href="#25-3-进程-I-O-观测" class="headerlink" title="25.3 进程 I/O 观测"></a>25.3 进程 I/O 观测</h4><p>除了每块磁盘的 I/O 情况，每个进程的 I/O 情况也是我们需要关注的重点。</p>
<p>上面提到的 iostat 只提供磁盘整体的 I/O 性能数据，缺点在于，并不能知道具体是哪些进程在进行磁盘读写。要观察进程的 I/O 情况，你还可以使用 pidstat 和 iotop 这两个工具。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ pidstat -d <span class="token number">1</span>
<span class="token number">13</span>:39:51      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
<span class="token number">13</span>:39:52      <span class="token number">102</span>       <span class="token number">916</span>      <span class="token number">0.00</span>      <span class="token number">4.00</span>      <span class="token number">0.00</span>       <span class="token number">0</span>  rsyslogd<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p>从 pidstat 的输出你能看到，它可以实时查看每个进程的 I/O 情况，包括下面这些内容。</p>
<ul>
<li>用户 ID（UID）和进程 ID（PID） 。</li>
<li>每秒读取的数据大小（kB_rd/s） ，单位是 KB。</li>
<li>每秒发出的写请求数据大小（kB_wr/s） ，单位是 KB。</li>
<li>每秒取消的写请求数据大小（kB_ccwr/s） ，单位是 KB。</li>
<li>块 I/O 延迟（iodelay），包括等待同步块 I/O 和换入块 I/O 结束的时间，单位是时钟周期。</li>
</ul>
<p>除了可以用 pidstat 实时查看，根据 I/O 大小对进程排序，也是性能分析中一个常用的方法。这一点，我推荐另一个工具， iotop。它是一个类似于 top 的工具，你可以按照 I/O 大小对进程排序，然后找到 I/O 较大的那些进程。</p>
<p>iotop 的输出如下所示：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ iotop
Total DISK READ <span class="token builtin class-name">:</span>       <span class="token number">0.00</span> B/s <span class="token operator">|</span> Total DISK WRITE <span class="token builtin class-name">:</span>       <span class="token number">7.85</span> K/s
Actual DISK READ:       <span class="token number">0.00</span> B/s <span class="token operator">|</span> Actual DISK WRITE:       <span class="token number">0.00</span> B/s
  TID  PRIO  <span class="token environment constant">USER</span>     DISK READ  DISK WRITE  SWAPIN     IO<span class="token operator">&gt;</span>    COMMAND
<span class="token number">15055</span> be/3 root        <span class="token number">0.00</span> B/s    <span class="token number">7.85</span> K/s  <span class="token number">0.00</span> %  <span class="token number">0.00</span> % systemd-journald<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>从这个输出，你可以看到，前两行分别表示，进程的磁盘读写大小总数和磁盘真实的读写大小总数。因为缓存、缓冲区、I/O 合并等因素的影响，它们可能并不相等。</p>
<p>剩下的部分，则是从各个角度来分别表示进程的 I/O 情况，包括线程 ID、I/O 优先级、每秒读磁盘的大小、每秒写磁盘的大小、换入和等待 I/O 的时钟百分比等。</p>
<p>这两个工具，是我们分析磁盘 I/O 性能时最常用到的。你先了解它们的功能和指标含义，具体的使用方法，接下来的案例实战中我们一起学习。</p>
<h3 id="26-案例篇：如何找出狂打日志的“内鬼”？"><a href="#26-案例篇：如何找出狂打日志的“内鬼”？" class="headerlink" title="26 | 案例篇：如何找出狂打日志的“内鬼”？"></a>26 | 案例篇：如何找出狂打日志的“内鬼”？</h3><p>文件系统，是对存储设备上的文件进行组织管理的一种机制。为了支持各类不同的文件系统，Linux 在各种文件系统上，抽象了一层虚拟文件系统 VFS。</p>
<p>它定义了一组所有文件系统都支持的数据结构和标准接口。这样，应用程序和内核中的其他子系统，就只需要跟 VFS 提供的统一接口进行交互。</p>
<p>在文件系统的下层，为了支持各种不同类型的存储设备，Linux 又在各种存储设备的基础上，抽象了一个通用块层。</p>
<p>通用块层，为文件系统和应用程序提供了访问块设备的标准接口；同时，为各种块设备的驱动程序提供了统一的框架。此外，通用块层还会对文件系统和应用程序发送过来的 I/O 请求进行排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率。</p>
<p>通用块层的下一层，自然就是设备层了，包括各种块设备的驱动程序以及物理存储设备。</p>
<p>文件系统、通用块层以及设备层，就构成了 Linux 的存储 I/O 栈。存储系统的 I/O ，通常是整个系统中最慢的一环。所以，Linux 采用多种缓存机制，来优化 I/O 的效率，比方说，</p>
<ul>
<li>为了优化文件访问的性能，采用页缓存、索引节点缓存、目录项缓存等多种缓存机制，减少对下层块设备的直接调用。</li>
<li>同样的，为了优化块设备的访问效率，使用缓冲区来缓存块设备的数据。</li>
</ul>
<p>不过，在碰到文件系统和磁盘的 I/O 问题时，具体应该怎么定位和分析呢？</p>
<h4 id="26-1-案例"><a href="#26-1-案例" class="headerlink" title="26.1 案例"></a>26.1 案例</h4><blockquote>
<p>机器配置： 2 CPU, 8 GB 内存。</p>
<p>安装软件：<code>apt install docker.io sysstat</code>。</p>
</blockquote>
<ol>
<li><p>在终端中执行下面的命令，运行今天的目标应用：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker run -v /tmp:/tmp --name<span class="token operator">=</span>app -itd feisky/logapp<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>然后，在终端中运行 ps 命令，确认案例应用正常启动。如果操作无误，你应该可以在 ps 的输出中，看到一个 app.py 的进程：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">ps</span> -ef <span class="token operator">|</span> <span class="token function">grep</span> /app.py
root     <span class="token number">18940</span> <span class="token number">18921</span> <span class="token number">73</span> <span class="token number">14</span>:41 pts/0    00:00:02 python /app.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p> 接着，我们来看看系统有没有性能问题。要观察哪些性能指标呢？前面文章中，我们知道 CPU、内存和磁盘 I/O 等系统资源，很容易出现资源瓶颈，这就是我们观察的方向了。我们来观察一下这些资源的使用情况。</p>
<p> 我的想法是，我们可以先用 top ，来观察 CPU 和内存的使用情况；然后再用 iostat ，来观察磁盘的 I/O 情况。</p>
</li>
<li><p>所以，接下来，你可以在终端中运行 top 命令，观察 CPU 和内存的使用情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 按 1 切换到每个 CPU 的使用情况</span>
$ <span class="token function">top</span>
<span class="token function">top</span> - <span class="token number">14</span>:43:43 up <span class="token number">1</span> day,  <span class="token number">1</span>:39,  <span class="token number">2</span> users,  load average: <span class="token number">2.48</span>, <span class="token number">1.09</span>, <span class="token number">0.63</span>
Tasks: <span class="token number">130</span> total,   <span class="token number">2</span> running,  <span class="token number">74</span> sleeping,   <span class="token number">0</span> stopped,   <span class="token number">0</span> zombie
%Cpu0  <span class="token builtin class-name">:</span>  <span class="token number">0.7</span> us,  <span class="token number">6.0</span> sy,  <span class="token number">0.0</span> ni,  <span class="token number">0.7</span> id, <span class="token number">92.7</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
%Cpu1  <span class="token builtin class-name">:</span>  <span class="token number">0.0</span> us,  <span class="token number">0.3</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">92.3</span> id,  <span class="token number">7.3</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
KiB Mem <span class="token builtin class-name">:</span>  <span class="token number">8169308</span> total,   <span class="token number">747684</span> free,   <span class="token number">741336</span> used,  <span class="token number">6680288</span> buff/cache
KiB Swap:        <span class="token number">0</span> total,        <span class="token number">0</span> free,        <span class="token number">0</span> used.  <span class="token number">7113124</span> avail Mem

  PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
<span class="token number">18940</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">656108</span> <span class="token number">355740</span>   <span class="token number">5236</span> R   <span class="token number">6.3</span>  <span class="token number">4.4</span>   <span class="token number">0</span>:12.56 python
 <span class="token number">1312</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">236532</span>  <span class="token number">24116</span>   <span class="token number">9648</span> S   <span class="token number">0.3</span>  <span class="token number">0.3</span>   <span class="token number">9</span>:29.80 python3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 观察 top 的输出，你会发现，CPU0 的使用率非常高，它的系统 CPU 使用率（sys%）为 6%，而 iowait 超过了 90%。这说明 CPU0 上，可能正在运行 I/O 密集型的进程。</p>
<p> 接着我们来看，进程部分的 CPU 使用情况。你会发现， python 进程的 CPU 使用率已经达到了 6%，而其余进程的 CPU 使用率都比较低，不超过 0.3%。看起来 python 是个可疑进程。</p>
<p> 最后再看内存的使用情况，总内存 8G，剩余内存只有 730 MB，而 Buffer/Cache 占用内存高达 6GB 之多，这说明内存主要被缓存占用。虽然大部分缓存可回收，我们还是得了解下缓存的去处，确认缓存使用都是合理的。</p>
<p> 到这一步，你基本可以判断出，CPU 使用率中的 iowait 是一个潜在瓶颈，而内存部分的缓存占比较大，那磁盘 I/O 又是怎么样的情况呢？</p>
</li>
<li><p>我们在终端中按 Ctrl+C ，停止 top 命令，再运行 iostat 命令，观察 I/O 的使用情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -d 表示显示 I/O 性能指标，-x 表示显示扩展统计（即所有 I/O 指标）</span>
$ iostat -x -d <span class="token number">1</span>
Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
loop0            <span class="token number">0.00</span>    <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>
sdb              <span class="token number">0.00</span>    <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>
sda              <span class="token number">0.00</span>   <span class="token number">64.00</span>      <span class="token number">0.00</span>  <span class="token number">32768.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">0.00</span> <span class="token number">7270.44</span> <span class="token number">1102.18</span>     <span class="token number">0.00</span>   <span class="token number">512.00</span>  <span class="token number">15.50</span>  <span class="token number">99.20</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 观察 iostat 的最后一列，你会看到，磁盘 sda 的 I/O 使用率已经高达 99%，很可能已经接近 I/O 饱和。</p>
<p> 再看前面的各个指标，每秒写磁盘请求数是 64 ，写大小是 32 MB，写请求的响应时间为 7 秒，而请求队列长度则达到了 1100。</p>
<p> 超慢的响应时间和特长的请求队列长度，进一步验证了 I/O 已经饱和的猜想。此时，sda 磁盘已经遇到了严重的性能瓶颈。</p>
<p> 到这里，也就可以理解，为什么前面看到的 iowait 高达 90% 了，这正是磁盘 sda 的 I/O 瓶颈导致的。接下来的重点就是分析 I/O 性能瓶颈的根源了。那要怎么知道，这些 I/O 请求相关的进程呢？</p>
</li>
<li><p>使用 pidstat 加上 -d 参数，就可以显示每个进程的 I/O 情况。所以，你可以在终端中运行如下命令来观察：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ pidstat -d <span class="token number">1</span>

<span class="token number">15</span>:08:35      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
<span class="token number">15</span>:08:36        <span class="token number">0</span>     <span class="token number">18940</span>      <span class="token number">0.00</span>  <span class="token number">45816.00</span>      <span class="token number">0.00</span>      <span class="token number">96</span>  python

<span class="token number">15</span>:08:36      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
<span class="token number">15</span>:08:37        <span class="token number">0</span>       <span class="token number">354</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">350</span>  jbd2/sda1-8
<span class="token number">15</span>:08:37        <span class="token number">0</span>     <span class="token number">18940</span>      <span class="token number">0.00</span>  <span class="token number">46000.00</span>      <span class="token number">0.00</span>      <span class="token number">96</span>  python
<span class="token number">15</span>:08:37        <span class="token number">0</span>     <span class="token number">20065</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>    <span class="token number">1503</span>  kworker/u4:2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从 pidstat 的输出，你可以发现，只有 python 进程的写比较大，而且每秒写的数据超过 45 MB，比上面 iostat 发现的 32MB 的结果还要大。很明显，正是 python 进程导致了 I/O 瓶颈。</p>
<p> 再往下看 iodelay 项。虽然只有 python 在大量写数据，但你应该注意到了，有两个进程 （kworker 和 jbd2 ）的延迟，居然比 python 进程还大很多。</p>
<p> 这其中，kworker 是一个内核线程，而 jbd2 是 ext4 文件系统中，用来保证数据完整性的内核线程。他们都是保证文件系统基本功能的内核线程，所以具体细节暂时就不用管了，我们只需要明白，它们延迟的根源还是大量 I/O。</p>
<p> 综合 pidstat 的输出来看，还是 python 进程的嫌疑最大。接下来，我们来分析 python 进程到底在写什么。</p>
<p> 首先留意一下 python 进程的 PID 号， 18940。看到 18940 ，你有没有觉得熟悉？其实前面在使用 top 时，我们记录过的 CPU 使用率最高的进程，也正是它。不过，虽然在 top 中使用率最高，也不过是 6%，并不算高。所以，以 I/O 问题为分析方向还是正确的。</p>
<p> 知道了进程的 PID 号，具体要怎么查看写的情况呢？</p>
<p> 其实，我在系统调用的案例中讲过，读写文件必须通过系统调用完成。观察系统调用情况，就可以知道进程正在写的文件。想起 strace 了吗，它正是我们分析系统调用时最常用的工具。</p>
</li>
<li><p>接下来，我们在终端中运行 strace 命令，并通过 -p 18940 指定 python 进程的 PID 号：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">strace</span> -p <span class="token number">18940</span>
strace: Process <span class="token number">18940</span> attached
<span class="token punctuation">..</span>.
mmap<span class="token punctuation">(</span>NULL, <span class="token number">314576896</span>, PROT_READ<span class="token operator">|</span>PROT_WRITE, MAP_PRIVATE<span class="token operator">|</span>MAP_ANONYMOUS, -1, <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">=</span> 0x7f0f7aee9000
mmap<span class="token punctuation">(</span>NULL, <span class="token number">314576896</span>, PROT_READ<span class="token operator">|</span>PROT_WRITE, MAP_PRIVATE<span class="token operator">|</span>MAP_ANONYMOUS, -1, <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">=</span> 0x7f0f682e8000
write<span class="token punctuation">(</span><span class="token number">3</span>, <span class="token string">"2018-12-05 15:23:01,709 - __main"</span><span class="token punctuation">..</span>., <span class="token number">314572844</span>
<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">314572844</span>
munmap<span class="token punctuation">(</span>0x7f0f682e8000, <span class="token number">314576896</span><span class="token punctuation">)</span>       <span class="token operator">=</span> <span class="token number">0</span>
write<span class="token punctuation">(</span><span class="token number">3</span>, <span class="token string">"<span class="token entity" title="\n">\n</span>"</span>, <span class="token number">1</span><span class="token punctuation">)</span>                       <span class="token operator">=</span> <span class="token number">1</span>
munmap<span class="token punctuation">(</span>0x7f0f7aee9000, <span class="token number">314576896</span><span class="token punctuation">)</span>       <span class="token operator">=</span> <span class="token number">0</span>
close<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>                                <span class="token operator">=</span> <span class="token number">0</span>
stat<span class="token punctuation">(</span><span class="token string">"/tmp/logtest.txt.1"</span>, <span class="token punctuation">{</span>st_mode<span class="token operator">=</span>S_IFREG<span class="token operator">|</span>0644, <span class="token assign-left variable">st_size</span><span class="token operator">=</span><span class="token number">943718535</span>, <span class="token punctuation">..</span>.<span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从 write() 系统调用上，我们可以看到，进程向文件描述符编号为 3 的文件中，写入了 300MB 的数据。看来，它应该是我们要找的文件。不过，write() 调用中只能看到文件的描述符编号，文件名和路径还是未知的。</p>
<p> 再观察后面的 stat() 调用，你可以看到，它正在获取 /tmp/logtest.txt.1 的状态。 这种“点 + 数字格式”的文件，在日志回滚中非常常见。我们可以猜测，这是第一个日志回滚文件，而正在写的日志文件路径，则是 /tmp/logtest.txt。</p>
</li>
<li><p>接下来，我们在终端中运行下面的 lsof 命令，看看进程 18940 都打开了哪些文件：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">lsof</span> -p <span class="token number">18940</span>
COMMAND   PID <span class="token environment constant">USER</span>   FD   TYPE DEVICE  SIZE/OFF    NODE NAME
python  <span class="token number">18940</span> root  cwd    DIR   <span class="token number">0,50</span>      <span class="token number">4096</span> <span class="token number">1549389</span> /
python  <span class="token number">18940</span> root  rtd    DIR   <span class="token number">0,50</span>      <span class="token number">4096</span> <span class="token number">1549389</span> /
…
python  <span class="token number">18940</span> root    2u   CHR  <span class="token number">136,0</span>       0t0       <span class="token number">3</span> /dev/pts/0
python  <span class="token number">18940</span> root    3w   REG    <span class="token number">8,1</span> <span class="token number">117944320</span>     <span class="token number">303</span> /tmp/logtest.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 有几列我简单介绍一下，FD 表示文件描述符号，TYPE 表示文件类型，NAME 表示文件路径。这也是我们需要关注的重点。</p>
<p> 再看最后一行，这说明，这个进程打开了文件 /tmp/logtest.txt，并且它的文件描述符是 3 号，而 3 后面的 w ，表示以写的方式打开。</p>
<p> 这跟刚才 strace 完我们猜测的结果一致，看来这就是问题的根源：进程 18940 以每次 300MB 的速度，在“疯狂”写日志，而日志文件的路径是 /tmp/logtest.txt。</p>
</li>
<li><p>你可以运行 docker cp 命令，把案例应用的源代码拷贝出来，然后查看它的内容。（你也可以点击<a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/tree/master/logging-app">这里</a>查看案例应用的源码）：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 拷贝案例应用源代码到当前目录</span>
$ docker <span class="token function">cp</span> app:/app.py <span class="token builtin class-name">.</span>

<span class="token comment"># 查看案例应用的源代码</span>
$ <span class="token function">cat</span> app.py

logger <span class="token operator">=</span> logging.getLogger<span class="token punctuation">(</span>__name__<span class="token punctuation">)</span>
logger.setLevel<span class="token punctuation">(</span>level<span class="token operator">=</span>logging.INFO<span class="token punctuation">)</span>
rHandler <span class="token operator">=</span> RotatingFileHandler<span class="token punctuation">(</span><span class="token string">"/tmp/logtest.txt"</span>, <span class="token assign-left variable">maxBytes</span><span class="token operator">=</span><span class="token number">1024</span> * <span class="token number">1024</span> * <span class="token number">1024</span>, <span class="token assign-left variable">backupCount</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
rHandler.setLevel<span class="token punctuation">(</span>logging.INFO<span class="token punctuation">)</span>

def write_log<span class="token punctuation">(</span>size<span class="token punctuation">)</span>:
  <span class="token string">''</span><span class="token string">'Write logs to file'</span><span class="token string">''</span>
  message <span class="token operator">=</span> get_message<span class="token punctuation">(</span>size<span class="token punctuation">)</span>
  <span class="token keyword">while</span> True:
    logger.info<span class="token punctuation">(</span>message<span class="token punctuation">)</span>
    time.sleep<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token builtin class-name">:</span>
  msg_size <span class="token operator">=</span> <span class="token number">300</span> * <span class="token number">1024</span> * <span class="token number">1024</span>
  write_log<span class="token punctuation">(</span>msg_size<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 分析这个源码，我们发现，它的日志路径是 /tmp/logtest.txt，默认记录 INFO 级别以上的所有日志，而且每次写日志的大小是 300MB。这跟我们上面的分析结果是一致的。</p>
</li>
<li><p>一般来说，生产系统的应用程序，应该有动态调整日志级别的功能。继续查看源码，你会发现，这个程序也可以调整日志级别。如果你给它发送 SIGUSR1 信号，就可以把日志调整为 INFO 级；发送 SIGUSR2 信号，则会调整为 WARNING 级：</p>
 <pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">set_logging_info</span><span class="token punctuation">(</span>signal_num<span class="token punctuation">,</span> frame<span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token triple-quoted-string string">'''Set loging level to INFO when receives SIGUSR1'''</span>
logger<span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>logging<span class="token punctuation">.</span>INFO<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">set_logging_warning</span><span class="token punctuation">(</span>signal_num<span class="token punctuation">,</span> frame<span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token triple-quoted-string string">'''Set loging level to WARNING when receives SIGUSR2'''</span>
logger<span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>logging<span class="token punctuation">.</span>WARNING<span class="token punctuation">)</span>

signal<span class="token punctuation">.</span>signal<span class="token punctuation">(</span>signal<span class="token punctuation">.</span>SIGUSR1<span class="token punctuation">,</span> set_logging_info<span class="token punctuation">)</span>
signal<span class="token punctuation">.</span>signal<span class="token punctuation">(</span>signal<span class="token punctuation">.</span>SIGUSR2<span class="token punctuation">,</span> set_logging_warning<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 根据源码中的日志调用 logger. info(message) ，我们知道，它的日志是 INFO 级，这也正是它的默认级别。那么，只要把默认级别调高到 WARNING 级，日志问题应该就解决了。</p>
</li>
<li><p>接下来，我们就来检查一下，刚刚的分析对不对。在终端中运行下面的 kill 命令，给进程 18940 发送 SIGUSR2 信号：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">kill</span> -SIGUSR2 <span class="token number">18940</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>然后，再执行 top 和 iostat 观察一下：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">top</span>
<span class="token punctuation">..</span>.
%Cpu<span class="token punctuation">(</span>s<span class="token punctuation">)</span>:  <span class="token number">0.3</span> us,  <span class="token number">0.2</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">99.5</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ iostat -d -x <span class="token number">1</span>
Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
loop0            <span class="token number">0.00</span>    <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>
sdb              <span class="token number">0.00</span>    <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>
sda              <span class="token number">0.00</span>    <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>观察 top 和 iostat 的输出，你会发现，稍等一段时间后，iowait 会变成 0，而 sda 磁盘的 I/O 使用率也会逐渐减少到 0。</p>
</li>
</ol>
<h4 id="26-2-问答区"><a href="#26-2-问答区" class="headerlink" title="26.2 问答区"></a>26.2 问答区</h4><p>“日志回滚文件”，打印日志的过程中从直觉来看很容易误认为日志是在“回滚”，我也犯过这样的错误；rotating英文直译为“旋转”或“轮流”，实际的日志打印过程中，日志名称是“旋转”的，例如log.1(当前打印的日志文件并且一直会打印这个文件)，log.2(较早日志)，log.3(更早日志)，当触发“旋转”条件时，日志名称会发生变更，假如log.3是上限数，那么log.3发生“旋转”就被remove，log.2被rename为log.3。更形象一点的描述是，日志名称发生了滚动，log.1=&gt;log.2=&gt;log.3不断的更新。</p>
<h3 id="27-案例篇：为什么我的磁盘I-O延迟很高？"><a href="#27-案例篇：为什么我的磁盘I-O延迟很高？" class="headerlink" title="27 | 案例篇：为什么我的磁盘I/O延迟很高？"></a>27 | 案例篇：为什么我的磁盘I/O延迟很高？</h3><h4 id="27-1-案例"><a href="#27-1-案例" class="headerlink" title="27.1 案例"></a>27.1 案例</h4><blockquote>
<p>机器配置： 2 CPU, 8 GB 内存。</p>
<p>安装软件：<code>apt install docker.io sysstat</code>。</p>
</blockquote>
<ol>
<li><p>在第一个终端中执行下面的命令，运行本次案例要分析的目标应用：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker run --name<span class="token operator">=</span>app -p <span class="token number">10000</span>:80 -itd feisky/word-pop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>在第二个终端中运行 curl 命令，访问 <a target="_blank" rel="noopener" href="http://192.168.0.10:1000/，确认案例正常启动。你应该可以在">http://192.168.0.10:1000/，确认案例正常启动。你应该可以在</a> curl 的输出界面里，看到一个 hello world 的输出：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">curl</span> http://192.168.0.10:10000/
hello world<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>接下来，在第二个终端中，访问案例应用的单词热度接口，也就是 <a target="_blank" rel="noopener" href="http://192.168.0.10:1000/popularity/word。">http://192.168.0.10:1000/popularity/word。</a></p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">curl</span> http://192.168.0.10:1000/popularity/word<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> 稍等一会儿，你会发现，这个接口居然这么长时间都没响应，究竟是怎么回事呢？我们先回到终端一来分析一下。</p>
<p> 我们试试在第一个终端里，随便执行一个命令，比如执行 df 命令，查看一下文件系统的使用情况。奇怪的是，这么简单的命令，居然也要等好久才有输出。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">df</span>
Filesystem     1K-blocks    Used Available Use% Mounted on
udev             <span class="token number">4073376</span>       <span class="token number">0</span>   <span class="token number">4073376</span>   <span class="token number">0</span>% /dev
tmpfs             <span class="token number">816932</span>    <span class="token number">1188</span>    <span class="token number">815744</span>   <span class="token number">1</span>% /run
/dev/sda1       <span class="token number">30308240</span> <span class="token number">8713640</span>  <span class="token number">21578216</span>  <span class="token number">29</span>% /<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 通过 df 我们知道，系统还有足够多的磁盘空间。那为什么响应会变慢呢？看来还是得观察一下，系统的资源使用情况，像是 CPU、内存和磁盘 I/O 等的具体使用情况。</p>
<p> 这里的思路其实跟上一个案例比较类似，我们可以先用 top 来观察 CPU 和内存的使用情况，然后再用 iostat 来观察磁盘的 I/O 情况。</p>
</li>
<li><p>为了避免分析过程中 curl 请求突然结束，我们回到终端二，按 Ctrl+C 停止刚才的应用程序；然后，把 curl 命令放到一个循环里执行；这次我们还要加一个 time 命令，观察每次的执行时间：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token keyword">while</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token keyword">do</span> <span class="token function">time</span> <span class="token function">curl</span> http://192.168.0.10:10000/popularity/word<span class="token punctuation">;</span> <span class="token function">sleep</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token keyword">done</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>继续回到终端一来分析性能。我们在终端一中运行 top 命令，观察 CPU 和内存的使用情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">top</span>
<span class="token function">top</span> - <span class="token number">14</span>:27:02 up <span class="token number">10</span>:30,  <span class="token number">1</span> user,  load average: <span class="token number">1.82</span>, <span class="token number">1.26</span>, <span class="token number">0.76</span>
Tasks: <span class="token number">129</span> total,   <span class="token number">1</span> running,  <span class="token number">74</span> sleeping,   <span class="token number">0</span> stopped,   <span class="token number">0</span> zombie
%Cpu0  <span class="token builtin class-name">:</span>  <span class="token number">3.5</span> us,  <span class="token number">2.1</span> sy,  <span class="token number">0.0</span> ni,  <span class="token number">0.0</span> id, <span class="token number">94.4</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
%Cpu1  <span class="token builtin class-name">:</span>  <span class="token number">2.4</span> us,  <span class="token number">0.7</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">70.4</span> id, <span class="token number">26.5</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
KiB Mem <span class="token builtin class-name">:</span>  <span class="token number">8169300</span> total,  <span class="token number">3323248</span> free,   <span class="token number">436748</span> used,  <span class="token number">4409304</span> buff/cache
KiB Swap:        <span class="token number">0</span> total,        <span class="token number">0</span> free,        <span class="token number">0</span> used.  <span class="token number">7412556</span> avail Mem

  PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
<span class="token number">12280</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">103304</span>  <span class="token number">28824</span>   <span class="token number">7276</span> S  <span class="token number">14.0</span>  <span class="token number">0.4</span>   <span class="token number">0</span>:08.77 python
   <span class="token number">16</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> S   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:09.22 ksoftirqd/1
<span class="token number">1549</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">236712</span>  <span class="token number">24480</span>   <span class="token number">9864</span> S   <span class="token number">0.3</span>  <span class="token number">0.3</span>   <span class="token number">3</span>:31.38 python3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 观察 top 的输出可以发现，两个 CPU 的 iowait 都非常高。特别是 CPU0， iowait 已经高达 94 %，而剩余内存还有 3GB，看起来也是充足的。</p>
<p> 再往下看，进程部分有一个 python 进程的 CPU 使用率稍微有点高，达到了 14%。虽然 14% 并不能成为性能瓶颈，不过有点嫌疑——可能跟 iowait 的升高有关。</p>
<p> 那这个 PID 号为 12280 的 python 进程，到底是不是我们的案例应用呢？</p>
</li>
<li><p>我们在第一个终端中，按下 Ctrl+C，停止 top 命令；然后执行下面的 ps 命令，查找案例应用 app.py 的 PID 号：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">ps</span> aux <span class="token operator">|</span> <span class="token function">grep</span> app.py
root     <span class="token number">12222</span>  <span class="token number">0.4</span>  <span class="token number">0.2</span>  <span class="token number">96064</span> <span class="token number">23452</span> pts/0    Ss+  <span class="token number">14</span>:37   <span class="token number">0</span>:00 python /app.py
root     <span class="token number">12280</span> <span class="token number">13.9</span>  <span class="token number">0.3</span> <span class="token number">102424</span> <span class="token number">27904</span> pts/0    Sl+  <span class="token number">14</span>:37   <span class="token number">0</span>:09 /usr/local/bin/python /app.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 从 ps 的输出，你可以看到，这个 CPU 使用率较高的进程，正是我们的案例应用。不过先别着急分析 CPU 问题，毕竟 iowait 已经高达 94%， I/O 问题才是我们首要解决的。</p>
</li>
<li><p>接下来，我们在终端一中，运行下面的 iostat 命令，其中:</p>
<ul>
<li>-d 选项是指显示出 I/O 的性能指标；</li>
<li><p>-x 选项是指显示出扩展统计信息（即显示所有 I/O 指标）。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ iostat -d -x <span class="token number">1</span>
Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
loop0            <span class="token number">0.00</span>    <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">0.00</span>    <span class="token number">0.00</span>   <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>
sda              <span class="token number">0.00</span>   <span class="token number">71.00</span>      <span class="token number">0.00</span>  <span class="token number">32912.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">0.00</span> <span class="token number">18118.31</span> <span class="token number">241.89</span>     <span class="token number">0.00</span>   <span class="token number">463.55</span>  <span class="token number">13.86</span>  <span class="token number">98.40</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以发现，磁盘 sda 的 I/O 使用率已经达到 98% ，接近饱和了。而且，写请求的响应时间高达 18 秒，每秒的写数据为 32 MB，显然写磁盘碰到了瓶颈。</p>
<p>那要怎么知道，这些 I/O 请求到底是哪些进程导致的呢？</p>
</li>
</ul>
</li>
<li><p>在终端一中，运行下面的 pidstat 命令，观察进程的 I/O 情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ pidstat -d <span class="token number">1</span>
<span class="token number">14</span>:39:14      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
<span class="token number">14</span>:39:15        <span class="token number">0</span>     <span class="token number">12280</span>      <span class="token number">0.00</span> <span class="token number">335716.00</span>      <span class="token number">0.00</span>       <span class="token number">0</span>  python<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<p> 从 pidstat 的输出，我们再次看到了 PID 号为 12280 的结果。这说明，正是案例应用引发 I/O 的性能瓶颈。</p>
<p> 走到这一步，你估计觉得，接下来就很简单了，上一个案例不刚刚学过吗？无非就是，先用 strace 确认它是不是在写文件，再用 lsof 找出文件描述符对应的文件即可。</p>
</li>
<li><p>到底是不是这样呢？我们不妨来试试。还是在终端一中，执行下面的 strace 命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">strace</span> -p <span class="token number">12280</span>
strace: Process <span class="token number">12280</span> attached
select<span class="token punctuation">(</span><span class="token number">0</span>, NULL, NULL, NULL, <span class="token punctuation">{</span>tv_sec<span class="token operator">=</span><span class="token number">0</span>, <span class="token assign-left variable">tv_usec</span><span class="token operator">=</span><span class="token number">567708</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0</span> <span class="token punctuation">(</span>Timeout<span class="token punctuation">)</span>
stat<span class="token punctuation">(</span><span class="token string">"/usr/local/lib/python3.7/importlib/_bootstrap.py"</span>, <span class="token punctuation">{</span>st_mode<span class="token operator">=</span>S_IFREG<span class="token operator">|</span>0644, <span class="token assign-left variable">st_size</span><span class="token operator">=</span><span class="token number">39278</span>, <span class="token punctuation">..</span>.<span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0</span>
stat<span class="token punctuation">(</span><span class="token string">"/usr/local/lib/python3.7/importlib/_bootstrap.py"</span>, <span class="token punctuation">{</span>st_mode<span class="token operator">=</span>S_IFREG<span class="token operator">|</span>0644, <span class="token assign-left variable">st_size</span><span class="token operator">=</span><span class="token number">39278</span>, <span class="token punctuation">..</span>.<span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从 strace 中，你可以看到大量的 stat 系统调用，并且大都为 python 的文件，但是，请注意，这里并没有任何 write 系统调用。</p>
<p> 由于 strace 的输出比较多，我们可以用 grep ，来过滤一下 write，比如：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">strace</span> -p <span class="token number">12280</span> <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">grep</span> <span class="token function">write</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> 遗憾的是，这里仍然没有任何输出。</p>
<p> 难道此时已经没有性能问题了吗？重新执行刚才的 top 和 iostat 命令，你会不幸地发现，性能问题仍然存在。</p>
<p> 我们只好综合 strace、pidstat 和 iostat 这三个结果来分析了。很明显，你应该发现了这里的矛盾：iostat 已经证明磁盘 I/O 有性能瓶颈，而 pidstat 也证明了，这个瓶颈是由 12280 号进程导致的，但 strace 跟踪这个进程，却没有找到任何 write 系统调用。</p>
<p> 这就奇怪了。难道因为案例使用的编程语言是 Python ，而 Python 是解释型的，所以找不到？还是说，因为案例运行在 Docker 中呢？这里留个悬念，你自己想想。</p>
<p> 文件写，明明应该有相应的 write 系统调用，但用现有工具却找不到痕迹，这时就该想想换工具的问题了。怎样才能知道哪里在写文件呢？</p>
<p> 这里我给你介绍一个新工具， <a target="_blank" rel="noopener" href="https://github.com/iovisor/bcc/blob/master/tools/filetop.py">filetop</a> 。它是 <a target="_blank" rel="noopener" href="https://github.com/iovisor/bcc">bcc</a> 软件包的一部分，基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制，主要跟踪内核中文件的读写情况，并输出线程 ID（TID）、读写大小、读写类型以及文件名称。</p>
</li>
<li><p>首先，在终端一中运行下面的命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 切换到工具目录</span>
$ <span class="token builtin class-name">cd</span> /usr/share/bcc/tools

<span class="token comment"># -C 选项表示输出新内容时不清空屏幕</span>
$ ./filetop -C

TID    COMM             READS  WRITES R_Kb    W_Kb    T FILE
<span class="token number">514</span>    python           <span class="token number">0</span>      <span class="token number">1</span>      <span class="token number">0</span>       <span class="token number">2832</span>    R <span class="token number">669</span>.txt
<span class="token number">514</span>    python           <span class="token number">0</span>      <span class="token number">1</span>      <span class="token number">0</span>       <span class="token number">2490</span>    R <span class="token number">667</span>.txt
<span class="token number">514</span>    python           <span class="token number">0</span>      <span class="token number">1</span>      <span class="token number">0</span>       <span class="token number">2685</span>    R <span class="token number">671</span>.txt
<span class="token number">514</span>    python           <span class="token number">0</span>      <span class="token number">1</span>      <span class="token number">0</span>       <span class="token number">2392</span>    R <span class="token number">670</span>.txt
<span class="token number">514</span>    python           <span class="token number">0</span>      <span class="token number">1</span>      <span class="token number">0</span>       <span class="token number">2050</span>    R <span class="token number">672</span>.txt

<span class="token punctuation">..</span>.

TID    COMM             READS  WRITES R_Kb    W_Kb    T FILE
<span class="token number">514</span>    python           <span class="token number">2</span>      <span class="token number">0</span>      <span class="token number">5957</span>    <span class="token number">0</span>       R <span class="token number">651</span>.txt
<span class="token number">514</span>    python           <span class="token number">2</span>      <span class="token number">0</span>      <span class="token number">5371</span>    <span class="token number">0</span>       R <span class="token number">112</span>.txt
<span class="token number">514</span>    python           <span class="token number">2</span>      <span class="token number">0</span>      <span class="token number">4785</span>    <span class="token number">0</span>       R <span class="token number">861</span>.txt
<span class="token number">514</span>    python           <span class="token number">2</span>      <span class="token number">0</span>      <span class="token number">4736</span>    <span class="token number">0</span>       R <span class="token number">213</span>.txt
<span class="token number">514</span>    python           <span class="token number">2</span>      <span class="token number">0</span>      <span class="token number">4443</span>    <span class="token number">0</span>       R <span class="token number">45</span>.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>你会看到，filetop 输出了 8 列内容，分别是线程 ID、线程命令行、读写次数、读写的大小（单位 KB）、文件类型以及读写的文件名称。</p>
<p>这些内容里，你可能会看到很多动态链接库，不过这不是我们的重点，暂且忽略即可。我们的重点，是一个 python 应用，所以要特别关注 python 相关的内容。</p>
<p>多观察一会儿，你就会发现，每隔一段时间，线程号为 514 的 python 应用就会先写入大量的 txt 文件，再大量地读。</p>
</li>
<li><p>线程号为 514 的线程，属于哪个进程呢？我们可以用 ps 命令查看。先在终端一中，按下 Ctrl+C ，停止 filetop ；然后，运行下面的 ps 命令。这个输出的第二列内容，就是我们想知道的进程号：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">ps</span> -efT <span class="token operator">|</span> <span class="token function">grep</span> <span class="token number">514</span>
root     <span class="token number">12280</span>  <span class="token number">514</span> <span class="token number">14626</span> <span class="token number">33</span> <span class="token number">14</span>:47 pts/0    00:00:05 /usr/local/bin/python /app.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>我们看到，这个线程正是案例应用 12280 的线程。终于可以先松一口气，不过还没完，filetop 只给出了文件名称，却没有文件路径，还得继续找啊。</p>
<p>我再介绍一个好用的工具，opensnoop 。它同属于 bcc 软件包，可以动态跟踪内核中的 open 系统调用。这样，我们就可以找出这些 txt 文件的路径。</p>
</li>
<li><p>接下来，在终端一中，运行下面的 opensnoop 命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ opensnoop
<span class="token number">12280</span>  python              <span class="token number">6</span>   <span class="token number">0</span> /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/650.txt
<span class="token number">12280</span>  python              <span class="token number">6</span>   <span class="token number">0</span> /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/651.txt
<span class="token number">12280</span>  python              <span class="token number">6</span>   <span class="token number">0</span> /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/652.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>这次，通过 opensnoop 的输出，你可以看到，这些 txt 路径位于 /tmp 目录下。你还能看到，它打开的文件数量，按照数字编号，从 0.txt 依次增大到 999.txt，这可远多于前面用 filetop 看到的数量。</p>
</li>
<li><p>综合 filetop 和 opensnoop ，我们就可以进一步分析了。我们可以大胆猜测，案例应用在写入 1000 个 txt 文件后，又把这些内容读到内存中进行处理。我们来检查一下，这个目录中是不是真的有 1000 个文件：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">ls</span> /tmp/9046db9e-fe25-11e8-b13f-0242ac110002 <span class="token operator">|</span> <span class="token function">wc</span> -l
ls: cannot access <span class="token string">'/tmp/9046db9e-fe25-11e8-b13f-0242ac110002'</span><span class="token builtin class-name">:</span> No such <span class="token function">file</span> or directory
<span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li><p>操作后却发现，目录居然不存在了。怎么回事呢？我们回到 opensnoop 再观察一会儿：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ opensnoop
<span class="token number">12280</span>  python              <span class="token number">6</span>   <span class="token number">0</span> /tmp/defee970-fe25-11e8-b13f-0242ac110002/261.txt
<span class="token number">12280</span>  python              <span class="token number">6</span>   <span class="token number">0</span> /tmp/defee970-fe25-11e8-b13f-0242ac110002/840.txt
<span class="token number">12280</span>  python              <span class="token number">6</span>   <span class="token number">0</span> /tmp/defee970-fe25-11e8-b13f-0242ac110002/136.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>原来，这时的路径已经变成了另一个目录。这说明，这些目录都是应用程序动态生成的，用完就删了。</p>
<p>结合前面的所有分析，我们基本可以判断，案例应用会动态生成一批文件，用来临时存储数据，用完就会删除它们。但不幸的是，正是这些文件读写，引发了 I/O 的性能瓶颈，导致整个处理过程非常慢。</p>
</li>
<li><p>当然，我们还需要验证这个猜想。老办法，还是查看应用程序的源码 app.py，</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token decorator annotation punctuation">@app<span class="token punctuation">.</span>route</span><span class="token punctuation">(</span><span class="token string">"/popularity/&lt;word&gt;"</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">word_popularity</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
dir_path <span class="token operator">=</span> <span class="token string">'/tmp/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>uuid<span class="token punctuation">.</span>uuid1<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
count <span class="token operator">=</span> <span class="token number">0</span>
sample_size <span class="token operator">=</span> <span class="token number">1000</span>

<span class="token keyword">def</span> <span class="token function">save_to_file</span><span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> content<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>content<span class="token punctuation">)</span>

<span class="token keyword">try</span><span class="token punctuation">:</span>
    <span class="token comment"># initial directory firstly</span>
    os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>dir_path<span class="token punctuation">)</span>

    <span class="token comment"># save article to files</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>sample_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        file_name <span class="token operator">=</span> <span class="token string">'{}/{}.txt'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>dir_path<span class="token punctuation">,</span> i<span class="token punctuation">)</span>
        article <span class="token operator">=</span> generate_article<span class="token punctuation">(</span><span class="token punctuation">)</span>
        save_to_file<span class="token punctuation">(</span>file_name<span class="token punctuation">,</span> article<span class="token punctuation">)</span>

    <span class="token comment"># count word popularity</span>
    <span class="token keyword">for</span> root<span class="token punctuation">,</span> dirs<span class="token punctuation">,</span> files <span class="token keyword">in</span> os<span class="token punctuation">.</span>walk<span class="token punctuation">(</span>dir_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> file_name <span class="token keyword">in</span> files<span class="token punctuation">:</span>
            <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'{}/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>dir_path<span class="token punctuation">,</span> file_name<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
                <span class="token keyword">if</span> validate<span class="token punctuation">(</span>word<span class="token punctuation">,</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    count <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">finally</span><span class="token punctuation">:</span>
        <span class="token comment"># clean files</span>
        shutil<span class="token punctuation">.</span>rmtree<span class="token punctuation">(</span>dir_path<span class="token punctuation">,</span> ignore_errors<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> jsonify<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'popularity'</span><span class="token punctuation">:</span> count <span class="token operator">/</span> sample_size <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token string">'word'</span><span class="token punctuation">:</span> word<span class="token punctuation">}</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>源码中可以看到，这个案例应用，在每个请求的处理过程中，都会生成一批临时文件，然后读入内存处理，最后再把整个目录删除掉。</p>
<p>这是一种常见的利用磁盘空间处理大量数据的技巧，不过，本次案例中的 I/O 请求太重，导致磁盘 I/O 利用率过高。</p>
<p>要解决这一点，其实就是算法优化问题了。比如在内存充足时，就可以把所有数据都放到内存中处理，这样就能避免 I/O 的性能问题。</p>
</li>
</ol>
<h4 id="27-2-思考"><a href="#27-2-思考" class="headerlink" title="27.2 思考"></a>27.2 思考</h4><p>今天的案例中，iostat 已经证明，磁盘 I/O 出现了性能瓶颈， pidstat 也证明了这个瓶颈是由 12280 号进程导致的。但是，strace 跟踪这个进程，却没有发现任何 write 系统调用。</p>
<p>答案：在strace -p PID后加上-f，多进程和多线程都可以跟踪。</p>
<h3 id="28-案例篇：一个SQL查询要15秒，这是怎么回事？"><a href="#28-案例篇：一个SQL查询要15秒，这是怎么回事？" class="headerlink" title="28 | 案例篇：一个SQL查询要15秒，这是怎么回事？"></a>28 | 案例篇：一个SQL查询要15秒，这是怎么回事？</h3><h4 id="28-1-案例"><a href="#28-1-案例" class="headerlink" title="28.1 案例"></a>28.1 案例</h4><blockquote>
<p>机器配置： 2 CPU, 8 GB 内存。</p>
<p>安装软件：<code>apt install docker.io sysstat make git</code>。</p>
</blockquote>
<p>案例总共由三个容器组成，包括一个 MySQL 数据库应用、一个商品搜索应用以及一个数据处理的应用。其中，商品搜索应用以 HTTP 的形式提供了一个接口：</p>
<ul>
<li>/：返回 Index Page；</li>
<li>/db/insert/products/：插入指定数量的商品信息；</li>
<li>/products/：查询指定商品的信息，并返回处理时间。</li>
</ul>
<ol>
<li><p>在第一个终端中执行下面命令，拉取本次案例所需脚本：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">git</span> clone https://github.com/feiskyer/linux-perf-examples
$ <span class="token builtin class-name">cd</span> linux-perf-examples/mysql-slow<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>接着，执行下面的命令，运行本次的目标应用。正常情况下，你应该可以看到下面的输出：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 注意下面的随机字符串是容器 ID，每次运行均会不同，并且你不需要关注它，因为我们只会用到名字</span>
$ <span class="token function">make</span> run
docker run --name<span class="token operator">=</span>mysql -itd -p <span class="token number">10000</span>:80 -m 800m feisky/mysql:5.6
WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
4156780da5be0b9026bcf27a3fa56abc15b8408e358fa327f472bcc5add4453f
docker run --name<span class="token operator">=</span>dataservice -itd --privileged feisky/mysql-dataservice
f724d0816d7e47c0b2b1ff701e9a39239cb9b5ce70f597764c793b68131122bb
docker run --name<span class="token operator">=</span>app --network<span class="token operator">=</span>container:mysql -itd feisky/mysql-slow
81d3392ba25bb8436f6151662a13ff6182b6bc6f2a559fc2e9d873cd07224ab6<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>然后，再运行 docker ps 命令，确认三个容器都处在运行（Up）状态：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker <span class="token function">ps</span>
CONTAINER ID        IMAGE                      COMMAND                  CREATED             STATUS              PORTS                             NAMES
9a4e3c580963        feisky/mysql-slow          <span class="token string">"python /app.py"</span>         <span class="token number">42</span> seconds ago      Up <span class="token number">36</span> seconds                                         app
2a47aab18082        feisky/mysql-dataservice   <span class="token string">"python /dataservice…"</span>   <span class="token number">46</span> seconds ago      Up <span class="token number">41</span> seconds                                         dataservice
4c3ff7b24748        feisky/mysql:5.6           <span class="token string">"docker-entrypoint.s…"</span>   <span class="token number">47</span> seconds ago      Up <span class="token number">46</span> seconds       <span class="token number">3306</span>/tcp, <span class="token number">0.0</span>.0.0:10000-<span class="token operator">&gt;</span><span class="token number">80</span>/tcp   mysql<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> MySQL 数据库的启动过程，需要做一些初始化工作，这通常需要花费几分钟时间。你可以运行 docker logs 命令，查看它的启动过程。</p>
</li>
<li><p>当你看到下面这个输出时，说明 MySQL 初始化完成，可以接收外部请求了：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker logs -f mysql
<span class="token punctuation">..</span>.
<span class="token punctuation">..</span>. <span class="token punctuation">[</span>Note<span class="token punctuation">]</span> mysqld: ready <span class="token keyword">for</span> connections.
Version: <span class="token string">'5.6.42-log'</span>  socket: <span class="token string">'/var/run/mysqld/mysqld.sock'</span>  port: <span class="token number">3306</span>  MySQL Community Server <span class="token punctuation">(</span>GPL<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>而商品搜索应用则是在 10000 端口监听。你可以按 Ctrl+C ，停止 docker logs 命令；然后，执行下面的命令，确认它也已经正常运行。如果一切正常，你会看到 Index Page 的输出：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">curl</span> http://127.0.0.1:10000/
Index Page<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>接下来，运行 make init 命令，初始化数据库，并插入 10000 条商品信息。这个过程比较慢，比如在我的机器中，就花了十几分钟时间。耐心等待一段时间后，你会看到如下的输出：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">make</span> init
docker <span class="token builtin class-name">exec</span> -i mysql mysql -uroot -P3306 <span class="token operator">&lt;</span> tables.sql
<span class="token function">curl</span> http://127.0.0.1:10000/db/insert/products/10000
insert <span class="token number">10000</span> lines<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>接着，我们切换到第二个终端，访问一下商品搜索的接口，看看能不能找到想要的商品。执行如下的 curl 命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">curl</span> http://192.168.0.10:10000/products/geektime
Got data: <span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token number">15.364538192749023</span> sec<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p> 稍等一会儿，你会发现，这个接口返回的是空数据，而且处理时间超过 15 秒。这么慢的响应速度让人无法忍受，到底出了什么问题呢？</p>
<p> 既然今天用了 MySQL，你估计会猜到是慢查询的问题。</p>
<p> 不过别急，在具体分析前，为了避免在分析过程中客户端的请求结束，我们把 curl 命令放到一个循环里执行。同时，为了避免给系统过大压力，我们设置在每次查询后，都先等待 5 秒，然后再开始新的请求。</p>
</li>
<li><p>所以，你可以在终端二中，继续执行下面的命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token keyword">while</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token keyword">do</span> <span class="token function">curl</span> http://192.168.0.10:10000/products/geektime<span class="token punctuation">;</span> <span class="token function">sleep</span> <span class="token number">5</span><span class="token punctuation">;</span> <span class="token keyword">done</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> 接下来，重新回到终端一中，分析接口响应速度慢的原因。不过，重回终端一后，你会发现系统响应也明显变慢了，随便执行一个命令，都得停顿一会儿才能看到输出。</p>
</li>
<li><p>首先，我们在终端一执行 top 命令，分析系统的 CPU 使用情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">top</span>
<span class="token function">top</span> - <span class="token number">12</span>:02:15 up <span class="token number">6</span> days,  <span class="token number">8</span>:05,  <span class="token number">1</span> user,  load average: <span class="token number">0.66</span>, <span class="token number">0.72</span>, <span class="token number">0.59</span>
Tasks: <span class="token number">137</span> total,   <span class="token number">1</span> running,  <span class="token number">81</span> sleeping,   <span class="token number">0</span> stopped,   <span class="token number">0</span> zombie
%Cpu0  <span class="token builtin class-name">:</span>  <span class="token number">0.7</span> us,  <span class="token number">1.3</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">35.9</span> id, <span class="token number">62.1</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
%Cpu1  <span class="token builtin class-name">:</span>  <span class="token number">0.3</span> us,  <span class="token number">0.7</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">84.7</span> id, <span class="token number">14.3</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">0.0</span> si,  <span class="token number">0.0</span> st
KiB Mem <span class="token builtin class-name">:</span>  <span class="token number">8169300</span> total,  <span class="token number">7238472</span> free,   <span class="token number">546132</span> used,   <span class="token number">384696</span> buff/cache
KiB Swap:        <span class="token number">0</span> total,        <span class="token number">0</span> free,        <span class="token number">0</span> used.  <span class="token number">7316952</span> avail Mem

  PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
<span class="token number">27458</span> <span class="token number">999</span>       <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">833852</span>  <span class="token number">57968</span>  <span class="token number">13176</span> S   <span class="token number">1.7</span>  <span class="token number">0.7</span>   <span class="token number">0</span>:12.40 mysqld
<span class="token number">27617</span> root      <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">24348</span>   <span class="token number">9216</span>   <span class="token number">4692</span> S   <span class="token number">1.0</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:04.40 python
 <span class="token number">1549</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">236716</span>  <span class="token number">24568</span>   <span class="token number">9864</span> S   <span class="token number">0.3</span>  <span class="token number">0.3</span>  <span class="token number">51</span>:46.57 python3
<span class="token number">22421</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> I   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:01.16 kworker/u<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 观察 top 的输出，我们发现，两个 CPU 的 iowait 都比较高，特别是 CPU0，iowait 已经超过 60%。而具体到各个进程， CPU 使用率并不高，最高的也只有 1.7%。</p>
</li>
<li><p>既然 CPU 的嫌疑不大，那问题应该还是出在了 I/O 上。我们仍然在第一个终端，按下 Ctrl+C，停止 top 命令；然后，执行下面的 iostat 命令，看看有没有 I/O 性能问题：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ iostat -d -x <span class="token number">1</span>
Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
<span class="token punctuation">..</span>.
sda            <span class="token number">273.00</span>    <span class="token number">0.00</span>  <span class="token number">32568.00</span>      <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">0.00</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span>    <span class="token number">7.90</span>    <span class="token number">0.00</span>   <span class="token number">1.16</span>   <span class="token number">119.30</span>     <span class="token number">0.00</span>   <span class="token number">3.56</span>  <span class="token number">97.20</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>iostat 的输出你应该非常熟悉。观察这个界面，我们发现，磁盘 sda 每秒的读数据为 32 MB， 而 I/O 使用率高达 97% ，接近饱和，这说明，磁盘 sda 的读取确实碰到了性能瓶颈。</p>
</li>
<li><p>那要怎么知道，这些 I/O 请求到底是哪些进程导致的呢？当然可以找我们的老朋友， pidstat。接下来，在终端一中，按下 Ctrl+C 停止 iostat 命令，然后运行下面的 pidstat 命令，观察进程的 I/O 情况：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -d 选项表示展示进程的 I/O 情况</span>
$ pidstat -d <span class="token number">1</span>
<span class="token number">12</span>:04:11      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
<span class="token number">12</span>:04:12      <span class="token number">999</span>     <span class="token number">27458</span>  <span class="token number">32640.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>       <span class="token number">0</span>  mysqld
<span class="token number">12</span>:04:12        <span class="token number">0</span>     <span class="token number">27617</span>      <span class="token number">4.00</span>      <span class="token number">4.00</span>      <span class="token number">0.00</span>       <span class="token number">3</span>  python
<span class="token number">12</span>:04:12        <span class="token number">0</span>     <span class="token number">27864</span>      <span class="token number">0.00</span>      <span class="token number">4.00</span>      <span class="token number">0.00</span>       <span class="token number">0</span>  systemd-journal<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>从 pidstat 的输出可以看到，PID 为 27458 的 mysqld 进程正在进行大量的读，而且读取速度是 32 MB/s，跟刚才 iostat 的发现一致。两个结果一对比，我们自然就找到了磁盘 I/O 瓶颈的根源，即 mysqld 进程。</p>
<p>不过，这事儿还没完。我们自然要怀疑一下，为什么 mysqld 会去读取大量的磁盘数据呢？按照前面猜测，我们提到过，这有可能是个慢查询问题。</p>
<p>可是，回想一下，慢查询的现象大多是 CPU 使用率高（比如 100% ），但这里看到的却是 I/O 问题。看来，这并不是一个单纯的慢查询问题，我们有必要分析一下 MySQL 读取的数据。</p>
<p>要分析进程的数据读取，当然还要靠上一节用到过的 strace+ lsof 组合。</p>
</li>
<li><p>接下来，还是在终端一中，执行 strace 命令，并且指定 mysqld 的进程号 27458。我们知道，MySQL 是一个多线程的数据库应用，为了不漏掉这些线程的数据读取情况，你要记得在执行 stace 命令时，加上 -f 参数：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">strace</span> -f -p <span class="token number">27458</span>
<span class="token punctuation">[</span>pid <span class="token number">28014</span><span class="token punctuation">]</span> read<span class="token punctuation">(</span><span class="token number">38</span>, <span class="token string">"934EiwT363aak7VtqF1mHGa4LL4Dhbks"</span><span class="token punctuation">..</span>., <span class="token number">131072</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">131072</span>
<span class="token punctuation">[</span>pid <span class="token number">28014</span><span class="token punctuation">]</span> read<span class="token punctuation">(</span><span class="token number">38</span>, <span class="token string">"hSs7KBDepBqA6m4ce6i6iUfFTeG9Ot9z"</span><span class="token punctuation">..</span>., <span class="token number">20480</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">20480</span>
<span class="token punctuation">[</span>pid <span class="token number">28014</span><span class="token punctuation">]</span> read<span class="token punctuation">(</span><span class="token number">38</span>, <span class="token string">"NRhRjCSsLLBjTfdqiBRLvN9K6FRfqqLm"</span><span class="token punctuation">..</span>., <span class="token number">131072</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">131072</span>
<span class="token punctuation">[</span>pid <span class="token number">28014</span><span class="token punctuation">]</span> read<span class="token punctuation">(</span><span class="token number">38</span>, <span class="token string">"AKgsik4BilLb7y6OkwQUjjqGeCTQTaRl"</span><span class="token punctuation">..</span>., <span class="token number">24576</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">24576</span>
<span class="token punctuation">[</span>pid <span class="token number">28014</span><span class="token punctuation">]</span> read<span class="token punctuation">(</span><span class="token number">38</span>, <span class="token string">"hFMHx7FzUSqfFI22fQxWCpSnDmRjamaW"</span><span class="token punctuation">..</span>., <span class="token number">131072</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">131072</span>
<span class="token punctuation">[</span>pid <span class="token number">28014</span><span class="token punctuation">]</span> read<span class="token punctuation">(</span><span class="token number">38</span>, <span class="token string">"ajUzLmKqivcDJSkiw7QWf2ETLgvQIpfC"</span><span class="token punctuation">..</span>., <span class="token number">20480</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">20480</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>观察一会，你会发现，线程 28014 正在读取大量数据，且读取文件的描述符编号为 38。这儿的 38 又对应着哪个文件呢？我们可以执行下面的 lsof 命令，并且指定线程号 28014 ，具体查看这个可疑线程和可疑文件：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">lsof</span> -p <span class="token number">28014</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>奇怪的是，lsof 并没有给出任何输出。实际上，如果你查看 lsof 命令的返回值，就会发现，这个命令的执行失败了。</p>
<p>我们知道，在 SHELL 中，特殊标量 $? 表示上一条命令退出时的返回值。查看这个特殊标量，你会发现它的返回值是 1。可是别忘了，在 Linux 中，返回值为 0 ，才表示命令执行成功。返回值为 1，显然表明执行失败。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token builtin class-name">echo</span> <span class="token variable">$?</span>
<span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>事实上，通过查询 lsof 的文档，你会发现，-p 参数需要指定进程号，而我们刚才传入的是线程号，所以 lsof 失败了。你看，任何一个细节都可能成为性能分析的“拦路虎”。</p>
</li>
<li><p>回过头我们看，mysqld 的进程号是 27458，而 28014 只是它的一个线程。而且，如果你观察 一下 mysqld 进程的线程，你会发现，mysqld 其实还有很多正在运行的其他线程：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -t 表示显示线程，-a 表示显示命令行参数</span>
$ pstree -t -a -p <span class="token number">27458</span>
mysqld,27458 --log_bin<span class="token operator">=</span>on --sync_binlog<span class="token operator">=</span><span class="token number">1</span>
<span class="token punctuation">..</span>.
  ├─<span class="token punctuation">{</span>mysqld<span class="token punctuation">}</span>,27922
  ├─<span class="token punctuation">{</span>mysqld<span class="token punctuation">}</span>,27923
  └─<span class="token punctuation">{</span>mysqld<span class="token punctuation">}</span>,28014<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>找到了原因，lsof 的问题就容易解决了。把线程号换成进程号，继续执行 lsof 命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">lsof</span> -p <span class="token number">27458</span>
COMMAND  PID <span class="token environment constant">USER</span>   FD   TYPE DEVICE SIZE/OFF NODE NAME
<span class="token punctuation">..</span>.
​mysqld  <span class="token number">27458</span>      <span class="token number">999</span>   38u   REG    <span class="token number">8,1</span> <span class="token number">512440000</span> <span class="token number">2601895</span> /var/lib/mysql/test/products.MYD<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>这次我们得到了 lsof 的输出。从输出中可以看到， mysqld 进程确实打开了大量文件，而根据文件描述符（FD）的编号，我们知道，描述符为 38 的是一个路径为 /var/lib/mysql/test/products.MYD 的文件。这里注意， 38 后面的 u 表示， mysqld 以读写的方式访问文件。</p>
<p>看到这个文件，熟悉 MySQL 的你可能笑了：</p>
<ul>
<li>MYD 文件，是 MyISAM 引擎用来存储表数据的文件；</li>
<li>文件名就是数据表的名字；</li>
<li>而这个文件的父目录，也就是数据库的名字。</li>
</ul>
<p>换句话说，这个文件告诉我们，mysqld 在读取数据库 test 中的 products 表。</p>
</li>
<li><p>实际上，你可以执行下面的命令，查看 mysqld 在管理数据库 test 时的存储文件。不过要注意，由于 MySQL 运行在容器中，你需要通过 docker exec 到容器中查看：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker <span class="token builtin class-name">exec</span> -it mysql <span class="token function">ls</span> /var/lib/mysql/test/
db.opt    products.MYD  products.MYI  products.frm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>从这里你可以发现，/var/lib/mysql/test/ 目录中有四个文件，每个文件的作用分别是：</p>
<ul>
<li>MYD 文件用来存储表的数据；</li>
<li>MYI 文件用来存储表的索引；</li>
<li>frm 文件用来存储表的元信息（比如表结构）；</li>
<li>opt 文件则用来存储数据库的元信息（比如字符集、字符校验规则等）。</li>
</ul>
<p>当然，看到这些，你可能还有一个疑问，那就是，这些文件到底是不是 mysqld 正在使用的数据库文件呢？有没有可能是不再使用的旧数据呢？其实，这个很容易确认，查一下 mysqld 配置的数据路径即可。</p>
</li>
<li><p>你可以在终端一中，继续执行下面的命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker <span class="token builtin class-name">exec</span> -i -t mysql mysql -e <span class="token string">'show global variables like "%datadir%";'</span>
+---------------+-----------------+
<span class="token operator">|</span> Variable_name <span class="token operator">|</span> Value           <span class="token operator">|</span>
+---------------+-----------------+
<span class="token operator">|</span> datadir       <span class="token operator">|</span> /var/lib/mysql/ <span class="token operator">|</span>
+---------------+-----------------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里可以看到，/var/lib/mysql/ 确实是 mysqld 正在使用的数据存储目录。刚才分析得出的数据库 test 和数据表 products ，都是正在使用。</p>
<blockquote>
<p>注：其实 lsof 的结果已经可以确认，它们都是 mysqld 正在访问的文件。再查询 datadir ，只是想换一个思路，进一步确认一下。</p>
</blockquote>
</li>
<li><p>既然已经找出了数据库和表，接下来要做的，就是弄清楚数据库中正在执行什么样的 SQL 了。我们继续在终端一中，运行下面的 docker exec 命令，进入 MySQL 的命令行界面：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker <span class="token builtin class-name">exec</span> -i -t mysql mysql
<span class="token punctuation">..</span>.
​
Type <span class="token string">'help;'</span> or <span class="token string">'\h'</span> <span class="token keyword">for</span> help. Type <span class="token string">'<span class="token entity" title="\c">\c</span>'</span> to <span class="token function">clear</span> the current input statement.
​
mysql<span class="token operator">&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>为了保证 SQL 语句不截断，这里我们可以执行 show full processlist 命令。如果一切正常，你应该可以看到如下输出：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">mysql<span class="token operator">&gt;</span> show full processlist<span class="token punctuation">;</span>
+----+------+-----------------+------+---------+------+--------------+-----------------------------------------------------+
<span class="token operator">|</span> Id <span class="token operator">|</span> User <span class="token operator">|</span> Host            <span class="token operator">|</span> db   <span class="token operator">|</span> Command <span class="token operator">|</span> Time <span class="token operator">|</span> State        <span class="token operator">|</span> Info                                                <span class="token operator">|</span>
+----+------+-----------------+------+---------+------+--------------+-----------------------------------------------------+
<span class="token operator">|</span> <span class="token number">27</span> <span class="token operator">|</span> root <span class="token operator">|</span> localhost       <span class="token operator">|</span> <span class="token builtin class-name">test</span> <span class="token operator">|</span> Query   <span class="token operator">|</span>    <span class="token number">0</span> <span class="token operator">|</span> init         <span class="token operator">|</span> show full processlist                               <span class="token operator">|</span>
<span class="token operator">|</span> <span class="token number">28</span> <span class="token operator">|</span> root <span class="token operator">|</span> <span class="token number">127.0</span>.0.1:42262 <span class="token operator">|</span> <span class="token builtin class-name">test</span> <span class="token operator">|</span> Query   <span class="token operator">|</span>    <span class="token number">1</span> <span class="token operator">|</span> Sending data <span class="token operator">|</span> <span class="token keyword">select</span> * from products where <span class="token assign-left variable">productName</span><span class="token operator">=</span><span class="token string">'geektime'</span> <span class="token operator">|</span>
+----+------+-----------------+------+---------+------+--------------+-----------------------------------------------------+
<span class="token number">2</span> rows <span class="token keyword">in</span> <span class="token builtin class-name">set</span> <span class="token punctuation">(</span><span class="token number">0.00</span> sec<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这个输出中，</p>
<ul>
<li>db 表示数据库的名字；</li>
<li>Command 表示 SQL 类型；</li>
<li>Time 表示执行时间；</li>
<li>State 表示状态；</li>
<li>而 Info 则包含了完整的 SQL 语句。</li>
</ul>
<p>多执行几次 show full processlist 命令，你可看到 select * from products where productName=‘geektime’ 这条 SQL 语句的执行时间比较长。</p>
<p>再回忆一下，案例开始时，我们在终端二查询的产品名称 <a target="_blank" rel="noopener" href="http://192.168.0.10:10000/products/geektime，其中的">http://192.168.0.10:10000/products/geektime，其中的</a> geektime 也符合这条查询语句的条件。</p>
<p>我们知道，MySQL 的慢查询问题，很可能是没有利用好索引导致的，那这条查询语句是不是这样呢？我们又该怎么确认，查询语句是否利用了索引呢？</p>
</li>
<li><p>其实，MySQL 内置的 explain 命令，就可以帮你解决这个问题。继续在 MySQL 终端中，运行下面的 explain 命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 切换到 test 库</span>
mysql<span class="token operator">&gt;</span> use <span class="token builtin class-name">test</span><span class="token punctuation">;</span>
<span class="token comment"># 执行 explain 命令</span>
mysql<span class="token operator">&gt;</span> explain <span class="token keyword">select</span> * from products where <span class="token assign-left variable">productName</span><span class="token operator">=</span><span class="token string">'geektime'</span><span class="token punctuation">;</span>
+----+-------------+----------+------+---------------+------+---------+------+-------+-------------+
<span class="token operator">|</span> <span class="token function">id</span> <span class="token operator">|</span> select_type <span class="token operator">|</span> table    <span class="token operator">|</span> <span class="token builtin class-name">type</span> <span class="token operator">|</span> possible_keys <span class="token operator">|</span> key  <span class="token operator">|</span> key_len <span class="token operator">|</span> ref  <span class="token operator">|</span> rows  <span class="token operator">|</span> Extra       <span class="token operator">|</span>
+----+-------------+----------+------+---------------+------+---------+------+-------+-------------+
<span class="token operator">|</span>  <span class="token number">1</span> <span class="token operator">|</span> SIMPLE      <span class="token operator">|</span> products <span class="token operator">|</span> ALL  <span class="token operator">|</span> NULL          <span class="token operator">|</span> NULL <span class="token operator">|</span> NULL    <span class="token operator">|</span> NULL <span class="token operator">|</span> <span class="token number">10000</span> <span class="token operator">|</span> Using where <span class="token operator">|</span>
+----+-------------+----------+------+---------------+------+---------+------+-------+-------------+
<span class="token number">1</span> row <span class="token keyword">in</span> <span class="token builtin class-name">set</span> <span class="token punctuation">(</span><span class="token number">0.00</span> sec<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>观察这次的输出。这个界面中，有几个比较重要的字段需要你注意，我就以这个输出为例，分别解释一下：</p>
<ul>
<li>select_type 表示查询类型，而这里的 SIMPLE 表示此查询不包括 UNION 查询或者子查询；</li>
<li>table 表示数据表的名字，这里是 products；</li>
<li>type 表示查询类型，这里的 ALL 表示全表查询，但索引查询应该是 index 类型才对；</li>
<li>possible_keys 表示可能选用的索引，这里是 NULL；</li>
<li>key 表示确切会使用的索引，这里也是 NULL；</li>
<li>rows 表示查询扫描的行数，这里是 10000。</li>
</ul>
<p>根据这些信息，我们可以确定，这条查询语句压根儿没有使用索引，所以查询时，会扫描全表，并且扫描行数高达 10000 行。响应速度那么慢也就难怪了。</p>
<p>走到这一步，你应该很容易想到优化方法，没有索引那我们就自己建立，给 productName 建立索引就可以了。不过，增加索引前，你需要先弄清楚，这个表结构到底长什么样儿。</p>
</li>
<li><p>执行下面的 MySQL 命令，查询 products 表的结构，你会看到，它只有一个 id 主键，并不包括 productName 的索引：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">mysql<span class="token operator">&gt;</span> show create table products<span class="token punctuation">;</span>
<span class="token punctuation">..</span>.
<span class="token operator">|</span> products <span class="token operator">|</span> CREATE TABLE <span class="token variable"><span class="token variable">`</span>products<span class="token variable">`</span></span> <span class="token punctuation">(</span>
  <span class="token variable"><span class="token variable">`</span><span class="token function">id</span><span class="token variable">`</span></span> int<span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">)</span> NOT NULL,
  <span class="token variable"><span class="token variable">`</span>productCode<span class="token variable">`</span></span> text NOT NULL COMMENT <span class="token string">'产品代码'</span>,
  <span class="token variable"><span class="token variable">`</span>productName<span class="token variable">`</span></span> text NOT NULL COMMENT <span class="token string">'产品名称'</span>,
<span class="token punctuation">..</span>.
  PRIMARY KEY <span class="token punctuation">(</span><span class="token variable"><span class="token variable">`</span><span class="token function">id</span><span class="token variable">`</span></span><span class="token punctuation">)</span>
<span class="token punctuation">)</span> <span class="token assign-left variable">ENGINE</span><span class="token operator">=</span>MyISAM DEFAULT <span class="token assign-left variable">CHARSET</span><span class="token operator">=</span>utf8 <span class="token assign-left variable">ROW_FORMAT</span><span class="token operator">=</span>DYNAMIC <span class="token operator">|</span>
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>接下来，我们就可以给 productName 建立索引了，也就是执行下面的 CREATE INDEX 命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">mysql<span class="token operator">&gt;</span> CREATE INDEX products_index ON products <span class="token punctuation">(</span>productName<span class="token punctuation">)</span><span class="token punctuation">;</span>
ERROR <span class="token number">1170</span> <span class="token punctuation">(</span><span class="token number">42000</span><span class="token punctuation">)</span>: BLOB/TEXT <span class="token function">column</span> <span class="token string">'productName'</span> used <span class="token keyword">in</span> key specification without a key length<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>不过，醒目的 ERROR 告诉我们，这条命令运行失败了。根据错误信息，productName 是一个 BLOB/TEXT 类型，需要设置一个长度。所以，想要创建索引，就必须为 productName 指定一个前缀长度。</p>
</li>
<li><p>那前缀长度设置为多大比较合适呢？这里其实有专门的算法，即通过计算前缀长度的选择性，来确定索引的长度。不过，我们可以稍微简化一下，直接使用一个固定数值（比如 64），执行下面的命令创建索引：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">mysql<span class="token operator">&gt;</span> CREATE INDEX products_index ON products <span class="token punctuation">(</span>productName<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">))</span><span class="token punctuation">;</span>
Query OK, <span class="token number">10000</span> rows affected <span class="token punctuation">(</span><span class="token number">14.45</span> sec<span class="token punctuation">)</span>
Records: <span class="token number">10000</span>  Duplicates: <span class="token number">0</span>  Warnings: <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li><p>我们切换到终端二中，查看还在执行的 curl 命令的结果：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">Got data: ()in 15.383180141448975 sec
Got data: ()in 15.384996891021729 sec
Got data: ()in 0.0021054744720458984 sec
Got data: ()in 0.003951072692871094 sec<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>显然，查询时间已经从 15 秒缩短到了 3 毫秒。看来，没有索引果然就是这次性能问题的罪魁祸首，解决了索引，就解决了查询慢的问题。</p>
</li>
</ol>
<h4 id="28-2-案例思考"><a href="#28-2-案例思考" class="headerlink" title="28.2 案例思考"></a>28.2 案例思考</h4><p>案例开始时，我们启动的几个容器应用。除了 MySQL 和商品搜索应用外，还有一个 DataService 应用。为什么这个案例开始时，要运行一个看起来毫不相关的应用呢？</p>
<p>实际上，DataService 是一个严重影响 MySQL 性能的干扰应用。抛开上述索引优化方法不说，这个案例还有一种优化方法，也就是停止 DataService 应用。</p>
<p>接下来，我们就删除数据库索引，回到原来的状态；然后停止 DataService 应用，看看优化效果如何。</p>
<ol>
<li><p>在终端二中停止 curl 命令，然后回到终端一中，执行下面的命令删除索引：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 删除索引</span>
$ docker <span class="token builtin class-name">exec</span> -i -t mysql mysql
​
mysql<span class="token operator">&gt;</span> use <span class="token builtin class-name">test</span><span class="token punctuation">;</span>
mysql<span class="token operator">&gt;</span> DROP INDEX products_index ON products<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>在终端二中重新运行 curl 命令。当然，这次你会发现，处理时间又变慢了：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token keyword">while</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token keyword">do</span> <span class="token function">curl</span> http://192.168.0.10:10000/products/geektime<span class="token punctuation">;</span> <span class="token function">sleep</span> <span class="token number">5</span><span class="token punctuation">;</span> <span class="token keyword">done</span>
Got data: <span class="token punctuation">(</span><span class="token punctuation">)</span>in <span class="token number">16.884345054626465</span> sec<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>再次回到终端一中，执行下面的命令，停止 DataService 应用：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 停止 DataService 应用</span>
$ docker <span class="token function">rm</span> -f dataservice<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>最后，我们回到终端二中，观察 curl 的结果：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">Got data: <span class="token punctuation">(</span><span class="token punctuation">)</span>in <span class="token number">16.884345054626465</span> sec
Got data: <span class="token punctuation">(</span><span class="token punctuation">)</span>in <span class="token number">15.238174200057983</span> sec
Got data: <span class="token punctuation">(</span><span class="token punctuation">)</span>in <span class="token number">0.12604427337646484</span> sec
Got data: <span class="token punctuation">(</span><span class="token punctuation">)</span>in <span class="token number">0.1101069450378418</span> sec
Got data: <span class="token punctuation">(</span><span class="token punctuation">)</span>in <span class="token number">0.11235237121582031</span> sec<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 果然，停止 DataService 后，处理时间从 15 秒缩短到了 0.1 秒，虽然比不上增加索引后的 3 毫秒，但相对于 15 秒来说，优化效果还是非常明显的。</p>
<p> 那么，这种情况下，还有没有 I/O 瓶颈了呢？</p>
</li>
<li><p>我们切换到终端一中，运行下面的 vmstat 命令（注意不是 iostat，稍后解释原因），观察 I/O 的变化情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">vmstat</span> <span class="token number">1</span>
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   <span class="token function">free</span>   buff  cache   si   so    bi    bo   <span class="token keyword">in</span>   cs us sy <span class="token function">id</span> wa st
 <span class="token number">0</span>  <span class="token number">1</span>      <span class="token number">0</span> <span class="token number">6809304</span>   <span class="token number">1368</span> <span class="token number">856744</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">32640</span>     <span class="token number">0</span>   <span class="token number">52</span>  <span class="token number">478</span>  <span class="token number">1</span>  <span class="token number">0</span> <span class="token number">50</span> <span class="token number">49</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">1</span>      <span class="token number">0</span> <span class="token number">6776620</span>   <span class="token number">1368</span> <span class="token number">889456</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">32640</span>     <span class="token number">0</span>   <span class="token number">33</span>  <span class="token number">490</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">50</span> <span class="token number">49</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6747540</span>   <span class="token number">1368</span> <span class="token number">918576</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">29056</span>     <span class="token number">0</span>   <span class="token number">42</span>  <span class="token number">568</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">56</span> <span class="token number">44</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6747540</span>   <span class="token number">1368</span> <span class="token number">918576</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>     <span class="token number">0</span>   <span class="token number">40</span>  <span class="token number">141</span>  <span class="token number">1</span>  <span class="token number">0</span> <span class="token number">100</span>  <span class="token number">0</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6747160</span>   <span class="token number">1368</span> <span class="token number">918576</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>     <span class="token number">0</span>   <span class="token number">40</span>  <span class="token number">148</span>  <span class="token number">0</span>  <span class="token number">1</span> <span class="token number">99</span>  <span class="token number">0</span>  <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<blockquote>
<p>在查看 I/O 情况时，我并没用 iostat 命令，而是用了 vmstat。其实，相对于 iostat 来说，vmstat 可以同时提供 CPU、内存和 I/O 的使用情况。</p>
</blockquote>
</li>
</ol>
<h4 id="28-3-思考"><a href="#28-3-思考" class="headerlink" title="28.3 思考"></a>28.3 思考</h4><p>停止 DataService 后，商品搜索应用的处理时间，从 15 秒缩短到了 0.1 秒。这是为什么呢？</p>
<p>我给个小小的提示。你可以先查看 <a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/blob/master/mysql-slow/dataservice.py">dataservice.py</a>，你会发现，DataService 实际上是在读写一个仅包括 “data” 字符串的小文件。不过在读取文件前，它会先把 /proc/sys/vm/drop_caches 改成 1。</p>
<p>答案：echo 1&gt;/proc/sys/vm/drop_caches表示释放pagecache，也就是文件缓存，而mysql读书的数据就是文件缓存，dataservice不停的释放文件缓存，就导致MySQL都无法利用磁盘缓存，也就慢了。</p>
<h3 id="29-案例篇：Redis响应严重延迟，如何解决？"><a href="#29-案例篇：Redis响应严重延迟，如何解决？" class="headerlink" title="29 | 案例篇：Redis响应严重延迟，如何解决？"></a>29 | 案例篇：Redis响应严重延迟，如何解决？</h3><h4 id="29-1-案例"><a href="#29-1-案例" class="headerlink" title="29.1 案例"></a>29.1 案例</h4><blockquote>
<p>机器配置： 2 CPU, 8 GB 内存。</p>
<p>安装软件：<code>apt install docker.io sysstat</code>。</p>
</blockquote>
<p>今天的案例由 Python 应用 +Redis 两部分组成。其中，Python 应用是一个基于 Flask 的应用，它会利用 Redis ，来管理应用程序的缓存，并对外提供三个 HTTP 接口：</p>
<ul>
<li><p>/：返回 hello redis；</p>
</li>
<li><p>/init/：插入指定数量的缓存数据，如果不指定数量，默认的是 5000 条；</p>
<p>  缓存的键格式为 uuid；</p>
<p>  缓存的值为 good、bad 或 normal 三者之一。</p>
</li>
<li><p>/get_cache/<type_name>：查询指定值的缓存数据，并返回处理时间。其中，type_name 参数只支持 good, bad 和 normal（也就是找出具有相同 value 的 key 列表）。</type_name></p>
</li>
</ul>
<ol>
<li><p>在第一个终端中，执行下面的命令，运行本次案例要分析的目标应用。正常情况下，你应该可以看到下面的输出：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 注意下面的随机字符串是容器 ID，每次运行均会不同，并且你不需要关注它</span>
$ docker run --name<span class="token operator">=</span>redis -itd -p <span class="token number">10000</span>:80 feisky/redis-server
ec41cb9e4dd5cb7079e1d9f72b7cee7de67278dbd3bd0956b4c0846bff211803
$ docker run --name<span class="token operator">=</span>app --network<span class="token operator">=</span>container:redis -itd feisky/redis-app
2c54eb252d0552448320d9155a2618b799a1e71d7289ec7277a61e72a9de5fd0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>然后，再运行 docker ps 命令，确认两个容器都处于运行（Up）状态：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker <span class="token function">ps</span>
CONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS              PORTS                             NAMES
2c54eb252d05        feisky/redis-app      <span class="token string">"python /app.py"</span>         <span class="token number">48</span> seconds ago      Up <span class="token number">47</span> seconds                                         app
ec41cb9e4dd5        feisky/redis-server   <span class="token string">"docker-entrypoint.s…"</span>   <span class="token number">49</span> seconds ago      Up <span class="token number">48</span> seconds       <span class="token number">6379</span>/tcp, <span class="token number">0.0</span>.0.0:10000-<span class="token operator">&gt;</span><span class="token number">80</span>/tcp   redis<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>我们切换到第二个终端，使用 curl 工具，访问应用首页。如果你看到 hello redis 的输出，说明应用正常启动：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">curl</span> http://192.168.0.10:10000/
hello redis<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>接下来，继续在终端二中，执行下面的 curl 命令，来调用应用的 /init 接口，初始化 Redis 缓存，并且插入 5000 条缓存信息。这个过程比较慢，比如我的机器就花了十几分钟时间。耐心等一会儿后，你会看到下面这行输出：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 案例插入 5000 条数据，在实践时可以根据磁盘的类型适当调整，比如使用 SSD 时可以调大，而 HDD 可以适当调小</span>
$ <span class="token function">curl</span> http://192.168.0.10:10000/init/5000
<span class="token punctuation">{</span><span class="token string">"elapsed_seconds"</span>:30.26814079284668,<span class="token string">"keys_initialized"</span>:5000<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li><p>继续执行下一个命令，访问应用的缓存查询接口。如果一切正常，你会看到如下输出：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">curl</span> http://192.168.0.10:10000/get_cache
<span class="token punctuation">{</span><span class="token string">"count"</span>:1677,<span class="token string">"data"</span>:<span class="token punctuation">[</span><span class="token string">"d97662fa-06ac-11e9-92c7-0242ac110002"</span>,<span class="token punctuation">..</span>.<span class="token punctuation">]</span>,<span class="token string">"elapsed_seconds"</span>:10.545469760894775,<span class="token string">"type"</span><span class="token builtin class-name">:</span><span class="token string">"good"</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>为了避免分析过程中客户端的请求结束，在进行性能分析前，我们先要把 curl 命令放到一个循环里来执行。你可以在终端二中，继续执行下面的命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token keyword">while</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token keyword">do</span> <span class="token function">curl</span> http://192.168.0.10:10000/get_cache<span class="token punctuation">;</span> <span class="token keyword">done</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>在终端一中执行 top 命令，分析系统的 CPU 使用情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">top</span>
<span class="token function">top</span> - <span class="token number">12</span>:46:18 up <span class="token number">11</span> days,  <span class="token number">8</span>:49,  <span class="token number">1</span> user,  load average: <span class="token number">1.36</span>, <span class="token number">1.36</span>, <span class="token number">1.04</span>
Tasks: <span class="token number">137</span> total,   <span class="token number">1</span> running,  <span class="token number">79</span> sleeping,   <span class="token number">0</span> stopped,   <span class="token number">0</span> zombie
%Cpu0  <span class="token builtin class-name">:</span>  <span class="token number">6.0</span> us,  <span class="token number">2.7</span> sy,  <span class="token number">0.0</span> ni,  <span class="token number">5.7</span> id, <span class="token number">84.7</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">1.0</span> si,  <span class="token number">0.0</span> st
%Cpu1  <span class="token builtin class-name">:</span>  <span class="token number">1.0</span> us,  <span class="token number">3.0</span> sy,  <span class="token number">0.0</span> ni, <span class="token number">94.7</span> id,  <span class="token number">0.0</span> wa,  <span class="token number">0.0</span> hi,  <span class="token number">1.3</span> si,  <span class="token number">0.0</span> st
KiB Mem <span class="token builtin class-name">:</span>  <span class="token number">8169300</span> total,  <span class="token number">7342244</span> free,   <span class="token number">432912</span> used,   <span class="token number">394144</span> buff/cache
KiB Swap:        <span class="token number">0</span> total,        <span class="token number">0</span> free,        <span class="token number">0</span> used.  <span class="token number">7478748</span> avail Mem

  PID <span class="token environment constant">USER</span>      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 <span class="token number">9181</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">193004</span>  <span class="token number">27304</span>   <span class="token number">8716</span> S   <span class="token number">8.6</span>  <span class="token number">0.3</span>   <span class="token number">0</span>:07.15 python
 <span class="token number">9085</span> systemd+  <span class="token number">20</span>   <span class="token number">0</span>   <span class="token number">28352</span>   <span class="token number">9760</span>   <span class="token number">1860</span> D   <span class="token number">5.0</span>  <span class="token number">0.1</span>   <span class="token number">0</span>:04.34 redis-server
  <span class="token number">368</span> root      <span class="token number">20</span>   <span class="token number">0</span>       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> D   <span class="token number">1.0</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:33.88 jbd2/sda1-8
  <span class="token number">149</span> root       <span class="token number">0</span> -20       <span class="token number">0</span>      <span class="token number">0</span>      <span class="token number">0</span> I   <span class="token number">0.3</span>  <span class="token number">0.0</span>   <span class="token number">0</span>:10.63 kworker/0:1H
 <span class="token number">1549</span> root      <span class="token number">20</span>   <span class="token number">0</span>  <span class="token number">236716</span>  <span class="token number">24576</span>   <span class="token number">9864</span> S   <span class="token number">0.3</span>  <span class="token number">0.3</span>  <span class="token number">91</span>:37.30 python3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 观察 top 的输出可以发现，CPU0 的 iowait 比较高，已经达到了 84%；而各个进程的 CPU 使用率都不太高，最高的 python 和 redis-server ，也分别只有 8% 和 5%。再看内存，总内存 8GB，剩余内存还有 7GB 多，显然内存也没啥问题。</p>
<p> 综合 top 的信息，最有嫌疑的就是 iowait。所以，接下来还是要继续分析，是不是 I/O 问题。</p>
</li>
<li><p>还在第一个终端中，先按下 Ctrl+C，停止 top 命令；然后，执行下面的 iostat 命令，查看有没有 I/O 性能问题：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ iostat -d -x <span class="token number">1</span>
Device            r/s     w/s     rkB/s     wkB/s   rrqm/s   wrqm/s  %rrqm  %wrqm r_await w_await aqu-sz rareq-sz wareq-sz  svctm  %util
<span class="token punctuation">..</span>.
sda              <span class="token number">0.00</span>  <span class="token number">492.00</span>      <span class="token number">0.00</span>   <span class="token number">2672.00</span>     <span class="token number">0.00</span>   <span class="token number">176.00</span>   <span class="token number">0.00</span>  <span class="token number">26.35</span>    <span class="token number">0.00</span>    <span class="token number">1.76</span>   <span class="token number">0.00</span>     <span class="token number">0.00</span>     <span class="token number">5.43</span>   <span class="token number">0.00</span>   <span class="token number">0.00</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 观察 iostat 的输出，我们发现，磁盘 sda 每秒的写数据（wkB/s）为 2.5MB，I/O 使用率（%util）是 0。看来，虽然有些 I/O 操作，但并没导致磁盘的 I/O 瓶颈。</p>
<p> 排查一圈儿下来，CPU 和内存使用没问题，I/O 也没有瓶颈，接下来好像就没啥分析方向了？</p>
<p> 回想一下，今天的案例问题是从 Redis 缓存中查询数据慢。对查询来说，对应的 I/O 应该是磁盘的读操作，但刚才我们用 iostat 看到的却是写操作。虽说 I/O 本身并没有性能瓶颈，但这里的磁盘写也是比较奇怪的。为什么会有磁盘写呢？那我们就得知道，到底是哪个进程在写磁盘。</p>
</li>
<li><p>要知道 I/O 请求来自哪些进程，还是要靠我们的老朋友 pidstat。在终端一中运行下面的 pidstat 命令，观察进程的 I/O 情况：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ pidstat -d <span class="token number">1</span>
<span class="token number">12</span>:49:35      <span class="token environment constant">UID</span>       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
<span class="token number">12</span>:49:36        <span class="token number">0</span>       <span class="token number">368</span>      <span class="token number">0.00</span>     <span class="token number">16.00</span>      <span class="token number">0.00</span>      <span class="token number">86</span>  jbd2/sda1-8
<span class="token number">12</span>:49:36      <span class="token number">100</span>      <span class="token number">9085</span>      <span class="token number">0.00</span>    <span class="token number">636.00</span>      <span class="token number">0.00</span>       <span class="token number">1</span>  redis-server<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 从 pidstat 的输出，我们看到，I/O 最多的进程是 PID 为 9085 的 redis-server，并且它也刚好是在写磁盘。这说明，确实是 redis-server 在进行磁盘写。</p>
<p> 当然，光找到读写磁盘的进程还不够，我们还要再用 strace+lsof 组合，看看 redis-server 到底在写什么。</p>
</li>
<li><p>接下来，还是在终端一中，执行 strace 命令，并且指定 redis-server 的进程号 9085：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -f 表示跟踪子进程和子线程，-T 表示显示系统调用的时长，-tt 表示显示跟踪时间</span>
$ <span class="token function">strace</span> -f -T -tt -p <span class="token number">9085</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.826131 epoll_pwait<span class="token punctuation">(</span><span class="token number">5</span>, <span class="token punctuation">[</span><span class="token punctuation">{</span>EPOLLIN, <span class="token punctuation">{</span>u32<span class="token operator">=</span><span class="token number">8</span>, <span class="token assign-left variable">u64</span><span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">]</span>, <span class="token number">10128</span>, <span class="token number">65</span>, NULL, <span class="token number">8</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">&lt;</span><span class="token number">0.00005</span><span class="token operator"><span class="token file-descriptor important">5</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.826301 read<span class="token punctuation">(</span><span class="token number">8</span>, <span class="token string">"*2<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$3</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>GET<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$41</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>uuid:5b2e76cc-"</span><span class="token punctuation">..</span>., <span class="token number">16384</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">61</span> <span class="token operator">&lt;</span><span class="token number">0.00007</span><span class="token operator"><span class="token file-descriptor important">1</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.826477 read<span class="token punctuation">(</span><span class="token number">3</span>, 0x7fff366a5747, <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">=</span> -1 EAGAIN <span class="token punctuation">(</span>Resource temporarily unavailable<span class="token punctuation">)</span> <span class="token operator">&lt;</span><span class="token number">0.00006</span><span class="token operator"><span class="token file-descriptor important">3</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.826645 write<span class="token punctuation">(</span><span class="token number">8</span>, <span class="token string">"<span class="token variable">$3</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>bad<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>"</span>, <span class="token number">9</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">9</span> <span class="token operator">&lt;</span><span class="token number">0.00017</span><span class="token operator"><span class="token file-descriptor important">3</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.826907 epoll_pwait<span class="token punctuation">(</span><span class="token number">5</span>, <span class="token punctuation">[</span><span class="token punctuation">{</span>EPOLLIN, <span class="token punctuation">{</span>u32<span class="token operator">=</span><span class="token number">8</span>, <span class="token assign-left variable">u64</span><span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">]</span>, <span class="token number">10128</span>, <span class="token number">65</span>, NULL, <span class="token number">8</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">&lt;</span><span class="token number">0.00003</span><span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.827030 read<span class="token punctuation">(</span><span class="token number">8</span>, <span class="token string">"*2<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$3</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>GET<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$41</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>uuid:55862ada-"</span><span class="token punctuation">..</span>., <span class="token number">16384</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">61</span> <span class="token operator">&lt;</span><span class="token number">0.00004</span><span class="token operator"><span class="token file-descriptor important">4</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.827149 read<span class="token punctuation">(</span><span class="token number">3</span>, 0x7fff366a5747, <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">=</span> -1 EAGAIN <span class="token punctuation">(</span>Resource temporarily unavailable<span class="token punctuation">)</span> <span class="token operator">&lt;</span><span class="token number">0.00004</span><span class="token operator"><span class="token file-descriptor important">3</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.827285 write<span class="token punctuation">(</span><span class="token number">8</span>, <span class="token string">"<span class="token variable">$3</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>bad<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>"</span>, <span class="token number">9</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">9</span> <span class="token operator">&lt;</span><span class="token number">0.00014</span><span class="token operator"><span class="token file-descriptor important">1</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.827514 epoll_pwait<span class="token punctuation">(</span><span class="token number">5</span>, <span class="token punctuation">[</span><span class="token punctuation">{</span>EPOLLIN, <span class="token punctuation">{</span>u32<span class="token operator">=</span><span class="token number">8</span>, <span class="token assign-left variable">u64</span><span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">]</span>, <span class="token number">10128</span>, <span class="token number">64</span>, NULL, <span class="token number">8</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">&lt;</span><span class="token number">0.00004</span><span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.827641 read<span class="token punctuation">(</span><span class="token number">8</span>, <span class="token string">"*2<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$3</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>GET<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$41</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>uuid:53522908-"</span><span class="token punctuation">..</span>., <span class="token number">16384</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">61</span> <span class="token operator">&lt;</span><span class="token number">0.00004</span><span class="token operator"><span class="token file-descriptor important">3</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.827784 read<span class="token punctuation">(</span><span class="token number">3</span>, 0x7fff366a5747, <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">=</span> -1 EAGAIN <span class="token punctuation">(</span>Resource temporarily unavailable<span class="token punctuation">)</span> <span class="token operator">&lt;</span><span class="token number">0.00003</span><span class="token operator"><span class="token file-descriptor important">4</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.827945 write<span class="token punctuation">(</span><span class="token number">8</span>, <span class="token string">"<span class="token variable">$4</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>good<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>"</span>, <span class="token number">10</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">10</span> <span class="token operator">&lt;</span><span class="token number">0.00028</span><span class="token operator"><span class="token file-descriptor important">8</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.828339 epoll_pwait<span class="token punctuation">(</span><span class="token number">5</span>, <span class="token punctuation">[</span><span class="token punctuation">{</span>EPOLLIN, <span class="token punctuation">{</span>u32<span class="token operator">=</span><span class="token number">8</span>, <span class="token assign-left variable">u64</span><span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">]</span>, <span class="token number">10128</span>, <span class="token number">63</span>, NULL, <span class="token number">8</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">&lt;</span><span class="token number">0.00005</span><span class="token operator"><span class="token file-descriptor important">7</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.828486 read<span class="token punctuation">(</span><span class="token number">8</span>, <span class="token string">"*3<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$4</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>SADD<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$4</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>good<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$36</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>535"</span><span class="token punctuation">..</span>., <span class="token number">16384</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">67</span> <span class="token operator">&lt;</span><span class="token number">0.00004</span><span class="token operator"><span class="token file-descriptor important">0</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.828623 read<span class="token punctuation">(</span><span class="token number">3</span>, 0x7fff366a5747, <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">=</span> -1 EAGAIN <span class="token punctuation">(</span>Resource temporarily unavailable<span class="token punctuation">)</span> <span class="token operator">&lt;</span><span class="token number">0.00005</span><span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.828760 write<span class="token punctuation">(</span><span class="token number">7</span>, <span class="token string">"*3<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$4</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>SADD<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$4</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>good<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$36</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>535"</span><span class="token punctuation">..</span>., <span class="token number">67</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">67</span> <span class="token operator">&lt;</span><span class="token number">0.00006</span><span class="token operator"><span class="token file-descriptor important">0</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.828970 fdatasync<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0</span> <span class="token operator">&lt;</span><span class="token number">0.00541</span><span class="token operator"><span class="token file-descriptor important">5</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:20:16.834493 write<span class="token punctuation">(</span><span class="token number">8</span>, <span class="token string">":1<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>"</span>, <span class="token number">4</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">4</span> <span class="token operator">&lt;</span><span class="token number">0.00025</span><span class="token operator"><span class="token file-descriptor important">0</span>&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>事实上，从系统调用来看， epoll_pwait、read、write、fdatasync 这些系统调用都比较频繁。那么，刚才观察到的写磁盘，应该就是 write 或者 fdatasync 导致的了。</p>
</li>
<li><p>接着再来运行 lsof 命令，找出这些系统调用的操作对象：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">lsof</span> -p <span class="token number">9085</span>
redis-ser <span class="token number">9085</span> systemd-network    3r     FIFO   <span class="token number">0,12</span>      0t0 <span class="token number">15447970</span> pipe
redis-ser <span class="token number">9085</span> systemd-network    4w     FIFO   <span class="token number">0,12</span>      0t0 <span class="token number">15447970</span> pipe
redis-ser <span class="token number">9085</span> systemd-network    5u  a_inode   <span class="token number">0,13</span>        <span class="token number">0</span>    <span class="token number">10179</span> <span class="token punctuation">[</span>eventpoll<span class="token punctuation">]</span>
redis-ser <span class="token number">9085</span> systemd-network    6u     sock    <span class="token number">0,9</span>      0t0 <span class="token number">15447972</span> protocol: TCP
redis-ser <span class="token number">9085</span> systemd-network    7w      REG    <span class="token number">8,1</span>  <span class="token number">8830146</span>  <span class="token number">2838532</span> /data/appendonly.aof
redis-ser <span class="token number">9085</span> systemd-network    8u     sock    <span class="token number">0,9</span>      0t0 <span class="token number">15448709</span> protocol: TCP<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>现在你会发现，描述符编号为 3 的是一个 pipe 管道，5 号是 eventpoll，7 号是一个普通文件，而 8 号是一个 TCP socket。</p>
<p>结合磁盘写的现象，我们知道，只有 7 号普通文件才会产生磁盘写，而它操作的文件路径是 /data/appendonly.aof，相应的系统调用包括 write 和 fdatasync。</p>
<p>如果你对 Redis 的持久化配置比较熟，看到这个文件路径以及 fdatasync 的系统调用，你应该能想到，这对应着正是 Redis 持久化配置中的 appendonly 和 appendfsync 选项。很可能是因为它们的配置不合理，导致磁盘写比较多。</p>
<p>接下来就验证一下这个猜测，我们可以通过 Redis 的命令行工具，查询这两个选项的配置。</p>
</li>
<li><p>继续在终端一中，运行下面的命令，查询 appendonly 和 appendfsync 的配置：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker <span class="token builtin class-name">exec</span> -it redis redis-cli config get <span class="token string">'append*'</span>
<span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">"appendfsync"</span>
<span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">"always"</span>
<span class="token number">3</span><span class="token punctuation">)</span> <span class="token string">"appendonly"</span>
<span class="token number">4</span><span class="token punctuation">)</span> <span class="token string">"yes"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>从这个结果你可以发现，appendfsync 配置的是 always，而 appendonly 配置的是 yes。这两个选项的详细含义，你可以从 <a target="_blank" rel="noopener" href="https://redis.io/topics/persistence">Redis Persistence</a> 的文档中查到，这里我做一下简单介绍。</p>
<p>Redis 提供了两种数据持久化的方式，分别是快照和追加文件。</p>
<ol>
<li><p>快照方式，会按照指定的时间间隔，生成数据的快照，并且保存到磁盘文件中。为了避免阻塞主进程，Redis 还会 fork 出一个子进程，来负责快照的保存。这种方式的性能好，无论是备份还是恢复，都比追加文件好很多。</p>
<p> 不过，它的缺点也很明显。在数据量大时，fork 子进程需要用到比较大的内存，保存数据也很耗时。所以，你需要设置一个比较长的时间间隔来应对，比如至少 5 分钟。这样，如果发生故障，你丢失的就是几分钟的数据。</p>
</li>
<li><p>追加文件，则是用在文件末尾追加记录的方式，对 Redis 写入的数据，依次进行持久化，所以它的持久化也更安全。</p>
<p> 此外，它还提供了一个用 appendfsync 选项设置 fsync 的策略，确保写入的数据都落到磁盘中，具体选项包括 always、everysec、no 等。</p>
<ul>
<li>always 表示，每个操作都会执行一次 fsync，是最为安全的方式；</li>
<li>everysec 表示，每秒钟调用一次 fsync ，这样可以保证即使是最坏情况下，也只丢失 1 秒的数据；</li>
<li>而 no 表示交给操作系统来处理。</li>
</ul>
</li>
</ol>
<p>回忆一下我们刚刚看到的配置，appendfsync 配置的是 always，意味着每次写数据时，都会调用一次 fsync，从而造成比较大的磁盘 I/O 压力。</p>
<p>当然，你还可以用 strace ，观察这个系统调用的执行情况。比如通过 -e 选项指定 fdatasync 后，你就会得到下面的结果：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">strace</span> -f -p <span class="token number">9085</span> -T -tt -e fdatasync
strace: Process <span class="token number">9085</span> attached with <span class="token number">4</span> threads
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:22:52.013547 fdatasync<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0</span> <span class="token operator">&lt;</span><span class="token number">0.00711</span><span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:22:52.022467 fdatasync<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0</span> <span class="token operator">&lt;</span><span class="token number">0.00857</span><span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span>
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:22:52.032223 fdatasync<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0</span> <span class="token operator">&lt;</span><span class="token number">0.00676</span><span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span>
<span class="token punctuation">..</span>.
<span class="token punctuation">[</span>pid  <span class="token number">9085</span><span class="token punctuation">]</span> <span class="token number">14</span>:22:52.139629 fdatasync<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0</span> <span class="token operator">&lt;</span><span class="token number">0.00818</span><span class="token operator"><span class="token file-descriptor important">3</span>&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>从这里你可以看到，每隔 10ms 左右，就会有一次 fdatasync 调用，并且每次调用本身也要消耗 7~8ms。</p>
<p>不管哪种方式，都可以验证我们的猜想，配置确实不合理。这样，我们就找出了 Redis 正在进行写入的文件，也知道了产生大量 I/O 的原因。</p>
</li>
<li><p>不过，回到最初的疑问，为什么查询时会有磁盘写呢？按理来说不应该只有数据的读取吗？这就需要我们再来审查一下 strace -f -T -tt -p 9085 的结果。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">read<span class="token punctuation">(</span><span class="token number">8</span>, <span class="token string">"*2<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$3</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>GET<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$41</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>uuid:53522908-"</span><span class="token punctuation">..</span>., <span class="token number">16384</span><span class="token punctuation">)</span>
write<span class="token punctuation">(</span><span class="token number">8</span>, <span class="token string">"<span class="token variable">$4</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>good<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>"</span>, <span class="token number">10</span><span class="token punctuation">)</span>
read<span class="token punctuation">(</span><span class="token number">8</span>, <span class="token string">"*3<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$4</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>SADD<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$4</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>good<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$36</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>535"</span><span class="token punctuation">..</span>., <span class="token number">16384</span><span class="token punctuation">)</span>
write<span class="token punctuation">(</span><span class="token number">7</span>, <span class="token string">"*3<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$4</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>SADD<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$4</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>good<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span><span class="token variable">$36</span><span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>535"</span><span class="token punctuation">..</span>., <span class="token number">67</span><span class="token punctuation">)</span>
write<span class="token punctuation">(</span><span class="token number">8</span>, <span class="token string">":1<span class="token entity" title="\r">\r</span><span class="token entity" title="\n">\n</span>"</span>, <span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>细心的你应该记得，根据 lsof 的分析，文件描述符编号为 7 的是一个普通文件 /data/appendonly.aof，而编号为 8 的是 TCP socket。而观察上面的内容，8 号对应的 TCP 读写，是一个标准的“请求 - 响应”格式，即：</p>
<ul>
<li>从 socket 读取 GET uuid:53522908-… 后，响应 good；</li>
<li>再从 socket 读取 SADD good 535… 后，响应 1。</li>
</ul>
<p>对 Redis 来说，SADD 是一个写操作，所以 Redis 还会把它保存到用于持久化的 appendonly.aof 文件中。</p>
<p>观察更多的 strace 结果，你会发现，每当 GET 返回 good 时，随后都会有一个 SADD 操作，这也就导致了，明明是查询接口，Redis 却有大量的磁盘写。</p>
<p>到这里，我们就找出了 Redis 写磁盘的原因。不过，在下最终结论前，我们还是要确认一下，8 号 TCP socket 对应的 Redis 客户端，到底是不是我们的案例应用。</p>
<p>我们可以给 lsof 命令加上 -i 选项，找出 TCP socket 对应的 TCP 连接信息。不过，由于 Redis 和 Python 应用都在容器中运行，我们需要进入容器的网络命名空间内部，才能看到完整的 TCP 连接。</p>
</li>
<li><p>还是在终端一中，运行下面的命令：</p>
<blockquote>
<p>注意：下面的命令用到的 <a target="_blank" rel="noopener" href="http://man7.org/linux/man-pages/man1/nsenter.1.html">nsenter</a> 工具，可以进入容器命名空间。如果你的系统没有安装，请运行下面命令安装 nsenter：</p>
<p>docker run —rm -v /usr/local/bin:/target jpetazzo/nsenter</p>
</blockquote>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 由于这两个容器共享同一个网络命名空间，所以我们只需要进入 app 的网络命名空间即可</span>
$ <span class="token assign-left variable">PID</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span>docker inspect --format <span class="token punctuation">{</span><span class="token punctuation">{</span>.State.Pid<span class="token punctuation">}</span><span class="token punctuation">}</span> app<span class="token variable">)</span></span>
<span class="token comment"># -i 表示显示网络套接字信息</span>
$ nsenter --target <span class="token variable">$PID</span> --net -- <span class="token function">lsof</span> -i
COMMAND    PID            <span class="token environment constant">USER</span>   FD   TYPE   DEVICE SIZE/OFF NODE NAME
redis-ser <span class="token number">9085</span> systemd-network    6u  IPv4 <span class="token number">15447972</span>      0t0  TCP localhost:6379 <span class="token punctuation">(</span>LISTEN<span class="token punctuation">)</span>
redis-ser <span class="token number">9085</span> systemd-network    8u  IPv4 <span class="token number">15448709</span>      0t0  TCP localhost:6379-<span class="token operator">&gt;</span>localhost:32996 <span class="token punctuation">(</span>ESTABLISHED<span class="token punctuation">)</span>
python    <span class="token number">9181</span>            root    3u  IPv4 <span class="token number">15448677</span>      0t0  TCP *:http <span class="token punctuation">(</span>LISTEN<span class="token punctuation">)</span>
python    <span class="token number">9181</span>            root    5u  IPv4 <span class="token number">15449632</span>      0t0  TCP localhost:32996-<span class="token operator">&gt;</span>localhost:6379 <span class="token punctuation">(</span>ESTABLISHED<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以看到，redis-server 的 8 号文件描述符，对应 TCP 连接 localhost:6379-&gt;localhost:32996。其中， localhost:6379 是 redis-server 自己的监听端口，自然 localhost:32996 就是 redis 的客户端。再观察最后一行，localhost:32996 对应的，正是我们的 Python 应用程序（进程号为 9181）。</p>
<p>历经各种波折，我们总算找出了 Redis 响应延迟的潜在原因。总结一下，我们找到两个问题。</p>
<ul>
<li>第一个问题，Redis 配置的 appendfsync 是 always，这就导致 Redis 每次的写操作，都会触发 fdatasync 系统调用。今天的案例，没必要用这么高频的同步写，使用默认的 1s 时间间隔，就足够了。</li>
<li>第二个问题，Python 应用在查询接口中会调用 Redis 的 SADD 命令，这很可能是不合理使用缓存导致的。</li>
</ul>
</li>
<li><p>对于第一个配置问题，我们可以执行下面的命令，把 appendfsync 改成 everysec：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker <span class="token builtin class-name">exec</span> -it redis redis-cli config <span class="token builtin class-name">set</span> appendfsync everysec
OK<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>改完后，切换到终端二中查看，你会发现，现在的请求时间，已经缩短到了 0.9s：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">{..., "elapsed_seconds":0.9368953704833984,"type":"good"}<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>而第二个问题，就要查看应用的源码了。点击 <a target="_blank" rel="noopener" href="https://github.com/feiskyer/linux-perf-examples/blob/master/redis-slow/app.py">Github</a> ，你就可以查看案例应用的源代码：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_cache</span><span class="token punctuation">(</span>type_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''handler for /get_cache'''</span>
    <span class="token keyword">for</span> key <span class="token keyword">in</span> redis_client<span class="token punctuation">.</span>scan_iter<span class="token punctuation">(</span><span class="token string">"uuid:*"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        value <span class="token operator">=</span> redis_client<span class="token punctuation">.</span>get<span class="token punctuation">(</span>key<span class="token punctuation">)</span>
        <span class="token keyword">if</span> value <span class="token operator">==</span> type_name<span class="token punctuation">:</span>
            redis_client<span class="token punctuation">.</span>sadd<span class="token punctuation">(</span>type_name<span class="token punctuation">,</span> key<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>redis_client<span class="token punctuation">.</span>smembers<span class="token punctuation">(</span>type_name<span class="token punctuation">)</span><span class="token punctuation">)</span>
    redis_client<span class="token punctuation">.</span>delete<span class="token punctuation">(</span>type_name<span class="token punctuation">)</span>
    <span class="token keyword">return</span> jsonify<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"type"</span><span class="token punctuation">:</span> type_name<span class="token punctuation">,</span> <span class="token string">'count'</span><span class="token punctuation">:</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">:</span> data<span class="token punctuation">}</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>果然，Python 应用把 Redis 当成临时空间，用来存储查询过程中找到的数据。不过我们知道，这些数据放内存中就可以了，完全没必要再通过网络调用存储到 Redis 中。</p>
<p>基于这个思路，我把修改后的代码也推送到了相同的源码文件中，你可以通过 <a target="_blank" rel="noopener" href="http://192.168.0.10:10000/get_cache_data">http://192.168.0.10:10000/get_cache_data</a> 这个接口来访问它。</p>
</li>
<li><p>我们切换到终端二，按 Ctrl+C 停止之前的 curl 命令；然后执行下面的 curl 命令，调用 <a target="_blank" rel="noopener" href="http://192.168.0.10:10000/get_cache_data">http://192.168.0.10:10000/get_cache_data</a> 新接口：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token keyword">while</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token keyword">do</span> <span class="token function">curl</span> http://192.168.0.10:10000/get_cache_data<span class="token punctuation">;</span> <span class="token keyword">done</span>
<span class="token punctuation">{</span><span class="token punctuation">..</span>.,<span class="token string">"elapsed_seconds"</span>:0.16034674644470215,<span class="token string">"type"</span><span class="token builtin class-name">:</span><span class="token string">"good"</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="30-套路篇：如何迅速分析出系统I-O的瓶颈在哪里？"><a href="#30-套路篇：如何迅速分析出系统I-O的瓶颈在哪里？" class="headerlink" title="30 | 套路篇：如何迅速分析出系统I/O的瓶颈在哪里？"></a>30 | 套路篇：如何迅速分析出系统I/O的瓶颈在哪里？</h3></li>
</ol>
<h4 id="30-1-性能指标"><a href="#30-1-性能指标" class="headerlink" title="30.1 性能指标"></a>30.1 性能指标</h4><p><img src="/images/《Linux性能优化实战》学习笔记/Linux存储系统的IO栈全景图.png" alt="Linux存储系统的IO栈全景图.png"></p>
<ol>
<li><p>文件系统 I/O 性能指标</p>
<ol>
<li><p><strong>首先，最容易想到的是存储空间的使用情况，包括容量、使用量以及剩余空间等。</strong></p>
<p> 不过要注意，这些只是文件系统向外展示的空间使用，而非在磁盘空间的真实用量，因为文件系统的元数据也会占用磁盘空间。</p>
<p> 而且，如果你配置了 RAID，从文件系统看到的使用量跟实际磁盘的占用空间，也会因为 RAID 级别的不同而不一样。比方说，配置 RAID10 后，你从文件系统最多也只能看到所有磁盘容量的一半。</p>
<p> 除了数据本身的存储空间，还有一个<strong>容易忽略的是索引节点的使用情况，它也包括容量、使用量以及剩余量等三个指标</strong>。如果文件系统中存储过多的小文件，就可能碰到索引节点容量已满的问题。</p>
</li>
<li><p><strong>其次，你应该想到的是前面多次提到过的缓存使用情况，包括页缓存、目录项缓存、索引节点缓存以及各个具体文件系统（如 ext4、XFS 等）的缓存</strong>。这些缓存会使用速度更快的内存，用来临时存储文件数据或者文件系统的元数据，从而可以减少访问慢速磁盘的次数。</p>
</li>
<li><p>除了以上这两点，文件 I/O 也是很重要的性能指标，包括 IOPS（包括 r/s 和 w/s）、响应时间（延迟）以及吞吐量（B/s）等。在考察这类指标时，通常还要考虑实际文件的读写情况。比如，结合文件大小、文件数量、I/O 类型等，综合分析文件 I/O 的性能。</p>
</li>
</ol>
</li>
<li><p>磁盘 I/O 性能指标</p>
<p> 在磁盘 I/O 原理的文章中，我曾提到过四个核心的磁盘 I/O 指标。</p>
<ol>
<li>使用率，是指磁盘忙处理 I/O 请求的百分比。过高的使用率（比如超过 60%）通常意味着磁盘 I/O 存在性能瓶颈。</li>
<li>IOPS（Input/Output Per Second），是指每秒的 I/O 请求数。</li>
<li>吞吐量，是指每秒的 I/O 请求大小。</li>
<li><p>响应时间，是指从发出 I/O 请求到收到响应的间隔时间。</p>
<p>考察这些指标时，一定要注意综合 I/O 的具体场景来分析，比如读写类型（顺序还是随机）、读写比例、读写大小、存储类型（有无 RAID 以及 RAID 级别、本地存储还是网络存储）等。</p>
<p>不过，这里有个大忌，就是把不同场景的 I/O 性能指标，直接进行分析对比。这是很常见的一个误区，你一定要避免。</p>
</li>
</ol>
</li>
</ol>
<p><img src="/images/《Linux性能优化实战》学习笔记/IO性能指标思维导图.png" alt="IO性能指标思维导图"></p>
<h4 id="30-2-性能工具"><a href="#30-2-性能工具" class="headerlink" title="30.2 性能工具"></a>30.2 性能工具</h4><ol>
<li><p>在文件系统的原理中，我介绍了查看文件系统容量的工具 df。它既可以查看文件系统数据的空间容量，也可以查看索引节点的容量。至于文件系统缓存，我们通过 /proc/meminfo、/proc/slabinfo 以及 slabtop 等各种来源，观察页缓存、目录项缓存、索引节点缓存以及具体文件系统的缓存情况。</p>
</li>
<li><p>在磁盘 I/O 的原理中，我们分别用 iostat 和 pidstat 观察了磁盘和进程的 I/O 情况。它们都是最常用的 I/O 性能分析工具。通过 iostat ，我们可以得到磁盘的 I/O 使用率、吞吐量、响应时间以及 IOPS 等性能指标；而通过 pidstat ，则可以观察到进程的 I/O 吞吐量以及块设备 I/O 的延迟等。</p>
</li>
<li><p>在狂打日志的案例中，我们先用 top 查看系统的 CPU 使用情况，发现 iowait 比较高；然后，又用 iostat 发现了磁盘的 I/O 使用率瓶颈，并用 pidstat 找出了大量 I/O 的进程；最后，通过 strace 和 lsof，我们找出了问题进程正在读写的文件，并最终锁定性能问题的来源——原来是进程在狂打日志。</p>
</li>
<li><p>在磁盘 I/O 延迟的单词热度案例中，我们同样先用 top、iostat ，发现磁盘有 I/O 瓶颈，并用 pidstat 找出了大量 I/O 的进程。可接下来，想要照搬上次操作的我们失败了。在随后的 strace 命令中，我们居然没看到 write 系统调用。于是，我们换了一个思路，用新工具 filetop 和 opensnoop ，从内核中跟踪系统调用，最终找出瓶颈的来源。</p>
</li>
<li><p>在 MySQL 和 Redis 的案例中，同样的思路，我们先用 top、iostat 以及 pidstat ，确定并找出 I/O 性能问题的瓶颈来源，它们正是 mysqld 和 redis-server。随后，我们又用 strace+lsof 找出了它们正在读写的文件。</p>
<p> 关于 MySQL 案例，根据 mysqld 正在读写的文件路径，再结合 MySQL 数据库引擎的原理，我们不仅找出了数据库和数据表的名称，还进一步发现了慢查询的问题，最终通过优化索引解决了性能瓶颈。</p>
<p> 至于 Redis 案例，根据 redis-server 读写的文件，以及正在进行网络通信的 TCP Socket，再结合 Redis 的工作原理，我们发现 Redis 持久化选项配置有问题；从 TCP Socket 通信的数据中，我们还发现了客户端的不合理行为。于是，我们修改 Redis 配置选项，并优化了客户端使用 Redis 的方式，从而减少网络通信次数，解决性能问题。</p>
</li>
</ol>
<h4 id="30-3-性能指标和工具的联系"><a href="#30-3-性能指标和工具的联系" class="headerlink" title="30.3 性能指标和工具的联系"></a>30.3 性能指标和工具的联系</h4><p>同前面 CPU 和内存板块的学习一样，我建议从指标和工具两个不同维度出发，整理记忆。</p>
<ul>
<li>从 I/O 指标出发，你更容易把性能工具同系统工作原理关联起来，对性能问题有宏观的认识和把握。</li>
<li>而从性能工具出发，可以让你更快上手使用工具，迅速找出我们想观察的性能指标。特别是在工具有限的情况下，我们更要充分利用好手头的每一个工具，少量工具也要尽力挖掘出大量信息。</li>
</ul>
<ol>
<li><p><strong>第一个维度，从文件系统和磁盘 I/O 的性能指标出发。换句话说，当你想查看某个性能指标时，要清楚知道，哪些工具可以做到。</strong></p>
<p> 根据不同的性能指标，对提供指标的性能工具进行分类和理解。这样，在实际排查性能问题时，你就可以清楚知道，什么工具可以提供你想要的指标，而不是毫无根据地挨个尝试，撞运气。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/根据指标找工具（文件系统和磁盘IO）.png" alt="根据指标找工具（文件系统和磁盘IO）"></p>
</li>
<li><p><strong>第二个维度，从工具出发。也就是当你已经安装了某个工具后，要知道这个工具能提供哪些指标。</strong></p>
<p> 这在实际环境中，特别是生产环境中也是非常重要的。因为很多情况下，你并没有权限安装新的工具包，只能最大化地利用好系统已有的工具，而这就需要你对它们有足够的了解。</p>
<p> 具体到每个工具的使用方法，一般都支持丰富的配置选项。不过不用担心，这些配置选项并不用背下来。你只要知道有哪些工具，以及这些工具的基本功能是什么就够了。真正要用到的时候， 通过 man 命令，查它们的使用手册就可以了。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/根据工具查指标（文件系统和磁盘IO）.png" alt="根据工具查指标（文件系统和磁盘IO）"></p>
</li>
</ol>
<h4 id="30-4-如何迅速分析-I-O-的性能瓶颈"><a href="#30-4-如何迅速分析-I-O-的性能瓶颈" class="headerlink" title="30.4 如何迅速分析 I/O 的性能瓶颈"></a>30.4 如何迅速分析 I/O 的性能瓶颈</h4><p>虽然文件系统和磁盘的 I/O 性能指标仍比较多，但核心的性能工具，其实就是那么几个。熟练掌握它们，再根据实际系统的现象，并配合系统和应用程序的原理， I/O 性能分析就很清晰了。</p>
<p><strong>想弄清楚性能指标的关联性，就要通晓每种性能指标的工作原理。</strong></p>
<p>以我们前面几期的案例为例，如果你仔细对比前面的几个案例，从 I/O 延迟的案例到 MySQL 和 Redis 的案例，就会发现，虽然这些问题千差万别，但从 I/O 角度来分析，最开始的分析思路基本上类似，都是：</p>
<ol>
<li>先用 iostat 发现磁盘 I/O 性能瓶颈；</li>
<li>再借助 pidstat ，定位出导致瓶颈的进程；</li>
<li>随后分析进程的 I/O 行为；</li>
<li>最后，结合应用程序的原理，分析这些 I/O 的来源。</li>
</ol>
<p><strong>所以，为了缩小排查范围，我通常会先运行那几个支持指标较多的工具，如 iostat、vmstat、pidstat 等</strong>。然后再根据观察到的现象，结合系统和应用程序的原理，寻找下一步的分析方向。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/如何迅速分析IO的性能瓶颈.png" alt="如何迅速分析IO的性能瓶颈"></p>
<p>图中列出了最常用的几个文件系统和磁盘 I/O 性能分析工具，以及相应的分析流程，箭头则表示分析方向。这其中，iostat、vmstat、pidstat 是最核心的几个性能工具，它们也提供了最重要的 I/O 性能指标。举几个例子你可能更容易理解。</p>
<p>例如，在前面讲过的 MySQL 和 Redis 案例中，我们就是通过 iostat 确认磁盘出现 I/O 性能瓶颈，然后用 pidstat 找出 I/O 最大的进程，接着借助 strace 找出该进程正在读写的文件，最后结合应用程序的原理，找出大量 I/O 的原因。</p>
<p>再如，当你用 iostat 发现磁盘有 I/O 性能瓶颈后，再用 pidstat 和 vmstat 检查，可能会发现 I/O 来自内核线程，如 Swap 使用大量升高。这种情况下，你就得进行内存分析了，先找出占用大量内存的进程，再设法减少内存的使用。</p>
<h3 id="31-套路篇：磁盘-I-O-性能优化的几个思路"><a href="#31-套路篇：磁盘-I-O-性能优化的几个思路" class="headerlink" title="31 | 套路篇：磁盘 I/O 性能优化的几个思路"></a>31 | 套路篇：磁盘 I/O 性能优化的几个思路</h3><h4 id="31-1-I-O-基准测试"><a href="#31-1-I-O-基准测试" class="headerlink" title="31.1 I/O 基准测试"></a>31.1 I/O 基准测试</h4><p>按照我的习惯，优化之前，我会先问自己， I/O 性能优化的目标是什么？换句话说，我们观察的这些 I/O 性能指标（比如 IOPS、吞吐量、延迟等），要达到多少才合适呢？</p>
<p>事实上，I/O 性能指标的具体标准，每个人估计会有不同的答案，因为我们每个人的应用场景、使用的文件系统和物理磁盘等，都有可能不一样。</p>
<p>为了更客观合理地评估优化效果，我们首先应该对磁盘和文件系统进行基准测试，得到文件系统或者磁盘 I/O 的极限性能。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/axboe/fio">fio</a>（Flexible I/O Tester）正是最常用的文件系统和磁盘 I/O 性能基准测试工具。它提供了大量的可定制化选项，可以用来测试，裸盘或者文件系统在各种场景下的 I/O 性能，包括了不同块大小、不同 I/O 引擎以及是否使用缓存等场景。</p>
<p>fio 的选项非常多， 我会通过几个常见场景的测试方法，介绍一些最常用的选项。这些常见场景包括随机读、随机写、顺序读以及顺序写等，你可以执行下面这些命令来测试：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 随机读</span>
fio -name<span class="token operator">=</span>randread -direct<span class="token operator">=</span><span class="token number">1</span> -iodepth<span class="token operator">=</span><span class="token number">64</span> -rw<span class="token operator">=</span>randread -ioengine<span class="token operator">=</span>libaio -bs<span class="token operator">=</span>4k -size<span class="token operator">=</span>1G -numjobs<span class="token operator">=</span><span class="token number">1</span> -runtime<span class="token operator">=</span><span class="token number">1000</span> -group_reporting -filename<span class="token operator">=</span>/dev/sdb

<span class="token comment"># 随机写</span>
fio -name<span class="token operator">=</span>randwrite -direct<span class="token operator">=</span><span class="token number">1</span> -iodepth<span class="token operator">=</span><span class="token number">64</span> -rw<span class="token operator">=</span>randwrite -ioengine<span class="token operator">=</span>libaio -bs<span class="token operator">=</span>4k -size<span class="token operator">=</span>1G -numjobs<span class="token operator">=</span><span class="token number">1</span> -runtime<span class="token operator">=</span><span class="token number">1000</span> -group_reporting -filename<span class="token operator">=</span>/dev/sdb

<span class="token comment"># 顺序读</span>
fio -name<span class="token operator">=</span>read -direct<span class="token operator">=</span><span class="token number">1</span> -iodepth<span class="token operator">=</span><span class="token number">64</span> -rw<span class="token operator">=</span>read -ioengine<span class="token operator">=</span>libaio -bs<span class="token operator">=</span>4k -size<span class="token operator">=</span>1G -numjobs<span class="token operator">=</span><span class="token number">1</span> -runtime<span class="token operator">=</span><span class="token number">1000</span> -group_reporting -filename<span class="token operator">=</span>/dev/sdb

<span class="token comment"># 顺序写</span>
fio -name<span class="token operator">=</span>write -direct<span class="token operator">=</span><span class="token number">1</span> -iodepth<span class="token operator">=</span><span class="token number">64</span> -rw<span class="token operator">=</span>write -ioengine<span class="token operator">=</span>libaio -bs<span class="token operator">=</span>4k -size<span class="token operator">=</span>1G -numjobs<span class="token operator">=</span><span class="token number">1</span> -runtime<span class="token operator">=</span><span class="token number">1000</span> -group_reporting -filename<span class="token operator">=</span>/dev/sdb<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在这其中，有几个参数需要你重点关注一下。</p>
<ul>
<li>direct，表示是否跳过系统缓存。上面示例中，我设置的 1 ，就表示跳过系统缓存。</li>
<li>iodepth，表示使用异步 I/O（asynchronous I/O，简称 AIO）时，同时发出的 I/O 请求上限。在上面的示例中，我设置的是 64。</li>
<li>rw，表示 I/O 模式。我的示例中， read/write 分别表示顺序读 / 写，而 randread/randwrite 则分别表示随机读 / 写。</li>
<li>ioengine，表示 I/O 引擎，它支持同步（sync）、异步（libaio）、内存映射（mmap）、网络（net）等各种 I/O 引擎。上面示例中，我设置的 libaio 表示使用异步 I/O。</li>
<li>bs，表示 I/O 的大小。示例中，我设置成了 4K（这也是默认值）。</li>
<li>filename，表示文件路径，当然，它可以是磁盘路径（测试磁盘性能），也可以是文件路径（测试文件系统性能）。示例中，我把它设置成了磁盘 /dev/sdb。不过注意，用磁盘路径测试写，会破坏这个磁盘中的文件系统，所以在使用前，你一定要事先做好数据备份。</li>
</ul>
<p>下面就是我使用 fio 测试顺序读的一个报告示例。</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">read: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64
fio-3.1
Starting 1 process
Jobs: 1 (f=1): [R(1)][100.0%][r=16.7MiB/s,w=0KiB/s][r=4280,w=0 IOPS][eta 00m:00s]
read: (groupid=0, jobs=1): err= 0: pid=17966: Sun Dec 30 08:31:48 2018
   read: IOPS=4257, BW=16.6MiB/s (17.4MB/s)(1024MiB/61568msec)
    slat (usec): min=2, max=2566, avg= 4.29, stdev=21.76
    clat (usec): min=228, max=407360, avg=15024.30, stdev=20524.39
     lat (usec): min=243, max=407363, avg=15029.12, stdev=20524.26
    clat percentiles (usec):
     |  1.00th=[   498],  5.00th=[  1020], 10.00th=[  1319], 20.00th=[  1713],
     | 30.00th=[  1991], 40.00th=[  2212], 50.00th=[  2540], 60.00th=[  2933],
     | 70.00th=[  5407], 80.00th=[ 44303], 90.00th=[ 45351], 95.00th=[ 45876],
     | 99.00th=[ 46924], 99.50th=[ 46924], 99.90th=[ 48497], 99.95th=[ 49021],
     | 99.99th=[404751]
   bw (  KiB/s): min= 8208, max=18832, per=99.85%, avg=17005.35, stdev=998.94, samples=123
   iops        : min= 2052, max= 4708, avg=4251.30, stdev=249.74, samples=123
  lat (usec)   : 250=0.01%, 500=1.03%, 750=1.69%, 1000=2.07%
  lat (msec)   : 2=25.64%, 4=37.58%, 10=2.08%, 20=0.02%, 50=29.86%
  lat (msec)   : 100=0.01%, 500=0.02%
  cpu          : usr=1.02%, sys=2.97%, ctx=33312, majf=0, minf=75
  IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0%
     issued rwt: total=262144,0,0, short=0,0,0, dropped=0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=64

Run status group 0 (all jobs):
   READ: bw=16.6MiB/s (17.4MB/s), 16.6MiB/s-16.6MiB/s (17.4MB/s-17.4MB/s), io=1024MiB (1074MB), run=61568-61568msec

Disk stats (read/write):
  sdb: ios=261897/0, merge=0/0, ticks=3912108/0, in_queue=3474336, util=90.09%<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这个报告中，需要我们重点关注的是， slat、clat、lat ，以及 bw 和 iops 这几行。</p>
<p>先来看刚刚提到的前三个参数。事实上，slat、clat、lat 都是指 I/O 延迟（latency）。不同之处在于：</p>
<ul>
<li>slat ，是指从 I/O 提交到实际执行 I/O 的时长（Submission latency）；</li>
<li>clat ，是指从 I/O 提交到 I/O 完成的时长（Completion latency）；</li>
<li>而 lat ，指的是从 fio 创建 I/O 到 I/O 完成的总时长。</li>
</ul>
<p>这里需要注意的是，对同步 I/O 来说，由于 I/O 提交和 I/O 完成是一个动作，所以 slat 实际上就是 I/O 完成的时间，而 clat 是 0。而从示例可以看到，使用异步 I/O（libaio）时，lat 近似等于 slat + clat 之和。</p>
<p>再来看 bw ，它代表吞吐量。在我上面的示例中，你可以看到，平均吞吐量大约是 16 MB（17005 KiB/1024）。</p>
<p>最后的 iops ，其实就是每秒 I/O 的次数，上面示例中的平均 IOPS 为 4250。</p>
<p>通常情况下，应用程序的 I/O 都是读写并行的，而且每次的 I/O 大小也不一定相同。所以，刚刚说的这几种场景，并不能精确模拟应用程序的 I/O 模式。那怎么才能精确模拟应用程序的 I/O 模式呢？</p>
<p>幸运的是，fio 支持 I/O 的重放。借助前面提到过的 blktrace，再配合上 fio，就可以实现对应用程序 I/O 模式的基准测试。你需要先用 blktrace ，记录磁盘设备的 I/O 访问情况；然后使用 fio ，重放 blktrace 的记录。</p>
<p>比如你可以运行下面的命令来操作：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 使用 blktrace 跟踪磁盘 I/O，注意指定应用程序正在操作的磁盘</span>
$ blktrace /dev/sdb

<span class="token comment"># 查看 blktrace 记录的结果</span>
<span class="token comment"># ls</span>
sdb.blktrace.0  sdb.blktrace.1

<span class="token comment"># 将结果转化为二进制文件</span>
$ blkparse sdb -d sdb.bin

<span class="token comment"># 使用 fio 重放日志</span>
$ fio --name<span class="token operator">=</span>replay --filename<span class="token operator">=</span>/dev/sdb --direct<span class="token operator">=</span><span class="token number">1</span> --read_iolog<span class="token operator">=</span>sdb.bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这样，我们就通过 blktrace+fio 的组合使用，得到了应用程序 I/O 模式的基准测试报告。</p>
<h4 id="31-2-I-O-性能优化"><a href="#31-2-I-O-性能优化" class="headerlink" title="31.2 I/O 性能优化"></a>31.2 I/O 性能优化</h4><p>得到 I/O 基准测试报告后，再用上我们上一节总结的性能分析套路，找出 I/O 的性能瓶颈并优化，就是水到渠成的事情了。当然， 想要优化 I/O 性能，肯定离不开 Linux 系统的 I/O 栈图的思路辅助。你可以结合下面的 I/O 栈图再回顾一下。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/Linux存储系统的IO栈全景图.png" alt="Linux存储系统的IO栈全景图.png"></p>
<ol>
<li><p>应用程序优化</p>
<p> 应用程序处于整个 I/O 栈的最上端，它可以通过系统调用，来调整 I/O 模式（如顺序还是随机、同步还是异步）， 同时，它也是 I/O 数据的最终来源。在我看来，可以有这么几种方式来优化应用程序的 I/O 性能。</p>
<ol>
<li>第一，可以用追加写代替随机写，减少寻址开销，加快 I/O 写的速度。</li>
<li>第二，可以借助缓存 I/O ，充分利用系统缓存，降低实际 I/O 的次数。</li>
<li><p>第三，可以在应用程序内部构建自己的缓存，或者用 Redis 这类外部缓存系统。这样，一方面，能在应用程序内部，控制缓存的数据和生命周期；另一方面，也能降低其他应用程序使用缓存对自身的影响。</p>
<p> 比如，在前面的 MySQL 案例中，我们已经见识过，只是因为一个干扰应用清理了系统缓存，就会导致 MySQL 查询有数百倍的性能差距（0.1s vs 15s）。</p>
<p> 再如， C 标准库提供的 fopen、fread 等库函数，都会利用标准库的缓存，减少磁盘的操作。而你直接使用 open、read 等系统调用时，就只能利用操作系统提供的页缓存和缓冲区等，而没有库函数的缓存可用。</p>
</li>
<li><p>第四，在需要频繁读写同一块磁盘空间时，可以用 mmap 代替 read/write，减少内存的拷贝次数。</p>
</li>
<li>第五，在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘，即可以用 fsync() 取代 O_SYNC。</li>
<li>第六，在多个应用程序共享相同磁盘时，为了保证 I/O 不被某个应用完全占用，推荐你使用 cgroups 的 I/O 子系统，来限制进程 / 进程组的 IOPS 以及吞吐量。</li>
<li>最后，在使用 CFQ 调度器时，可以用 ionice 来调整进程的 I/O 调度优先级，特别是提高核心应用的 I/O 优先级。ionice 支持三个优先级类：Idle、Best-effort 和 Realtime。其中， Best-effort 和 Realtime 还分别支持 0-7 的级别，数值越小，则表示优先级别越高。</li>
</ol>
</li>
<li><p>文件系统优化</p>
<p> 应用程序访问普通文件时，实际是由文件系统间接负责，文件在磁盘中的读写。所以，跟文件系统中相关的也有很多优化 I/O 性能的方式。</p>
<ol>
<li><p>第一，你可以根据实际负载场景的不同，选择最适合的文件系统。比如 Ubuntu 默认使用 ext4 文件系统，而 CentOS 7 默认使用 xfs 文件系统。</p>
<p> 相比于 ext4 ，xfs 支持更大的磁盘分区和更大的文件数量，如 xfs 支持大于 16TB 的磁盘。但是 xfs 文件系统的缺点在于无法收缩，而 ext4 则可以。</p>
</li>
<li><p>第二，在选好文件系统后，还可以进一步优化文件系统的配置选项，包括文件系统的特性（如 ext_attr、dir_index）、日志模式（如 journal、ordered、writeback）、挂载选项（如 noatime）等等。</p>
<p> 比如， 使用 tune2fs 这个工具，可以调整文件系统的特性（tune2fs 也常用来查看文件系统超级块的内容）。 而通过 /etc/fstab ，或者 mount 命令行参数，我们可以调整文件系统的日志模式和挂载选项等。</p>
</li>
<li><p>第三，可以优化文件系统的缓存。</p>
<p> 比如，你可以优化 pdflush 脏页的刷新频率（比如设置 dirty_expire_centisecs 和 dirty_writeback_centisecs）以及脏页的限额（比如调整 dirty_background_ratio 和 dirty_ratio 等）。</p>
<p> 再如，你还可以优化内核回收目录项缓存和索引节点缓存的倾向，即调整 vfs_cache_pressure（/proc/sys/vm/vfs_cache_pressure，默认值 100），数值越大，就表示越容易回收。</p>
</li>
<li>最后，在不需要持久化时，你还可以用内存文件系统 tmpfs，以获得更好的 I/O 性能 。tmpfs 把数据直接保存在内存中，而不是磁盘中。比如 /dev/shm/ ，就是大多数 Linux 默认配置的一个内存文件系统，它的大小默认为总内存的一半。</li>
</ol>
</li>
<li><p>磁盘优化</p>
<p> 数据的持久化存储，最终还是要落到具体的物理磁盘中，同时，磁盘也是整个 I/O 栈的最底层。从磁盘角度出发，自然也有很多有效的性能优化方法。</p>
<ol>
<li><p>第一，最简单有效的优化方法，就是换用性能更好的磁盘，比如用 SSD 替代 HDD。</p>
</li>
<li><p>第二，我们可以使用 RAID ，把多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列。这样做既可以提高数据的可靠性，又可以提升数据的访问性能。</p>
</li>
<li><p>第三，针对磁盘和应用程序 I/O 模式的特征，我们可以选择最适合的 I/O 调度算法。比方说，SSD 和虚拟机中的磁盘，通常用的是 noop 调度算法。而数据库应用，我更推荐使用 deadline 算法。</p>
</li>
<li><p>第四，我们可以对应用程序的数据，进行磁盘级别的隔离。比如，我们可以为日志、数据库等 I/O 压力比较重的应用，配置单独的磁盘。</p>
</li>
<li><p>第五，在顺序读比较多的场景中，我们可以增大磁盘的预读数据，比如，你可以通过下面两种方法，调整 /dev/sdb 的预读大小。</p>
<ul>
<li>调整内核选项 /sys/block/sdb/queue/read_ahead_kb，默认大小是 128 KB，单位为 KB。</li>
<li>使用 blockdev 工具设置，比如 blockdev —setra 8192 /dev/sdb，注意这里的单位是 512B（0.5KB），所以它的数值总是 read_ahead_kb 的两倍。</li>
</ul>
</li>
<li><p>第六，我们可以优化内核块设备 I/O 的选项。比如，可以调整磁盘队列的长度 /sys/block/sdb/queue/nr_requests，适当增大队列长度，可以提升磁盘的吞吐量（当然也会导致 I/O 延迟增大）。</p>
</li>
<li><p>最后，要注意，磁盘本身出现硬件错误，也会导致 I/O 性能急剧下降，所以发现磁盘性能急剧下降时，你还需要确认，磁盘本身是不是出现了硬件错误。</p>
<p> 比如，你可以查看 dmesg 中是否有硬件 I/O 故障的日志。 还可以使用 badblocks、smartctl 等工具，检测磁盘的硬件问题，或用 e2fsck 等来检测文件系统的错误。如果发现问题，你可以使用 fsck 等工具来修复。</p>
</li>
</ol>
</li>
</ol>
<h3 id="32-答疑（四）：阻塞、非阻塞-I-O-与同步、异步-I-O-的区别和联系"><a href="#32-答疑（四）：阻塞、非阻塞-I-O-与同步、异步-I-O-的区别和联系" class="headerlink" title="32 | 答疑（四）：阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系"></a>32 | 答疑（四）：阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系</h3><h4 id="32-1-问题-1：阻塞、非阻塞-I-O-与同步、异步-I-O-的区别和联系"><a href="#32-1-问题-1：阻塞、非阻塞-I-O-与同步、异步-I-O-的区别和联系" class="headerlink" title="32.1 问题 1：阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系"></a>32.1 问题 1：阻塞、非阻塞 I/O 与同步、异步 I/O 的区别和联系</h4><p>首先我们来看阻塞和非阻塞 I/O。根据应用程序是否阻塞自身运行，可以把 I/O 分为阻塞 I/O 和非阻塞 I/O。</p>
<ul>
<li>所谓阻塞 I/O，是指应用程序在执行 I/O 操作后，如果没有获得响应，就会阻塞当前线程，不能执行其他任务。</li>
<li>所谓非阻塞 I/O，是指应用程序在执行 I/O 操作后，不会阻塞当前的线程，可以继续执行其他的任务。</li>
</ul>
<p>再来看同步 I/O 和异步 I/O。根据 I/O 响应的通知方式的不同，可以把文件 I/O 分为同步 I/O 和异步 I/O。</p>
<ul>
<li>所谓同步 I/O，是指收到 I/O 请求后，系统不会立刻响应应用程序；等到处理完成，系统才会通过系统调用的方式，告诉应用程序 I/O 结果。</li>
<li>所谓异步 I/O，是指收到 I/O 请求后，系统会先告诉应用程序 I/O 请求已经收到，随后再去异步处理；等处理完成后，系统再通过事件通知的方式，告诉应用程序结果。</li>
</ul>
<p>你可以看出，阻塞 / 非阻塞和同步 / 异步，其实就是两个不同角度的 I/O 划分方式。它们描述的对象也不同，阻塞 / 非阻塞针对的是 I/O 调用者（即应用程序），而同步 / 异步针对的是 I/O 执行者（即系统）。</p>
<p>我举个例子来进一步解释下。比如在 Linux I/O 调用中，</p>
<ul>
<li>系统调用 read 是同步读，所以，在没有得到磁盘数据前，read 不会响应应用程序。</li>
<li>而 aio_read 是异步读，系统收到 AIO 读请求后不等处理就返回了，而具体的 read 结果，再通过回调异步通知应用程序。</li>
</ul>
<p>再如，在网络套接字的接口中，</p>
<ul>
<li>使用 send() 直接向套接字发送数据时，如果套接字没有设置 O_NONBLOCK 标识，那么 send() 操作就会一直阻塞，当前线程也没法去做其他事情。</li>
<li>当然，如果你用了 epoll，系统会告诉你这个套接字的状态，那就可以用非阻塞的方式使用。当这个套接字不可写的时候，你可以去做其他事情，比如读写其他套接字。</li>
</ul>
<h4 id="32-2-“文件系统”课后思考"><a href="#32-2-“文件系统”课后思考" class="headerlink" title="32.2 “文件系统”课后思考"></a>32.2 “文件系统”课后思考</h4><p>执行 find 命令时，会不会导致系统的缓存升高呢？如果会导致，升高的又是哪种类型的缓存呢？</p>
<p>通过学习 Linux 文件系统的原理，我们知道，文件名以及文件之间的目录关系，都放在目录项缓存中。而这是一个基于内存的数据结构，会根据需要动态构建。所以，查找文件时，Linux 就会动态构建不在缓存中的目录项结构，导致 dentry 缓存升高。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/执行find命令导致系统的缓存升高答案1.png" alt="执行find命令导致系统的缓存升高答案1"></p>
<p><img src="/images/《Linux性能优化实战》学习笔记/执行find命令导致系统的缓存升高答案2.png" alt="执行find命令导致系统的缓存升高答案2"></p>
<p>事实上，除了目录项缓存增加，Buffer 的使用也会增加。如果你用 vmstat 观察一下，会发现 Buffer 和 Cache 都在增长：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">vmstat</span> <span class="token number">1</span>
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   <span class="token function">free</span>   buff  cache   si   so    bi    bo   <span class="token keyword">in</span>   cs us sy <span class="token function">id</span> wa st
 <span class="token number">0</span>  <span class="token number">1</span>      <span class="token number">0</span> <span class="token number">7563744</span>   <span class="token number">6024</span> <span class="token number">225944</span>    <span class="token number">0</span>    <span class="token number">0</span>  <span class="token number">3736</span>     <span class="token number">0</span>  <span class="token number">574</span> <span class="token number">3249</span>  <span class="token number">3</span>  <span class="token number">5</span> <span class="token number">89</span>  <span class="token number">3</span>  <span class="token number">0</span>
 <span class="token number">1</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">7542792</span>  <span class="token number">14736</span> <span class="token number">236856</span>    <span class="token number">0</span>    <span class="token number">0</span>  <span class="token number">8708</span>     <span class="token number">0</span> <span class="token number">13494</span> <span class="token number">32335</span>  <span class="token number">8</span> <span class="token number">19</span> <span class="token number">66</span>  <span class="token number">7</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">1</span>      <span class="token number">0</span> <span class="token number">7494452</span>  <span class="token number">27280</span> <span class="token number">272284</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">12544</span>     <span class="token number">0</span> <span class="token number">4550</span> <span class="token number">17084</span>  <span class="token number">5</span> <span class="token number">15</span> <span class="token number">68</span> <span class="token number">13</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">1</span>      <span class="token number">0</span> <span class="token number">7475084</span>  <span class="token number">42380</span> <span class="token number">276320</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">15096</span>     <span class="token number">0</span> <span class="token number">2541</span> <span class="token number">14253</span>  <span class="token number">2</span>  <span class="token number">6</span> <span class="token number">78</span> <span class="token number">13</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">1</span>      <span class="token number">0</span> <span class="token number">7455728</span>  <span class="token number">57600</span> <span class="token number">280436</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">15220</span>     <span class="token number">0</span> <span class="token number">2025</span> <span class="token number">14518</span>  <span class="token number">2</span>  <span class="token number">6</span> <span class="token number">70</span> <span class="token number">22</span>  <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里，Buffer 的增长是因为，构建目录项缓存所需的元数据（比如文件名称、索引节点等），需要从文件系统中读取。</p>
<h4 id="32-3-问题-3：“磁盘-I-O-延迟”课后思考"><a href="#32-3-问题-3：“磁盘-I-O-延迟”课后思考" class="headerlink" title="32.3 问题 3：“磁盘 I/O 延迟”课后思考"></a>32.3 问题 3：“磁盘 I/O 延迟”课后思考</h4><p>我们通过 iostat ，确认磁盘 I/O 已经出现了性能瓶颈，还用 pidstat 找出了大量磁盘 I/O 的进程。但是，随后使用 strace 跟踪这个进程，却找不到任何 write 系统调用。这是为什么呢？</p>
<p>strace -p PID 后面需要加 -f 选项，以便跟踪多进程和多线程的系统调用情况。</p>
<h4 id="32-4-问题-4：“MySQL-案例”课后思考"><a href="#32-4-问题-4：“MySQL-案例”课后思考" class="headerlink" title="32.4 问题 4：“MySQL 案例”课后思考"></a>32.4 问题 4：“MySQL 案例”课后思考</h4><p>为什么 DataService 应用停止后，即使仍没有索引，MySQL 的查询速度还是快了很多，并且磁盘 I/O 瓶颈也消失了呢？</p>
<p>ninuxer 的留言基本解释了这个问题，不过还不够完善。</p>
<blockquote>
<p>ninuxer 的留言：echo 1&gt;/proc/sys/vm/drop_caches表示释放pagecache，也就是文件缓存，而mysql读书的数据就是文件缓存，dataservice不停的释放文件缓存，就导致MySQL都无法利用磁盘缓存，也就慢了。</p>
</blockquote>
<p>事实上，当你看到 DataService 在修改 /proc/sys/vm/drop_caches 时，就应该想到前面学过的 Cache 的作用。</p>
<p>我们知道，案例应用访问的数据表，基于 MyISAM 引擎，而 MyISAM 的一个特点，就是只在内存中缓存索引，并不缓存数据。所以，在查询语句无法使用索引时，就需要数据表从数据库文件读入内存，然后再进行处理。</p>
<p>所以，如果你用 vmstat 工具，观察缓存和 I/O 的变化趋势，就会发现下面这样的结果：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">vmstat</span> <span class="token number">1</span>

procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   <span class="token function">free</span>   buff  cache   si   so    bi    bo   <span class="token keyword">in</span>   cs us sy <span class="token function">id</span> wa st

<span class="token comment"># 备注： DataService 正在运行</span>
<span class="token number">0</span>  <span class="token number">1</span>      <span class="token number">0</span> <span class="token number">7293416</span>    <span class="token number">132</span> <span class="token number">366704</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">32516</span>    <span class="token number">12</span>   <span class="token number">36</span>  <span class="token number">546</span>  <span class="token number">1</span>  <span class="token number">3</span> <span class="token number">49</span> <span class="token number">48</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">1</span>      <span class="token number">0</span> <span class="token number">7260772</span>    <span class="token number">132</span> <span class="token number">399256</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">32640</span>     <span class="token number">0</span>   <span class="token number">37</span>  <span class="token number">463</span>  <span class="token number">1</span>  <span class="token number">1</span> <span class="token number">49</span> <span class="token number">48</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">1</span>      <span class="token number">0</span> <span class="token number">7228088</span>    <span class="token number">132</span> <span class="token number">432088</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">32640</span>     <span class="token number">0</span>   <span class="token number">30</span>  <span class="token number">477</span>  <span class="token number">0</span>  <span class="token number">1</span> <span class="token number">49</span> <span class="token number">49</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">7306560</span>    <span class="token number">132</span> <span class="token number">353084</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">20572</span>     <span class="token number">4</span>   <span class="token number">90</span>  <span class="token number">574</span>  <span class="token number">1</span>  <span class="token number">4</span> <span class="token number">69</span> <span class="token number">27</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">2</span>      <span class="token number">0</span> <span class="token number">7282300</span>    <span class="token number">132</span> <span class="token number">368536</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">15468</span>     <span class="token number">0</span>   <span class="token number">32</span>  <span class="token number">304</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">79</span> <span class="token number">20</span>  <span class="token number">0</span>

<span class="token comment"># 备注：DataService 从这里开始停止</span>
 <span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">7241852</span>   <span class="token number">1360</span> <span class="token number">424164</span>    <span class="token number">0</span>    <span class="token number">0</span>   <span class="token number">864</span>   <span class="token number">320</span>  <span class="token number">133</span> <span class="token number">1266</span>  <span class="token number">1</span>  <span class="token number">1</span> <span class="token number">94</span>  <span class="token number">5</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">1</span>      <span class="token number">0</span> <span class="token number">7228956</span>   <span class="token number">1368</span> <span class="token number">437400</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">13328</span>     <span class="token number">0</span>   <span class="token number">45</span>  <span class="token number">366</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">83</span> <span class="token number">17</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">1</span>      <span class="token number">0</span> <span class="token number">7196320</span>   <span class="token number">1368</span> <span class="token number">470148</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">32640</span>     <span class="token number">0</span>   <span class="token number">33</span>  <span class="token number">413</span>  <span class="token number">1</span>  <span class="token number">1</span> <span class="token number">50</span> <span class="token number">49</span>  <span class="token number">0</span>
<span class="token punctuation">..</span>.
 <span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6747540</span>   <span class="token number">1368</span> <span class="token number">918576</span>    <span class="token number">0</span>    <span class="token number">0</span> <span class="token number">29056</span>     <span class="token number">0</span>   <span class="token number">42</span>  <span class="token number">568</span>  <span class="token number">0</span>  <span class="token number">0</span> <span class="token number">56</span> <span class="token number">44</span>  <span class="token number">0</span>
 <span class="token number">0</span>  <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">6747540</span>   <span class="token number">1368</span> <span class="token number">918576</span>    <span class="token number">0</span>    <span class="token number">0</span>     <span class="token number">0</span>     <span class="token number">0</span>   <span class="token number">40</span>  <span class="token number">141</span>  <span class="token number">1</span>  <span class="token number">0</span> <span class="token number">100</span>  <span class="token number">0</span>  <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在 DataService 停止前，cache 会连续增长三次后再降回去，这正是因为 DataService 每隔 3 秒清理一次页缓存。而 DataService 停止后，cache 就会不停地增长，直到增长为 918576 后，就不再变了。</p>
<p>这时，磁盘的读（bi）降低到 0，同时，iowait（wa）也降低到 0，这说明，此时的所有数据都已经在系统的缓存中了。我们知道，缓存是内存的一部分，它的访问速度比磁盘快得多，这也就能解释，为什么 MySQL 的查询速度变快了很多。</p>
<p>从这个案例，你会发现，MySQL 的 MyISAM 引擎，本身并不缓存数据，而要依赖系统缓存来加速磁盘 I/O 的访问。一旦系统中还有其他应用同时运行，MyISAM 引擎就很难充分利用系统缓存。因为系统缓存可能被其他应用程序占用，甚至直接被清理掉。</p>
<p>所以，一般来说，我并不建议，把应用程序的性能优化完全建立在系统缓存上。还是那句话，最好能在应用程序的内部分配内存，构建完全自主控制的缓存，比如 MySQL 的 InnoDB 引擎，就同时缓存了索引和数据；或者，可以使用第三方的缓存应用，比如 Memcached、Redis 等。</p>
<h2 id="05-网络性能篇"><a href="#05-网络性能篇" class="headerlink" title="05-网络性能篇"></a><strong>05-网络性能篇</strong></h2><h3 id="33-关于-Linux-网络，你必须知道这些（上）"><a href="#33-关于-Linux-网络，你必须知道这些（上）" class="headerlink" title="33 | 关于 Linux 网络，你必须知道这些（上）"></a>33 | 关于 Linux 网络，你必须知道这些（上）</h3><h4 id="33-1-网络模型"><a href="#33-1-网络模型" class="headerlink" title="33.1 网络模型"></a>33.1 网络模型</h4><p>说到网络，我想你肯定经常提起七层负载均衡、四层负载均衡，或者三层设备、二层设备等等。那么，这里说的二层、三层、四层、七层又都是什么意思呢？</p>
<p>实际上，这些层都来自国际标准化组织制定的开放式系统互联通信参考模型（Open System Interconnection Reference Model），简称为 OSI 网络模型。</p>
<ul>
<li>应用层，负责为应用程序提供统一的接口。</li>
<li>表示层，负责把数据转换成兼容接收系统的格式。</li>
<li>会话层，负责维护计算机之间的通信连接。</li>
<li>传输层，负责为数据加上传输表头，形成数据包。</li>
<li>网络层，负责数据的路由和转发。</li>
<li>数据链路层，负责 MAC 寻址、错误侦测和改错。</li>
<li>物理层，负责在物理网络中传输数据帧。</li>
</ul>
<p>但是 OSI 模型还是太复杂了，也没能提供一个可实现的方法。所以，在 Linux 中，我们实际上使用的是另一个更实用的四层模型，即 TCP/IP 网络模型。</p>
<p>TCP/IP 模型，把网络互联的框架分为应用层、传输层、网络层、网络接口层等四层，其中，</p>
<ul>
<li>应用层，负责向用户提供一组应用程序，比如 HTTP、FTP、DNS 等。</li>
<li>传输层，负责端到端的通信，比如 TCP、UDP 等。</li>
<li>网络层，负责网络包的封装、寻址和路由，比如 IP、ICMP 等。</li>
<li>网络接口层，负责网络包在物理网络中的传输，比如 MAC 寻址、错误侦测以及通过网卡传输网络帧等。</li>
</ul>
<p><img src="/images/《Linux性能优化实战》学习笔记/TCPIP与OSI模型的关系.png" alt="TCPIP与OSI模型的关系"></p>
<p>TCP/IP 模型包括了大量的网络协议，这些协议的原理，也是我们每个人必须掌握的核心基础知识。如果你不太熟练，推荐你去学《TCP/IP 详解》的卷一和卷二，或者学习极客时间出品的 <a target="_blank" rel="noopener" href="https://time.geekbang.org/course/intro/85">《趣谈网络协议》</a> 专栏。</p>
<h4 id="33-2-Linux-网络栈"><a href="#33-2-Linux-网络栈" class="headerlink" title="33.2 Linux 网络栈"></a>33.2 Linux 网络栈</h4><p>有了 TCP/IP 模型后，在进行网络传输时，数据包就会按照协议栈，对上一层发来的数据进行逐层处理；然后封装上该层的协议头，再发送给下一层。</p>
<p>当然，网络包在每一层的处理逻辑，都取决于各层采用的网络协议。比如在应用层，一个提供 REST API 的应用，可以使用 HTTP 协议，把它需要传输的 JSON 数据封装到 HTTP 协议中，然后向下传递给 TCP 层。</p>
<p>而封装做的事情就很简单了，只是在原来的负载前后，增加固定格式的元数据，原始的负载数据并不会被修改。</p>
<p>比如，以通过 TCP 协议通信的网络包为例，通过下面这张图，我们可以看到，应用程序数据在每个层的封装格式。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/TCPIP协议栈.png" alt="TCPIP协议栈"></p>
<p>其中：</p>
<ul>
<li>传输层在应用程序数据前面增加了 TCP 头；</li>
<li>网络层在 TCP 数据包前增加了 IP 头；</li>
<li>而网络接口层，又在 IP 数据包前后分别增加了帧头和帧尾。</li>
</ul>
<p>这些新增的头部和尾部，都按照特定的协议格式填充，想了解具体格式，你可以查看协议的文档。 比如，你可以查看<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#%E5%B0%81%E5%8C%85%E7%B5%90%E6%A7%8B">这里</a>，了解 TCP 头的格式。</p>
<p>这些新增的头部和尾部，增加了网络包的大小，但我们都知道，物理链路中并不能传输任意大小的数据包。网络接口配置的最大传输单元（MTU），就规定了最大的 IP 包大小。在我们最常用的以太网中，MTU 默认值是 1500（这也是 Linux 的默认值）。</p>
<p>一旦网络包超过 MTU 的大小，就会在网络层分片，以保证分片后的 IP 包不大于 MTU 值。显然，MTU 越大，需要的分包也就越少，自然，网络吞吐能力就越好。</p>
<p>理解了 TCP/IP 网络模型和网络包的封装原理后，你很容易能想到，Linux 内核中的网络栈，其实也类似于 TCP/IP 的四层结构。如下图所示，就是 Linux 通用 IP 网络栈的示意图：</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/Linux通用IP网络栈的示意图.png" alt="Linux通用IP网络栈的示意图.png"></p>
<blockquote>
<p>（图片参考《性能之巅》图 10.7 通用 IP 网络栈绘制）</p>
</blockquote>
<p>我们从上到下来看这个网络栈，你可以发现，</p>
<ul>
<li>最上层的应用程序，需要通过系统调用，来跟套接字接口进行交互；</li>
<li>套接字的下面，就是我们前面提到的传输层、网络层和网络接口层；</li>
<li>最底层，则是网卡驱动程序以及物理网卡设备。</li>
</ul>
<p>网卡是发送和接收网络包的基本设备。在系统启动过程中，网卡通过内核中的网卡驱动程序注册到系统中。而在网络收发过程中，内核通过中断跟网卡进行交互。</p>
<p>再结合前面提到的 Linux 网络栈，可以看出，网络包的处理非常复杂。所以，网卡硬中断只处理最核心的网卡数据读取或发送，而协议栈中的大部分逻辑，都会放到软中断中处理。</p>
<h4 id="33-3-Linux-网络收发流程"><a href="#33-3-Linux-网络收发流程" class="headerlink" title="33.3 Linux 网络收发流程"></a>33.3 Linux 网络收发流程</h4><p>了解了 Linux 网络栈后，我们再来看看， Linux 到底是怎么收发网络包的。</p>
<blockquote>
<p>注意，以下内容都以物理网卡为例。事实上，Linux 还支持众多的虚拟网络设备，而它们的网络收发流程会有一些差别。</p>
</blockquote>
<p><img src="/images/《Linux性能优化实战》学习笔记/网络包的发送接收流程.png" alt="网络包的发送接收流程.png"></p>
<ol>
<li><p>网络包的接收流程</p>
<p> 当一个网络帧到达网卡后，网卡会通过 DMA 方式，把这个网络包放到收包队列中；然后通过硬中断，告诉中断处理程序已经收到了网络包。</p>
<p> 接着，网卡中断处理程序会为网络帧分配内核数据结构（sk_buff），并将其拷贝到 sk_buff 缓冲区中；然后再通过软中断，通知内核收到了新的网络帧。</p>
<p> 接下来，内核协议栈从缓冲区中取出网络帧，并通过网络协议栈，从下到上逐层处理这个网络帧。比如，</p>
<ul>
<li>在链路层检查报文的合法性，找出上层协议的类型（比如 IPv4 还是 IPv6），再去掉帧头、帧尾，然后交给网络层。</li>
<li>网络层取出 IP 头，判断网络包下一步的走向，比如是交给上层处理还是转发。当网络层确认这个包是要发送到本机后，就会取出上层协议的类型（比如 TCP 还是 UDP），去掉 IP 头，再交给传输层处理。</li>
<li><p>传输层取出 TCP 头或者 UDP 头后，根据 &lt; 源 IP、源端口、目的 IP、目的端口 &gt; 四元组作为标识，找出对应的 Socket，并把数据拷贝到 Socket 的接收缓存中。</p>
<p>最后，应用程序就可以使用 Socket 接口，读取到新接收到的数据了。</p>
</li>
</ul>
</li>
<li><p>网络包的发送流程</p>
<p> 首先，应用程序调用 Socket API（比如 sendmsg）发送网络包。</p>
<p> 由于这是一个系统调用，所以会陷入到内核态的套接字层中。套接字层会把数据包放到 Socket 发送缓冲区中。</p>
<p> 接下来，网络协议栈从 Socket 发送缓冲区中，取出数据包；再按照 TCP/IP 栈，从上到下逐层处理。比如，传输层和网络层，分别为其增加 TCP 头和 IP 头，执行路由查找确认下一跳的 IP，并按照 MTU 大小进行分片。</p>
<p> 分片后的网络包，再送到网络接口层，进行物理地址寻址，以找到下一跳的 MAC 地址。然后添加帧头和帧尾，放到发包队列中。这一切完成后，会有软中断通知驱动程序：发包队列中有新的网络帧需要发送。</p>
<p> 最后，驱动程序通过 DMA ，从发包队列中读出网络帧，并通过物理网卡把它发送出去。</p>
</li>
</ol>
<h3 id="34-关于-Linux-网络，你必须知道这些（下）"><a href="#34-关于-Linux-网络，你必须知道这些（下）" class="headerlink" title="34 | 关于 Linux 网络，你必须知道这些（下）"></a>34 | 关于 Linux 网络，你必须知道这些（下）</h3><h4 id="34-1-性能指标"><a href="#34-1-性能指标" class="headerlink" title="34.1 性能指标"></a>34.1 性能指标</h4><p>实际上，我们通常用带宽、吞吐量、延时、PPS（Packet Per Second）等指标衡量网络的性能。</p>
<ul>
<li><strong>带宽</strong>，表示链路的最大传输速率，单位通常为 b/s （比特 / 秒）。</li>
<li><strong>吞吐量</strong>，表示单位时间内成功传输的数据量，单位通常为 b/s（比特 / 秒）或者 B/s（字节 / 秒）。吞吐量受带宽限制，而吞吐量 / 带宽，也就是该网络的使用率。</li>
<li><strong>延时</strong>，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。在不同场景中，这一指标可能会有不同含义。比如，它可以表示，建立连接需要的时间（比如 TCP 握手延时），或一个数据包往返所需的时间（比如 RTT）。</li>
<li><strong>PPS</strong>，是 Packet Per Second（包 / 秒）的缩写，表示以网络包为单位的传输速率。PPS 通常用来评估网络的转发能力，比如硬件交换机，通常可以达到线性转发（即 PPS 可以达到或者接近理论最大值）。而基于 Linux 服务器的转发，则容易受网络包大小的影响。</li>
</ul>
<p>除了这些指标，<strong>网络的可用性</strong>（网络能否正常通信）、<strong>并发连接数</strong>（TCP 连接数量）、<strong>丢包率</strong>（丢包百分比）、<strong>重传率</strong>（重新传输的网络包比例）等也是常用的性能指标。</p>
<h4 id="34-2-网络配置"><a href="#34-2-网络配置" class="headerlink" title="34.2 网络配置"></a>34.2 网络配置</h4><p>可以使用 ifconfig 或者 ip 命令，来查看网络的配置。我个人更推荐使用 ip 工具，因为它提供了更丰富的功能和更易用的接口。</p>
<blockquote>
<p>ifconfig 和 ip 分别属于软件包 net-tools 和 iproute2，iproute2 是 net-tools 的下一代。通常情况下它们会在发行版中默认安装。但如果你找不到 ifconfig 或者 ip 命令，可以安装这两个软件包。</p>
</blockquote>
<p>以网络接口 eth0 为例，你可以运行下面的两个命令，查看它的配置和状态：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">ifconfig</span> eth0
eth0: <span class="token assign-left variable">flags</span><span class="token operator">=</span><span class="token number">416</span><span class="token operator"><span class="token file-descriptor important">3</span>&lt;</span>UP,BROADCAST,RUNNING,MULTICAST<span class="token operator">&gt;</span> mtu <span class="token number">1500</span>
      inet <span class="token number">10.240</span>.0.30 netmask <span class="token number">255.240</span>.0.0 broadcast <span class="token number">10.255</span>.255.255
      inet6 fe80::20d:3aff:fe07:cf2a prefixlen <span class="token number">64</span> scopeid 0x2<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>link<span class="token operator">&gt;</span>
      ether <span class="token number">78</span>:0d:3a:07:cf:3a txqueuelen <span class="token number">1000</span> <span class="token punctuation">(</span>Ethernet<span class="token punctuation">)</span>
      RX packets <span class="token number">40809142</span> bytes <span class="token number">9542369803</span> <span class="token punctuation">(</span><span class="token number">9.5</span> GB<span class="token punctuation">)</span>
      RX errors <span class="token number">0</span> dropped <span class="token number">0</span> overruns <span class="token number">0</span> frame <span class="token number">0</span>
      TX packets <span class="token number">32637401</span> bytes <span class="token number">4815573306</span> <span class="token punctuation">(</span><span class="token number">4.8</span> GB<span class="token punctuation">)</span>
      TX errors <span class="token number">0</span> dropped <span class="token number">0</span> overruns <span class="token number">0</span> carrier <span class="token number">0</span> collisions <span class="token number">0</span>
​
$ <span class="token function">ip</span> -s addr show dev eth0
<span class="token number">2</span>: eth0: <span class="token operator">&lt;</span>BROADCAST,MULTICAST,UP,LOWER_UP<span class="token operator">&gt;</span> mtu <span class="token number">1500</span> qdisc mq state UP group default qlen <span class="token number">1000</span>
  link/ether <span class="token number">78</span>:0d:3a:07:cf:3a brd ff:ff:ff:ff:ff:ff
  inet <span class="token number">10.240</span>.0.30/12 brd <span class="token number">10.255</span>.255.255 scope global eth0
      valid_lft forever preferred_lft forever
  inet6 fe80::20d:3aff:fe07:cf2a/64 scope <span class="token function">link</span>
      valid_lft forever preferred_lft forever
  RX: bytes packets errors dropped overrun mcast
   <span class="token number">9542432350</span> <span class="token number">40809397</span> <span class="token number">0</span>       <span class="token number">0</span>       <span class="token number">0</span>       <span class="token number">193</span>
  TX: bytes packets errors dropped carrier collsns
   <span class="token number">4815625265</span> <span class="token number">32637658</span> <span class="token number">0</span>       <span class="token number">0</span>       <span class="token number">0</span>       <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这些具体指标的含义，在文档中都有详细的说明，不过，这里有几个跟网络性能密切相关的指标，需要你特别关注一下。</p>
<ol>
<li><p>第一，网络接口的状态标志。ifconfig 输出中的 RUNNING ，或 ip 输出中的 LOWER_UP ，都表示物理网络是连通的，即网卡已经连接到了交换机或者路由器中。如果你看不到它们，通常表示网线被拔掉了。</p>
</li>
<li><p>第二，MTU 的大小。MTU 默认大小是 1500，根据网络架构的不同（比如是否使用了 VXLAN 等叠加网络），你可能需要调大或者调小 MTU 的数值。</p>
</li>
<li><p>第三，网络接口的 IP 地址、子网以及 MAC 地址。这些都是保障网络功能正常工作所必需的，你需要确保配置正确。</p>
</li>
<li><p>第四，网络收发的字节数、包数、错误数以及丢包情况，特别是 TX 和 RX 部分的 errors、dropped、overruns、carrier 以及 collisions 等指标不为 0 时，通常表示出现了网络 I/O 问题。其中：</p>
<ol>
<li>errors 表示发生错误的数据包数，比如校验错误、帧同步错误等；</li>
<li>dropped 表示丢弃的数据包数，即数据包已经收到了 Ring Buffer，但因为内存不足等原因丢包；</li>
<li>overruns 表示超限数据包数，即网络 I/O 速度过快，导致 Ring Buffer 中的数据包来不及处理（队列满）而导致的丢包；</li>
<li>carrier 表示发生 carrirer 错误的数据包数，比如双工模式不匹配、物理电缆出现问题等；</li>
<li>collisions 表示碰撞数据包数。</li>
</ol>
</li>
</ol>
<h4 id="34-3-套接字信息"><a href="#34-3-套接字信息" class="headerlink" title="34.3 套接字信息"></a>34.3 套接字信息</h4><p>使用 ss 来查询网络的连接信息，因为它比 netstat 提供了更好的性能（速度更快）。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># head -n 3 表示只显示前面 3 行</span>
<span class="token comment"># -l 表示只显示监听套接字</span>
<span class="token comment"># -n 表示显示数字地址和端口 (而不是名字)</span>
<span class="token comment"># -p 表示显示进程信息</span>
$ <span class="token function">netstat</span> -nlp <span class="token operator">|</span> <span class="token function">head</span> -n <span class="token number">3</span>
Active Internet connections <span class="token punctuation">(</span>only servers<span class="token punctuation">)</span>
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name
tcp        <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">127.0</span>.0.53:53           <span class="token number">0.0</span>.0.0:*               LISTEN      <span class="token number">840</span>/systemd-resolve

<span class="token comment"># -l 表示只显示监听套接字</span>
<span class="token comment"># -t 表示只显示 TCP 套接字</span>
<span class="token comment"># -n 表示显示数字地址和端口 (而不是名字)</span>
<span class="token comment"># -p 表示显示进程信息</span>
$ ss -ltnp <span class="token operator">|</span> <span class="token function">head</span> -n <span class="token number">3</span>
State    Recv-Q    Send-Q        Local Address:Port        Peer Address:Port
LISTEN   <span class="token number">0</span>         <span class="token number">128</span>           <span class="token number">127.0</span>.0.53%lo:53               <span class="token number">0.0</span>.0.0:*        users:<span class="token variable"><span class="token punctuation">((</span>"systemd<span class="token operator">-</span>resolve"<span class="token punctuation">,</span>pid<span class="token operator">=</span><span class="token number">840</span><span class="token punctuation">,</span>fd<span class="token operator">=</span><span class="token number">13</span><span class="token punctuation">))</span></span>
LISTEN   <span class="token number">0</span>         <span class="token number">128</span>                 <span class="token number">0.0</span>.0.0:22               <span class="token number">0.0</span>.0.0:*        users:<span class="token variable"><span class="token punctuation">((</span>"sshd"<span class="token punctuation">,</span>pid<span class="token operator">=</span><span class="token number">1459</span><span class="token punctuation">,</span>fd<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">))</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>其中，接收队列（Recv-Q）和发送队列（Send-Q）需要你特别关注，它们通常应该是 0。当你发现它们不是 0 时，说明有网络包的堆积发生。当然还要注意，在不同套接字状态下，它们的含义不同。</p>
<p>当套接字处于连接状态（Established）时，</p>
<ul>
<li>Recv-Q 表示套接字缓冲还没有被应用程序取走的字节数（即接收队列长度）。</li>
<li>而 Send-Q 表示还没有被远端主机确认的字节数（即发送队列长度）。</li>
</ul>
<p>当套接字处于监听状态（Listening）时，</p>
<ul>
<li>Recv-Q 表示 syn backlog 的当前值。</li>
<li>而 Send-Q 表示最大的 syn backlog 值。</li>
</ul>
<p>而 syn backlog 是 TCP 协议栈中的半连接队列长度，相应的也有一个全连接队列（accept queue），它们都是维护 TCP 状态的重要机制。</p>
<p>顾名思义，所谓半连接，就是还没有完成 TCP 三次握手的连接，连接只进行了一半，而服务器收到了客户端的 SYN 包后，就会把这个连接放到半连接队列中，然后再向客户端发送 SYN+ACK 包。</p>
<p>而全连接，则是指服务器收到了客户端的 ACK，完成了 TCP 三次握手，然后就会把这个连接挪到全连接队列中。这些全连接中的套接字，还需要再被 accept() 系统调用取走，这样，服务器就可以开始真正处理客户端的请求了。</p>
<h4 id="34-4-协议栈统计信息"><a href="#34-4-协议栈统计信息" class="headerlink" title="34.4 协议栈统计信息"></a>34.4 协议栈统计信息</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">netstat</span> -s
<span class="token punctuation">..</span>.
Tcp:
    <span class="token number">3244906</span> active connection openings
    <span class="token number">23143</span> passive connection openings
    <span class="token number">115732</span> failed connection attempts
    <span class="token number">2964</span> connection resets received
    <span class="token number">1</span> connections established
    <span class="token number">13025010</span> segments received
    <span class="token number">17606946</span> segments sent out
    <span class="token number">44438</span> segments retransmitted
    <span class="token number">42</span> bad segments received
    <span class="token number">5315</span> resets sent
    InCsumErrors: <span class="token number">42</span>
<span class="token punctuation">..</span>.

$ ss -s
Total: <span class="token number">186</span> <span class="token punctuation">(</span>kernel <span class="token number">1446</span><span class="token punctuation">)</span>
TCP:   <span class="token number">4</span> <span class="token punctuation">(</span>estab <span class="token number">1</span>, closed <span class="token number">0</span>, orphaned <span class="token number">0</span>, synrecv <span class="token number">0</span>, timewait <span class="token number">0</span>/0<span class="token punctuation">)</span>, ports <span class="token number">0</span>

Transport Total     IP        IPv6
*     <span class="token number">1446</span>      -         -
RAW   <span class="token number">2</span>         <span class="token number">1</span>         <span class="token number">1</span>
UDP   <span class="token number">2</span>         <span class="token number">2</span>         <span class="token number">0</span>
TCP   <span class="token number">4</span>         <span class="token number">3</span>         <span class="token number">1</span>
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这些协议栈的统计信息都很直观。ss 只显示已经连接、关闭、孤儿套接字等简要统计，而 netstat 则提供的是更详细的网络协议栈信息。</p>
<p>比如，上面 netstat 的输出示例，就展示了 TCP 协议的主动连接、被动连接、失败重试、发送和接收的分段数量等各种信息。</p>
<h4 id="34-5-网络吞吐和-PPS"><a href="#34-5-网络吞吐和-PPS" class="headerlink" title="34.5 网络吞吐和 PPS"></a>34.5 网络吞吐和 PPS</h4><p>给 sar 增加 -n 参数就可以查看网络的统计信息，比如网络接口（DEV）、网络接口错误（EDEV）、TCP、UDP、ICMP 等等。执行下面的命令，你就可以得到网络接口统计信息：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 数字 1 表示每隔 1 秒输出一组数据</span>
$ sar -n DEV <span class="token number">1</span>
Linux <span class="token number">4.15</span>.0-1035-azure <span class="token punctuation">(</span>ubuntu<span class="token punctuation">)</span>    01/06/19    _x86_64_    <span class="token punctuation">(</span><span class="token number">2</span> CPU<span class="token punctuation">)</span>

<span class="token number">13</span>:21:40        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
<span class="token number">13</span>:21:41         eth0     <span class="token number">18.00</span>     <span class="token number">20.00</span>      <span class="token number">5.79</span>      <span class="token number">4.25</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>
<span class="token number">13</span>:21:41      docker0      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>
<span class="token number">13</span>:21:41           lo      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span>      <span class="token number">0.00</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这儿输出的指标比较多，我来简单解释下它们的含义。</p>
<ul>
<li>rxpck/s 和 txpck/s 分别是接收和发送的 PPS，单位为包 / 秒。</li>
<li>rxkB/s 和 txkB/s 分别是接收和发送的吞吐量，单位是 KB/ 秒。</li>
<li>rxcmp/s 和 txcmp/s 分别是接收和发送的压缩数据包数，单位是包 / 秒。</li>
<li>%ifutil 是网络接口的使用率，即半双工模式下为 (rxkB/s+txkB/s)/Bandwidth，而全双工模式下为 max(rxkB/s, txkB/s)/Bandwidth。</li>
</ul>
<p>其中，Bandwidth 可以用 ethtool 来查询，它的单位通常是 Gb/s 或者 Mb/s，不过注意这里小写字母 b ，表示比特而不是字节。我们通常提到的千兆网卡、万兆网卡等，单位也都是比特。如下你可以看到，我的 eth0 网卡就是一个千兆网卡：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">ethtool</span> eth0 <span class="token operator">|</span> <span class="token function">grep</span> Speed
    Speed: 1000Mb/s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h4 id="34-6-连通性和延时"><a href="#34-6-连通性和延时" class="headerlink" title="34.6 连通性和延时"></a>34.6 连通性和延时</h4><p>最后，我们通常使用 ping ，来测试远程主机的连通性和延时，而这基于 ICMP 协议。比如，执行下面的命令，你就可以测试本机到 114.114.114.114 这个 IP 地址的连通性和延时：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -c3 表示发送三次 ICMP 包后停止</span>
$ <span class="token function">ping</span> -c3 <span class="token number">114.114</span>.114.114
PING <span class="token number">114.114</span>.114.114 <span class="token punctuation">(</span><span class="token number">114.114</span>.114.114<span class="token punctuation">)</span> <span class="token number">56</span><span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">)</span> bytes of data.
<span class="token number">64</span> bytes from <span class="token number">114.114</span>.114.114: <span class="token assign-left variable">icmp_seq</span><span class="token operator">=</span><span class="token number">1</span> <span class="token assign-left variable">ttl</span><span class="token operator">=</span><span class="token number">54</span> <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">244</span> ms
<span class="token number">64</span> bytes from <span class="token number">114.114</span>.114.114: <span class="token assign-left variable">icmp_seq</span><span class="token operator">=</span><span class="token number">2</span> <span class="token assign-left variable">ttl</span><span class="token operator">=</span><span class="token number">47</span> <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">244</span> ms
<span class="token number">64</span> bytes from <span class="token number">114.114</span>.114.114: <span class="token assign-left variable">icmp_seq</span><span class="token operator">=</span><span class="token number">3</span> <span class="token assign-left variable">ttl</span><span class="token operator">=</span><span class="token number">67</span> <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">244</span> ms

--- <span class="token number">114.114</span>.114.114 <span class="token function">ping</span> statistics ---
<span class="token number">3</span> packets transmitted, <span class="token number">3</span> received, <span class="token number">0</span>% packet loss, <span class="token function">time</span> 2001ms
rtt min/avg/max/mdev <span class="token operator">=</span> <span class="token number">244.023</span>/244.070/244.105/0.034 ms<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>ping 的输出，可以分为两部分。</p>
<ul>
<li>第一部分，是每个 ICMP 请求的信息，包括 ICMP 序列号（icmp_seq）、TTL（生存时间，或者跳数）以及往返延时。</li>
<li>第二部分，则是三次 ICMP 请求的汇总。</li>
</ul>
<p>比如上面的示例显示，发送了 3 个网络包，并且接收到 3 个响应，没有丢包发生，这说明测试主机到 114.114.114.114 是连通的；平均往返延时（RTT）是 244ms，也就是从发送 ICMP 开始，到接收到 114.114.114.114 回复的确认，总共经历 244ms。</p>
<h3 id="35-基础篇：C10K-和-C1000K-回顾"><a href="#35-基础篇：C10K-和-C1000K-回顾" class="headerlink" title="35 | 基础篇：C10K 和 C1000K 回顾"></a>35 | 基础篇：C10K 和 C1000K 回顾</h3><p>回顾下经典的 C10K 和 C1000K 问题，以更好理解 Linux 网络的工作原理，并进一步分析，如何做到单机支持 C10M。</p>
<p>注意，C10K 和 C1000K 的首字母 C 是 Client 的缩写。C10K 就是单机同时处理 1 万个请求（并发连接 1 万）的问题，而 C1000K 也就是单机支持处理 100 万个请求（并发连接 100 万）的问题。</p>
<h4 id="35-1-C10K"><a href="#35-1-C10K" class="headerlink" title="35.1 C10K"></a>35.1 C10K</h4><p><a target="_blank" rel="noopener" href="http://www.kegel.com/c10k.html">C10K 问题</a>最早由 Dan Kegel 在 1999 年提出。那时的服务器还只是 32 位系统，运行着 Linux 2.2 版本（后来又升级到了 2.4 和 2.6，而 2.6 才支持 x86_64），只配置了很少的内存（2GB）和千兆网卡。</p>
<p>怎么在这样的系统中支持并发 1 万的请求呢？</p>
<p>从资源上来说，对 2GB 内存和千兆网卡的服务器来说，同时处理 10000 个请求，只要每个请求处理占用不到 200KB（2GB/10000）的内存和 100Kbit （1000Mbit/10000）的网络带宽就可以。所以，物理资源是足够的，接下来自然是软件的问题，特别是网络的 I/O 模型问题。</p>
<p>说到 I/O 的模型，我在文件系统的原理中，曾经介绍过文件 I/O，其实网络 I/O 模型也类似。在 C10K 以前，Linux 中网络处理都用同步阻塞的方式，也就是每个请求都分配一个进程或者线程。请求数只有 100 个时，这种方式自然没问题，但增加到 10000 个请求时，10000 个进程或线程的调度、上下文切换乃至它们占用的内存，都会成为瓶颈。</p>
<p>既然每个请求分配一个线程的方式不合适，那么，为了支持 10000 个并发请求，这里就有两个问题需要我们解决。</p>
<ol>
<li>第一，怎样在一个线程内处理多个请求，也就是要在一个线程内响应多个网络 I/O。以前的同步阻塞方式下，一个线程只能处理一个请求，到这里不再适用，是不是可以用非阻塞 I/O 或者异步 I/O 来处理多个网络请求呢？</li>
<li>第二，怎么更节省资源地处理客户请求，也就是要用更少的线程来服务这些请求。是不是可以继续用原来的 100 个或者更少的线程，来服务现在的 10000 个请求呢？</li>
</ol>
<p>当然，事实上，现在 C10K 的问题早就解决了，在继续学习下面的内容前，你可以先自己思考一下这两个问题。结合前面学过的内容，你是不是已经有了解决思路呢？</p>
<h4 id="35-2-I-O-模型优化"><a href="#35-2-I-O-模型优化" class="headerlink" title="35.2 I/O 模型优化"></a>35.2 I/O 模型优化</h4><p>异步、非阻塞 I/O 的解决思路，你应该听说过，其实就是我们在网络编程中经常用到的 I/O 多路复用（I/O Multiplexing）。I/O 多路复用是什么意思呢？</p>
<p>别急，详细了解前，我先来讲两种 I/O 事件通知的方式：水平触发和边缘触发，它们常用在套接字接口的文件描述符中。</p>
<ul>
<li>水平触发：只要文件描述符可以非阻塞地执行 I/O ，就会触发通知。也就是说，应用程序可以随时检查文件描述符的状态，然后再根据状态，进行 I/O 操作。</li>
<li>边缘触发：只有在文件描述符的状态发生改变（也就是 I/O 请求达到）时，才发送一次通知。这时候，应用程序需要尽可能多地执行 I/O，直到无法继续读写，才可以停止。如果 I/O 没执行完，或者因为某种原因没来得及处理，那么这次通知也就丢失了。</li>
</ul>
<p>接下来，我们再回过头来看 I/O 多路复用的方法。这里其实有很多实现方法，我带你来逐个分析一下。</p>
<ol>
<li><p><strong>第一种，使用非阻塞 I/O 和水平触发通知，比如使用 select 或者 poll。</strong></p>
<p> 这种方式的最大优点，是对应用程序比较友好，它的 API 非常简单。</p>
<p> 但是，应用软件使用 select 和 poll 时，需要对这些文件描述符列表进行轮询，这样，请求数多的时候就会比较耗时。并且，select 和 poll 还有一些其他的限制。</p>
<p> select 使用固定长度的位相量，表示文件描述符的集合，因此会有最大描述符数量的限制。比如，在 32 位系统中，默认限制是 1024。并且，在 select 内部，检查套接字状态是用轮询的方法，再加上应用软件使用时的轮询，就变成了一个 O(n^2) 的关系。</p>
<p> 而 poll 改进了 select 的表示方法，换成了一个没有固定长度的数组，这样就没有了最大描述符数量的限制（当然还会受到系统文件描述符限制）。但应用程序在使用 poll 时，同样需要对文件描述符列表进行轮询，这样，处理耗时跟描述符数量就是 O(N) 的关系。</p>
<p> 除此之外，应用程序每次调用 select 和 poll 时，还需要把文件描述符的集合，从用户空间传入内核空间，由内核修改后，再传出到用户空间中。这一来一回的内核空间与用户空间切换，也增加了处理成本。</p>
</li>
<li><p><strong>第二种，使用非阻塞 I/O 和边缘触发通知，比如 epoll。</strong></p>
<p> 既然 select 和 poll 有那么多的问题，就需要继续对其进行优化，而 epoll 就很好地解决了这些问题。</p>
<ul>
<li>epoll 使用红黑树，在内核中管理文件描述符的集合，这样，就不需要应用程序在每次操作时都传入、传出这个集合。</li>
<li>epoll 使用事件驱动的机制，只关注有 I/O 事件发生的文件描述符，不需要轮询扫描整个集合。</li>
</ul>
</li>
<li><p><strong>第三种，使用异步 I/O（Asynchronous I/O，简称为 AIO）。</strong></p>
<p> 异步 I/O 允许应用程序同时发起很多 I/O 操作，而不用等待这些操作完成。而在 I/O 完成后，系统会用事件通知（比如信号或者回调函数）的方式，告诉应用程序。这时，应用程序才会去查询 I/O 操作的结果。</p>
<p> 异步 I/O 也是到了 Linux 2.6 才支持的功能，并且在很长时间里都处于不完善的状态，比如 glibc 提供的异步 I/O 库，就一直被社区诟病。同时，由于异步 I/O 跟我们的直观逻辑不太一样，想要使用的话，一定要小心设计，其使用难度比较高。</p>
</li>
</ol>
<h4 id="35-3-工作模型优化"><a href="#35-3-工作模型优化" class="headerlink" title="35.3 工作模型优化"></a>35.3 工作模型优化</h4><p>使用 I/O 多路复用后，就可以在一个进程或线程中处理多个请求，其中，又有下面两种不同的工作模型。</p>
<ol>
<li><p><strong>第一种，主进程 + 多个 worker 子进程，这也是最常用的一种模型。</strong> 这种方法的一个通用工作模式就是：</p>
<ul>
<li>主进程执行 bind() + listen() 后，创建多个子进程；</li>
<li><p>然后，在每个子进程中，都通过 accept() 或 epoll_wait() ，来处理相同的套接字。</p>
<p>比如，最常用的反向代理服务器 Nginx 就是这么工作的。它也是由主进程和多个 worker 进程组成。主进程主要用来初始化套接字，并管理子进程的生命周期；而 worker 进程，则负责实际的请求处理。我画了一张图来表示这个关系。</p>
<p><img src="/images/《Linux性能优化实战》学习笔记/主进程多个worker子进程工作模型.png" alt="主进程多个worker子进程工作模型"></p>
<p>这里要注意，accept() 和 epoll_wait() 调用，还存在一个惊群的问题。换句话说，当网络 I/O 事件发生时，多个进程被同时唤醒，但实际上只有一个进程来响应这个事件，其他被唤醒的进程都会重新休眠。</p>
</li>
<li><p>其中，accept() 的惊群问题，已经在 Linux 2.6 中解决了；</p>
</li>
<li><p>而 epoll 的问题，到了 Linux 4.5 ，才通过 EPOLLEXCLUSIVE 解决。</p>
<p>为了避免惊群问题， Nginx 在每个 worker 进程中，都增加一个了全局锁（accept_mutex）。这些 worker 进程需要首先竞争到锁，只有竞争到锁的进程，才会加入到 epoll 中，这样就确保只有一个 worker 子进程被唤醒。</p>
<p>不过，根据前面 CPU 模块的学习，你应该还记得，进程的管理、调度、上下文切换的成本非常高。那为什么使用多进程模式的 Nginx ，却具有非常好的性能呢？</p>
<p>这里最主要的一个原因就是，这些 worker 进程，实际上并不需要经常创建和销毁，而是在没任务时休眠，有任务时唤醒。只有在 worker 由于某些异常退出时，主进程才需要创建新的进程来代替它。</p>
<p>当然，你也可以用线程代替进程：主线程负责套接字初始化和子线程状态的管理，而子线程则负责实际的请求处理。由于线程的调度和切换成本比较低，实际上你可以进一步把 epoll_wait() 都放到主线程中，保证每次事件都只唤醒主线程，而子线程只需要负责后续的请求处理。</p>
</li>
</ul>
</li>
<li><p><strong>第二种，监听到相同端口的多进程模型。</strong> 在这种方式下，所有的进程都监听相同的接口，并且开启 SO_REUSEPORT 选项，由内核负责将请求负载均衡到这些监听进程中去。这一过程如下图所示。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/监听到相同端口的多进程工作模型.png" alt="监听到相同端口的多进程工作模型"></p>
<p> 由于内核确保了只有一个进程被唤醒，就不会出现惊群问题了。比如，Nginx 在 1.9.1 中就已经支持了这种模式。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/Nginx监听到相同端口的多进程工作模型.png" alt="Nginx监听到相同端口的多进程工作模型"></p>
<blockquote>
<p>图片来自 <a target="_blank" rel="noopener" href="https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/">Nginx 官网博客</a></p>
</blockquote>
</li>
</ol>
<h4 id="35-4-C1000K"><a href="#35-4-C1000K" class="headerlink" title="35.4 C1000K"></a>35.4 C1000K</h4><p>首先从物理资源使用上来说，100 万个请求需要大量的系统资源。比如，</p>
<ul>
<li>假设每个请求需要 16KB 内存的话，那么总共就需要大约 15 GB 内存。</li>
<li>而从带宽上来说，假设只有 20% 活跃连接，即使每个连接只需要 1KB/s 的吞吐量，总共也需要 1.6 Gb/s 的吞吐量。千兆网卡显然满足不了这么大的吞吐量，所以还需要配置万兆网卡，或者基于多网卡 Bonding 承载更大的吞吐量。</li>
</ul>
<p>其次，从软件资源上来说，大量的连接也会占用大量的软件资源，比如文件描述符的数量、连接状态的跟踪（CONNTRACK）、网络协议栈的缓存大小（比如套接字读写缓存、TCP 读写缓存）等等。</p>
<p>断负载均衡、CPU 绑定、RPS/RFS（软中断负载均衡到多个 CPU 核上），以及将网络包的处理卸载（Offload）到网络设备（如 TSO/GSO、LRO/GRO、VXLAN OFFLOAD）等各种硬件和软件的优化。</p>
<p>C1000K 的解决方法，本质上还是构建在 epoll 的非阻塞 I/O 模型上。只不过，除了 I/O 模型之外，还需要从应用程序到 Linux 内核、再到 CPU、内存和网络等各个层次的深度优化，特别是需要借助硬件，来卸载那些原来通过软件处理的大量功能。</p>
<h4 id="35-5-C10M"><a href="#35-5-C10M" class="headerlink" title="35.5 C10M"></a>35.5 C10M</h4><p>显然，人们对于性能的要求是无止境的。再进一步，有没有可能在单机中，同时处理 1000 万的请求呢？这也就是 <a target="_blank" rel="noopener" href="http://c10m.robertgraham.com/p/blog-page.html">C10M</a> 问题。</p>
<p>实际上，在 C1000K 问题中，各种软件、硬件的优化很可能都已经做到头了。特别是当升级完硬件（比如足够多的内存、带宽足够大的网卡、更多的网络功能卸载等）后，你可能会发现，无论你怎么优化应用程序和内核中的各种网络参数，想实现 1000 万请求的并发，都是极其困难的。</p>
<p>究其根本，还是 Linux 内核协议栈做了太多太繁重的工作。从网卡中断带来的硬中断处理程序开始，到软中断中的各层网络协议处理，最后再到应用程序，这个路径实在是太长了，就会导致网络包的处理优化，到了一定程度后，就无法更进一步了。</p>
<p>要解决这个问题，最重要就是跳过内核协议栈的冗长路径，把网络包直接送到要处理的应用程序那里去。这里有两种常见的机制，DPDK 和 XDP。</p>
<ol>
<li><p>第一种机制，DPDK，是用户态网络的标准。它跳过内核协议栈，直接由用户态进程通过轮询的方式，来处理网络接收。</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/DPDK.png" alt="DPDK"></p>
<blockquote>
<p>（图片来自 <a target="_blank" rel="noopener" href="https://blog.selectel.com/introduction-dpdk-architecture-principles/">https://blog.selectel.com/introduction-dpdk-architecture-principles/</a>）</p>
</blockquote>
<p> 说起轮询，你肯定会下意识认为它是低效的象征，但是进一步反问下自己，它的低效主要体现在哪里呢？是查询时间明显多于实际工作时间的情况下吧！那么，换个角度来想，如果每时每刻都有新的网络包需要处理，轮询的优势就很明显了。比如：</p>
<ul>
<li>在 PPS 非常高的场景中，查询时间比实际工作时间少了很多，绝大部分时间都在处理网络包；</li>
<li><p>而跳过内核协议栈后，就省去了繁杂的硬中断、软中断再到 Linux 网络协议栈逐层处理的过程，应用程序可以针对应用的实际场景，有针对性地优化网络包的处理逻辑，而不需要关注所有的细节。</p>
<p>此外，DPDK 还通过大页、CPU 绑定、内存对齐、流水线并发等多种机制，优化网络包的处理效率。</p>
</li>
</ul>
</li>
<li><p>第二种机制，XDP（eXpress Data Path），则是 Linux 内核提供的一种高性能网络数据路径。它允许网络包，在进入内核协议栈之前，就进行处理，也可以带来更高的性能。XDP 底层跟我们之前用到的 bcc-tools 一样，都是基于 Linux 内核的 eBPF 机制实现的。</p>
<p> XDP 的原理如下图所示：</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/XDP.png" alt="XDP"></p>
<blockquote>
<p>（图片来自 <a target="_blank" rel="noopener" href="https://www.iovisor.org/technology/xdp">https://www.iovisor.org/technology/xdp</a>）</p>
</blockquote>
<p> 你可以看到，XDP 对内核的要求比较高，需要的是 Linux <a target="_blank" rel="noopener" href="https://github.com/iovisor/bcc/blob/master/docs/kernel-versions.md#xdp">4.8 以上版本</a>，并且它也不提供缓存队列。基于 XDP 的应用程序通常是专用的网络应用，常见的有 IDS（入侵检测系统）、DDoS 防御、 <a target="_blank" rel="noopener" href="https://github.com/cilium/cilium">cilium</a> 容器网络插件等。</p>
</li>
</ol>
<h4 id="35-4-小结"><a href="#35-4-小结" class="headerlink" title="35.4 小结"></a>35.4 小结</h4><p>C10K 问题的根源，一方面在于系统有限的资源；另一方面，也是更重要的因素，是同步阻塞的 I/O 模型以及轮询的套接字接口，限制了网络事件的处理效率。Linux 2.6 中引入的 epoll ，完美解决了 C10K 的问题，现在的高性能网络方案都基于 epoll。</p>
<p>从 C10K 到 C100K ，可能只需要增加系统的物理资源就可以满足；但从 C100K 到 C1000K ，就不仅仅是增加物理资源就能解决的问题了。这时，就需要多方面的优化工作了，从硬件的中断处理和网络功能卸载、到网络协议栈的文件描述符数量、连接状态跟踪、缓存队列等内核的优化，再到应用程序的工作模型优化，都是考虑的重点。</p>
<p>再进一步，要实现 C10M ，就不只是增加物理资源，或者优化内核和应用程序可以解决的问题了。这时候，就需要用 XDP 的方式，在内核协议栈之前处理网络包；或者用 DPDK 直接跳过网络协议栈，在用户空间通过轮询的方式直接处理网络包。</p>
<p>当然了，实际上，在大多数场景中，我们并不需要单机并发 1000 万的请求。通过调整系统架构，把这些请求分发到多台服务器中来处理，通常是更简单和更容易扩展的方案。</p>
<h3 id="36-套路篇：怎么评估系统的网络性能？"><a href="#36-套路篇：怎么评估系统的网络性能？" class="headerlink" title="36 | 套路篇：怎么评估系统的网络性能？"></a>36 | 套路篇：怎么评估系统的网络性能？</h3><h4 id="36-1-性能指标回顾"><a href="#36-1-性能指标回顾" class="headerlink" title="36.1 性能指标回顾"></a>36.1 性能指标回顾</h4><ol>
<li><p>首先，<strong>带宽</strong>，表示链路的最大传输速率，单位是 b/s（比特 / 秒）。在你为服务器选购网卡时，带宽就是最核心的参考指标。常用的带宽有 1000M、10G、40G、100G 等。</p>
</li>
<li><p>第二，<strong>吞吐量</strong>，表示没有丢包时的最大数据传输速率，单位通常为 b/s （比特 / 秒）或者 B/s（字节 / 秒）。吞吐量受带宽的限制，吞吐量 / 带宽也就是该网络链路的使用率。</p>
</li>
<li><p>第三，<strong>延时</strong>，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。这个指标在不同场景中可能会有不同的含义。它可以表示建立连接需要的时间（比如 TCP 握手延时），或者一个数据包往返所需时间（比如 RTT）。</p>
</li>
<li><p>最后，<strong>PPS</strong>，是 Packet Per Second（包 / 秒）的缩写，表示以网络包为单位的传输速率。PPS 通常用来评估网络的转发能力，而基于 Linux 服务器的转发，很容易受到网络包大小的影响（交换机通常不会受到太大影响，即交换机可以线性转发）。</p>
</li>
</ol>
<p>这四个指标中，带宽跟物理网卡配置是直接关联的。一般来说，网卡确定后，带宽也就确定了（当然，实际带宽会受限于整个网络链路中最小的那个模块）。</p>
<p>另外，你可能在很多地方听说过“网络带宽测试”，这里测试的实际上不是带宽，而是网络吞吐量。Linux 服务器的网络吞吐量一般会比带宽小，而对交换机等专门的网络设备来说，吞吐量一般会接近带宽。</p>
<p>最后的 PPS，则是以网络包为单位的网络传输速率，通常用在需要大量转发的场景中。而对 TCP 或者 Web 服务来说，更多会用并发连接数和每秒请求数（QPS，Query per Second）等指标，它们更能反应实际应用程序的性能。</p>
<h4 id="36-2-网络基准测试"><a href="#36-2-网络基准测试" class="headerlink" title="36.2 网络基准测试"></a>36.2 网络基准测试</h4><p>测试之前，你应该弄清楚，你要评估的网络性能，究竟属于协议栈的哪一层？换句话说，你的应用程序基于协议栈的哪一层呢？</p>
<p>根据前面学过的 TCP/IP 协议栈的原理，这个问题应该不难回答。比如：</p>
<ul>
<li>基于 HTTP 或者 HTTPS 的 Web 应用程序，显然属于应用层，需要我们测试 HTTP/HTTPS 的性能；</li>
<li>而对大多数游戏服务器来说，为了支持更大的同时在线人数，通常会基于 TCP 或 UDP ，与客户端进行交互，这时就需要我们测试 TCP/UDP 的性能；</li>
<li>当然，还有一些场景，是把 Linux 作为一个软交换机或者路由器来用的。这种情况下，你更关注网络包的处理能力（即 PPS），重点关注网络层的转发性能。</li>
</ul>
<p>接下来，我就带你从下往上，了解不同协议层的网络性能测试方法。不过要注意，低层协议是其上的各层网络协议的基础。自然，低层协议的性能，也就决定了高层的网络性能。</p>
<h4 id="36-3-各协议层的性能测试"><a href="#36-3-各协议层的性能测试" class="headerlink" title="36.3 各协议层的性能测试"></a>36.3 各协议层的性能测试</h4><ol>
<li><p>转发性能</p>
<p> 我们首先来看，网络接口层和网络层，它们主要负责网络包的封装、寻址、路由以及发送和接收。在这两个网络协议层中，每秒可处理的网络包数 PPS，就是最重要的性能指标。特别是 64B 小包的处理能力，值得我们特别关注。那么，如何来测试网络包的处理能力呢？</p>
<p> 说到网络包相关的测试，你可能会觉得陌生。不过，其实在专栏开头的 CPU 性能篇中，我们就接触过一个相关工具，也就是软中断案例中的 hping3。</p>
<p> 在那个案例中，hping3 作为一个 SYN 攻击的工具来使用。实际上， hping3 更多的用途，是作为一个测试网络包处理能力的性能工具。</p>
<p> 今天我再来介绍另一个更常用的工具，Linux 内核自带的高性能网络测试工具 pktgen。pktgen 支持丰富的自定义选项，方便你根据实际需要构造所需网络包，从而更准确地测试出目标服务器的性能。</p>
<p> 不过，在 Linux 系统中，你并不能直接找到 pktgen 命令。因为 pktgen 作为一个内核线程来运行，需要你加载 pktgen 内核模块后，再通过 /proc 文件系统来交互。下面就是 pktgen 启动的两个内核线程和 /proc 文件系统的交互文件：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ modprobe pktgen
$ <span class="token function">ps</span> -ef <span class="token operator">|</span> <span class="token function">grep</span> pktgen <span class="token operator">|</span> <span class="token function">grep</span> -v <span class="token function">grep</span>
root     <span class="token number">26384</span>     <span class="token number">2</span>  <span class="token number">0</span> 06:17 ?        00:00:00 <span class="token punctuation">[</span>kpktgend_0<span class="token punctuation">]</span>
root     <span class="token number">26385</span>     <span class="token number">2</span>  <span class="token number">0</span> 06:17 ?        00:00:00 <span class="token punctuation">[</span>kpktgend_1<span class="token punctuation">]</span>
$ <span class="token function">ls</span> /proc/net/pktgen/
kpktgend_0  kpktgend_1  pgctrl<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> pktgen 在每个 CPU 上启动一个内核线程，并可以通过 /proc/net/pktgen 下面的同名文件，跟这些线程交互；而 pgctrl 则主要用来控制这次测试的开启和停止。</p>
<blockquote>
<p>如果 modprobe 命令执行失败，说明你的内核没有配置 CONFIG_NET_PKTGEN 选项。这就需要你配置 pktgen 内核模块（即 CONFIG_NET_PKTGEN=m）后，重新编译内核，才可以使用。</p>
</blockquote>
<p> 在使用 pktgen 测试网络性能时，需要先给每个内核线程 kpktgend_X 以及测试网卡，配置 pktgen 选项，然后再通过 pgctrl 启动测试。</p>
<p> 以发包测试为例，假设发包机器使用的网卡是 eth0，而目标机器的 IP 地址为 192.168.0.30，MAC 地址为 11:11:11:11:11:11。</p>
<p> 接下来，就是一个发包测试的示例。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 定义一个工具函数，方便后面配置各种测试选项</span>
<span class="token keyword">function</span> <span class="token function-name function">pgset</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token builtin class-name">local</span> result
    <span class="token builtin class-name">echo</span> <span class="token variable">$1</span> <span class="token operator">&gt;</span> <span class="token variable">$PGDEV</span>

    <span class="token assign-left variable">result</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token function">cat</span> $PGDEV <span class="token operator">|</span> <span class="token function">fgrep</span> <span class="token string">"Result: OK:"</span><span class="token variable">`</span></span>
    <span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">"<span class="token variable">$result</span>"</span> <span class="token operator">=</span> <span class="token string">""</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span>
         <span class="token function">cat</span> <span class="token variable">$PGDEV</span> <span class="token operator">|</span> <span class="token function">fgrep</span> Result:
    <span class="token keyword">fi</span>
<span class="token punctuation">}</span>

<span class="token comment"># 为 0 号线程绑定 eth0 网卡</span>
<span class="token assign-left variable">PGDEV</span><span class="token operator">=</span>/proc/net/pktgen/kpktgend_0
pgset <span class="token string">"rem_device_all"</span>   <span class="token comment"># 清空网卡绑定</span>
pgset <span class="token string">"add_device eth0"</span>  <span class="token comment"># 添加 eth0 网卡</span>

<span class="token comment"># 配置 eth0 网卡的测试选项</span>
<span class="token assign-left variable">PGDEV</span><span class="token operator">=</span>/proc/net/pktgen/eth0
pgset <span class="token string">"count 1000000"</span>    <span class="token comment"># 总发包数量</span>
pgset <span class="token string">"delay 5000"</span>       <span class="token comment"># 不同包之间的发送延迟 (单位纳秒)</span>
pgset <span class="token string">"clone_skb 0"</span>      <span class="token comment"># SKB 包复制</span>
pgset <span class="token string">"pkt_size 64"</span>      <span class="token comment"># 网络包大小</span>
pgset <span class="token string">"dst 192.168.0.30"</span> <span class="token comment"># 目的 IP</span>
pgset <span class="token string">"dst_mac 11:11:11:11:11:11"</span>  <span class="token comment"># 目的 MAC</span>

<span class="token comment"># 启动测试</span>
<span class="token assign-left variable">PGDEV</span><span class="token operator">=</span>/proc/net/pktgen/pgctrl
pgset <span class="token string">"start"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 稍等一会儿，测试完成后，结果可以从 /proc 文件系统中获取。通过下面代码段中的内容，我们可以查看刚才的测试报告：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">cat</span> /proc/net/pktgen/eth0
Params: count <span class="token number">1000000</span>  min_pkt_size: <span class="token number">64</span>  max_pkt_size: <span class="token number">64</span>
    frags: <span class="token number">0</span>  delay: <span class="token number">0</span>  clone_skb: <span class="token number">0</span>  ifname: eth0
    flows: <span class="token number">0</span> flowlen: <span class="token number">0</span>
<span class="token punctuation">..</span>.
Current:
    pkts-sofar: <span class="token number">1000000</span>  errors: <span class="token number">0</span>
    started: 1534853256071us  stopped: 1534861576098us idle: 70673us
<span class="token punctuation">..</span>.
Result: OK: <span class="token number">8320027</span><span class="token punctuation">(</span>c8249354+d70673<span class="token punctuation">)</span> usec, <span class="token number">1000000</span> <span class="token punctuation">(</span>64byte,0frags<span class="token punctuation">)</span>
120191pps 61Mb/sec <span class="token punctuation">(</span>61537792bps<span class="token punctuation">)</span> errors: <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 你可以看到，测试报告主要分为三个部分：</p>
<ul>
<li>第一部分的 Params 是测试选项；</li>
<li>第二部分的 Current 是测试进度，其中， packts so far（pkts-sofar）表示已经发送了 100 万个包，也就表明测试已完成。</li>
<li><p>第三部分的 Result 是测试结果，包含测试所用时间、网络包数量和分片、PPS、吞吐量以及错误数。</p>
<p>根据上面的结果，我们发现，PPS 为 12 万，吞吐量为 61 Mb/s，没有发生错误。那么，12 万的 PPS 好不好呢？</p>
<p>作为对比，你可以计算一下千兆交换机的 PPS。交换机可以达到线速（满负载时，无差错转发），它的 PPS 就是 1000Mbit 除以以太网帧的大小，即 1000Mbps/((64+20)*8bit) = 1.5 Mpps（其中，20B 为以太网帧前导和帧间距的大小）。</p>
<p>你看，即使是千兆交换机的 PPS，也可以达到 150 万 PPS，比我们测试得到的 12 万大多了。所以，看到这个数值你并不用担心，现在的多核服务器和万兆网卡已经很普遍了，稍做优化就可以达到数百万的 PPS。而且，如果你用了上节课讲到的 DPDK 或 XDP ，还能达到千万数量级。</p>
</li>
</ul>
</li>
<li><p>TCP/UDP 性能</p>
<p> 掌握了 PPS 的测试方法，接下来，我们再来看 TCP 和 UDP 的性能测试方法。说到 TCP 和 UDP 的测试，我想你已经很熟悉了，甚至可能一下子就能想到相应的测试工具，比如 iperf 或者 netperf。</p>
<p> 特别是现在的云计算时代，在你刚拿到一批虚拟机时，首先要做的，应该就是用 iperf ，测试一下网络性能是否符合预期。</p>
<p> iperf 和 netperf 都是最常用的网络性能测试工具，测试 TCP 和 UDP 的吞吐量。它们都以客户端和服务器通信的方式，测试一段时间内的平均吞吐量。</p>
<p> 接下来，我们就以 iperf 为例，看一下 TCP 性能的测试方法。目前，iperf 的最新版本为 iperf3，你可以运行下面的命令来安装：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Ubuntu</span>
<span class="token function">apt-get</span> <span class="token function">install</span> iperf3
<span class="token comment"># CentOS</span>
yum <span class="token function">install</span> iperf3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 然后，在目标机器上启动 iperf 服务端：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -s 表示启动服务端，-i 表示汇报间隔，-p 表示监听端口</span>
$ iperf3 -s -i <span class="token number">1</span> -p <span class="token number">10000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p> 接着，在另一台机器上运行 iperf 客户端，运行测试：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -c 表示启动客户端，192.168.0.30 为目标服务器的 IP</span>
<span class="token comment"># -b 表示目标带宽 (单位是 bits/s)</span>
<span class="token comment"># -t 表示测试时间</span>
<span class="token comment"># -P 表示并发数，-p 表示目标服务器监听端口</span>
$ iperf3 -c <span class="token number">192.168</span>.0.30 -b 1G -t <span class="token number">15</span> -P <span class="token number">2</span> -p <span class="token number">10000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 稍等一会儿（15 秒）测试结束后，回到目标服务器，查看 iperf 的报告：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span> ID<span class="token punctuation">]</span> Interval           Transfer     Bandwidth
<span class="token punctuation">..</span>.
<span class="token punctuation">[</span>SUM<span class="token punctuation">]</span>   <span class="token number">0.00</span>-15.04  sec  <span class="token number">0.00</span> Bytes  <span class="token number">0.00</span> bits/sec                  sender
<span class="token punctuation">[</span>SUM<span class="token punctuation">]</span>   <span class="token number">0.00</span>-15.04  sec  <span class="token number">1.51</span> GBytes   <span class="token number">860</span> Mbits/sec                  receiver<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 最后的 SUM 行就是测试的汇总结果，包括测试时间、数据传输量以及带宽等。按照发送和接收，这一部分又分为了 sender 和 receiver 两行。</p>
<p> 从测试结果你可以看到，这台机器 TCP 接收的带宽（吞吐量）为 860 Mb/s， 跟目标的 1Gb/s 相比，还是有些差距的。</p>
</li>
<li><p>HTTP 性能</p>
<p> 要测试 HTTP 的性能，也有大量的工具可以使用，比如 ab、webbench 等，都是常用的 HTTP 压力测试工具。其中，ab 是 Apache 自带的 HTTP 压测工具，主要测试 HTTP 服务的每秒请求数、请求延迟、吞吐量以及请求延迟的分布情况等。</p>
<p> 运行下面的命令，你就可以安装 ab 工具：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Ubuntu</span>
$ <span class="token function">apt-get</span> <span class="token function">install</span> -y apache2-utils
<span class="token comment"># CentOS</span>
$ yum <span class="token function">install</span> -y httpd-tools<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> 接下来，在目标机器上，使用 Docker 启动一个 Nginx 服务，然后用 ab 来测试它的性能。首先，在目标机器上运行下面的命令：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ docker run -p <span class="token number">80</span>:80 -itd nginx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> 而在另一台机器上，运行 ab 命令，测试 Nginx 的性能：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -c 表示并发请求数为 1000，-n 表示总的请求数为 10000</span>
$ ab -c <span class="token number">1000</span> -n <span class="token number">10000</span> http://192.168.0.30/
<span class="token punctuation">..</span>.
Server Software:        nginx/1.15.8
Server Hostname:        <span class="token number">192.168</span>.0.30
Server Port:            <span class="token number">80</span>

<span class="token punctuation">..</span>.

Requests per second:    <span class="token number">1078.54</span> <span class="token punctuation">[</span><span class="token comment">#/sec] (mean)</span>
Time per request:       <span class="token number">927.183</span> <span class="token punctuation">[</span>ms<span class="token punctuation">]</span> <span class="token punctuation">(</span>mean<span class="token punctuation">)</span>
Time per request:       <span class="token number">0.927</span> <span class="token punctuation">[</span>ms<span class="token punctuation">]</span> <span class="token punctuation">(</span>mean, across all concurrent requests<span class="token punctuation">)</span>
Transfer rate:          <span class="token number">890.00</span> <span class="token punctuation">[</span>Kbytes/sec<span class="token punctuation">]</span> received

Connection Times <span class="token punctuation">(</span>ms<span class="token punctuation">)</span>
              min  mean<span class="token punctuation">[</span>+/-sd<span class="token punctuation">]</span> median   max
Connect:        <span class="token number">0</span>   <span class="token number">27</span> <span class="token number">152.1</span>      <span class="token number">1</span>    <span class="token number">1038</span>
Processing:     <span class="token number">9</span>  <span class="token number">207</span> <span class="token number">843.0</span>     <span class="token number">22</span>    <span class="token number">9242</span>
Waiting:        <span class="token number">8</span>  <span class="token number">207</span> <span class="token number">843.0</span>     <span class="token number">22</span>    <span class="token number">9242</span>
Total:         <span class="token number">15</span>  <span class="token number">233</span> <span class="token number">857.7</span>     <span class="token number">23</span>    <span class="token number">9268</span>

Percentage of the requests served within a certain <span class="token function">time</span> <span class="token punctuation">(</span>ms<span class="token punctuation">)</span>
  <span class="token number">50</span>%     <span class="token number">23</span>
  <span class="token number">66</span>%     <span class="token number">24</span>
  <span class="token number">75</span>%     <span class="token number">24</span>
  <span class="token number">80</span>%     <span class="token number">26</span>
  <span class="token number">90</span>%    <span class="token number">274</span>
  <span class="token number">95</span>%   <span class="token number">1195</span>
  <span class="token number">98</span>%   <span class="token number">2335</span>
  <span class="token number">99</span>%   <span class="token number">4663</span>
 <span class="token number">100</span>%   <span class="token number">9268</span> <span class="token punctuation">(</span>longest request<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 可以看到，ab 的测试结果分为三个部分，分别是请求汇总、连接时间汇总还有请求延迟汇总。以上面的结果为例，我们具体来看。</p>
<p> 在请求汇总部分，你可以看到：</p>
<ul>
<li>Requests per second 为 1074；</li>
<li>每个请求的延迟（Time per request）分为两行，第一行的 927 ms 表示平均延迟，包括了线程运行的调度时间和网络请求响应时间，而下一行的 0.927ms ，则表示实际请求的响应时间；</li>
<li><p>Transfer rate 表示吞吐量（BPS）为 890 KB/s。</p>
<p>连接时间汇总部分，则是分别展示了建立连接、请求、等待以及汇总等的各类时间，包括最小、最大、平均以及中值处理时间。</p>
<p>最后的请求延迟汇总部分，则给出了不同时间段内处理请求的百分比，比如， 90% 的请求，都可以在 274ms 内完成。</p>
</li>
</ul>
</li>
<li><p>应用负载性能</p>
<p> 当你用 iperf 或者 ab 等测试工具，得到 TCP、HTTP 等的性能数据后，这些数据是否就能表示应用程序的实际性能呢？我想，你的答案应该是否定的。</p>
<p> 比如，你的应用程序基于 HTTP 协议，为最终用户提供一个 Web 服务。这时，使用 ab 工具，可以得到某个页面的访问性能，但这个结果跟用户的实际请求，很可能不一致。因为用户请求往往会附带着各种各种的负载（payload），而这些负载会影响 Web 应用程序内部的处理逻辑，从而影响最终性能。</p>
<p> 那么，为了得到应用程序的实际性能，就要求性能工具本身可以模拟用户的请求负载，而 iperf、ab 这类工具就无能为力了。幸运的是，我们还可以用 wrk、TCPCopy、Jmeter 或者 LoadRunner 等实现这个目标。</p>
<p> 以 <a target="_blank" rel="noopener" href="https://github.com/wg/wrk">wrk</a> 为例，它是一个 HTTP 性能测试工具，内置了 LuaJIT，方便你根据实际需求，生成所需的请求负载，或者自定义响应的处理方法。</p>
<p> wrk 工具本身不提供 yum 或 apt 的安装方法，需要通过源码编译来安装。比如，你可以运行下面的命令，来编译和安装 wrk：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ https://github.com/wg/wrk
$ <span class="token builtin class-name">cd</span> wrk
$ <span class="token function">apt-get</span> <span class="token function">install</span> build-essential -y
$ <span class="token function">make</span>
$ <span class="token function">sudo</span> <span class="token function">cp</span> wrk /usr/local/bin/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> wrk 的命令行参数比较简单。比如，我们可以用 wrk ，来重新测一下前面已经启动的 Nginx 的性能。</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># -c 表示并发连接数 1000，-t 表示线程数为 2</span>
$ wrk -c <span class="token number">1000</span> -t <span class="token number">2</span> http://192.168.0.30/
Running 10s <span class="token builtin class-name">test</span> @ http://192.168.0.30/
  <span class="token number">2</span> threads and <span class="token number">1000</span> connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    <span class="token number">65</span>.83ms  <span class="token number">174</span>.06ms   <span class="token number">1</span>.99s    <span class="token number">95.85</span>%
    Req/Sec     <span class="token number">4</span>.87k   <span class="token number">628.73</span>     <span class="token number">6</span>.78k    <span class="token number">69.00</span>%
  <span class="token number">96954</span> requests <span class="token keyword">in</span> <span class="token number">10</span>.06s, <span class="token number">78</span>.59MB <span class="token builtin class-name">read</span>
  Socket errors: connect <span class="token number">0</span>, <span class="token builtin class-name">read</span> <span class="token number">0</span>, <span class="token function">write</span> <span class="token number">0</span>, <span class="token function">timeout</span> <span class="token number">179</span>
Requests/sec:   <span class="token number">9641.31</span>
Transfer/sec:      <span class="token number">7</span>.82MB<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 这里使用 2 个线程、并发 1000 连接，重新测试了 Nginx 的性能。你可以看到，每秒请求数为 9641，吞吐量为 7.82MB，平均延迟为 65ms，比前面 ab 的测试结果要好很多。</p>
<p> 这也说明，性能工具本身的性能，对性能测试也是至关重要的。不合适的性能工具，并不能准确测出应用程序的最佳性能。</p>
<p> 当然，wrk 最大的优势，是其内置的 LuaJIT，可以用来实现复杂场景的性能测试。wrk 在调用 Lua 脚本时，可以将 HTTP 请求分为三个阶段，即 setup、running、done，如下图所示：</p>
<p> <img src="/images/《Linux性能优化实战》学习笔记/wrk脚本执行流程.png" alt="wrk脚本执行流程.png"></p>
<blockquote>
<p>图片来自<a target="_blank" rel="noopener" href="https://sq.163yun.com/blog/article/200008406328934400">网易云博客</a></p>
</blockquote>
<p> 比如，你可以在 setup 阶段，为请求设置认证参数（来自于 wrk 官方<a target="_blank" rel="noopener" href="https://github.com/wg/wrk/blob/master/scripts/auth.lua">示例</a>）：</p>
 <pre class="line-numbers language-lua" data-language="lua"><code class="language-lua"><span class="token comment">-- example script that demonstrates response handling and</span>
<span class="token comment">-- retrieving an authentication token to set on all future</span>
<span class="token comment">-- requests</span>

token <span class="token operator">=</span> <span class="token keyword">nil</span>
path  <span class="token operator">=</span> <span class="token string">"/authenticate"</span>

request <span class="token operator">=</span> <span class="token keyword">function</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
   <span class="token keyword">return</span> wrk<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"GET"</span><span class="token punctuation">,</span> path<span class="token punctuation">)</span>
<span class="token keyword">end</span>

response <span class="token operator">=</span> <span class="token keyword">function</span><span class="token punctuation">(</span>status<span class="token punctuation">,</span> headers<span class="token punctuation">,</span> body<span class="token punctuation">)</span>
   <span class="token keyword">if</span> <span class="token keyword">not</span> token <span class="token keyword">and</span> status <span class="token operator">==</span> <span class="token number">200</span> <span class="token keyword">then</span>
      token <span class="token operator">=</span> headers<span class="token punctuation">[</span><span class="token string">"X-Token"</span><span class="token punctuation">]</span>
      path  <span class="token operator">=</span> <span class="token string">"/resource"</span>
      wrk<span class="token punctuation">.</span>headers<span class="token punctuation">[</span><span class="token string">"X-Token"</span><span class="token punctuation">]</span> <span class="token operator">=</span> token
   <span class="token keyword">end</span>
<span class="token keyword">end</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p> 而在执行测试时，通过 -s 选项，执行脚本的路径：</p>
 <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ wrk -c <span class="token number">1000</span> -t <span class="token number">2</span> -s auth.lua http://192.168.0.30/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> wrk 需要你用 Lua 脚本，来构造请求负载。这对于大部分场景来说，可能已经足够了 。不过，它的缺点也正是，所有东西都需要代码来构造，并且工具本身不提供 GUI 环境。</p>
<p> 像 Jmeter 或者 LoadRunner（商业产品），则针对复杂场景提供了脚本录制、回放、GUI 等更丰富的功能，使用起来也更加方便。</p>
</li>
</ol>
<h4 id="36-4-小结"><a href="#36-4-小结" class="headerlink" title="36.4 小结"></a>36.4 小结</h4><p>性能评估是优化网络性能的前提，只有在你发现网络性能瓶颈时，才需要进行网络性能优化。根据 TCP/IP 协议栈的原理，不同协议层关注的性能重点不完全一样，也就对应不同的性能测试方法。比如，</p>
<ul>
<li>在应用层，你可以使用 wrk、Jmeter 等模拟用户的负载，测试应用程序的每秒请求数、处理延迟、错误数等；</li>
<li>而在传输层，则可以使用 iperf 等工具，测试 TCP 的吞吐情况；</li>
<li>再向下，你还可以用 Linux 内核自带的 pktgen ，测试服务器的 PPS。</li>
</ul>
<p>由于低层协议是高层协议的基础。所以，一般情况下，我们需要从上到下，对每个协议层进行性能测试，然后根据性能测试的结果，结合 Linux 网络协议栈的原理，找出导致性能瓶颈的根源，进而优化网络性能。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://kibazen.cn" rel="external nofollow noreferrer">Kiba Amor</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                    </span>
                <span class="reprint-info">
                    <a href="https://kibazen.cn/linux-xing-neng-you-hua-shi-zhan-xue-xi-bi-ji/">https://kibazen.cn/linux-xing-neng-you-hua-shi-zhan-xue-xi-bi-ji/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY-NC-ND 4.0</a>
                    许可协议。转载请注明来源
                    <a href="https://kibazen.cn" target="_blank">Kiba Amor</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/">
                                    <span class="chip bg-color">性能分析</span>
                                </a>
                            
                                <a href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">
                                    <span class="chip bg-color">极客时间</span>
                                </a>
                            
                                <a href="/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">
                                    <span class="chip bg-color">性能优化</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="qq,wechat,weibo,douban" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/linux-xing-neng-you-hua-shi-zhan-xue-xi-bi-ji/">
                    <div class="card-image">
                        
                        
                        <img src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/featureimages/7.jpg" class="responsive-img" alt="《Linux性能优化实战》学习笔记">
                        
                        <span class="card-title">《Linux性能优化实战》学习笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-11-04
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="post-category">
                                    学习笔记
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/">
                        <span class="chip bg-color">性能分析</span>
                    </a>
                    
                    <a href="/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">
                        <span class="chip bg-color">极客时间</span>
                    </a>
                    
                    <a href="/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">
                        <span class="chip bg-color">性能优化</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/linux-xing-neng-fen-xi/">
                    <div class="card-image">
                        
                        
                        <img src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/medias/featureimages/12.jpg" class="responsive-img" alt="Linux性能分析">
                        
                        <span class="card-title">Linux性能分析</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-11-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Linux/" class="post-category">
                                    Linux
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/">
                        <span class="chip bg-color">性能分析</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (true) {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: 木叶禅<br />'
            + '文章作者: Kiba Amor<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者木叶禅所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('3'),
            headingSelector: 'h2, h3, h4, h5'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4, h5').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2021</span>
            
            <span id="year">2019</span>
            <a href="/about" target="_blank">Kiba Amor</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">332.8k</span>&nbsp;字
            
            
            
            
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link ">
    <a href="https://github.com/kibaamor" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>









    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=562236616" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 562236616" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/kibaamor" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/kibaamor" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/materialize/materialize.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/aos/aos.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    

    

    

	
    

    

    

    
    <script src="https://cdn.jsdelivr.net/gh/kibaamor/kibaamor.github.io/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
